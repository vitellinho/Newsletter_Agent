[
  {
    "url": "https://www.cio.de/article/3987891/wie-lenovo-versucht-ki-pcs-fur-cios-relevant-zu-machen-2.html",
    "title": "Wie Lenovo versucht, KI-PCs für CIOs relevant zu machen",
    "published": "2025-05-20T08:55:25+00:00",
    "author": "",
    "text": "JHVEPhoto / Shutterstock Während PC-Anbieter weiterhin zahlreiche Varianten von KI-PCs auf den Markt bringen, haben sich Microsoft Copilot und Copilot+ PCs bislang als wenig relevant für Unternehmen erwiesen. Der Grund: Es fehlen schlicht überzeugende Use Cases, die die Anschaffung rechtfertigen. Lenovo möchte das nun mit seinem eigenen KI-Assistenten AI Now ändern. Lenovo AI Now ist ein kleines Sprachmodell ( Small Language Model – SLM ), das auf Llama 3.0 von Meta basiert und sich auf eine begrenzte Anzahl von Aufgaben fokussiert, etwa Dokumente zu organisieren und Devices zu managen. Die Verarbeitung erfolgt lokal auf dem Gerät, so dass sich Anwender keine Sorgen um die Weitergabe ihrer Daten an Dritte machen müssen. Außerdem können Aufgaben wie das Zusammenfassen von Dokumenten sogar im Flugzeug ohne Internetverbindung erledigt werden. Die Inspiration für AI Now kommt aus der eher bescheidenen Erfolgsgeschichte von Copilot als PC-Assistent. „Als Microsoft Copilot im Juni letzten Jahres eingeführt hat, waren die Versprechungen groß – und anschließend mussten sie einen Rückzieher machen“, erklärt Tom Butler, Executive Director of Commercial Portfolio and Product Management bei Lenovo. „Ich glaube, es wird noch einige Zeit dauern, bis wir eine breite Einführung sehen werden, insbesondere für Funktionen wie Recall, die Microsoft gezeigt und dann wieder zurückgezogen hat.“ „Für AI Now haben wir ein sehr fokussiertes lokales Modell verwendet. Wir wollen nicht in die Cloud. Wir demonstrieren eigentlich nur zwei Dinge. Das eine ist der Wissensassistent, der Ihre persönliche Wissensdatenbank nutzt; Sie legen bestimmte Dateien und Dokumente in dieser Wissensdatenbank ab. Dann können Sie Abfragen, Vergleiche und Zusammenfassungen durchführen und nur diese Dokumente bearbeiten“, so Butler. „Der andere Aspekt ist ein PC-Assistent, der auf Sprachbefehle reagieren kann, etwa, um die PC-Einstellungen zu ändern, beispielsweise mit dem Befehl ‘Dark Mode einschalten‘.“ Datenschutzprobleme im Zusammenhang mit Microsoft Recall, das als einer der wichtigsten Anwendungsfälle für Microsoft Copilot+ PCs beworben wurde, hätten die Positionierung von Microsoft beeinträchtigt, erklärt Udit Singh, Vice President der Everest Group. „Insofern ist der Business Case für Microsoft Copilot+ derzeit schwach. Allerdings ist das für Microsoft nicht ungewöhnlich. Das Unternehmen beginnt oft mit einem vagen Business Caseund baut das Angebot dann schrittweise aus.“ Auch andere Experten tun sich schwer damit, einen triftigen Grund für Unternehmen zu erkennen, in KI-PCs zu investieren. „Zum jetzigen Zeitpunkt bieten KI-PCs keinen ausreichenden Mehrwert, um große Investitionen zu rechtfertigen“, führt Eric Helmer, CTO bei Rimini Street, an. Das gelte insbesondere für Unternehmen, die bereits über KI-Fähigkeiten in Cloud- oder Rechenzentrumsumgebungen verfügten. Viele KI-Workloads könnten schon heute effektiv verwaltet werden, ohne dass auf jedem Mitarbeitergerät eine dedizierte Neural Processing Unit (NPU) erforderlich sei, so Helmer. Da viele Unternehmen bei den IT-Ausgaben ohnehin bereits zurückhaltend agierten, hätten Initiativen, die einen sofortigen und messbaren ROI bieten, weiterhin Priorität. Heute in KI-PCs zu investieren, könnte bedeuten, einen Aufpreis für Funktionen zu zahlen, die bald durch Standard-Hardware- und Software-Fortschritte verfügbar sein könnten, betont Helmer. „Anstatt auf von Anbietern vorangetriebene Zyklen zu reagieren, sollten CIOs prüfen, ob KI-PCs mit ihren umfassenderen IT-Modernisierungsstrategien übereinstimmen und ob die Investition angesichts der spezifischen Anforderungen ihres Unternehmens sinnvoll ist.“ Himani Reddy, PC-Research-Manager bei Canalys, sieht PC-Anbieter wie Lenovo mit der Entwicklung von On-Device-AI-Lösungen auf dem richtigen Weg. „Dieser Ansatz adressiert das wichtigste Anliegen von Unternehmen: den Datenschutz“, argumentiert Reddy. „Derzeit gibt es auf dem Markt nur begrenzte Optionen, und Verbraucher müssen sich entweder für die verfügbaren Lösungen entscheiden oder auf zukünftige Entwicklungen warten.“ Wenn Anbieter keine eigene KI für PCs entwickeln, wie beispielsweise Lenovo mit „AI Now“ und HP mit „AI Companion“, seien Copilot+ PCs trotz Datenschutzbedenken die erste Wahl, räumt sie ein. Obwohl Copilot mit Datenschutzbedenken behaftet sei, bleibe es eine sicherere Option als öffentlich verfügbare generative KI-Modelle, bei deren Einführung Unternehmen möglicherweise zögerten. Lenovo will sich allerdings nicht nur mit einem lokalen KI-Assistenten zufriedengeben, sondern daraus eine Plattform entwickeln, über die Unternehmen künftig zwischen verschiedenen LLMs (Large Language Models) und Agentic-AI-Angeboten von Anbietern wie OpenAI, Meta oder DeepSeek wählen können. „Bei unserer Vision als Unternehmen haben wir zwei Leitsätze. Der erste lautet: Smartere KI für alle – und das zu jedem Preisniveau“, so Butler. Das andere Ziel von Lenovo ist es laut Butler, den PC zum digitalen Zwilling des Benutzers zu machen. „Wenn jedes dieser Geräte unsere individuelle Stimme, unseren digitalen Zwilling repräsentiert, und ich AI Now sagen kann: ‚Plane meinen Flug in die USA‘, und das System erledigt das einfach – dann ist das eine enorme Zeitersparnis“, so der Lenovo-Manager. Um diesen digitalen Zwilling zu erschaffen, will Lenovo auf Agentic AI setzen. Mit dieser Technologie soll AI Now von einem bloßen persönlichen Assistenten zu einem digitalen Zwilling werden, der das Maximum aus der Hardware herausholt. Um weitere LLMs und AI Agents zu integrieren und diese Vision Wirklichkeit werden zu lassen, arbeitet Lenovo mit mehreren Softwareanbietern zusammen. (mb) JHVEPhoto / Shutterstock Während PC-Anbieter weiterhin zahlreiche Varianten von KI-PCs auf den Markt bringen, haben sich Microsoft Copilot und Copilot+ PCs bislang als wenig relevant für Unternehmen erwiesen. Der Grund: Es fehlen schlicht überzeugende Use Cases, die die Anschaffung rechtfertigen. Lenovo möchte das nun mit seinem eigenen KI-Assistenten AI Now ändern. Lenovo AI Now ist ein kleines Sprachmodell ( Small Language Model – SLM ), das auf Llama 3.0 von Meta basiert und sich auf eine begrenzte Anzahl von Aufgaben fokussiert, etwa Dokumente zu organisieren und Devices zu managen. Die Verarbeitung erfolgt lokal auf dem Gerät, so dass sich Anwender keine Sorgen um die Weitergabe ihrer Daten an Dritte machen müssen. Außerdem können Aufgaben wie das Zusammenfassen von Dokumenten sogar im Flugzeug ohne Internetverbindung erledigt werden. Die Inspiration für AI Now kommt aus der eher bescheidenen Erfolgsgeschichte von Copilot als PC-Assistent. „Als Microsoft Copilot im Juni letzten Jahres eingeführt hat, waren die Versprechungen groß – und anschließend mussten sie einen Rückzieher machen“, erklärt Tom Butler, Executive Director of Commercial Portfolio and Product Management bei Lenovo. „Ich glaube, es wird noch einige Zeit dauern, bis wir eine breite Einführung sehen werden, insbesondere für Funktionen wie Recall, die Microsoft gezeigt und dann wieder zurückgezogen hat.“ „Für AI Now haben wir ein sehr fokussiertes lokales Modell verwendet. Wir wollen nicht in die Cloud. Wir demonstrieren eigentlich nur zwei Dinge. Das eine ist der Wissensassistent, der Ihre persönliche Wissensdatenbank nutzt; Sie legen bestimmte Dateien und Dokumente in dieser Wissensdatenbank ab. Dann können Sie Abfragen, Vergleiche und Zusammenfassungen durchführen und nur diese Dokumente bearbeiten“, so Butler. „Der andere Aspekt ist ein PC-Assistent, der auf Sprachbefehle reagieren kann, etwa, um die PC-Einstellungen zu ändern, beispielsweise mit dem Befehl ‘Dark Mode einschalten‘.“ Datenschutzprobleme im Zusammenhang mit Microsoft Recall, das als einer der wichtigsten Anwendungsfälle für Microsoft Copilot+ PCs beworben wurde, hätten die Positionierung von Microsoft beeinträchtigt, erklärt Udit Singh, Vice President der Everest Group. „Insofern ist der Business Case für Microsoft Copilot+ derzeit schwach. Allerdings ist das für Microsoft nicht ungewöhnlich. Das Unternehmen beginnt oft mit einem vagen Business Caseund baut das Angebot dann schrittweise aus.“ Auch andere Experten tun sich schwer damit, einen triftigen Grund für Unternehmen zu erkennen, in KI-PCs zu investieren. „Zum jetzigen Zeitpunkt bieten KI-PCs keinen ausreichenden Mehrwert, um große Investitionen zu rechtfertigen“, führt Eric Helmer, CTO bei Rimini Street, an. Das gelte insbesondere für Unternehmen, die bereits über KI-Fähigkeiten in Cloud- oder Rechenzentrumsumgebungen verfügten. Viele KI-Workloads könnten schon heute effektiv verwaltet werden, ohne dass auf jedem Mitarbeitergerät eine dedizierte Neural Processing Unit (NPU) erforderlich sei, so Helmer. Da viele Unternehmen bei den IT-Ausgaben ohnehin bereits zurückhaltend agierten, hätten Initiativen, die einen sofortigen und messbaren ROI bieten, weiterhin Priorität. Heute in KI-PCs zu investieren, könnte bedeuten, einen Aufpreis für Funktionen zu zahlen, die bald durch Standard-Hardware- und Software-Fortschritte verfügbar sein könnten, betont Helmer. „Anstatt auf von Anbietern vorangetriebene Zyklen zu reagieren, sollten CIOs prüfen, ob KI-PCs mit ihren umfassenderen IT-Modernisierungsstrategien übereinstimmen und ob die Investition angesichts der spezifischen Anforderungen ihres Unternehmens sinnvoll ist.“ Himani Reddy, PC-Research-Manager bei Canalys, sieht PC-Anbieter wie Lenovo mit der Entwicklung von On-Device-AI-Lösungen auf dem richtigen Weg. „Dieser Ansatz adressiert das wichtigste Anliegen von Unternehmen: den Datenschutz“, argumentiert Reddy. „Derzeit gibt es auf dem Markt nur begrenzte Optionen, und Verbraucher müssen sich entweder für die verfügbaren Lösungen entscheiden oder auf zukünftige Entwicklungen warten.“ Wenn Anbieter keine eigene KI für PCs entwickeln, wie beispielsweise Lenovo mit „AI Now“ und HP mit „AI Companion“, seien Copilot+ PCs trotz Datenschutzbedenken die erste Wahl, räumt sie ein. Obwohl Copilot mit Datenschutzbedenken behaftet sei, bleibe es eine sicherere Option als öffentlich verfügbare generative KI-Modelle, bei deren Einführung Unternehmen möglicherweise zögerten. Lenovo will sich allerdings nicht nur mit einem lokalen KI-Assistenten zufriedengeben, sondern daraus eine Plattform entwickeln, über die Unternehmen künftig zwischen verschiedenen LLMs (Large Language Models) und Agentic-AI-Angeboten von Anbietern wie OpenAI, Meta oder DeepSeek wählen können. „Bei unserer Vision als Unternehmen haben wir zwei Leitsätze. Der erste lautet: Smartere KI für alle – und das zu jedem Preisniveau“, so Butler. Das andere Ziel von Lenovo ist es laut Butler, den PC zum digitalen Zwilling des Benutzers zu machen. „Wenn jedes dieser Geräte unsere individuelle Stimme, unseren digitalen Zwilling repräsentiert, und ich AI Now sagen kann: ‚Plane meinen Flug in die USA‘, und das System erledigt das einfach – dann ist das eine enorme Zeitersparnis“, so der Lenovo-Manager. Um diesen digitalen Zwilling zu erschaffen, will Lenovo auf Agentic AI setzen. Mit dieser Technologie soll AI Now von einem bloßen persönlichen Assistenten zu einem digitalen Zwilling werden, der das Maximum aus der Hardware herausholt. Um weitere LLMs und AI Agents zu integrieren und diese Vision Wirklichkeit werden zu lassen, arbeitet Lenovo mit mehreren Softwareanbietern zusammen. (mb)",
    "source": "cio",
    "crawled_at": "2025-05-27T08:10:52.776371+00:00"
  },
  {
    "url": "https://www.cio.de/article/3990204/nvidia-15-milliarden-dollar-ausfall-durch-us-exporthurden.html",
    "title": "Nvidia: 15 Milliarden Dollar Ausfall durch US-Exporthürden",
    "published": "2025-05-20T09:54:00+00:00",
    "author": "",
    "text": "NVIDIA Der Chipkonzern Nvidia schätzt das entgangene Geschäft durch die verschärften Ausfuhr-Beschränkungen der US-Regierung auf 15 Milliarden Dollar. Dieser Umsatzausfall komme zusätzlich zu den bereits gemeldeten Abschreibungen von 5,5 Milliarden Dollar für Lagerbestände hinzu, sagte Nvidia-Chef Jensen Huang im Podcast “Stratechery”. Er sagte zugleich, dass die Exporthürden China nicht davon abhalten würden, Künstliche Intelligenz zu entwickeln. Aber in dem Land entstehe als “ungewollte Folge” der US-Politik eine abgeschottete KI-Industrie, die später weltweit mit der amerikanischen konkurrieren werde, warnte Huang. Schon unter dem vorherigen Präsidenten Joe Biden schufen die USA Hürden für den Verkauf der modernsten Hochleistungschips nach China. Nvidia konnte deswegen an chinesische Unternehmen nur eine langsamere Version mit dem Namen H20 liefern. Doch selbst diese Chipsysteme fallen seit Mitte April angesichts der Handelspolitik von Bidens Nachfolger Donald Trump unter Exportbeschränkungen. Wer dachte, dass man China mit dem Stopp der H20-Chips die Fähigkeit nehmen würde, Künstliche Intelligenz zu entwickeln, sei “zutiefst uninformiert”, sagte Huang. Nvidias KI-Chips könnten technisch auch nicht noch weiter abgespeckt werden als die H20-Version. Chips von Nvidia sind zur Schlüsseltechnik für das boomende Geschäft mit Künstlicher Intelligenz geworden. Auch chinesische KI-Entwickler kommen an ihnen nicht vorbei. (dpa/rs) NVIDIA Der Chipkonzern Nvidia schätzt das entgangene Geschäft durch die verschärften Ausfuhr-Beschränkungen der US-Regierung auf 15 Milliarden Dollar. Dieser Umsatzausfall komme zusätzlich zu den bereits gemeldeten Abschreibungen von 5,5 Milliarden Dollar für Lagerbestände hinzu, sagte Nvidia-Chef Jensen Huang im Podcast “Stratechery”. Er sagte zugleich, dass die Exporthürden China nicht davon abhalten würden, Künstliche Intelligenz zu entwickeln. Aber in dem Land entstehe als “ungewollte Folge” der US-Politik eine abgeschottete KI-Industrie, die später weltweit mit der amerikanischen konkurrieren werde, warnte Huang. Schon unter dem vorherigen Präsidenten Joe Biden schufen die USA Hürden für den Verkauf der modernsten Hochleistungschips nach China. Nvidia konnte deswegen an chinesische Unternehmen nur eine langsamere Version mit dem Namen H20 liefern. Doch selbst diese Chipsysteme fallen seit Mitte April angesichts der Handelspolitik von Bidens Nachfolger Donald Trump unter Exportbeschränkungen. Wer dachte, dass man China mit dem Stopp der H20-Chips die Fähigkeit nehmen würde, Künstliche Intelligenz zu entwickeln, sei “zutiefst uninformiert”, sagte Huang. Nvidias KI-Chips könnten technisch auch nicht noch weiter abgespeckt werden als die H20-Version. Chips von Nvidia sind zur Schlüsseltechnik für das boomende Geschäft mit Künstlicher Intelligenz geworden. Auch chinesische KI-Entwickler kommen an ihnen nicht vorbei. (dpa/rs)",
    "source": "cio",
    "crawled_at": "2025-05-27T08:10:52.851220+00:00"
  },
  {
    "url": "https://www.cio.de/article/3982915/ki-aus-der-cloud-souveran-und-kosteneffizient-moglich.html",
    "title": "KI aus der Cloud: Souverän und kosteneffizient möglich",
    "published": "2025-05-20T10:13:00+00:00",
    "author": "",
    "text": "Die Nutzung von KI schreitet rasant voran. Laut einer IHK-Studie setzen mittlerweile über ein Drittel der deutschen Großunternehmen auf KI. Kleinere Unternehmen sind jedoch deutlich zurückhaltender, hier beträgt der Anteil erst zehn Prozent. Die Gründe dafür sind vielfältig. So verfügen kleinere Unternehmen nur über begrenzte finanzielle und personelle Ressourcen, sodass es ihnen schwerer fällt, auf die umfassenden Datenschutzanforderungen und rechtlichen Belange einzugehen sowie in komplexe und kostenintensive Technologien zu investieren. Einem Bericht von Deloitte zufolge sehen 30 Prozent der Befragten die regulatorischen Unsicherheiten als kritisch und 43 Prozent betrachten die gesetzlichen Vorgaben als die größte Hürde für den Einsatz von KI. Diese Zurückhaltung ist bedenklich, denn laut der oben erwähnten IHK-Untersuchung liegt Deutschland bei der KI-Nutzung im europäischen Vergleich nur auf Platz sieben; relativ weit abgeschlagen hinter dem Spitzenreiter Dänemark. Daraus ergeben sich drei wichtige Fragen: Shutterstock.com – Shutterstock AI Generator Was die erste Frage angeht, so ist die Antwort relativ leicht. Es gibt bei nahezu allen Cloud Providern leistungsstarke KI-Hosting-Lösungen. Für jeden Use Case lässt sich heute das jeweils passende KI-Modell einrichten und ohne großen Administrationsaufwand betreiben. Das ist zumeist deutlich kosteneffizienter und ressourcenschonender als eine In-House-KI – zumindest bei den KMUs. Aber auch für Großunternehmen kann eine cloud-basierte KI günstiger sein als der Betrieb im eigenen Rechenzentrum, weil beispielsweise stark schwankende Rechenkapazitäten benötigt werden. Schwieriger sind die Antworten zu den Fragen zwei und drei. Diese zielen auf die Rechtssicherheit und Datensouveränität in der Cloud ab. Gerade die aktuelle US-Politik wirft bei den deutschen Anwendern von US-Hyperscalern viele brisante Fragen auf. Bekanntermaßen erlaubt der US CLOUD Act den US-Behörden auf alle Daten zuzugreifen, die bei US-Anbietern gespeichert sind – und zwar völlig egal, wo sich die Daten befinden. Das davon betroffene Unternehmen muss nicht einmal über einen solchen Datenzugriff informiert werden. Das steht im krassen Widerspruch zu den strengen europäischen Datenschutzstandards und gefährdet sensible Informationen vor allem bei den besonders regulierten Branchen und im öffentlichen Sektor. Deutsche Cloud Provider sind hier eine echte Alternative. Sie erfüllen alle Anforderungen hinsichtlich des europäischen und deutschen Datenschutzes, verursachen oftmals keinen Vendor-Lock-in und bieten langfristige Planungssicherheit. Dass sie kleiner sind als ihre US-Konkurrenten, erweist sich oft als Vorteil. So schreibt das Beratungshaus ISG in einer aktuellen Marktstudie : „Mittelständische Anbieter von hybriden Cloud-Lösungen können aufgrund ihrer geringeren Gemeinkosten häufig wettbewerbsfähigere Preise anbieten“. Außerdem seien sie „agiler und können sich besser an veränderte Marktbedingungen anpassen“. Hinzu kommen Aspekte, die bei europäischen Anbietern eine hohe Priorität genießen, wie klimaneutrale Rechenzentren und energieeffiziente Hardware mit geringer Abwärme. Organisationen können solche Hoster beispielsweise an der ISO-50001-Zertifizierung erkennen. IONOS ist die souveräne Cloud für Unternehmen und Institutionen. Das Unternehmen bietet eine 100 % unabhängige, DSGVO-konforme und zukunftssichere Cloud-Infrastruktur – entwickelt und betrieben in Deutschland – für maximale Kontrolle, Sicherheit und digitale Souveränität. Mit seinem AI Model Hub hat IONOS die erste deutsche, multimodale KI-Plattform zur Nutzung der wichtigsten generativen Open-Source-KI-Modelle auf den Markt gebracht. Die Plattform wird auf der souveränen Cloud-Infrastruktur von IONOS in deutschen Rechenzentren gehostet und erlaubt die Einbettung von text- und bildgenerierenden Modellen per Standard API in jede individuelle Anwendung. „Unser Ziel ist es, künstliche Intelligenz zu demokratisieren und diese Technologie auch kleinen und mittelständischen Unternehmen einfach und schnell zur Verfügung zu stellen”, sagt Achim Weiß, CEO von IONOS. Die dabei verwendeten Daten verbleiben ausschließlich in Deutschland sowie beim Anwender. Sie werden zudem nicht genutzt, um KI-Modelle weiter zu trainieren. „Auf diese Weise können sich unsere Kunden auf die Integration von künstlicher Intelligenz in ihre spezifischen Anwendungen konzentrieren und müssen sich weder um die komplexe Infrastruktur dahinter noch um Datensicherheit und digitale Souveränität kümmern”, so Achim Weiß weiter. Außerdem weist er darauf hin, dass IONOS im AI Model Hub die besten Open-Source-KI-Modelle bereitstellt, die es auf dem Markt gibt. Das verhindert einen Vendor Lock-in, reduziert die Abhängigkeit von einzelnen Herstellern und sorgt für einfache Interoperabilität. Auch sonst überzeugt die IONOS Cloud: Sie ist klimaneutral, nutzt eine energieeffiziente Hardware mit geringer Abwärme und ist nach ISO 50001 zertifiziert. Die verfügbaren Open-Source-Modelle erlauben eine Vielzahl an Use Cases, wie die Zusammenfassung, Generierung, Klassifizierung und das Clustern von Texten und die Generierung von Bildern. Zudem lassen sich eigene anwendungs- und unternehmensspezifische Dokumente hochladen, die über Retrieval Augmented Generation (RAG) die Ergebnisse der Sprachmodelle verbessern. Das KI-Modell greift mit RAG auf diese Dokumente und Datenbanken zu und bietet so für spezielle Aufgaben gezielte Lösungen. Für den Upload unternehmensspezifischer Daten steht die Vektordatenbank ChromaDB ebenfalls in deutschen Rechenzentren zur Verfügung. IONOS Die Leistungsfähigkeit und Souveränität der IONOS Cloud überzeugt immer wieder sowohl Unternehmen als auch Behörden. So erteilte das Informationstechnikzentrum Bund (ITZBund) IONOS den Auftrag , eine maßgeschneiderte private Enterprise Cloud zu entwickeln, die in den hochsicheren Rechenzentren des ITZBund betrieben wird und die IT-Infrastruktur von 200 Bundesbehörden grundlegend modernisieren wird. Der Vertrag hat eine Laufzeit von fünf Jahren und ist ein wesentlicher Bestandteil der Cloud-First-Strategie des Bundes. IONOS konnte das ITZBund vor allem durch die hohen Sicherheitsstandards und die Garantie digitaler Souveränität überzeugen. Die neue Cloud-Lösung, die vollständig in Deutschland entwickelt wurde, steht für maximale Sicherheit und Zuverlässigkeit. Die Entscheidung des ITZBund zugunsten von IONOS zeigt auch, dass deutsche Cloud-Lösungen international konkurrenzfähig sind und höchsten Anforderungen an Sicherheit und Datenschutz gerecht werden. Leistung, Sicherheit, Compliance und digitale Souveränität sind bei KI essenziell. Die Skalierbarkeit und Flexibilität von Cloud-Lösungen ermöglichen es Organisationen jeder Größe, KI-Lösungen effizient zu nutzen. Der AI Model Hub von IONOS macht innovative KI-Tools leicht zugänglich und stellt eine schlüsselfertige Lösung dar. Er ermöglicht eine souveräne KI-Nutzung „End-to-End”, ohne sich um das aufwendige Management der Modellumgebung kümmern zu müssen. Darüber hinaus stehen für die effiziente Nutzung der Open-Source-KI-Modelle auch die bewährten Administrations-Tools der IONOS Cloud zur Verfügung. So lassen sich mithilfe von Load Balancing und Monitoring die KI-Modelle in jeder Produktionsumgebung optimal betreiben und bei Bedarf skalieren. Mehr Informationen rund um den AI Model Hub Die Nutzung von KI schreitet rasant voran. Laut einer IHK-Studie setzen mittlerweile über ein Drittel der deutschen Großunternehmen auf KI. Kleinere Unternehmen sind jedoch deutlich zurückhaltender, hier beträgt der Anteil erst zehn Prozent. Die Gründe dafür sind vielfältig. So verfügen kleinere Unternehmen nur über begrenzte finanzielle und personelle Ressourcen, sodass es ihnen schwerer fällt, auf die umfassenden Datenschutzanforderungen und rechtlichen Belange einzugehen sowie in komplexe und kostenintensive Technologien zu investieren. Einem Bericht von Deloitte zufolge sehen 30 Prozent der Befragten die regulatorischen Unsicherheiten als kritisch und 43 Prozent betrachten die gesetzlichen Vorgaben als die größte Hürde für den Einsatz von KI. Diese Zurückhaltung ist bedenklich, denn laut der oben erwähnten IHK-Untersuchung liegt Deutschland bei der KI-Nutzung im europäischen Vergleich nur auf Platz sieben; relativ weit abgeschlagen hinter dem Spitzenreiter Dänemark. Daraus ergeben sich drei wichtige Fragen: Shutterstock.com – Shutterstock AI Generator Was die erste Frage angeht, so ist die Antwort relativ leicht. Es gibt bei nahezu allen Cloud Providern leistungsstarke KI-Hosting-Lösungen. Für jeden Use Case lässt sich heute das jeweils passende KI-Modell einrichten und ohne großen Administrationsaufwand betreiben. Das ist zumeist deutlich kosteneffizienter und ressourcenschonender als eine In-House-KI – zumindest bei den KMUs. Aber auch für Großunternehmen kann eine cloud-basierte KI günstiger sein als der Betrieb im eigenen Rechenzentrum, weil beispielsweise stark schwankende Rechenkapazitäten benötigt werden. Schwieriger sind die Antworten zu den Fragen zwei und drei. Diese zielen auf die Rechtssicherheit und Datensouveränität in der Cloud ab. Gerade die aktuelle US-Politik wirft bei den deutschen Anwendern von US-Hyperscalern viele brisante Fragen auf. Bekanntermaßen erlaubt der US CLOUD Act den US-Behörden auf alle Daten zuzugreifen, die bei US-Anbietern gespeichert sind – und zwar völlig egal, wo sich die Daten befinden. Das davon betroffene Unternehmen muss nicht einmal über einen solchen Datenzugriff informiert werden. Das steht im krassen Widerspruch zu den strengen europäischen Datenschutzstandards und gefährdet sensible Informationen vor allem bei den besonders regulierten Branchen und im öffentlichen Sektor. Deutsche Cloud Provider sind hier eine echte Alternative. Sie erfüllen alle Anforderungen hinsichtlich des europäischen und deutschen Datenschutzes, verursachen oftmals keinen Vendor-Lock-in und bieten langfristige Planungssicherheit. Dass sie kleiner sind als ihre US-Konkurrenten, erweist sich oft als Vorteil. So schreibt das Beratungshaus ISG in einer aktuellen Marktstudie : „Mittelständische Anbieter von hybriden Cloud-Lösungen können aufgrund ihrer geringeren Gemeinkosten häufig wettbewerbsfähigere Preise anbieten“. Außerdem seien sie „agiler und können sich besser an veränderte Marktbedingungen anpassen“. Hinzu kommen Aspekte, die bei europäischen Anbietern eine hohe Priorität genießen, wie klimaneutrale Rechenzentren und energieeffiziente Hardware mit geringer Abwärme. Organisationen können solche Hoster beispielsweise an der ISO-50001-Zertifizierung erkennen. IONOS ist die souveräne Cloud für Unternehmen und Institutionen. Das Unternehmen bietet eine 100 % unabhängige, DSGVO-konforme und zukunftssichere Cloud-Infrastruktur – entwickelt und betrieben in Deutschland – für maximale Kontrolle, Sicherheit und digitale Souveränität. Mit seinem AI Model Hub hat IONOS die erste deutsche, multimodale KI-Plattform zur Nutzung der wichtigsten generativen Open-Source-KI-Modelle auf den Markt gebracht. Die Plattform wird auf der souveränen Cloud-Infrastruktur von IONOS in deutschen Rechenzentren gehostet und erlaubt die Einbettung von text- und bildgenerierenden Modellen per Standard API in jede individuelle Anwendung. „Unser Ziel ist es, künstliche Intelligenz zu demokratisieren und diese Technologie auch kleinen und mittelständischen Unternehmen einfach und schnell zur Verfügung zu stellen”, sagt Achim Weiß, CEO von IONOS. Die dabei verwendeten Daten verbleiben ausschließlich in Deutschland sowie beim Anwender. Sie werden zudem nicht genutzt, um KI-Modelle weiter zu trainieren. „Auf diese Weise können sich unsere Kunden auf die Integration von künstlicher Intelligenz in ihre spezifischen Anwendungen konzentrieren und müssen sich weder um die komplexe Infrastruktur dahinter noch um Datensicherheit und digitale Souveränität kümmern”, so Achim Weiß weiter. Außerdem weist er darauf hin, dass IONOS im AI Model Hub die besten Open-Source-KI-Modelle bereitstellt, die es auf dem Markt gibt. Das verhindert einen Vendor Lock-in, reduziert die Abhängigkeit von einzelnen Herstellern und sorgt für einfache Interoperabilität. Auch sonst überzeugt die IONOS Cloud: Sie ist klimaneutral, nutzt eine energieeffiziente Hardware mit geringer Abwärme und ist nach ISO 50001 zertifiziert. Die verfügbaren Open-Source-Modelle erlauben eine Vielzahl an Use Cases, wie die Zusammenfassung, Generierung, Klassifizierung und das Clustern von Texten und die Generierung von Bildern. Zudem lassen sich eigene anwendungs- und unternehmensspezifische Dokumente hochladen, die über Retrieval Augmented Generation (RAG) die Ergebnisse der Sprachmodelle verbessern. Das KI-Modell greift mit RAG auf diese Dokumente und Datenbanken zu und bietet so für spezielle Aufgaben gezielte Lösungen. Für den Upload unternehmensspezifischer Daten steht die Vektordatenbank ChromaDB ebenfalls in deutschen Rechenzentren zur Verfügung. IONOS Die Leistungsfähigkeit und Souveränität der IONOS Cloud überzeugt immer wieder sowohl Unternehmen als auch Behörden. So erteilte das Informationstechnikzentrum Bund (ITZBund) IONOS den Auftrag , eine maßgeschneiderte private Enterprise Cloud zu entwickeln, die in den hochsicheren Rechenzentren des ITZBund betrieben wird und die IT-Infrastruktur von 200 Bundesbehörden grundlegend modernisieren wird. Der Vertrag hat eine Laufzeit von fünf Jahren und ist ein wesentlicher Bestandteil der Cloud-First-Strategie des Bundes. IONOS konnte das ITZBund vor allem durch die hohen Sicherheitsstandards und die Garantie digitaler Souveränität überzeugen. Die neue Cloud-Lösung, die vollständig in Deutschland entwickelt wurde, steht für maximale Sicherheit und Zuverlässigkeit. Die Entscheidung des ITZBund zugunsten von IONOS zeigt auch, dass deutsche Cloud-Lösungen international konkurrenzfähig sind und höchsten Anforderungen an Sicherheit und Datenschutz gerecht werden. Leistung, Sicherheit, Compliance und digitale Souveränität sind bei KI essenziell. Die Skalierbarkeit und Flexibilität von Cloud-Lösungen ermöglichen es Organisationen jeder Größe, KI-Lösungen effizient zu nutzen. Der AI Model Hub von IONOS macht innovative KI-Tools leicht zugänglich und stellt eine schlüsselfertige Lösung dar. Er ermöglicht eine souveräne KI-Nutzung „End-to-End”, ohne sich um das aufwendige Management der Modellumgebung kümmern zu müssen. Darüber hinaus stehen für die effiziente Nutzung der Open-Source-KI-Modelle auch die bewährten Administrations-Tools der IONOS Cloud zur Verfügung. So lassen sich mithilfe von Load Balancing und Monitoring die KI-Modelle in jeder Produktionsumgebung optimal betreiben und bei Bedarf skalieren. Mehr Informationen rund um den AI Model Hub",
    "source": "cio",
    "crawled_at": "2025-05-27T08:10:53.074920+00:00"
  },
  {
    "url": "https://www.cio.de/article/3990406/weniger-unternehmen-beklagen-fachkraftemangel.html",
    "title": "Weniger Unternehmen beklagen Fachkräftemangel",
    "published": "2025-05-20T10:21:00+00:00",
    "author": "",
    "text": "Janet Worg – shutterstock.com In der Wirtschaftskrise leiden weniger Unternehmen in Deutschland unter Fachkräftemangel. Zu Beginn des zweiten Quartals klagten 27,2 Prozent der Unternehmen über Einschränkungen wegen fehlenden Personals, zeigt eine Erhebung der staatlichen Förderbank KfW. Im vierten Quartal 2024 waren es demnach noch knapp 32 Prozent, im Sommer 2022 sogar 49,7 Prozent. Damit habe sich der Fachkräftemangel deutlich abgeschwächt, liege aber weiter “auf historisch hohem Niveau”. Grund sei die schwache Konjunktur, erklärt die KfW. “Diese hat vor allem in der Industrie zu Absatz- und Auftragsrückgängen sowie zu Entlassungen oder Einstellungsstopps geführt.” Zudem belaste die große Unsicherheit über den Kurs der US-Regierung die Unternehmen. Für die KfW-Studie werden Konjunkturumfragen des Ifo-Instituts ausgewertet. Dafür werden einmal pro Quartal rund 9.000 Unternehmen befragt, darunter 7.500 Mittelständler. In der Industrie berichteten laut KfW im zweiten Quartal mit 17,9 Prozent weniger als halb so viele Unternehmen über Fachkräftemangel wie zum Höchststand von 44,5 Prozent im Jahr 2022. Die Zahl der betroffenen Unternehmen sei aber immer noch viel höher als im langfristigen Schnitt ab 1991, der bei 9,8 Prozent liege. Während Hersteller von Möbeln und Arzneien kaum von Fachkräftemangel betroffen seien, belaste er Produzenten von Metallerzeugnissen stark (26,5 Prozent). Besonders stark spüre die Dienstleistungsbranche den Fachkräftemangel. Fast ein Drittel (32,9 Prozent) der Unternehmen dort beklagten fehlendes Personal – nach 39,1 Prozent im vierten Quartal. Besonders stark betroffen seien Rechtsanwälte und Steuerberater (64,6 Prozent) sowie Betriebe im Straßen- und Schienenverkehr (über 40 Prozent). “Der Fachkräftemangel ist weiterhin eine Wachstumsbremse für einen beträchtlichen Teil der Unternehmen”, sagt KfW-Chefvolkswirt Dirk Schumacher. Der jüngste Rückgang sei nur eine Momentaufnahme. Der Fachkräftemangel werde sich in den kommenden Jahren verschärfen, sofern sich die Konjunktur erhole. Es sei dringend nötig gegenzusteuern – etwa über mehr Erwerbsbeteiligung, qualifizierte Zuwanderung und mehr Produktivität. (dpa/rs) Janet Worg – shutterstock.com In der Wirtschaftskrise leiden weniger Unternehmen in Deutschland unter Fachkräftemangel. Zu Beginn des zweiten Quartals klagten 27,2 Prozent der Unternehmen über Einschränkungen wegen fehlenden Personals, zeigt eine Erhebung der staatlichen Förderbank KfW. Im vierten Quartal 2024 waren es demnach noch knapp 32 Prozent, im Sommer 2022 sogar 49,7 Prozent. Damit habe sich der Fachkräftemangel deutlich abgeschwächt, liege aber weiter “auf historisch hohem Niveau”. Grund sei die schwache Konjunktur, erklärt die KfW. “Diese hat vor allem in der Industrie zu Absatz- und Auftragsrückgängen sowie zu Entlassungen oder Einstellungsstopps geführt.” Zudem belaste die große Unsicherheit über den Kurs der US-Regierung die Unternehmen. Für die KfW-Studie werden Konjunkturumfragen des Ifo-Instituts ausgewertet. Dafür werden einmal pro Quartal rund 9.000 Unternehmen befragt, darunter 7.500 Mittelständler. In der Industrie berichteten laut KfW im zweiten Quartal mit 17,9 Prozent weniger als halb so viele Unternehmen über Fachkräftemangel wie zum Höchststand von 44,5 Prozent im Jahr 2022. Die Zahl der betroffenen Unternehmen sei aber immer noch viel höher als im langfristigen Schnitt ab 1991, der bei 9,8 Prozent liege. Während Hersteller von Möbeln und Arzneien kaum von Fachkräftemangel betroffen seien, belaste er Produzenten von Metallerzeugnissen stark (26,5 Prozent). Besonders stark spüre die Dienstleistungsbranche den Fachkräftemangel. Fast ein Drittel (32,9 Prozent) der Unternehmen dort beklagten fehlendes Personal – nach 39,1 Prozent im vierten Quartal. Besonders stark betroffen seien Rechtsanwälte und Steuerberater (64,6 Prozent) sowie Betriebe im Straßen- und Schienenverkehr (über 40 Prozent). “Der Fachkräftemangel ist weiterhin eine Wachstumsbremse für einen beträchtlichen Teil der Unternehmen”, sagt KfW-Chefvolkswirt Dirk Schumacher. Der jüngste Rückgang sei nur eine Momentaufnahme. Der Fachkräftemangel werde sich in den kommenden Jahren verschärfen, sofern sich die Konjunktur erhole. Es sei dringend nötig gegenzusteuern – etwa über mehr Erwerbsbeteiligung, qualifizierte Zuwanderung und mehr Produktivität. (dpa/rs)",
    "source": "cio",
    "crawled_at": "2025-05-27T08:10:53.153857+00:00"
  },
  {
    "url": "https://www.cio.de/article/3990419/gericht-zweifelt-an-cookies-in-db-navigator-app.html",
    "title": "Gericht zweifelt an Cookies in DB Navigator App",
    "published": "2025-05-20T10:31:00+00:00",
    "author": "",
    "text": "Camilo Concha – shutterstock.com Im ersten Zivilprozess um die Datensicherheit der Bahn-App “DB Navigator” hat das Gericht Zweifel geäußert, ob einige der automatisch installierten Cookies rechtmäßig sind. Vor dem Landgericht Frankfurt ist aber noch keine Entscheidung gefallen. Stattdessen will die Kammer in einem erneuten Termin IT-Spezialisten der Bahn und einen unabhängigen Sachverständigen anhören. Für die Bahn-Kunden wird sich mit dem Zivilprozess (Az.: 2-25 O 209/22) erst einmal nichts ändern. Das Verfahren steckt in der ersten Instanz und ist von einem rechtskräftigen Urteil noch weit entfernt. Das Gericht rechnet auch damit, dass nach seinem Urteil Berufung beim Oberlandesgericht eingelegt wird. Der Kläger, ein Privatmann mit dem Künstlernamen “padeluun”, hofft auf weitreichenden Folgen. “Wenn wir diese Klage gewinnen, können ich und alle anderen Kunden auf der Welt den DB-Navigator verwenden, ohne dass Google, Adobe und andere Leute in den USA davon Kenntnis erhalten.” Im Falle eines Erfolgs müssten auch andere Anbieter ihre Apps ändern. Die Deutsche Bahn hat die Vorwürfe im Vorfeld des Prozesses zurückgewiesen: Die gesetzlichen Regelungen würden eingehalten und die Daten nur für eigene Zwecke und nicht für unzulässiges Marketing eingesetzt. Die Zusammenarbeit mit “sorgfältig ausgewählten und vertraglich gebundenen Dienstleistern” sei notwendig, um die Dienste des Navigators verlässlich anbieten zu können. Es sei keine namentliche Nachverfolgung einzelner Nutzer möglich. In der mündlichen Verhandlung ging es im Kern um drei nicht abwählbare Cookies, die bei der Installation des Navigators ohne Einwilligung der Kunden gesetzt werden und unterschiedliche Hilfsprogramme einbinden. Der Vorsitzende Richter Daniel Köhler sagte zum Verhandlungsschluss, man sehe Adobe Analytics “kritisch”, Optimizely “sehr kritisch” und Crashlytics “weniger kritisch”. Das letztgenannte Programm soll den Absturz der App vor allem zum Zeitpunkt der Fahrkartenkontrolle im Zug verhindern. Das Adobe-Programm benötigt die Bahn nach eigenen Angaben, um auch größeren gleichzeitigen Zugriffszahlen standhalten zu können. Optimizely werde zum Test verschiedener Software-Versionen eingesetzt, ob diese beispielsweise sämtliche Informationen zur Sicherung der Fahrgastrechte korrekt speichern. Zu einem noch nicht festgelegten Termin will das Gericht nun mit Hilfe von IT-Fachleuten und einem Gutachter einen Buchungsprozess starten und analysieren, welche Cookies auf dem Endgerät des Nutzers gesetzt werden. Laut Bahn liefert der Navigator vor und während der Fahrt verlässliche Informationen zu Verbindungen, Preisen und Angeboten sowie Umsteigezeiten, Fahrplananpassungen oder Reservierungsänderungen. Auch Tickets können über die Mobilanwendung gekauft werden, die fast 80 Millionen Mal heruntergeladen worden sei. Der Kläger ist Vorsitzender des Bielefelder Vereins Digitalcourage und bemängelt zusätzlich, dass Kunden des staatlichen Grundversorgers Deutsche Bahn am Navigator kaum vorbeikommen. Manche Services seien ohne die App nicht verfügbar. Er sagt: “Wer reisen will, wird zur App gezwungen – und wer die App nutzt, wird ausgespäht. Das ist Digitalzwang und Datenmissbrauch.” Die Kunden wollten Bahn fahren, ohne überwacht zu werden. (dpa/rs) Camilo Concha – shutterstock.com Im ersten Zivilprozess um die Datensicherheit der Bahn-App “DB Navigator” hat das Gericht Zweifel geäußert, ob einige der automatisch installierten Cookies rechtmäßig sind. Vor dem Landgericht Frankfurt ist aber noch keine Entscheidung gefallen. Stattdessen will die Kammer in einem erneuten Termin IT-Spezialisten der Bahn und einen unabhängigen Sachverständigen anhören. Für die Bahn-Kunden wird sich mit dem Zivilprozess (Az.: 2-25 O 209/22) erst einmal nichts ändern. Das Verfahren steckt in der ersten Instanz und ist von einem rechtskräftigen Urteil noch weit entfernt. Das Gericht rechnet auch damit, dass nach seinem Urteil Berufung beim Oberlandesgericht eingelegt wird. Der Kläger, ein Privatmann mit dem Künstlernamen “padeluun”, hofft auf weitreichenden Folgen. “Wenn wir diese Klage gewinnen, können ich und alle anderen Kunden auf der Welt den DB-Navigator verwenden, ohne dass Google, Adobe und andere Leute in den USA davon Kenntnis erhalten.” Im Falle eines Erfolgs müssten auch andere Anbieter ihre Apps ändern. Die Deutsche Bahn hat die Vorwürfe im Vorfeld des Prozesses zurückgewiesen: Die gesetzlichen Regelungen würden eingehalten und die Daten nur für eigene Zwecke und nicht für unzulässiges Marketing eingesetzt. Die Zusammenarbeit mit “sorgfältig ausgewählten und vertraglich gebundenen Dienstleistern” sei notwendig, um die Dienste des Navigators verlässlich anbieten zu können. Es sei keine namentliche Nachverfolgung einzelner Nutzer möglich. In der mündlichen Verhandlung ging es im Kern um drei nicht abwählbare Cookies, die bei der Installation des Navigators ohne Einwilligung der Kunden gesetzt werden und unterschiedliche Hilfsprogramme einbinden. Der Vorsitzende Richter Daniel Köhler sagte zum Verhandlungsschluss, man sehe Adobe Analytics “kritisch”, Optimizely “sehr kritisch” und Crashlytics “weniger kritisch”. Das letztgenannte Programm soll den Absturz der App vor allem zum Zeitpunkt der Fahrkartenkontrolle im Zug verhindern. Das Adobe-Programm benötigt die Bahn nach eigenen Angaben, um auch größeren gleichzeitigen Zugriffszahlen standhalten zu können. Optimizely werde zum Test verschiedener Software-Versionen eingesetzt, ob diese beispielsweise sämtliche Informationen zur Sicherung der Fahrgastrechte korrekt speichern. Zu einem noch nicht festgelegten Termin will das Gericht nun mit Hilfe von IT-Fachleuten und einem Gutachter einen Buchungsprozess starten und analysieren, welche Cookies auf dem Endgerät des Nutzers gesetzt werden. Laut Bahn liefert der Navigator vor und während der Fahrt verlässliche Informationen zu Verbindungen, Preisen und Angeboten sowie Umsteigezeiten, Fahrplananpassungen oder Reservierungsänderungen. Auch Tickets können über die Mobilanwendung gekauft werden, die fast 80 Millionen Mal heruntergeladen worden sei. Der Kläger ist Vorsitzender des Bielefelder Vereins Digitalcourage und bemängelt zusätzlich, dass Kunden des staatlichen Grundversorgers Deutsche Bahn am Navigator kaum vorbeikommen. Manche Services seien ohne die App nicht verfügbar. Er sagt: “Wer reisen will, wird zur App gezwungen – und wer die App nutzt, wird ausgespäht. Das ist Digitalzwang und Datenmissbrauch.” Die Kunden wollten Bahn fahren, ohne überwacht zu werden. (dpa/rs)",
    "source": "cio",
    "crawled_at": "2025-05-27T08:10:53.229692+00:00"
  },
  {
    "url": "https://www.cio.de/article/3990424/vodafone-verbucht-milliardenverlust.html",
    "title": "Vodafone verbucht Milliardenverlust",
    "published": "2025-05-20T10:37:00+00:00",
    "author": "",
    "text": "Ralf Liebhold – shutterstock.com Konzernweit fuhren die Briten im vergangenen Jahr einen Milliardenverlust ein. Unter dem Strich lag der Nettoverlust für das Geschäftsjahr 2024/25 (Ende März) bei 3,7 Milliarden Euro, wie der Konzern am Dienstag in Newbury mitteilte. Ein Jahr zuvor hatte Vodafone noch 1,5 Milliarden Euro Gewinn gemacht. Für die Geschäfte in Deutschland und Rumänien schrieb der Konzern 4,5 Milliarden Euro ab. Vodafone leidet weiterhin vor allem unter dem Wegfall des sogenannten Nebenkostenprivilegs für TV-Kabelverträge in Deutschland. Insgesamt stieg der Umsatz um zwei Prozent auf gut 37,4 Milliarden Euro. Dabei konnte Vodafone im Schlussquartal die wichtigen Serviceerlöse aus eigener Kraft mit 5,4 Prozent deutlicher steigern als von Experten erwartet – dabei sind Wechselkursschwankungen sowie Zu- und Verkäufe ausgeklammert. Das bereinigte Ergebnis vor Zinsen, Steuern und Abschreibungen sowie nach Leasingkosten (Ebitda AL) fiel im Gesamtjahr mit einem Rückgang um 0,8 Prozent auf 10,9 Milliarden Euro aber etwas schlechter als gedacht aus. Für das neue Jahr peilt Konzernchefin Margherita Della Valle einen operativen Gewinn von 11 bis 11,3 Milliarden Euro an. Das hatten Analysten in der Mitte der Spanne bisher auch so auf dem Zettel. Dass die Briten angesichts deutlicher Rückgänge bei Umsatz und Ergebnis in Deutschland überhaupt noch Zahlen in dieser Größenordnung vorweisen konnten, lag an den weiter wachsenden Geschäften in der Türkei, in Großbritannien und Afrika. In Deutschland war ab Juli 2024 die Regelung weggefallen, mit der Vermieter die Kosten für TV-Kabelverträge über die Nebenkosten im Mietvertrag abrechnen durften. Viele Kabelkunden von Vodafone können sich seitdem frei entscheiden, wie und bei welchem Anbieter sie TV-Verträge abschließen. Die Dividende für das vergangene Jahr soll inklusive der Schlussdividende von 2,25 Cent insgesamt 4,5 Cent je Aktie betragen – gerade einmal halb so viel wie ein Jahr zuvor. Wie bereits in Aussicht gestellt, will der Konzern nun für weitere zwei Milliarden Euro Aktien zurückkaufen, nachdem er das spanische und italienische Geschäft abgestoßen hat. (dpa/rs) Ralf Liebhold – shutterstock.com Konzernweit fuhren die Briten im vergangenen Jahr einen Milliardenverlust ein. Unter dem Strich lag der Nettoverlust für das Geschäftsjahr 2024/25 (Ende März) bei 3,7 Milliarden Euro, wie der Konzern am Dienstag in Newbury mitteilte. Ein Jahr zuvor hatte Vodafone noch 1,5 Milliarden Euro Gewinn gemacht. Für die Geschäfte in Deutschland und Rumänien schrieb der Konzern 4,5 Milliarden Euro ab. Vodafone leidet weiterhin vor allem unter dem Wegfall des sogenannten Nebenkostenprivilegs für TV-Kabelverträge in Deutschland. Insgesamt stieg der Umsatz um zwei Prozent auf gut 37,4 Milliarden Euro. Dabei konnte Vodafone im Schlussquartal die wichtigen Serviceerlöse aus eigener Kraft mit 5,4 Prozent deutlicher steigern als von Experten erwartet – dabei sind Wechselkursschwankungen sowie Zu- und Verkäufe ausgeklammert. Das bereinigte Ergebnis vor Zinsen, Steuern und Abschreibungen sowie nach Leasingkosten (Ebitda AL) fiel im Gesamtjahr mit einem Rückgang um 0,8 Prozent auf 10,9 Milliarden Euro aber etwas schlechter als gedacht aus. Für das neue Jahr peilt Konzernchefin Margherita Della Valle einen operativen Gewinn von 11 bis 11,3 Milliarden Euro an. Das hatten Analysten in der Mitte der Spanne bisher auch so auf dem Zettel. Dass die Briten angesichts deutlicher Rückgänge bei Umsatz und Ergebnis in Deutschland überhaupt noch Zahlen in dieser Größenordnung vorweisen konnten, lag an den weiter wachsenden Geschäften in der Türkei, in Großbritannien und Afrika. In Deutschland war ab Juli 2024 die Regelung weggefallen, mit der Vermieter die Kosten für TV-Kabelverträge über die Nebenkosten im Mietvertrag abrechnen durften. Viele Kabelkunden von Vodafone können sich seitdem frei entscheiden, wie und bei welchem Anbieter sie TV-Verträge abschließen. Die Dividende für das vergangene Jahr soll inklusive der Schlussdividende von 2,25 Cent insgesamt 4,5 Cent je Aktie betragen – gerade einmal halb so viel wie ein Jahr zuvor. Wie bereits in Aussicht gestellt, will der Konzern nun für weitere zwei Milliarden Euro Aktien zurückkaufen, nachdem er das spanische und italienische Geschäft abgestoßen hat. (dpa/rs)",
    "source": "cio",
    "crawled_at": "2025-05-27T08:10:53.377542+00:00"
  },
  {
    "url": "https://www.cio.de/article/3990431/eu-will-kinder-im-internet-besser-schuetzen.html",
    "title": "EU will Kinder im Internet besser schützen",
    "published": "2025-05-20T10:43:00+00:00",
    "author": "",
    "text": "Altersprüfung, private Konto-Einstellungen, kindgerechte Meldewege: Mit neuen Leitlinien will die EU-Kommission Online-Plattformen bei einem besseren Schutz von Minderjährigen unterstützen. Die Empfehlungen sollen helfen, bestehende Pflichten aus dem Gesetz über digitale Dienste (DSA) kindgerecht umzusetzen, etwa beim Datenschutz oder bei der Sicherheit. Die Leitlinien richten sich demnach an alle Online-Plattformen, die für Minderjährige zugänglich sind – einschließlich besonders großer Plattformen mit mehr als 45 Millionen Nutzerinnen und Nutzern pro Monat in der EU. Ausgenommen sind Kleinst- und Kleinunternehmen. “Die Sicherheit von Kindern im Netz hat für uns höchste Priorität”, sagte Kommissionsvizepräsidentin Henna Virkkunen. Zu den Richtlinien zählt neben der Überprüfung des Alters auch die Verbesserung der Nutzerempfehlungen, um das Risiko zu senken, dass Kinder schädlichen Inhalten ausgesetzt werden. Sie sollen Virkkunen zufolge dabei helfen, ein sichereres digitales Umfeld für junge Nutzerinnen und Nutzer zu schaffen. (dpa/rs) Altersprüfung, private Konto-Einstellungen, kindgerechte Meldewege: Mit neuen Leitlinien will die EU-Kommission Online-Plattformen bei einem besseren Schutz von Minderjährigen unterstützen. Die Empfehlungen sollen helfen, bestehende Pflichten aus dem Gesetz über digitale Dienste (DSA) kindgerecht umzusetzen, etwa beim Datenschutz oder bei der Sicherheit. Die Leitlinien richten sich demnach an alle Online-Plattformen, die für Minderjährige zugänglich sind – einschließlich besonders großer Plattformen mit mehr als 45 Millionen Nutzerinnen und Nutzern pro Monat in der EU. Ausgenommen sind Kleinst- und Kleinunternehmen. “Die Sicherheit von Kindern im Netz hat für uns höchste Priorität”, sagte Kommissionsvizepräsidentin Henna Virkkunen. Zu den Richtlinien zählt neben der Überprüfung des Alters auch die Verbesserung der Nutzerempfehlungen, um das Risiko zu senken, dass Kinder schädlichen Inhalten ausgesetzt werden. Sie sollen Virkkunen zufolge dabei helfen, ein sichereres digitales Umfeld für junge Nutzerinnen und Nutzer zu schaffen. (dpa/rs)",
    "source": "cio",
    "crawled_at": "2025-05-27T08:10:53.703330+00:00"
  },
  {
    "url": "https://www.cio.de/article/3990437/worum-es-bei-der-google-entwicklerkonferenz-geht.html",
    "title": "Worum es bei der Google-Entwicklerkonferenz geht",
    "published": "2025-05-20T10:52:00+00:00",
    "author": "",
    "text": "testing – shutterstock.com Google gibt am Dienstag ab 19 Uhr bei der jährlichen Entwicklerkonferenz einen Ausblick auf seine Zukunftspläne. Diesmal wird von der Google I/O ein klarer Fokus auf Künstliche Intelligenz erwartet. Der Internet-Konzern macht sein Geld nach wie vor hauptsächlich mit Werbung im Umfeld der Websuche. Dieses Geschäft greifen gerade KI-Wettbewerber an, die direkte Antworten statt Weblinks liefern wollen. Google experimentiert bereits mit KI-Zusammenfassungen, die Informationen bündeln. Mit ChatGPT und anderen KI-Chatbots konkurriert Google wiederum mit seiner eigenen Software Gemini. Von der Google I/O werden neue Funktionen für Gemini sowie andere KI-Werkzeuge des Konzerns erwartet. Neuigkeiten zum Mobil-Betriebssystem Android hatte Google diesmal bereits eine Woche vorher bekanntgegeben. (dpa/rs) testing – shutterstock.com Google gibt am Dienstag ab 19 Uhr bei der jährlichen Entwicklerkonferenz einen Ausblick auf seine Zukunftspläne. Diesmal wird von der Google I/O ein klarer Fokus auf Künstliche Intelligenz erwartet. Der Internet-Konzern macht sein Geld nach wie vor hauptsächlich mit Werbung im Umfeld der Websuche. Dieses Geschäft greifen gerade KI-Wettbewerber an, die direkte Antworten statt Weblinks liefern wollen. Google experimentiert bereits mit KI-Zusammenfassungen, die Informationen bündeln. Mit ChatGPT und anderen KI-Chatbots konkurriert Google wiederum mit seiner eigenen Software Gemini. Von der Google I/O werden neue Funktionen für Gemini sowie andere KI-Werkzeuge des Konzerns erwartet. Neuigkeiten zum Mobil-Betriebssystem Android hatte Google diesmal bereits eine Woche vorher bekanntgegeben. (dpa/rs)",
    "source": "cio",
    "crawled_at": "2025-05-27T08:10:53.783566+00:00"
  },
  {
    "url": "https://www.cio.de/article/3989256/wie-fielmann-von-einem-software-asset-management-profitiert.html",
    "title": "Fielmann schafft IT-Durchblick mit Software Asset Management",
    "published": "2025-05-20T13:26:01+00:00",
    "author": "",
    "text": "Die Fielmann Group erzielte im Geschäftsjahr 2024 einen Umsatz von rund 2,3 Milliarden Euro. Der Spezialist für Augenoptik hat mehr als 24.000 Beschäftigte und unterhält ein Netz mit über 1.200 Niederlassungen in Europa und den USA. Fielmann Group Fielmann hat sich seit der Gründung im Jahr 1977 zu einem der weltweit führenden Anbieter von Brillen und Services rund um die Augenoptik entwickelt. Heute ist das Unternehmen aus Hamburg, das weltweit rund 24.000 Mitarbeitende beschäftigt, in 13 europäischen Ländern und Nordamerika tätig. Abonnieren Sie unsere CIO-Newsletter für mehr spannende Praxisberichte, Best Practices und Hintergründe aus der CIO-Community. Eine solche verteilte Struktur bringt Herausforderungen mit sich, etwa bei der Verwaltung der Software und der dazugehörigen Lizenzen. Deshalb entschloss sich Fielmann, ein globales Software Asset Management (SAM) einzuführen. Mithilfe eines solchen Frameworks wollte das Unternehmen den Überblick über die vorhandenen Anwendungen verbessern, Stichwort Transparenz, und die Kostenkontrolle effizienter gestalten. Bei der Planung und Umsetzung des Vorhabens griff Fielmann auf die Unterstützung von Hisolutions zurück. Zu den Schwerpunkten des Berliner Technologieberatungsunternehmens zählen neben Cybersecurity und der Digitalisierung auch Projekte im Bereich SAM. Hisolutions hat mit “Slim” (Software Asset & Licence Management) einen Ansatz entwickelt, mit dem sich die Anforderungen von Unternehmen im Bereich SAM analysieren lassen. Darauf aufbauend entwickeln die Fachleute des Beratungshauses zusammen mit IT-Spezialistinnen und -Spezialisten von Anwenderunternehmen eine maßgeschneiderte Lösung. So auch bei der Fielmann Group: Das Team von Hisolutions führte Gespräche mit allen Stakeholdern und analysierte die vorhandene SAM-Organisation, inklusive der Softwarenutzung und den Verträgen. Im Rahmen dieser Evaluierung wurden Verbesserungspotenziale, Risiken und Handlungsempfehlungen identifiziert. Diese Ergebnisse bildeten den Grundstein für den Aufbau einer skalierbaren und zukunftssicheren SAM-Organisation. Zusammen mit den Fachabteilungen und Entscheidern bei Fielmann erarbeiteten die Expertinnen und Experten des Dienstleisters ein globales SAM-Framework. Es wurde auf die spezifischen Geschäftsanforderungen des Spezialisten für Augenoptik zugeschnitten. Außerdem legten die Fachleute klare Strukturen und Verantwortlichkeiten für das Management der Anwendungen und Lizenzen fest. Ein weiterer Punkt war die Implementierung einer Kostensteuerung. Alle Faktoren ermöglich es Fielmann, das SAM-Modell effizienter als bislang zu betreiben und die Wertschöpfung zu erhöhen. Ein Software-Asset-Management-Tool (SAM) zu implementieren, reicht nicht aus. Um unnötige Kosten und Risiken zu vermeiden, ist eine regelmßige Überwachung und Pflege solcher Werkzeuge erforderlich. Herstellerneutrale Spezialisten unterstützen Unternehmen bei der Auswahl, Implementierung und beim Betrieb des passenden SAM-Frameworks. Hisolutions AG Ein Vorteil, den herstellerunabhängige Beratungsunternehmen wie Hisolutions bei solchen Projekten bieten, ist die neutrale Beratung. Sie vermeidet ungeplante Mehrausgaben beim Einsatz von SAM-Tools, etwa weil ein Anwender nach einiger Zeit weitere Funktionen hinzubuchen muss oder die Lizenzabdeckung fehlerhaft. Hinzu kommt, dass ein herstellerunabhängiges Consulting dazu beitragen kann, unnötige Software-Kosten zu vermeiden. Das gilt beispielsweise für Unternehmensanwendungen von Oracle, SAP, IBM und Microsoft. Für Maik Riedl, Head of Software Asset Management & Enterprise Architecture bei Fielmann, ist das neue SAM-Framework ein Ausgangspunkt, um weitere Optimierungen vorzunehmen: “Unser Ziel ist es, flexibel auf neue Entwicklungen und Anforderungen zu reagieren. Durch regelmäßige Schulungen und die enge Zusammenarbeit mit unseren Fachabteilungen werden wir unser SAM-Modell weiter stärken.” Fielmann | Software Asset Management Branche : Handel Use Case : Zentrale Verwaltung von Software und Lizenzen Lösung : Implementierung von maßgeschneidertem SAM-Framework Partner : Hisolutions AG Die Fielmann Group erzielte im Geschäftsjahr 2024 einen Umsatz von rund 2,3 Milliarden Euro. Der Spezialist für Augenoptik hat mehr als 24.000 Beschäftigte und unterhält ein Netz mit über 1.200 Niederlassungen in Europa und den USA. Fielmann Group Fielmann hat sich seit der Gründung im Jahr 1977 zu einem der weltweit führenden Anbieter von Brillen und Services rund um die Augenoptik entwickelt. Heute ist das Unternehmen aus Hamburg, das weltweit rund 24.000 Mitarbeitende beschäftigt, in 13 europäischen Ländern und Nordamerika tätig. Abonnieren Sie unsere CIO-Newsletter für mehr spannende Praxisberichte, Best Practices und Hintergründe aus der CIO-Community. Eine solche verteilte Struktur bringt Herausforderungen mit sich, etwa bei der Verwaltung der Software und der dazugehörigen Lizenzen. Deshalb entschloss sich Fielmann, ein globales Software Asset Management (SAM) einzuführen. Mithilfe eines solchen Frameworks wollte das Unternehmen den Überblick über die vorhandenen Anwendungen verbessern, Stichwort Transparenz, und die Kostenkontrolle effizienter gestalten. Bei der Planung und Umsetzung des Vorhabens griff Fielmann auf die Unterstützung von Hisolutions zurück. Zu den Schwerpunkten des Berliner Technologieberatungsunternehmens zählen neben Cybersecurity und der Digitalisierung auch Projekte im Bereich SAM. Hisolutions hat mit “Slim” (Software Asset & Licence Management) einen Ansatz entwickelt, mit dem sich die Anforderungen von Unternehmen im Bereich SAM analysieren lassen. Darauf aufbauend entwickeln die Fachleute des Beratungshauses zusammen mit IT-Spezialistinnen und -Spezialisten von Anwenderunternehmen eine maßgeschneiderte Lösung. So auch bei der Fielmann Group: Das Team von Hisolutions führte Gespräche mit allen Stakeholdern und analysierte die vorhandene SAM-Organisation, inklusive der Softwarenutzung und den Verträgen. Im Rahmen dieser Evaluierung wurden Verbesserungspotenziale, Risiken und Handlungsempfehlungen identifiziert. Diese Ergebnisse bildeten den Grundstein für den Aufbau einer skalierbaren und zukunftssicheren SAM-Organisation. Zusammen mit den Fachabteilungen und Entscheidern bei Fielmann erarbeiteten die Expertinnen und Experten des Dienstleisters ein globales SAM-Framework. Es wurde auf die spezifischen Geschäftsanforderungen des Spezialisten für Augenoptik zugeschnitten. Außerdem legten die Fachleute klare Strukturen und Verantwortlichkeiten für das Management der Anwendungen und Lizenzen fest. Ein weiterer Punkt war die Implementierung einer Kostensteuerung. Alle Faktoren ermöglich es Fielmann, das SAM-Modell effizienter als bislang zu betreiben und die Wertschöpfung zu erhöhen. Ein Software-Asset-Management-Tool (SAM) zu implementieren, reicht nicht aus. Um unnötige Kosten und Risiken zu vermeiden, ist eine regelmßige Überwachung und Pflege solcher Werkzeuge erforderlich. Herstellerneutrale Spezialisten unterstützen Unternehmen bei der Auswahl, Implementierung und beim Betrieb des passenden SAM-Frameworks. Hisolutions AG Ein Vorteil, den herstellerunabhängige Beratungsunternehmen wie Hisolutions bei solchen Projekten bieten, ist die neutrale Beratung. Sie vermeidet ungeplante Mehrausgaben beim Einsatz von SAM-Tools, etwa weil ein Anwender nach einiger Zeit weitere Funktionen hinzubuchen muss oder die Lizenzabdeckung fehlerhaft. Hinzu kommt, dass ein herstellerunabhängiges Consulting dazu beitragen kann, unnötige Software-Kosten zu vermeiden. Das gilt beispielsweise für Unternehmensanwendungen von Oracle, SAP, IBM und Microsoft. Für Maik Riedl, Head of Software Asset Management & Enterprise Architecture bei Fielmann, ist das neue SAM-Framework ein Ausgangspunkt, um weitere Optimierungen vorzunehmen: “Unser Ziel ist es, flexibel auf neue Entwicklungen und Anforderungen zu reagieren. Durch regelmäßige Schulungen und die enge Zusammenarbeit mit unseren Fachabteilungen werden wir unser SAM-Modell weiter stärken.” Fielmann | Software Asset Management Branche : Handel Use Case : Zentrale Verwaltung von Software und Lizenzen Lösung : Implementierung von maßgeschneidertem SAM-Framework Partner : Hisolutions AG",
    "source": "cio",
    "crawled_at": "2025-05-27T08:10:53.870843+00:00"
  },
  {
    "url": "https://www.cio.de/article/3990442/dhl-group-setzt-bei-automatisierung-verstaerkt-auf-roboter.html",
    "title": "DHL Group setzt bei Automatisierung verstärkt auf Roboter",
    "published": "2025-05-21T03:30:00+00:00",
    "author": "",
    "text": "Der Roboter “Stretch” bei der DHL Group: Roboter sind ein Bestandteil der Strategie, mit der die DHL Group Prozesse in der Logistik automatisieren und digitalisieren möchte. DHL Group Bereits seit 2018 arbeiten die DHL Group und Boston Dynamics zusammen. Die Sparte DHL Supply Chain nutzt Systeme des amerikanischen Roboterherstellers, um ihre Logistikprozesse zu automatisieren. So kommt der Roboter “Stretch” beim automatisierten Entladen von Containerbrücken zum Einsatz. Er nimmt Kartons auf und platziert sie am gewünschten Ort, etwa in einem Fahrzeug. Die Mehrheit der Anteile an Boston Dynamics hat 2024 der koranische Automobilhersteller Hyundai Motors übernommen. Nun hat die DHL Group die Kooperation mit dem Robotik-Spezialisten erweitert. In einer Absichtserklärung (Memorandum of Understanding) legen beide Unternehmen fest, dass DHL weitere 1.000 Roboter von dem Hersteller bezieht. Außerdem prüft die DHL Group, wie sie zusammen mit Boston Dynamics Robotersysteme weiterentwickeln und in anderen Geschäftsbereichen nutzen kann. Abonnieren Sie unsere CIO-Newsletter für mehr spannende Best Practices, Praxisberichte und Hintergründe aus der CIO-Community. Ein Beispiel ist das Kommissionieren von Kartons – die arbeitsintensivste Tätigkeit innerhalb von Supply Chain von DHL. Stretch kann bis zu 700 Kartons pro Stunde entladen. Diese Tätigkeit ist für die Beschäftigten oft mit einer hohen körperlichen Belastung verbunden, zumal in Lkw-Anhängern im Sommer hohe, im Winter dagegen oft niedrige Temperaturen herrschen. Ein Roboter wie Stretch entlastet daher die Mitarbeiterinnen und Mitarbeiter von DHL. “Mit unserer Agenda zur schnelleren Digitalisierung setzen wir darauf, die Wirkung von Robotik und Automatisierung in all unseren Betrieben und Geschäftsbereichen zu maximieren”, sagt Sally Miller, Global CIO von DHL Supply Chain. “In der nun definierten Zusammenarbeit findet ein grundlegendes Umdenken statt, das unsere Arbeitsweise neu organisiert und den Service für unsere Kunden gleichzeitig verbessert.” Sally Miller ist Global CIO von DHL Supply Chain. DHL Group Ein Ziel ist laut Miller, widerstandsfähigere, reaktionsschnellere und intelligentere Lösungen zu erarbeiten, die auf die individuellen Herausforderungen von DHL abgestimmt sind. “Durch die erweiterte Partnerschaft mit Boston Dynamics wird DHL daher eine aktivere Rolle in der Gestaltung und Steuerung bei der Entwicklung von Robotern übernehmen”, so die Managerin. In den letzten drei Jahren hat die DHL Group über eine Milliarde Euro in die Automatisierung der Kontraktlogistik-Sparte investiert. Weltweit setzt das Unternehmen derzeit über 7.500 Roboter, mehr als 200.000 Handheld-Geräte und an die 800.000 IoT-Sensoren ein. In Zusammenarbeit mit Boston Dynamics hat der Logistik-Spezialist bereits integrierte Automatisierungssysteme entwickelt, die auch Förderbänder und Palettiersysteme mit einschließt. Laut DHL sind mittlerweile 90 Prozent aller Lager des Unternehmens mit mindestens einem Automatisierungs- oder Digitalisierungssystem ausgestattet. Während Stretch darauf spezialisiert ist, schwere Gegenstände zu bewegen, lassen sich humanoide Roboter vielseitiger einsetzen. BMW testet beispielsweise in seinem Werk Spartanburg (USA) das System “Figure 02” des US-Hersteller Figure. Der Roboter ist in der Lage, Blechteile in Produktionsanlagen einzulegen – eine Aufgabe, die im wahrsten Sinne des Wortes “Fingerspitzengefühl” erfordert, also taktile Fähigkeiten. Figure 02 ist mit einem KI-Modell ausgestattet, das es dem Roboter erlaubt, sich mit Menschen zu verständigen autonom Aufgaben zu erfüllen und aus Fehlern zu lernen. Die BMW Group führt in ihrem Automobilwerk in Spartanburg (USA) Tests mit dem humanoiden Roboter Figure 02 des amerikanischen Anbieters Figure durch. Ein Einsatzfeld ist die Karosseriefertigung. BMW Group Auch Tesla hat mit Optimus einem humanoiden Roboter entwickelt. Mercedes-Benz wiederum führt Feldversuche mit dem System Apollo der amerikanischen Firma Apptronik durch. Auch Boston Dynamics ist im Bereich humanoide Roboter aktiv – mit Atlas. Die zweite Generation des Systems ist mit elektrischen statt hydraulischen Komponenten ausgestattet. Atlas diente bislang dazu, die Entwicklung humanoider Systeme voranzutreiben. Allerdings plant Hyundai, im Lauf der kommenden Jahre mehrere Tausend der Roboter zu kaufen und in seinen Werken einzusetzen. DHL Group | Roboter in Logistik Branche : Transport Use Case : Automatisierung von Prozessen mithilfe von Robotern Lösung : Einsatz und Weiterentwicklung von Robotern von Boston Dynamics Partner : Boston Dynamics Der Roboter “Stretch” bei der DHL Group: Roboter sind ein Bestandteil der Strategie, mit der die DHL Group Prozesse in der Logistik automatisieren und digitalisieren möchte. DHL Group Bereits seit 2018 arbeiten die DHL Group und Boston Dynamics zusammen. Die Sparte DHL Supply Chain nutzt Systeme des amerikanischen Roboterherstellers, um ihre Logistikprozesse zu automatisieren. So kommt der Roboter “Stretch” beim automatisierten Entladen von Containerbrücken zum Einsatz. Er nimmt Kartons auf und platziert sie am gewünschten Ort, etwa in einem Fahrzeug. Die Mehrheit der Anteile an Boston Dynamics hat 2024 der koranische Automobilhersteller Hyundai Motors übernommen. Nun hat die DHL Group die Kooperation mit dem Robotik-Spezialisten erweitert. In einer Absichtserklärung (Memorandum of Understanding) legen beide Unternehmen fest, dass DHL weitere 1.000 Roboter von dem Hersteller bezieht. Außerdem prüft die DHL Group, wie sie zusammen mit Boston Dynamics Robotersysteme weiterentwickeln und in anderen Geschäftsbereichen nutzen kann. Abonnieren Sie unsere CIO-Newsletter für mehr spannende Best Practices, Praxisberichte und Hintergründe aus der CIO-Community. Ein Beispiel ist das Kommissionieren von Kartons – die arbeitsintensivste Tätigkeit innerhalb von Supply Chain von DHL. Stretch kann bis zu 700 Kartons pro Stunde entladen. Diese Tätigkeit ist für die Beschäftigten oft mit einer hohen körperlichen Belastung verbunden, zumal in Lkw-Anhängern im Sommer hohe, im Winter dagegen oft niedrige Temperaturen herrschen. Ein Roboter wie Stretch entlastet daher die Mitarbeiterinnen und Mitarbeiter von DHL. “Mit unserer Agenda zur schnelleren Digitalisierung setzen wir darauf, die Wirkung von Robotik und Automatisierung in all unseren Betrieben und Geschäftsbereichen zu maximieren”, sagt Sally Miller, Global CIO von DHL Supply Chain. “In der nun definierten Zusammenarbeit findet ein grundlegendes Umdenken statt, das unsere Arbeitsweise neu organisiert und den Service für unsere Kunden gleichzeitig verbessert.” Sally Miller ist Global CIO von DHL Supply Chain. DHL Group Ein Ziel ist laut Miller, widerstandsfähigere, reaktionsschnellere und intelligentere Lösungen zu erarbeiten, die auf die individuellen Herausforderungen von DHL abgestimmt sind. “Durch die erweiterte Partnerschaft mit Boston Dynamics wird DHL daher eine aktivere Rolle in der Gestaltung und Steuerung bei der Entwicklung von Robotern übernehmen”, so die Managerin. In den letzten drei Jahren hat die DHL Group über eine Milliarde Euro in die Automatisierung der Kontraktlogistik-Sparte investiert. Weltweit setzt das Unternehmen derzeit über 7.500 Roboter, mehr als 200.000 Handheld-Geräte und an die 800.000 IoT-Sensoren ein. In Zusammenarbeit mit Boston Dynamics hat der Logistik-Spezialist bereits integrierte Automatisierungssysteme entwickelt, die auch Förderbänder und Palettiersysteme mit einschließt. Laut DHL sind mittlerweile 90 Prozent aller Lager des Unternehmens mit mindestens einem Automatisierungs- oder Digitalisierungssystem ausgestattet. Während Stretch darauf spezialisiert ist, schwere Gegenstände zu bewegen, lassen sich humanoide Roboter vielseitiger einsetzen. BMW testet beispielsweise in seinem Werk Spartanburg (USA) das System “Figure 02” des US-Hersteller Figure. Der Roboter ist in der Lage, Blechteile in Produktionsanlagen einzulegen – eine Aufgabe, die im wahrsten Sinne des Wortes “Fingerspitzengefühl” erfordert, also taktile Fähigkeiten. Figure 02 ist mit einem KI-Modell ausgestattet, das es dem Roboter erlaubt, sich mit Menschen zu verständigen autonom Aufgaben zu erfüllen und aus Fehlern zu lernen. Die BMW Group führt in ihrem Automobilwerk in Spartanburg (USA) Tests mit dem humanoiden Roboter Figure 02 des amerikanischen Anbieters Figure durch. Ein Einsatzfeld ist die Karosseriefertigung. BMW Group Auch Tesla hat mit Optimus einem humanoiden Roboter entwickelt. Mercedes-Benz wiederum führt Feldversuche mit dem System Apollo der amerikanischen Firma Apptronik durch. Auch Boston Dynamics ist im Bereich humanoide Roboter aktiv – mit Atlas. Die zweite Generation des Systems ist mit elektrischen statt hydraulischen Komponenten ausgestattet. Atlas diente bislang dazu, die Entwicklung humanoider Systeme voranzutreiben. Allerdings plant Hyundai, im Lauf der kommenden Jahre mehrere Tausend der Roboter zu kaufen und in seinen Werken einzusetzen. DHL Group | Roboter in Logistik Branche : Transport Use Case : Automatisierung von Prozessen mithilfe von Robotern Lösung : Einsatz und Weiterentwicklung von Robotern von Boston Dynamics Partner : Boston Dynamics",
    "source": "cio",
    "crawled_at": "2025-05-27T08:10:54.099364+00:00"
  },
  {
    "url": "https://www.cio.de/article/3690411/was-staerkt-die-resilienz.html",
    "title": "Was stärkt die Resilienz?",
    "published": "2025-05-21T04:13:45+00:00",
    "author": "",
    "text": "Ein Leuchtturm im Meer trotzt den Wellen: Resiliente Menschen reagieren unempfindlicher auf psychische Belastungen wie Stress und Frust und handeln flexibler in schwierigen und sich ändernden Situationen. Foto: Jorge Felix Costa – shutterstock.com Resiliente Menschen gehen leichter mit Krisen um und finden schneller wieder zu einem stabilen psychischen Zustand zurück. Mehr noch: Sie bleiben in Situationen stabil, die nicht-resiliente Menschen aus der Bahn werfen würden. Resilienz wird zwar in der Kindheit in uns angelegt, ist aber auch in späteren Jahren noch trainierbar. Wer dies richtig angeht, kommt in Berufs- und Privatleben mit Problemen und Belastungen besser klar. Dieser Artikel zeigt Ihnen, was Sie dafür tun können. Der Begriff Resilienz kommt eigentlich aus der Werkstoffphysik und bedeutet Spannkraft, Elastizität, Strapazierfähigkeit. Die Resilienz eines Materials bemisst, ob und wie dieses nach Verformung wieder in die Ausgangsform zurückgeht. Die Resilienz bei Menschen kann als psychische Widerstandsfähigkeit beschrieben werden. Sie ist so etwas wie unser “seelisches Immunsystem”. Resiliente Menschen reagieren unempfindlicher auf psychische Belastungen wie Stress und Frust und handeln flexibler in schwierigen und sich ändernden Situationen. Resiliente Menschen sind aber keine Daueroptimisten! Eine Krise belastet auch sie in sehr hohem Maße. Aber sie stehen schneller wieder auf und verlassen schneller als andere die Opferrolle. Vorreiterin der Resilienzforschung ist die amerikanische Entwicklungsforscherin Emmy Werner , die seit den 1950er-Jahren die Entwicklung von 210 Jungen und Mädchen auf der hawaiianischen Insel Kauai über 40 Jahre beobachtete und dokumentierte. Zwei Drittel der Kinder entwickelten sich den schlechten Umständen (alkoholabhängige Eltern, Vernachlässigung bis hin zu Misshandlungen) entsprechend, aber das letzte Drittel führte trotz düsterer Prognosen ein zufriedenes Leben. Bei ihnen zeigte sich das, was wir heute Resilienz nennen. “Der allergrößte Schutz im Leben ist Bindung”, sagt Friedrich Lösel , emeritierter Professor für Psychologie und Kriminologie in Christina Berndts Buch “Resilienz”. So trägt beispielsweise die Bindung zur Mutter stark zur Resilienz bei. Aber auch andere Bezugspersonen wie Trainer, Mentoren, Onkel oder Väter/Mütter von Freunden können diese bindungsfördernde Rolle einnehmen. Auch unsere genetische Disposition entscheidet über unsere Resilienz. So hängt es beispielsweise von unseren Genen ab, wie gut das “Glückshormon” Serotonin transportiert wird und wie viel dieser Substanz im Gehirn überhaupt verfügbar ist. Resilienz lässt sich gleichwohl trainieren und erlernen. Sie gründet auf feingliedrigen Verschaltungen von Nervenzellen im Gehirn, den neuronalen Netzen. Und keine andere Spezies kommt mit einem derart formbaren Gehirn zur Welt wie wir. Während also der Einfluss unserer Gene unveränderbar ist und sich mit dem Umwelteinfluss die Waage hält, sind sowohl Umwelt als auch Training durch uns selbst mitbestimm- und gestaltbar. Und durch Training können wir fehlende genetisch veranlagte Resilienz erlernen. Einflussfaktoren, durch die Resilienz geprägt werden. Foto: Oliver Janzen Allgemein spricht man von sieben Säulen oder Faktoren, auf die sich Resilienz stützt. Die ersten drei davon betreffen unsere Haltung im Umgang mit Krisen und Rückschlägen: Akzeptanz Optimismus Lösungsorientierung Die vier weiteren Faktoren beschreiben Handlungsaspekte: Opferrolle verlassen Verantwortung übernehmen Netzwerkorientierung Zukunftsorientierung Die sieben Resilienz-Faktoren. Foto: Oliver Janzen Aber, was genau bedeuten diese sieben Punkte? Nehmen wir als beispielhafte Krise die Corona-Pandemie und den ersten Lockdown im März/April 2020. Akzeptanz: “Es ist eine Pandemie. Sie ist da.” Es geht darum, dies anzunehmen und zu verstehen, dass es jetzt neue Regeln gibt. Zu versuchen, alle “Wenn das jetzt nicht da wäre, könnte ich aber”-Gedanken von vornherein wegzulassen. Optimismus: Der Kölner sagt: “Et hätt noch immer jut jejange.” Und wenn wir unser Leben anschauen, gibt es viele Gründe, optimistisch zu sein. Auch weil Optimisten im Schnitt mindestens so lang leben wie Pessimisten, und dabei auch noch besser! Lösungsorientierung: Rückschläge sorgen dafür, dass unser Ziel bzw. unser Zielzustand, wie beispielsweise das Glücklichsein, in die Ferne rückt – ein Problem, das wir gern bejammern. Lösungsorientiert sein heißt hier, nach vorne zu schauen und die Lösung in den Blick zu nehmen. Die Opferrolle verlassen: Sich bewusst machen, dass niemand Corona erschaffen hat, um uns persönlich zu ärgern. Die Opferrolle verlassen heißt hier, die Steine als Teil unseres Lebens anzuerkennen, einen Plan zu machen und über die Steine zu klettern oder darum herum zu laufen. Verantwortung übernehmen: Wer sich vornimmt, über die Steine zu klettern, übernimmt bereits Verantwortung – für sich selbst! Schuldzuweisungen und Selbstmitleid (“Ich kann doch auch nichts dafür, dass alles so ist, wie es ist!”) bringen niemanden weiter. Netzwerkorientierung: Bindung ist die wichtigste Voraussetzung für die Ausprägung von Resilienz. Und sich mit anderen zu vernetzen, bedeutet Bindungen aufzubauen und zu erkennen: Ich bin nicht allein! Plus: Man bekommt selbst auch Hilfe, wenn man diese braucht. Zukunftsorientierung: Es hilft, nach vorne schauen, statt zurückzublicken. Ein Motto wie “Gestärkt aus der Krise” beschreibt einen erreichten Zielzustand zu einem Zeitpunkt in der Zukunft, an dem die Krise bereits überwunden ist. Um die eigene Resilienz so aufzubauen, dass eine Krise eher als Herausforderung gesehen wird, bieten sich folgende Methoden oder Denkansätze an: Meditation: Meditation kann glücklich machen und fördert die Ausgeglichenheit. Schon zwanzig Minuten täglich genügen, um diesen Effekt am eigenen Leib zu erfahren. Unser Verstand will uns ständig vor Gefahren warnen. Deshalb drehen sich unsere Gedanken auch oft um Probleme; leider meistens, ohne sie zu lösen. Meditation befreit uns zumindest vorübergehend von diesen Gedanken. Reflexion: Durch die Reflexion bisheriger Krisen lernen wir, welche Herausforderungen wir bereits bewältigt haben, wie wir sie bewältigt haben – und vor allem, dass wir es können: “Yes, we can!” Bewusstheit: Wenn wir uns gezielt das vor Augen führen, was uns täglich beschäftigt, welche Gedanken wir dazu haben, machen wir sie uns bewusst. Ein sehr gutes Instrument dafür ist das Tagebuch, in dem wir all diese Dinge aufschreiben. Dadurch nehmen wir eine andere Perspektive ein und merken, wo wir eigentlich stehen. Empathie: Empathie stärkt die Netzwerkbildung – eine Säule der Resilienz: Nur wenn wir die Gefühle unseres Gegenübers erkennen und beachten, können wir positive Beziehungen aufbauen. Dankbarkeit: Dankbarkeit wieder neu zu erlernen, ist einer der größten Hebel für Resilienz. Dankbar sein macht uns glücklich, macht uns bewusst, worüber wir uns freuen können und dass wir nicht alles als selbstverständlich hinnehmen sollten. Zielsetzung: “Ein Ziel ist ein Traum mit einem Abgabetermin.” Gesetzte Ziele geben uns eine Richtung für unser Denken und Handeln. Wir machen uns klar, was wir wollen, und schöpfen daraus die Energie, unsere Handlungen auf unsere Ziele auszurichten. Übung 1: Dankbarkeit Dankbarkeit hilft, Resilienz aufzubauen. Wenn Sie das Gefühl der Dankbarkeit zulassen und/oder abrufen, verändert es Ihren Blick auf die Welt. Überlegen Sie sich Antworten auf die folgenden Fragen, um Dankbarkeit zu spüren: Wofür sind Sie dankbar? Was ist Ihnen in Ihrem Leben Gutes widerfahren? Für welche Menschen und Ereignisse sind Sie dankbar? Notieren Sie jeden Morgen drei Punkte, für die Sie dankbar sind, und drei Dinge, auf die Sie sich an diesem Tag freuen. Übung 2: Empathie Empathie stärkt Resilienz, aber wie lässt sich die Empathie stärken? Hier eine einfache, aber wirksame Methode: Nehmen Sie sich für jeden Tag zwei Begegnungen mit Mitmenschen vor, nach denen Sie sich aktiv selbst hinterfragen und kontrollieren: Habe ich mein Gegenüber verstanden? Habe ich ihm/ihr ganz bewusst ins Gesicht geschaut und mir bewusst gemacht, wie er/sie sich gerade fühlt? Was ist mir an seinen/ihren Gesichtsausdrücken aufgefallen? Damit zeigen Sie, dass Sie ihr Gegenüber wirklich wahrnehmen, und Sie können Ihre Beziehungen intensivieren. Viel wichtiger aber: Sie versetzen sich wirklich in Ihr Gegenüber und denken für einen Moment nicht darüber nach, was Ihnen selbst denn noch zum Glück fehlen könnte. Übung 3: Zielsetzung Ziele geben Richtung und Zukunftsorientierung. Eine gute Übung zur Stärkung der Resilienz ist es deshalb, sich täglich Ziele zu setzen. Diese sollten realistisch und erreichbar sein, damit sich das Gefühl von Erfolg einstellen kann. Nehmen Sie sich jeden Morgen ein paar Minuten Zeit, um sich folgende Punkte zu überlegen und kurz niederzuschreiben: Was möchten Sie heute machen und erreichen? Was soll Sie heute ausmachen, wer wollen Sie heute sein? Die tägliche Zielsetzung holt Sie aus der Opferrolle und richtet Ihren Blick nach vorne. Regelmäßiges Formulieren von kurzfristigen Zielen hilft außerdem, mittel- und langfristige Ziele zu erkennen und zu sehen, was wirklich wichtig ist und was die eigene Widerstandskraft stärkt. Ein Leuchtturm im Meer trotzt den Wellen: Resiliente Menschen reagieren unempfindlicher auf psychische Belastungen wie Stress und Frust und handeln flexibler in schwierigen und sich ändernden Situationen. Foto: Jorge Felix Costa – shutterstock.com Resiliente Menschen gehen leichter mit Krisen um und finden schneller wieder zu einem stabilen psychischen Zustand zurück. Mehr noch: Sie bleiben in Situationen stabil, die nicht-resiliente Menschen aus der Bahn werfen würden. Resilienz wird zwar in der Kindheit in uns angelegt, ist aber auch in späteren Jahren noch trainierbar. Wer dies richtig angeht, kommt in Berufs- und Privatleben mit Problemen und Belastungen besser klar. Dieser Artikel zeigt Ihnen, was Sie dafür tun können. Der Begriff Resilienz kommt eigentlich aus der Werkstoffphysik und bedeutet Spannkraft, Elastizität, Strapazierfähigkeit. Die Resilienz eines Materials bemisst, ob und wie dieses nach Verformung wieder in die Ausgangsform zurückgeht. Die Resilienz bei Menschen kann als psychische Widerstandsfähigkeit beschrieben werden. Sie ist so etwas wie unser “seelisches Immunsystem”. Resiliente Menschen reagieren unempfindlicher auf psychische Belastungen wie Stress und Frust und handeln flexibler in schwierigen und sich ändernden Situationen. Resiliente Menschen sind aber keine Daueroptimisten! Eine Krise belastet auch sie in sehr hohem Maße. Aber sie stehen schneller wieder auf und verlassen schneller als andere die Opferrolle. Vorreiterin der Resilienzforschung ist die amerikanische Entwicklungsforscherin Emmy Werner , die seit den 1950er-Jahren die Entwicklung von 210 Jungen und Mädchen auf der hawaiianischen Insel Kauai über 40 Jahre beobachtete und dokumentierte. Zwei Drittel der Kinder entwickelten sich den schlechten Umständen (alkoholabhängige Eltern, Vernachlässigung bis hin zu Misshandlungen) entsprechend, aber das letzte Drittel führte trotz düsterer Prognosen ein zufriedenes Leben. Bei ihnen zeigte sich das, was wir heute Resilienz nennen. “Der allergrößte Schutz im Leben ist Bindung”, sagt Friedrich Lösel , emeritierter Professor für Psychologie und Kriminologie in Christina Berndts Buch “Resilienz”. So trägt beispielsweise die Bindung zur Mutter stark zur Resilienz bei. Aber auch andere Bezugspersonen wie Trainer, Mentoren, Onkel oder Väter/Mütter von Freunden können diese bindungsfördernde Rolle einnehmen. Auch unsere genetische Disposition entscheidet über unsere Resilienz. So hängt es beispielsweise von unseren Genen ab, wie gut das “Glückshormon” Serotonin transportiert wird und wie viel dieser Substanz im Gehirn überhaupt verfügbar ist. Resilienz lässt sich gleichwohl trainieren und erlernen. Sie gründet auf feingliedrigen Verschaltungen von Nervenzellen im Gehirn, den neuronalen Netzen. Und keine andere Spezies kommt mit einem derart formbaren Gehirn zur Welt wie wir. Während also der Einfluss unserer Gene unveränderbar ist und sich mit dem Umwelteinfluss die Waage hält, sind sowohl Umwelt als auch Training durch uns selbst mitbestimm- und gestaltbar. Und durch Training können wir fehlende genetisch veranlagte Resilienz erlernen. Einflussfaktoren, durch die Resilienz geprägt werden. Foto: Oliver Janzen Allgemein spricht man von sieben Säulen oder Faktoren, auf die sich Resilienz stützt. Die ersten drei davon betreffen unsere Haltung im Umgang mit Krisen und Rückschlägen: Akzeptanz Optimismus Lösungsorientierung Die vier weiteren Faktoren beschreiben Handlungsaspekte: Opferrolle verlassen Verantwortung übernehmen Netzwerkorientierung Zukunftsorientierung Die sieben Resilienz-Faktoren. Foto: Oliver Janzen Aber, was genau bedeuten diese sieben Punkte? Nehmen wir als beispielhafte Krise die Corona-Pandemie und den ersten Lockdown im März/April 2020. Akzeptanz: “Es ist eine Pandemie. Sie ist da.” Es geht darum, dies anzunehmen und zu verstehen, dass es jetzt neue Regeln gibt. Zu versuchen, alle “Wenn das jetzt nicht da wäre, könnte ich aber”-Gedanken von vornherein wegzulassen. Optimismus: Der Kölner sagt: “Et hätt noch immer jut jejange.” Und wenn wir unser Leben anschauen, gibt es viele Gründe, optimistisch zu sein. Auch weil Optimisten im Schnitt mindestens so lang leben wie Pessimisten, und dabei auch noch besser! Lösungsorientierung: Rückschläge sorgen dafür, dass unser Ziel bzw. unser Zielzustand, wie beispielsweise das Glücklichsein, in die Ferne rückt – ein Problem, das wir gern bejammern. Lösungsorientiert sein heißt hier, nach vorne zu schauen und die Lösung in den Blick zu nehmen. Die Opferrolle verlassen: Sich bewusst machen, dass niemand Corona erschaffen hat, um uns persönlich zu ärgern. Die Opferrolle verlassen heißt hier, die Steine als Teil unseres Lebens anzuerkennen, einen Plan zu machen und über die Steine zu klettern oder darum herum zu laufen. Verantwortung übernehmen: Wer sich vornimmt, über die Steine zu klettern, übernimmt bereits Verantwortung – für sich selbst! Schuldzuweisungen und Selbstmitleid (“Ich kann doch auch nichts dafür, dass alles so ist, wie es ist!”) bringen niemanden weiter. Netzwerkorientierung: Bindung ist die wichtigste Voraussetzung für die Ausprägung von Resilienz. Und sich mit anderen zu vernetzen, bedeutet Bindungen aufzubauen und zu erkennen: Ich bin nicht allein! Plus: Man bekommt selbst auch Hilfe, wenn man diese braucht. Zukunftsorientierung: Es hilft, nach vorne schauen, statt zurückzublicken. Ein Motto wie “Gestärkt aus der Krise” beschreibt einen erreichten Zielzustand zu einem Zeitpunkt in der Zukunft, an dem die Krise bereits überwunden ist. Um die eigene Resilienz so aufzubauen, dass eine Krise eher als Herausforderung gesehen wird, bieten sich folgende Methoden oder Denkansätze an: Meditation: Meditation kann glücklich machen und fördert die Ausgeglichenheit. Schon zwanzig Minuten täglich genügen, um diesen Effekt am eigenen Leib zu erfahren. Unser Verstand will uns ständig vor Gefahren warnen. Deshalb drehen sich unsere Gedanken auch oft um Probleme; leider meistens, ohne sie zu lösen. Meditation befreit uns zumindest vorübergehend von diesen Gedanken. Reflexion: Durch die Reflexion bisheriger Krisen lernen wir, welche Herausforderungen wir bereits bewältigt haben, wie wir sie bewältigt haben – und vor allem, dass wir es können: “Yes, we can!” Bewusstheit: Wenn wir uns gezielt das vor Augen führen, was uns täglich beschäftigt, welche Gedanken wir dazu haben, machen wir sie uns bewusst. Ein sehr gutes Instrument dafür ist das Tagebuch, in dem wir all diese Dinge aufschreiben. Dadurch nehmen wir eine andere Perspektive ein und merken, wo wir eigentlich stehen. Empathie: Empathie stärkt die Netzwerkbildung – eine Säule der Resilienz: Nur wenn wir die Gefühle unseres Gegenübers erkennen und beachten, können wir positive Beziehungen aufbauen. Dankbarkeit: Dankbarkeit wieder neu zu erlernen, ist einer der größten Hebel für Resilienz. Dankbar sein macht uns glücklich, macht uns bewusst, worüber wir uns freuen können und dass wir nicht alles als selbstverständlich hinnehmen sollten. Zielsetzung: “Ein Ziel ist ein Traum mit einem Abgabetermin.” Gesetzte Ziele geben uns eine Richtung für unser Denken und Handeln. Wir machen uns klar, was wir wollen, und schöpfen daraus die Energie, unsere Handlungen auf unsere Ziele auszurichten. Übung 1: Dankbarkeit Dankbarkeit hilft, Resilienz aufzubauen. Wenn Sie das Gefühl der Dankbarkeit zulassen und/oder abrufen, verändert es Ihren Blick auf die Welt. Überlegen Sie sich Antworten auf die folgenden Fragen, um Dankbarkeit zu spüren: Wofür sind Sie dankbar? Was ist Ihnen in Ihrem Leben Gutes widerfahren? Für welche Menschen und Ereignisse sind Sie dankbar? Notieren Sie jeden Morgen drei Punkte, für die Sie dankbar sind, und drei Dinge, auf die Sie sich an diesem Tag freuen. Übung 2: Empathie Empathie stärkt Resilienz, aber wie lässt sich die Empathie stärken? Hier eine einfache, aber wirksame Methode: Nehmen Sie sich für jeden Tag zwei Begegnungen mit Mitmenschen vor, nach denen Sie sich aktiv selbst hinterfragen und kontrollieren: Habe ich mein Gegenüber verstanden? Habe ich ihm/ihr ganz bewusst ins Gesicht geschaut und mir bewusst gemacht, wie er/sie sich gerade fühlt? Was ist mir an seinen/ihren Gesichtsausdrücken aufgefallen? Damit zeigen Sie, dass Sie ihr Gegenüber wirklich wahrnehmen, und Sie können Ihre Beziehungen intensivieren. Viel wichtiger aber: Sie versetzen sich wirklich in Ihr Gegenüber und denken für einen Moment nicht darüber nach, was Ihnen selbst denn noch zum Glück fehlen könnte. Übung 3: Zielsetzung Ziele geben Richtung und Zukunftsorientierung. Eine gute Übung zur Stärkung der Resilienz ist es deshalb, sich täglich Ziele zu setzen. Diese sollten realistisch und erreichbar sein, damit sich das Gefühl von Erfolg einstellen kann. Nehmen Sie sich jeden Morgen ein paar Minuten Zeit, um sich folgende Punkte zu überlegen und kurz niederzuschreiben: Was möchten Sie heute machen und erreichen? Was soll Sie heute ausmachen, wer wollen Sie heute sein? Die tägliche Zielsetzung holt Sie aus der Opferrolle und richtet Ihren Blick nach vorne. Regelmäßiges Formulieren von kurzfristigen Zielen hilft außerdem, mittel- und langfristige Ziele zu erkennen und zu sehen, was wirklich wichtig ist und was die eigene Widerstandskraft stärkt.",
    "source": "cio",
    "crawled_at": "2025-05-27T08:10:54.186568+00:00"
  },
  {
    "url": "https://www.cio.de/article/3987874/5-alternativen-zu-vmware-vsphere-2.html",
    "title": "5 Alternativen zu VMware vSphere",
    "published": "2025-05-21T05:11:00+00:00",
    "author": "",
    "text": "JLStock | shutterstock.com Es gibt viele Alternativen für Organisationen, die mit der Richtung, die Broadcom mit der VMware-Virtualisierungsplattform einschlägt, unzufrieden sind. Zum Beispiel, indem sie virtuelle Maschinen (VMs) hinter sich lassen und: Es gibt jedoch genug Anwender, für die keine der beiden Optionen in Frage kommt – sie suchen ausschließlich nach einer alternativen Virtualisierungsplattform. Die fünf (ihrer Meinung nach) besten Alternativen in diesem Bereich haben die Analysten der Data Center Intelligence Group (DCIG) identifiziert (Download gegen Daten). Diese stellen wir Ihnen nachfolgend (in alphabetischer Reihenfolge) inklusive einer kurzen Beschreibung vor. Bei HiveIO handelt es sich um eine VM-Plattform auf Basis des Linux Kernels (KVM), die mit diversen Features aufwarten kann. Darunter beispielsweise: Der Cloud-basierte Monitoring-Service HiveSense sorgt dabei für proaktives Monitoring und erkennt Anomalien. Die Plattform von HiveIO ist in drei Lizenzierungsstufen verfügbar – darunter auch eine kostenlose Community-Edition. Der Enterprise-Plan umfasst unter anderem: Für Microsoft-zentrische Unternehmen ist Azure Stack HCI eine Alternative zu VMwares vSphere-Plattform. Die Plattform läuft bei den Redmondern inzwischen unter dem Banner von Azure Local und nutzt erwartungsgemäß die Azure Cloud und Microsofts Hyper-V-Technologie. Die Anwender können dabei zwischen zwei Ansätzen wählen: Eine weitere nennenswerte Funktion von Azure Stack HCI ist beispielsweise ein Migrations-Tool, das dabei hilft, vorhandene VMware-Workloads zu überführen. Davon abgesehen ermöglicht die Microsoft-Lösung, Applikationen, VMs oder containerbasierte Workloads entweder On-Premises oder über die Azure Cloud auszuführen – und das zugehörige Portal zu managen. Zudem unterstützt Azure Stack HCI auch GPU-Partitionierung – laut den DCIG-Analysten ein entscheidendes Feature für vSphere-Anwender, die nach einer alternativen Lösung suchen. Anwender, die ihre Virtualisierungsstrategie unabhängig von Broadcom weiterführen wollen und sich in diesem Zuge für Nutanix entscheiden, haben den Vorteil, den Hypervisor nicht wechseln zu müssen. Denn diese Plattform unterstützt neben dem hauseigenen Acropolis Hypervisor (AHV) auch vSphere und Hyper-V. Entsprechend forsch positioniert sich auch Nutanix als alternative Anlaufstelle für verärgerte VMware-Kunden . Die Storage Services des Anbieters aggregieren Ressourcen in Pools und stellen diese jeder Art von virtueller Maschine zur Verfügung. Zu den Features der Plattform zählen unter anderem: Dabei denkt Nutanix auch an Anwender, die High-Performance-Datenbanken betreiben und dazu im Regelfall auf externe Storage-Arrays zurückgreifen. Diesen Bedarf deckt der Anbieter durch Storage-Zertifizierungen für SAP HANA und Oracle RAC ab. Mit der Scale Computing Platform bekommen abwanderungswillige VMware-Kunden ein All-In-One-Paket, das Software, Hardware und sämtliche nötigen Lizenzen bündelt. Zu den Features auf Softwareseite zählen unter anderem: Scale bietet zudem ein Tool an, um vSphere-Migrationen automatisiert zu bewältigen. Auch diese Plattform setzt auf Storage Pools und bietet darüber hinaus die Möglichkeit, unterschiedliche Hardware Appliances in einem Cluster zusammenzuführen. VergeIO ist nach eigener Aussage „mehr als eine VMware-Alternative“. Das liegt in erster Linie am Konzept der „Ultraconverged Infrastructure“ (UCI), das der Anbieter verfolgt: Dabei wird Virtualisierung, Storage und Networking in einem Betriebssystem für Rechenzentren integriert – VergeOS. Die Plattform virtualisiert also nicht nur den „normalen“ Rechen-, Netzwerk- und Storage-Stack, sondern implementiert auch Mandantenfähigkeit in Form von Virtual Data Centers (VDCs). Die Anwender können jedes VDC – ähnlich wie die von den Hyperscalern angebotenen Virtual Private Clouds – einzeln managen und nutzen. Dieses Modell soll laut VergeIO eine erhöhte Workload-Dichte realisieren, die wiederum beiträgt zu: Auch VergeIO hat seine Bemühungen verstärkt, gezielt VMware-Kunden zu gewinnen. Deshalb bietet das Unternehmen etwa auch einen Migrationsservice für vSphere an und ermöglicht es Anwendern außerdem, vorhandene Server wiederzuverwenden, um VergeOS zu hosten. JLStock | shutterstock.com Es gibt viele Alternativen für Organisationen, die mit der Richtung, die Broadcom mit der VMware-Virtualisierungsplattform einschlägt, unzufrieden sind. Zum Beispiel, indem sie virtuelle Maschinen (VMs) hinter sich lassen und: Es gibt jedoch genug Anwender, für die keine der beiden Optionen in Frage kommt – sie suchen ausschließlich nach einer alternativen Virtualisierungsplattform. Die fünf (ihrer Meinung nach) besten Alternativen in diesem Bereich haben die Analysten der Data Center Intelligence Group (DCIG) identifiziert (Download gegen Daten). Diese stellen wir Ihnen nachfolgend (in alphabetischer Reihenfolge) inklusive einer kurzen Beschreibung vor. Bei HiveIO handelt es sich um eine VM-Plattform auf Basis des Linux Kernels (KVM), die mit diversen Features aufwarten kann. Darunter beispielsweise: Der Cloud-basierte Monitoring-Service HiveSense sorgt dabei für proaktives Monitoring und erkennt Anomalien. Die Plattform von HiveIO ist in drei Lizenzierungsstufen verfügbar – darunter auch eine kostenlose Community-Edition. Der Enterprise-Plan umfasst unter anderem: Für Microsoft-zentrische Unternehmen ist Azure Stack HCI eine Alternative zu VMwares vSphere-Plattform. Die Plattform läuft bei den Redmondern inzwischen unter dem Banner von Azure Local und nutzt erwartungsgemäß die Azure Cloud und Microsofts Hyper-V-Technologie. Die Anwender können dabei zwischen zwei Ansätzen wählen: Eine weitere nennenswerte Funktion von Azure Stack HCI ist beispielsweise ein Migrations-Tool, das dabei hilft, vorhandene VMware-Workloads zu überführen. Davon abgesehen ermöglicht die Microsoft-Lösung, Applikationen, VMs oder containerbasierte Workloads entweder On-Premises oder über die Azure Cloud auszuführen – und das zugehörige Portal zu managen. Zudem unterstützt Azure Stack HCI auch GPU-Partitionierung – laut den DCIG-Analysten ein entscheidendes Feature für vSphere-Anwender, die nach einer alternativen Lösung suchen. Anwender, die ihre Virtualisierungsstrategie unabhängig von Broadcom weiterführen wollen und sich in diesem Zuge für Nutanix entscheiden, haben den Vorteil, den Hypervisor nicht wechseln zu müssen. Denn diese Plattform unterstützt neben dem hauseigenen Acropolis Hypervisor (AHV) auch vSphere und Hyper-V. Entsprechend forsch positioniert sich auch Nutanix als alternative Anlaufstelle für verärgerte VMware-Kunden . Die Storage Services des Anbieters aggregieren Ressourcen in Pools und stellen diese jeder Art von virtueller Maschine zur Verfügung. Zu den Features der Plattform zählen unter anderem: Dabei denkt Nutanix auch an Anwender, die High-Performance-Datenbanken betreiben und dazu im Regelfall auf externe Storage-Arrays zurückgreifen. Diesen Bedarf deckt der Anbieter durch Storage-Zertifizierungen für SAP HANA und Oracle RAC ab. Mit der Scale Computing Platform bekommen abwanderungswillige VMware-Kunden ein All-In-One-Paket, das Software, Hardware und sämtliche nötigen Lizenzen bündelt. Zu den Features auf Softwareseite zählen unter anderem: Scale bietet zudem ein Tool an, um vSphere-Migrationen automatisiert zu bewältigen. Auch diese Plattform setzt auf Storage Pools und bietet darüber hinaus die Möglichkeit, unterschiedliche Hardware Appliances in einem Cluster zusammenzuführen. VergeIO ist nach eigener Aussage „mehr als eine VMware-Alternative“. Das liegt in erster Linie am Konzept der „Ultraconverged Infrastructure“ (UCI), das der Anbieter verfolgt: Dabei wird Virtualisierung, Storage und Networking in einem Betriebssystem für Rechenzentren integriert – VergeOS. Die Plattform virtualisiert also nicht nur den „normalen“ Rechen-, Netzwerk- und Storage-Stack, sondern implementiert auch Mandantenfähigkeit in Form von Virtual Data Centers (VDCs). Die Anwender können jedes VDC – ähnlich wie die von den Hyperscalern angebotenen Virtual Private Clouds – einzeln managen und nutzen. Dieses Modell soll laut VergeIO eine erhöhte Workload-Dichte realisieren, die wiederum beiträgt zu: Auch VergeIO hat seine Bemühungen verstärkt, gezielt VMware-Kunden zu gewinnen. Deshalb bietet das Unternehmen etwa auch einen Migrationsservice für vSphere an und ermöglicht es Anwendern außerdem, vorhandene Server wiederzuverwenden, um VergeOS zu hosten.",
    "source": "cio",
    "crawled_at": "2025-05-27T08:10:55.005430+00:00"
  },
  {
    "url": "https://www.cio.de/article/3690824/erfolgsfaktor-mitarbeitermotivation.html",
    "title": "Erfolgsfaktor Mitarbeitermotivation",
    "published": "2025-05-21T06:11:05+00:00",
    "author": "",
    "text": "Führungskräfte sollten wissen, was ihre Mitarbeiter motiviert, um ihnen passende Aufgaben zu übertragen. Dann motivieren sich Mitarbeiter von selbst. Foto: Standret – shutterstock.com Welche Kompetenzen und persönlichen Eigenschaften brauchen unsere Mitarbeiter künftig? Vor dieser Frage stehen Unternehmen immer häufiger und finden darauf nur schwer eine Antwort. Der Grund: in der von rascher Veränderung und sinkender Planbarkeit geprägten VUCA -Welt (Volatility, Uncertainty, Complexity und Ambiguity) wissen sie heute oft noch nicht, wie viele Mitarbeiter sie in drei, fünf oder gar zehn Jahren benötigen und über welche Fähigkeiten und Fertigkeiten diese dann verfügen müssen. Die Hauptursache hierfür ist der rasante technische Fortschritt, der Unternehmen insbesondere im IT-Bereich ganz neue Möglichkeiten eröffnet, Probleme zu lösen. Zudem werden neue Geschäftsmodelle möglich, weshalb nicht selten ganz neue Mitbewerber am Markt erscheinen und sich die Märkte sowie die Bedürfnisse der Kunden immer rascher wandeln. Dies erschwert Betrieben heute, ihren Personal- und Kompetenzbedarf langfristig zu planen. Deshalb haben viele Unternehmen in den letzten Jahren ihre strategische, also langfristig orientierte Personalentwicklung weitgehend auf Eis gelegt oder überdenken diese gerade grundlegend. Dabei lassen sie sich von folgenden Grundannahmen leiten: 1. In der modernen Arbeitswelt stehen die Mitarbeiter immer häufiger vor neuen Herausforderungen und Aufgaben. Also benötigen Firmen zunehmend Mitarbeiter, die diese beherzt angehen – und zwar eigeninitiativ. Denn unter den VUCA-Einflüssen auf die Wirtschaftswelt sind in Unternehmen die Veränderungen auf allen Ebenen sowie in ihrem Umfeld so vielfältig, dass der Veränderungsbedarf top-down nur noch bedingt erfasst und befriedigt werden kann. Außerdem würde ein solches Vorgehen das Bestreben der Betriebe torpedieren, möglichst schnell und flexibel auf Veränderungen im Markt sowie bei Kundenwünschen zu reagieren. Also müssen Mitarbeiter oft – alleine oder im Team – Eigeninitiative ergreifen. 2. Um neue Herausforderungen zu meistern, benötigen Mitarbeiter oft auch neue Fähigkeiten und Skills. Welche dies sind, ist top-down ebenfalls immer schwieriger zu ermitteln. Zudem wird die Aufgabe zunehmend komplexer, die Entwicklungsbedarfe mit zentral organisierten Personalentwicklungsprogrammen zu decken – unter anderem, weil die Tätigkeiten der Mitarbeiter, ihre Erfahrungen sowie ihre bereits vorhandenen Kompetenzen unterschiedlich sind. Darüber hinaus würde eine strategische Kompetenzentwicklung häufig zu lange dauern, um auf akuten Bedarf zeitnah zu reagieren. Deshalb müssen Beschäftigte zunehmend in der Lage sein, den Entwicklungsbedarf bei sich eigenständig zu erkennen und diesen alleine oder mit selbst organisierter Hilfe zu befriedigen. Sie müssen sozusagen Selbstentwickler werden. Ihre Führungskräfte sollten deshalb wissen, was ihre Mitarbeiter motiviert, um ihnen passende Aufgaben zu übertragen. Sowohl das beherzte Angehen neuer Aufgaben und Herausforderungen als auch das eigenständige Aneignen der hierfür erforderlichen Kompetenzen setzen voraus, dass die Mitarbeiter • eine hohe Eigenmotivation beziehungsweise intrinsische Motivation haben und • sich sowohl mit dem Unternehmen als auch ihren Aufgaben identifizieren. Deshalb achten Personalabteilungen heute schon beim Einstellen neuer Mitarbeiter verstärkt darauf, wie die betreffenden Personen gestrickt sind. Außerdem ermitteln sie nicht selten im Personalauswahlprozess zum Beispiel mit einem Analysetool wie der MotivStrukturAnalyse (MSA), was die Kandidaten motiviert und antreibt. Handelt es sich zum Beispiel um Personen, die gerne selbst die Initiative ergreifen oder übertragene Aufgaben lieber gemäß den Vorgaben systematisch abarbeiten? Hierdurch wollen die Unternehmen unter anderem sicherstellen, dass die nötige Passung zwischen dem neu eingestellten Mitarbeiter und der vakanten Position besteht. Sind die Mitarbeiter mit dem gewünschten Persönlichkeitsprofil dann an Bord, ist aber noch keinesfalls sicher, dass diese im Betriebsalltag tatsächlich dauerhaft das gewünschte Verhalten zeigen. Denn neben dem “Wollen” ist hierfür auch das entsprechende “Können” und “Dürfen” wichtig. Unternehmen und mit ihnen ihre Führungskräfte stehen, wenn ihre Mitarbeiter weitgehend selbständig und eigenverantwortlich arbeiten sollen, unter anderem vor der Herausforderung, in der Organisation die hierfür nötigen Rahmenbedingungen zu schaffen. Hierzu zählt, den Beschäftigten die erforderlichen Entscheidungs- und Handlungsspielräume einzuräumen. Dies setzt bei Führungskräften wiederum einen Führungsstil voraus, der primär darauf abzielt, die Eigenmotivation der Mitarbeiter zu nutzen. Ein solch motivationaler Führungsstil ist unter anderem aufgrund folgender Faktoren nötig: 1. Heute werden die Kernleistungen der meisten Unternehmen von Expertenteams in bereichs- oder oft sogar unternehmensübergreifender Team- und Projektarbeit erbracht. Deshalb können die Führungskräfte ihren Mitarbeitern immer seltener sagen “Tue dies oder tue das, dann hast du…” beziehungsweise “…, dann haben wir Erfolg”. Sie müssen vielmehr auf deren Motivation vertrauen, eine Top-Leistung zu erbringen. 2. Speziell hochqualifizierte Mitarbeiter, die außer über ein großes Können auch über eine hohe Eigenmotivation verfügen, sind in der Regel sehr selbstbewusst. Sie erwarten nicht nur, dass sie sich bei ihrer Arbeit weitgehend selbstverwirklichen können, sondern auch, dass sie als Individuum wahrgenommen und wertgeschätzt werden. Ist dies nicht der Fall, wechseln sie rasch den Arbeitsgeber – was in einem Arbeitsmarkt, in dem gute, das heißt fachlich hochqualifizierte und hochmotivierte Fach- und Führungskräfte rar sind, für sie kein Problem darstellt. Auch deshalb ist ein neuer Führungsstil nötig, der primär darauf abzielt, den Angestellten ein weitgehend ihrem Motivprofil entsprechendes Arbeitsumfeld zu bieten, um ihre Topleistung zu bewahren und sie dauerhaft ans Unternehmen zu binden. Eine Grundvoraussetzung hierfür ist, dass die Führungskraft die Grundmotive ihrer Mitarbeiter kennt – also das, was diese motiviert und antreibt. Dieses Führen entlang der intrinsischen Motivation wird in den kommenden Jahren, speziell in den Unternehmensbereichen, in denen immer wieder neue Problemlösungen zu entwerfen sind, an Bedeutung gewinnen, während das fachliche Führen an Bedeutung verliert. Dieses motivationale Führen setzt ein bestimmtes Handeln und Selbstverständnis der Führungskraft voraus. Sie muss unter anderem dafür sorgen, dass in ihren Bereichen eine Kultur entsteht, die von wechselseitigem Respekt vor der Unterschiedlichkeit geprägt ist. Ein Beispiel: Eine planvoll-strukturierte Führungskraft führt einen gerne spontan und flexibel agierenden Mitarbeiter, der aufblüht, wenn viele Aufgaben gleichzeitig auf ihn zukommen. In diesem Fall ist es nicht zielführend, wenn der Chef seinen Mitarbeiter “strukturiert”, also zu ihm sagt: “Erledige zuerst die Aufgabe A, dann B, dann C!” Vielmehr entfaltet der Mitarbeiter seine Motivation, wenn er eigenständig A, B und C parallel erledigen kann. Das bedeutet für die “ordentliche” Führungskraft, Wertschätzung gegenüber “Unordentlichkeit” zu entwickeln. Zudem müssen Führungskräfte sich in ihrem Führungsalltag als Befähiger und Coach ihrer Mitarbeiter verstehen. Solche Vorgesetzte achten bei ihrer Führungsarbeit unter anderem darauf, dass ihre Untergebenen nicht dauerhaft unterfordert sind – denn dies erzeugt Frust und nachlassende Motivation. Zudem bewirkt es keine Entwicklung ihrer Kompetenz. Die Führungskraft achtet jedoch zugleich darauf, dass die übertragenen Aufgaben den Mitarbeiter nicht völlig überfordern. Denn dies erzeugt Stress, der in der Regel ein Lernen verhindert. Ziel des Führungsverhaltens ist es, dass der Mitarbeiter sich in einem Entwicklungskorridor bewegt, der dazu führt, dass seine Motivation “bedient” wird, und seine Kompetenz und sein Selbstvertrauen kontinuierlich steigen. Ein solches Führungsverhalten setzt bei der Führungskraft voraus, dass sie außer der Motivstruktur ihrer Mitarbeiter, ihre eigene kennt – also weiß: Was motiviert mich, was treibt mich an? Denn nur dann kann sie ihr eigenes Verhalten so reflektieren, dass ihr ihre unbekannten (Motiv-)Flecken bewusst werden und sie diese reduzieren kann, sodass ihre (Selbst-)Wirksamkeit steigt. Die Führungskraft muss sich also als Lernende verstehen und dies ihren Mitarbeitern auch signalisieren – unter anderem, indem sie erkennbar über das Verringern ihrer eigenen weißen Flecken lernt, den Wert zu schätzen, dass ihre Mitarbeiter anders als sie selbst sind. Denn nur dann ist auf Dauer ein von wechselseitigem Vertrauen geprägtes Miteinander auf Augenhöhe und kollektives Lernen möglich. Prämien und Anerkennung vom Chef Foto: fizkes – shutterstock.com Ein gutes Betriebsklima ist das A und O für den Erfolg eines Unternehmens sowie die Mitarbeiterbindung. Grund genug, sich als Chef und HR-Abteilung Gedanken über die Motivation der Angestellten zu machen. Benefit-Berater Markus Sobau nennt die sieben größten Mitarbeiterwünsche. Flexible Arbeitszeiten Foto: Black Salmon – shutterstock.com Besonders ausgeprägt ist der Wunsch nach flexiblen Arbeitszeiten. Jeder zweite Beschäftigte möchte selbst entscheiden können, wann er wie viel arbeitet. Home-Office Foto: Zivica Kerkez – shutterstock.com Ein Drittel der Beschäftigten möchte zu Hause arbeiten. Übernimmt der Arbeitgeber für das Arbeiten im Home-Office die Kosten für die nötige Infrastruktur, ist das Interesse an Heimarbeit sogar noch größer. Mehr brutto vom Netto Foto: Bernd Leitner Fotodesign – shutterstock.com Ein höheres Gehalt motiviert allen Unkenrufen zum Trotz doch – vorzugsweise, wenn es sich netto auswirkt. Das geht elegant über eine Firmen-Card. Auf diese können Arbeitgeber monatlich 50 Euro überweisen. Der Betrag steht dem Mitarbeiter netto als Sachbezug zur Verfügung. Er kann damit essen gehen, sein Auto tanken oder das Geld sparen. So ein Benefit ist mehr wert als eine Gehaltserhöhung von 100 Euro, die versteuert werden muss. Altersvorsorge Foto: PhotographyByMK – shutterstock.com Viele Mitarbeiter wünschen sich, dass der Chef bei der Altersvorsorge hilft. Firmen sollten daher eine betriebliche Altersvorsorge anbieten. Für Beiträge, die sie in die private Rente der Mitarbeiter überweisen, entfallen anteilige Sozialversicherungsbeiträge. Legt der Chef diese 20 Prozent als Zuschuss oben drauf, ist das auch eine gute Investition in das Betriebsklima. Gesundheitsvorsorge Foto: Mathias Rosenthal – shutterstock.com Liegt einem Unternehmen die Gesundheit seiner Mitarbeiter besonders am Herzen, ist eine betriebliche Krankenversicherung ein guter Tipp. Sie spart dem Arbeitnehmer etwa die Ausgaben für Brille, Zahnersatz oder Heilpraktiker-Behandlung. Vorteil für den Arbeitgeber: Er kann die Versicherung zunächst für ein Jahr abschließen, etwa als Bonus für erfolgreiche Mitarbeiter, und später bei Bedarf verlängern. Kredit vom Chef Foto: Bartolomiej Pietrzyk – shutterstock.com Unternehmen erhalten aufgrund ihrer oft großen Kreditvolumina und der nötigen Bonität günstige Zinskonditionen. Diese können sie an ihre Leute weitergeben. So bezahlt der Mitarbeiter statt elf Prozent Überziehungszins bei seiner Hausbank vier Prozent an seinen Chef. Selbständiges Arbeiten Foto: keport – shutterstock.com Mitarbeiter legen Wert darauf, dass Chefs ihnen vertrauen und zutrauen, die gestellten Aufgaben eigenverantwortlich zu erledigen. Im Sinne einer agilen Unternehmenskultur wollen sie Aufgaben auf Basis vereinbarter Leitplanken wie Umsatzerlöse, Renditeziele oder Produktinnovationen eigenständig entwickeln. Führungskräfte sollten wissen, was ihre Mitarbeiter motiviert, um ihnen passende Aufgaben zu übertragen. Dann motivieren sich Mitarbeiter von selbst. Foto: Standret – shutterstock.com Welche Kompetenzen und persönlichen Eigenschaften brauchen unsere Mitarbeiter künftig? Vor dieser Frage stehen Unternehmen immer häufiger und finden darauf nur schwer eine Antwort. Der Grund: in der von rascher Veränderung und sinkender Planbarkeit geprägten VUCA -Welt (Volatility, Uncertainty, Complexity und Ambiguity) wissen sie heute oft noch nicht, wie viele Mitarbeiter sie in drei, fünf oder gar zehn Jahren benötigen und über welche Fähigkeiten und Fertigkeiten diese dann verfügen müssen. Die Hauptursache hierfür ist der rasante technische Fortschritt, der Unternehmen insbesondere im IT-Bereich ganz neue Möglichkeiten eröffnet, Probleme zu lösen. Zudem werden neue Geschäftsmodelle möglich, weshalb nicht selten ganz neue Mitbewerber am Markt erscheinen und sich die Märkte sowie die Bedürfnisse der Kunden immer rascher wandeln. Dies erschwert Betrieben heute, ihren Personal- und Kompetenzbedarf langfristig zu planen. Deshalb haben viele Unternehmen in den letzten Jahren ihre strategische, also langfristig orientierte Personalentwicklung weitgehend auf Eis gelegt oder überdenken diese gerade grundlegend. Dabei lassen sie sich von folgenden Grundannahmen leiten: 1. In der modernen Arbeitswelt stehen die Mitarbeiter immer häufiger vor neuen Herausforderungen und Aufgaben. Also benötigen Firmen zunehmend Mitarbeiter, die diese beherzt angehen – und zwar eigeninitiativ. Denn unter den VUCA-Einflüssen auf die Wirtschaftswelt sind in Unternehmen die Veränderungen auf allen Ebenen sowie in ihrem Umfeld so vielfältig, dass der Veränderungsbedarf top-down nur noch bedingt erfasst und befriedigt werden kann. Außerdem würde ein solches Vorgehen das Bestreben der Betriebe torpedieren, möglichst schnell und flexibel auf Veränderungen im Markt sowie bei Kundenwünschen zu reagieren. Also müssen Mitarbeiter oft – alleine oder im Team – Eigeninitiative ergreifen. 2. Um neue Herausforderungen zu meistern, benötigen Mitarbeiter oft auch neue Fähigkeiten und Skills. Welche dies sind, ist top-down ebenfalls immer schwieriger zu ermitteln. Zudem wird die Aufgabe zunehmend komplexer, die Entwicklungsbedarfe mit zentral organisierten Personalentwicklungsprogrammen zu decken – unter anderem, weil die Tätigkeiten der Mitarbeiter, ihre Erfahrungen sowie ihre bereits vorhandenen Kompetenzen unterschiedlich sind. Darüber hinaus würde eine strategische Kompetenzentwicklung häufig zu lange dauern, um auf akuten Bedarf zeitnah zu reagieren. Deshalb müssen Beschäftigte zunehmend in der Lage sein, den Entwicklungsbedarf bei sich eigenständig zu erkennen und diesen alleine oder mit selbst organisierter Hilfe zu befriedigen. Sie müssen sozusagen Selbstentwickler werden. Ihre Führungskräfte sollten deshalb wissen, was ihre Mitarbeiter motiviert, um ihnen passende Aufgaben zu übertragen. Sowohl das beherzte Angehen neuer Aufgaben und Herausforderungen als auch das eigenständige Aneignen der hierfür erforderlichen Kompetenzen setzen voraus, dass die Mitarbeiter • eine hohe Eigenmotivation beziehungsweise intrinsische Motivation haben und • sich sowohl mit dem Unternehmen als auch ihren Aufgaben identifizieren. Deshalb achten Personalabteilungen heute schon beim Einstellen neuer Mitarbeiter verstärkt darauf, wie die betreffenden Personen gestrickt sind. Außerdem ermitteln sie nicht selten im Personalauswahlprozess zum Beispiel mit einem Analysetool wie der MotivStrukturAnalyse (MSA), was die Kandidaten motiviert und antreibt. Handelt es sich zum Beispiel um Personen, die gerne selbst die Initiative ergreifen oder übertragene Aufgaben lieber gemäß den Vorgaben systematisch abarbeiten? Hierdurch wollen die Unternehmen unter anderem sicherstellen, dass die nötige Passung zwischen dem neu eingestellten Mitarbeiter und der vakanten Position besteht. Sind die Mitarbeiter mit dem gewünschten Persönlichkeitsprofil dann an Bord, ist aber noch keinesfalls sicher, dass diese im Betriebsalltag tatsächlich dauerhaft das gewünschte Verhalten zeigen. Denn neben dem “Wollen” ist hierfür auch das entsprechende “Können” und “Dürfen” wichtig. Unternehmen und mit ihnen ihre Führungskräfte stehen, wenn ihre Mitarbeiter weitgehend selbständig und eigenverantwortlich arbeiten sollen, unter anderem vor der Herausforderung, in der Organisation die hierfür nötigen Rahmenbedingungen zu schaffen. Hierzu zählt, den Beschäftigten die erforderlichen Entscheidungs- und Handlungsspielräume einzuräumen. Dies setzt bei Führungskräften wiederum einen Führungsstil voraus, der primär darauf abzielt, die Eigenmotivation der Mitarbeiter zu nutzen. Ein solch motivationaler Führungsstil ist unter anderem aufgrund folgender Faktoren nötig: 1. Heute werden die Kernleistungen der meisten Unternehmen von Expertenteams in bereichs- oder oft sogar unternehmensübergreifender Team- und Projektarbeit erbracht. Deshalb können die Führungskräfte ihren Mitarbeitern immer seltener sagen “Tue dies oder tue das, dann hast du…” beziehungsweise “…, dann haben wir Erfolg”. Sie müssen vielmehr auf deren Motivation vertrauen, eine Top-Leistung zu erbringen. 2. Speziell hochqualifizierte Mitarbeiter, die außer über ein großes Können auch über eine hohe Eigenmotivation verfügen, sind in der Regel sehr selbstbewusst. Sie erwarten nicht nur, dass sie sich bei ihrer Arbeit weitgehend selbstverwirklichen können, sondern auch, dass sie als Individuum wahrgenommen und wertgeschätzt werden. Ist dies nicht der Fall, wechseln sie rasch den Arbeitsgeber – was in einem Arbeitsmarkt, in dem gute, das heißt fachlich hochqualifizierte und hochmotivierte Fach- und Führungskräfte rar sind, für sie kein Problem darstellt. Auch deshalb ist ein neuer Führungsstil nötig, der primär darauf abzielt, den Angestellten ein weitgehend ihrem Motivprofil entsprechendes Arbeitsumfeld zu bieten, um ihre Topleistung zu bewahren und sie dauerhaft ans Unternehmen zu binden. Eine Grundvoraussetzung hierfür ist, dass die Führungskraft die Grundmotive ihrer Mitarbeiter kennt – also das, was diese motiviert und antreibt. Dieses Führen entlang der intrinsischen Motivation wird in den kommenden Jahren, speziell in den Unternehmensbereichen, in denen immer wieder neue Problemlösungen zu entwerfen sind, an Bedeutung gewinnen, während das fachliche Führen an Bedeutung verliert. Dieses motivationale Führen setzt ein bestimmtes Handeln und Selbstverständnis der Führungskraft voraus. Sie muss unter anderem dafür sorgen, dass in ihren Bereichen eine Kultur entsteht, die von wechselseitigem Respekt vor der Unterschiedlichkeit geprägt ist. Ein Beispiel: Eine planvoll-strukturierte Führungskraft führt einen gerne spontan und flexibel agierenden Mitarbeiter, der aufblüht, wenn viele Aufgaben gleichzeitig auf ihn zukommen. In diesem Fall ist es nicht zielführend, wenn der Chef seinen Mitarbeiter “strukturiert”, also zu ihm sagt: “Erledige zuerst die Aufgabe A, dann B, dann C!” Vielmehr entfaltet der Mitarbeiter seine Motivation, wenn er eigenständig A, B und C parallel erledigen kann. Das bedeutet für die “ordentliche” Führungskraft, Wertschätzung gegenüber “Unordentlichkeit” zu entwickeln. Zudem müssen Führungskräfte sich in ihrem Führungsalltag als Befähiger und Coach ihrer Mitarbeiter verstehen. Solche Vorgesetzte achten bei ihrer Führungsarbeit unter anderem darauf, dass ihre Untergebenen nicht dauerhaft unterfordert sind – denn dies erzeugt Frust und nachlassende Motivation. Zudem bewirkt es keine Entwicklung ihrer Kompetenz. Die Führungskraft achtet jedoch zugleich darauf, dass die übertragenen Aufgaben den Mitarbeiter nicht völlig überfordern. Denn dies erzeugt Stress, der in der Regel ein Lernen verhindert. Ziel des Führungsverhaltens ist es, dass der Mitarbeiter sich in einem Entwicklungskorridor bewegt, der dazu führt, dass seine Motivation “bedient” wird, und seine Kompetenz und sein Selbstvertrauen kontinuierlich steigen. Ein solches Führungsverhalten setzt bei der Führungskraft voraus, dass sie außer der Motivstruktur ihrer Mitarbeiter, ihre eigene kennt – also weiß: Was motiviert mich, was treibt mich an? Denn nur dann kann sie ihr eigenes Verhalten so reflektieren, dass ihr ihre unbekannten (Motiv-)Flecken bewusst werden und sie diese reduzieren kann, sodass ihre (Selbst-)Wirksamkeit steigt. Die Führungskraft muss sich also als Lernende verstehen und dies ihren Mitarbeitern auch signalisieren – unter anderem, indem sie erkennbar über das Verringern ihrer eigenen weißen Flecken lernt, den Wert zu schätzen, dass ihre Mitarbeiter anders als sie selbst sind. Denn nur dann ist auf Dauer ein von wechselseitigem Vertrauen geprägtes Miteinander auf Augenhöhe und kollektives Lernen möglich. Prämien und Anerkennung vom Chef Foto: fizkes – shutterstock.com Ein gutes Betriebsklima ist das A und O für den Erfolg eines Unternehmens sowie die Mitarbeiterbindung. Grund genug, sich als Chef und HR-Abteilung Gedanken über die Motivation der Angestellten zu machen. Benefit-Berater Markus Sobau nennt die sieben größten Mitarbeiterwünsche. Flexible Arbeitszeiten Foto: Black Salmon – shutterstock.com Besonders ausgeprägt ist der Wunsch nach flexiblen Arbeitszeiten. Jeder zweite Beschäftigte möchte selbst entscheiden können, wann er wie viel arbeitet. Home-Office Foto: Zivica Kerkez – shutterstock.com Ein Drittel der Beschäftigten möchte zu Hause arbeiten. Übernimmt der Arbeitgeber für das Arbeiten im Home-Office die Kosten für die nötige Infrastruktur, ist das Interesse an Heimarbeit sogar noch größer. Mehr brutto vom Netto Foto: Bernd Leitner Fotodesign – shutterstock.com Ein höheres Gehalt motiviert allen Unkenrufen zum Trotz doch – vorzugsweise, wenn es sich netto auswirkt. Das geht elegant über eine Firmen-Card. Auf diese können Arbeitgeber monatlich 50 Euro überweisen. Der Betrag steht dem Mitarbeiter netto als Sachbezug zur Verfügung. Er kann damit essen gehen, sein Auto tanken oder das Geld sparen. So ein Benefit ist mehr wert als eine Gehaltserhöhung von 100 Euro, die versteuert werden muss. Altersvorsorge Foto: PhotographyByMK – shutterstock.com Viele Mitarbeiter wünschen sich, dass der Chef bei der Altersvorsorge hilft. Firmen sollten daher eine betriebliche Altersvorsorge anbieten. Für Beiträge, die sie in die private Rente der Mitarbeiter überweisen, entfallen anteilige Sozialversicherungsbeiträge. Legt der Chef diese 20 Prozent als Zuschuss oben drauf, ist das auch eine gute Investition in das Betriebsklima. Gesundheitsvorsorge Foto: Mathias Rosenthal – shutterstock.com Liegt einem Unternehmen die Gesundheit seiner Mitarbeiter besonders am Herzen, ist eine betriebliche Krankenversicherung ein guter Tipp. Sie spart dem Arbeitnehmer etwa die Ausgaben für Brille, Zahnersatz oder Heilpraktiker-Behandlung. Vorteil für den Arbeitgeber: Er kann die Versicherung zunächst für ein Jahr abschließen, etwa als Bonus für erfolgreiche Mitarbeiter, und später bei Bedarf verlängern. Kredit vom Chef Foto: Bartolomiej Pietrzyk – shutterstock.com Unternehmen erhalten aufgrund ihrer oft großen Kreditvolumina und der nötigen Bonität günstige Zinskonditionen. Diese können sie an ihre Leute weitergeben. So bezahlt der Mitarbeiter statt elf Prozent Überziehungszins bei seiner Hausbank vier Prozent an seinen Chef. Selbständiges Arbeiten Foto: keport – shutterstock.com Mitarbeiter legen Wert darauf, dass Chefs ihnen vertrauen und zutrauen, die gestellten Aufgaben eigenverantwortlich zu erledigen. Im Sinne einer agilen Unternehmenskultur wollen sie Aufgaben auf Basis vereinbarter Leitplanken wie Umsatzerlöse, Renditeziele oder Produktinnovationen eigenständig entwickeln.",
    "source": "cio",
    "crawled_at": "2025-05-27T08:10:55.174101+00:00"
  },
  {
    "url": "https://www.cio.de/article/3991899/wirtschaftsweise-senken-die-prognose-fur-deutschland.html",
    "title": "Wirtschaftsweise senken die Prognose für Deutschland",
    "published": "2025-05-21T07:00:00+00:00",
    "author": "",
    "text": "michelsass – shutterstock.com Die deutsche Wirtschaft tritt weiter auf der Stelle – das dürfte sich auch unter der neuen Bundesregierung so schnell nicht ändern. Die “Wirtschaftsweisen” senken ihre Konjunkturprognose für dieses Jahr und erwarten für 2025 nur eine Stagnation des Bruttoinlandsprodukts. Im Herbst hatte der Sachverständigenrat noch mit einem Wachstum von 0,4 Prozent gerechnet. Die deutsche Wirtschaft befinde sich weiterhin in einer “ausgeprägten Schwächephase”, teilte das fünfköpfige Gremium in Berlin mit. 2026 könnte sich die Konjunktur etwas erholen, mit einem Plus von einem Prozent Wachstum. Doch ob Deutschland auch mittel- und langfristig zurück in die wirtschaftliche Erfolgsspur findet, ist aus Sicht der Experten alles andere als sicher. Nach zwei Rezessionsjahren in Folge hatte vor einem Monat der damalige Wirtschaftsminister Robert Habeck (Grüne) die Prognose der Regierung bereits heruntergeschraubt. Auch Habeck hatte nur eine Stagnation des Bruttoinlandsprodukts erwartet und für 2026 ein Wachstum von 1,0 Prozent. Aus Sicht der “Wirtschaftsweisen” bremsen bürokratische Anforderungen und lange Genehmigungsverfahren das Wachstum. Auch die unberechenbare und sprunghafte Zollpolitik von US-Präsident Donald Trump belaste die exportorientierte deutsche Wirtschaft. Der dadurch beschleunigte Strukturwandel werde in Zukunft auch Branchen und Regionen in Deutschland erreichen, die bisher wirtschaftsstark waren, wie es im Frühjahrsgutachten heißt. Die wirtschaftliche Schwäche zeige sich am Arbeitsmarkt, heißt es im Gutachten. Im April war die Frühjahrsbelebung laut Bundesagentur für Arbeit vergleichsweise schwach ausgefallen. Die “Wirtschaftsweisen” rechnen damit, dass die Arbeitslosenquote im Jahr 2025 auf 6,2 Prozent steigt. Die Inflation geht laut Prognose in diesem und im kommenden Jahr voraussichtlich weiter leicht zurück: 2025 auf durchschnittlich 2,1 Prozent, 2026 auf 2,0 Prozent. Diese Prognose sei allerdings noch “mit großer Unsicherheit behaftet”, so die Wirtschaftsweise Veronika Grimm. Handelskonflikte könnten die Preise erneut in Bewegung bringen, sowohl nach oben, als auch nach unten. Auch voluminöse Ausgabenprogramme der Bundesregierung könnten die inländische Nachfrage ankurbeln und die Preise wieder schneller in die Höhe treiben. Die neue Bundesregierung aus Union und SPD will die Wirtschaft mit verschiedenen Maßnahmen entlasten. Für mehr Wachstum soll auch das 500 Milliarden schwere, kreditfinanzierte Paket für zusätzliche Investitionen in Infrastruktur und Klimaschutz sorgen. Die “Wirtschaftsweisen” halten es für entscheidend, wie die Mittel konkret eingesetzt werden: Je mehr in zusätzliche öffentliche Investitionen fließe, desto größer seien die langfristigen Wachstumseffekte, heißt es im Frühjahrsgutachten. “Das Finanzpaket bietet eine große Chance: Richtig eingesetzt können die Mittel Deutschland zukunftsfähig machen und die Volkswirtschaft wieder auf einen höheren Wachstumspfad führen”, sagte Ratsmitglied Achim Truger. Um zu verhindern, dass die Mittel aus dem Paket für Konsum oder für bereits fest verplante Haushaltsposten ausgegeben werden, fordern die “Wirtschaftsweisen” die Regierung zu klaren gesetzlichen Leitplanken auf. So solle gesetzlich festgeschrieben werden, dass mindestens zehn Prozent des Kernhaushalts in Investitionen fließen müssen. Experten zufolge droht Deutschland mit dem Milliarden-Finanzpaket für Verteidigung und Infrastruktur die EU-Schuldenvorgaben nicht einzuhalten. Die “Wirtschaftsweisen” schreiben, die Kompatibilität des Finanzpakets mit den EU-Fiskalregeln unterliege “hoher Unsicherheit”. Realistischerweise könne sie nur mit einer starken Investitionsorientierung und begleitenden Strukturreformen erreicht werden. Neben Investitionen sehen die Ökonomen auch beim Bürokratieabbau erheblichen Nachholbedarf. Dieser müsse endlich Fahrt aufnehmen. Wirtschaftsverbände sehen Bürokratielasten wie das Lieferkettengesetz als einen der wesentlichen Gründe für die Konjunkturflaute. Die “Wirtschaftsweisen” schlagen unter anderem weniger Informationspflichten, schnellere Antrags- und Genehmigungsverfahren und eine Digitalisierung der öffentlichen Verwaltung vor. Ziel sei es, nicht nur bestehende Auflagen zu verringern, sondern auch einem erneuten Bürokratieanstieg vorzubeugen. “Gesetze, bei denen unklar ist, ob sie das gesteckte Ziel erreichen, und die hohe Kosten verursachen, sind zu hinterfragen”, sagte Ratsmitglied Martin Werding. Die Sachverständigen fordern die Regierung zu einem neuen Kurs in der Wirtschaftspolitik auf. “Eine Wirtschaftspolitik, die darauf setzt, den Strukturwandel mit Subventionen aufzuhalten, kann auf Dauer nicht erfolgreich sein”, sagte die Ratsvorsitzende Monika Schnitzer. Statt Arbeitsplätze zu erhalten, die langfristig “nicht überlebensfähig” seien, solle man gezielt den Übergang in neue Geschäftsmodelle und Berufe fördern, etwa durch Investitionen in ein modernes Straßen- und Schienennetz, in digitale Infrastruktur oder in Forschung, von der möglichst viele Branchen profitieren. (dpa/rs) michelsass – shutterstock.com Die deutsche Wirtschaft tritt weiter auf der Stelle – das dürfte sich auch unter der neuen Bundesregierung so schnell nicht ändern. Die “Wirtschaftsweisen” senken ihre Konjunkturprognose für dieses Jahr und erwarten für 2025 nur eine Stagnation des Bruttoinlandsprodukts. Im Herbst hatte der Sachverständigenrat noch mit einem Wachstum von 0,4 Prozent gerechnet. Die deutsche Wirtschaft befinde sich weiterhin in einer “ausgeprägten Schwächephase”, teilte das fünfköpfige Gremium in Berlin mit. 2026 könnte sich die Konjunktur etwas erholen, mit einem Plus von einem Prozent Wachstum. Doch ob Deutschland auch mittel- und langfristig zurück in die wirtschaftliche Erfolgsspur findet, ist aus Sicht der Experten alles andere als sicher. Nach zwei Rezessionsjahren in Folge hatte vor einem Monat der damalige Wirtschaftsminister Robert Habeck (Grüne) die Prognose der Regierung bereits heruntergeschraubt. Auch Habeck hatte nur eine Stagnation des Bruttoinlandsprodukts erwartet und für 2026 ein Wachstum von 1,0 Prozent. Aus Sicht der “Wirtschaftsweisen” bremsen bürokratische Anforderungen und lange Genehmigungsverfahren das Wachstum. Auch die unberechenbare und sprunghafte Zollpolitik von US-Präsident Donald Trump belaste die exportorientierte deutsche Wirtschaft. Der dadurch beschleunigte Strukturwandel werde in Zukunft auch Branchen und Regionen in Deutschland erreichen, die bisher wirtschaftsstark waren, wie es im Frühjahrsgutachten heißt. Die wirtschaftliche Schwäche zeige sich am Arbeitsmarkt, heißt es im Gutachten. Im April war die Frühjahrsbelebung laut Bundesagentur für Arbeit vergleichsweise schwach ausgefallen. Die “Wirtschaftsweisen” rechnen damit, dass die Arbeitslosenquote im Jahr 2025 auf 6,2 Prozent steigt. Die Inflation geht laut Prognose in diesem und im kommenden Jahr voraussichtlich weiter leicht zurück: 2025 auf durchschnittlich 2,1 Prozent, 2026 auf 2,0 Prozent. Diese Prognose sei allerdings noch “mit großer Unsicherheit behaftet”, so die Wirtschaftsweise Veronika Grimm. Handelskonflikte könnten die Preise erneut in Bewegung bringen, sowohl nach oben, als auch nach unten. Auch voluminöse Ausgabenprogramme der Bundesregierung könnten die inländische Nachfrage ankurbeln und die Preise wieder schneller in die Höhe treiben. Die neue Bundesregierung aus Union und SPD will die Wirtschaft mit verschiedenen Maßnahmen entlasten. Für mehr Wachstum soll auch das 500 Milliarden schwere, kreditfinanzierte Paket für zusätzliche Investitionen in Infrastruktur und Klimaschutz sorgen. Die “Wirtschaftsweisen” halten es für entscheidend, wie die Mittel konkret eingesetzt werden: Je mehr in zusätzliche öffentliche Investitionen fließe, desto größer seien die langfristigen Wachstumseffekte, heißt es im Frühjahrsgutachten. “Das Finanzpaket bietet eine große Chance: Richtig eingesetzt können die Mittel Deutschland zukunftsfähig machen und die Volkswirtschaft wieder auf einen höheren Wachstumspfad führen”, sagte Ratsmitglied Achim Truger. Um zu verhindern, dass die Mittel aus dem Paket für Konsum oder für bereits fest verplante Haushaltsposten ausgegeben werden, fordern die “Wirtschaftsweisen” die Regierung zu klaren gesetzlichen Leitplanken auf. So solle gesetzlich festgeschrieben werden, dass mindestens zehn Prozent des Kernhaushalts in Investitionen fließen müssen. Experten zufolge droht Deutschland mit dem Milliarden-Finanzpaket für Verteidigung und Infrastruktur die EU-Schuldenvorgaben nicht einzuhalten. Die “Wirtschaftsweisen” schreiben, die Kompatibilität des Finanzpakets mit den EU-Fiskalregeln unterliege “hoher Unsicherheit”. Realistischerweise könne sie nur mit einer starken Investitionsorientierung und begleitenden Strukturreformen erreicht werden. Neben Investitionen sehen die Ökonomen auch beim Bürokratieabbau erheblichen Nachholbedarf. Dieser müsse endlich Fahrt aufnehmen. Wirtschaftsverbände sehen Bürokratielasten wie das Lieferkettengesetz als einen der wesentlichen Gründe für die Konjunkturflaute. Die “Wirtschaftsweisen” schlagen unter anderem weniger Informationspflichten, schnellere Antrags- und Genehmigungsverfahren und eine Digitalisierung der öffentlichen Verwaltung vor. Ziel sei es, nicht nur bestehende Auflagen zu verringern, sondern auch einem erneuten Bürokratieanstieg vorzubeugen. “Gesetze, bei denen unklar ist, ob sie das gesteckte Ziel erreichen, und die hohe Kosten verursachen, sind zu hinterfragen”, sagte Ratsmitglied Martin Werding. Die Sachverständigen fordern die Regierung zu einem neuen Kurs in der Wirtschaftspolitik auf. “Eine Wirtschaftspolitik, die darauf setzt, den Strukturwandel mit Subventionen aufzuhalten, kann auf Dauer nicht erfolgreich sein”, sagte die Ratsvorsitzende Monika Schnitzer. Statt Arbeitsplätze zu erhalten, die langfristig “nicht überlebensfähig” seien, solle man gezielt den Übergang in neue Geschäftsmodelle und Berufe fördern, etwa durch Investitionen in ein modernes Straßen- und Schienennetz, in digitale Infrastruktur oder in Forschung, von der möglichst viele Branchen profitieren. (dpa/rs)",
    "source": "cio",
    "crawled_at": "2025-05-27T08:10:55.250128+00:00"
  },
  {
    "url": "https://www.cio.de/article/3991790/unternehmenssterben-steigt-auf-hoechststand-seit-2011.html",
    "title": "Unternehmenssterben steigt auf Höchststand seit 2011",
    "published": "2025-05-21T07:12:32+00:00",
    "author": "",
    "text": "Michael Bihlmayer – shutterstock.com Fehlende Nachfolger und andere Probleme: Immer mehr Unternehmen in Deutschland werfen das Handtuch. Die Zahl der Unternehmensschließungen lag im vergangenen Jahr bei 196.100 – das waren 16 Prozent mehr als 2023, wie die Auskunftei Creditreform und das Zentrum für Europäische Wirtschaftsforschung (ZEW) mitteilten . So hoch war die Zahl der Schließungen seit 2011 nicht mehr gewesen – damals sorgten die Folgen der Finanzkrise für Bremsspuren in Deutschlands Wirtschaft. “Die Schließungszahlen sind in allen Wirtschaftsbereichen alarmierend”, sagt der Creditreform-Wirtschaftsforscher Patrik-Ludwig Hantzsch. “Vor allem die Industriebetriebe leiden unter den hohen Energiekosten in der Produktion, während der Wettbewerbsdruck durch ausländische Anbieter steigt.” In den energieintensiven Wirtschaftsbereichen wurden 1.050 Betriebsschließungen gezählt und damit 26 Prozent mehr als 2023. Auch im Bereich “IT, Produktentwicklung, Umwelttechnik und Diagnostik” nahm die Zahl der Schließungen um etwa ein Viertel zu. ZEW-Forscherin Sandra Gottschalk weist darauf hin, dass dieser Wirtschaftsbereich eigentlich wachsen müsste, da er eine Zukunftsbranche sei. Doch wegen eines gravierenden Fachkräftemangels konkurrierten Unternehmen um knappe Ressourcen. “Das führt dazu, dass nicht genug Aufträge angenommen werden können, um wirtschaftlich zu arbeiten.” Auch in der Pharma- und Chemie-Industrie war die Zahl der Schließungen ungewöhnlich hoch. Bei den Schließungen geht es häufig um kleine inhabergeführte Betriebe, in den vergangenen Jahren waren es aber auch immer mehr größere Unternehmen. Beispiel: Ein Hotel stellt den Betrieb ein. Es ist in die Jahre gekommen und hat einen Investitionsstau, es liegt aber in guter Lage. Ein Immobilienunternehmen kauft das Grundstück, reißt das Gebäude ab und baut neue Wohnungen auf dem Grundstück. Diese werden an Privatleute verkauft. Mit Unternehmensschließung gemeint sind nicht nur Insolvenzen, sondern auch mehr oder minder freiwillige Geschäftsaufgaben – etwa wenn ein Firmeninhaber partout keinen Nachfolger findet und endlich in den Ruhestand gehen möchte. Außerdem gibt es Fälle, in denen ein Unternehmen zwar noch profitabel ist, die langfristige Perspektive aber düster. Hinzu kommen Todes- oder Krankheitsfälle, was eine Fortführung der Geschäfte unmöglich macht. Das Statistische Bundesamt hatte sich im Februar zu dem Thema ebenfalls zu Wort gemeldet. Den Statistikern zufolge wurden in Deutschland im vergangenen Jahr mehr Betriebe gegründet als aufgegeben. Allerdings ging es hierbei nur um größere beziehungsweise relativ wichtige Unternehmen. (dpa/rs) Michael Bihlmayer – shutterstock.com Fehlende Nachfolger und andere Probleme: Immer mehr Unternehmen in Deutschland werfen das Handtuch. Die Zahl der Unternehmensschließungen lag im vergangenen Jahr bei 196.100 – das waren 16 Prozent mehr als 2023, wie die Auskunftei Creditreform und das Zentrum für Europäische Wirtschaftsforschung (ZEW) mitteilten . So hoch war die Zahl der Schließungen seit 2011 nicht mehr gewesen – damals sorgten die Folgen der Finanzkrise für Bremsspuren in Deutschlands Wirtschaft. “Die Schließungszahlen sind in allen Wirtschaftsbereichen alarmierend”, sagt der Creditreform-Wirtschaftsforscher Patrik-Ludwig Hantzsch. “Vor allem die Industriebetriebe leiden unter den hohen Energiekosten in der Produktion, während der Wettbewerbsdruck durch ausländische Anbieter steigt.” In den energieintensiven Wirtschaftsbereichen wurden 1.050 Betriebsschließungen gezählt und damit 26 Prozent mehr als 2023. Auch im Bereich “IT, Produktentwicklung, Umwelttechnik und Diagnostik” nahm die Zahl der Schließungen um etwa ein Viertel zu. ZEW-Forscherin Sandra Gottschalk weist darauf hin, dass dieser Wirtschaftsbereich eigentlich wachsen müsste, da er eine Zukunftsbranche sei. Doch wegen eines gravierenden Fachkräftemangels konkurrierten Unternehmen um knappe Ressourcen. “Das führt dazu, dass nicht genug Aufträge angenommen werden können, um wirtschaftlich zu arbeiten.” Auch in der Pharma- und Chemie-Industrie war die Zahl der Schließungen ungewöhnlich hoch. Bei den Schließungen geht es häufig um kleine inhabergeführte Betriebe, in den vergangenen Jahren waren es aber auch immer mehr größere Unternehmen. Beispiel: Ein Hotel stellt den Betrieb ein. Es ist in die Jahre gekommen und hat einen Investitionsstau, es liegt aber in guter Lage. Ein Immobilienunternehmen kauft das Grundstück, reißt das Gebäude ab und baut neue Wohnungen auf dem Grundstück. Diese werden an Privatleute verkauft. Mit Unternehmensschließung gemeint sind nicht nur Insolvenzen, sondern auch mehr oder minder freiwillige Geschäftsaufgaben – etwa wenn ein Firmeninhaber partout keinen Nachfolger findet und endlich in den Ruhestand gehen möchte. Außerdem gibt es Fälle, in denen ein Unternehmen zwar noch profitabel ist, die langfristige Perspektive aber düster. Hinzu kommen Todes- oder Krankheitsfälle, was eine Fortführung der Geschäfte unmöglich macht. Das Statistische Bundesamt hatte sich im Februar zu dem Thema ebenfalls zu Wort gemeldet. Den Statistikern zufolge wurden in Deutschland im vergangenen Jahr mehr Betriebe gegründet als aufgegeben. Allerdings ging es hierbei nur um größere beziehungsweise relativ wichtige Unternehmen. (dpa/rs)",
    "source": "cio",
    "crawled_at": "2025-05-27T08:10:55.331072+00:00"
  },
  {
    "url": "https://www.cio.de/article/3991811/eu-kommission-prueft-abgaben-fur-temu-pakete.html",
    "title": "EU-Kommission prüft Abgaben für Temu-Pakete",
    "published": "2025-05-21T07:22:00+00:00",
    "author": "",
    "text": "Audio und werbung – shutterstock.com Angesichts einer rasant steigenden Zahl von Paketen aus Drittstaaten erwägt die EU-Kommission eine Pauschalabgabe von bis zu zwei Euro auf entsprechende Bestellungen. Einem Papier der Brüsseler Behörde zufolge sollen damit unter anderem “erhöhte Überwachungskosten” gedeckt werden. Laut EU-Kommission sind im vergangenen Jahr täglich rund zwölf Millionen Pakete in der EU angekommen – deutlich mehr als in den beiden Vorjahren. Nach Angaben der Vorsitzenden des Binnenmarktausschusses im EU-Parlament, Anna Cavazzini, seien von der Abgabe insbesondere E-Commerce-Giganten wie Temu und Shein betroffen. “Das Phänomen der Einzelpakete mit niedrigstem Wert ist jung und wächst durch Billigst-Marktplätze wie Shein und Temu unaufhörlich”, so die Grünen-Politikerin. Das europäische System aus Zoll und Marktüberwachung sei nie darauf ausgelegt gewesen. Temu ist ein Online-Marktplatz – also ein Portal, auf dem zahlreiche Unternehmen verschiedene Waren verkaufen. Das chinesische Unternehmen ist seit Frühjahr 2023 in Deutschland aktiv und sorgt immer wieder mit Minipreisen und hohen Rabatten für Aufsehen. Produkte werden häufig direkt vom Hersteller zum Kunden geliefert. Der in China gegründete und heute in Singapur ansässige Modekonzern Shein ist sowohl Hersteller, Händler als auch Marktplatz. Als Direktanbieter kann er Handelsexperten zufolge schnell auf Modetrends reagieren. Da Shein seine Produkte weltweit versendet und es keine Geschäfte und kaum Lagerbestände gibt, kann Shein seine Preise extrem niedrig halten. (dpa/rs) Audio und werbung – shutterstock.com Angesichts einer rasant steigenden Zahl von Paketen aus Drittstaaten erwägt die EU-Kommission eine Pauschalabgabe von bis zu zwei Euro auf entsprechende Bestellungen. Einem Papier der Brüsseler Behörde zufolge sollen damit unter anderem “erhöhte Überwachungskosten” gedeckt werden. Laut EU-Kommission sind im vergangenen Jahr täglich rund zwölf Millionen Pakete in der EU angekommen – deutlich mehr als in den beiden Vorjahren. Nach Angaben der Vorsitzenden des Binnenmarktausschusses im EU-Parlament, Anna Cavazzini, seien von der Abgabe insbesondere E-Commerce-Giganten wie Temu und Shein betroffen. “Das Phänomen der Einzelpakete mit niedrigstem Wert ist jung und wächst durch Billigst-Marktplätze wie Shein und Temu unaufhörlich”, so die Grünen-Politikerin. Das europäische System aus Zoll und Marktüberwachung sei nie darauf ausgelegt gewesen. Temu ist ein Online-Marktplatz – also ein Portal, auf dem zahlreiche Unternehmen verschiedene Waren verkaufen. Das chinesische Unternehmen ist seit Frühjahr 2023 in Deutschland aktiv und sorgt immer wieder mit Minipreisen und hohen Rabatten für Aufsehen. Produkte werden häufig direkt vom Hersteller zum Kunden geliefert. Der in China gegründete und heute in Singapur ansässige Modekonzern Shein ist sowohl Hersteller, Händler als auch Marktplatz. Als Direktanbieter kann er Handelsexperten zufolge schnell auf Modetrends reagieren. Da Shein seine Produkte weltweit versendet und es keine Geschäfte und kaum Lagerbestände gibt, kann Shein seine Preise extrem niedrig halten. (dpa/rs)",
    "source": "cio",
    "crawled_at": "2025-05-27T08:10:55.415761+00:00"
  },
  {
    "url": "https://www.cio.de/article/3991835/google-blast-zum-angriff-bei-kuenstlicher-intelligenz.html",
    "title": "So tarnt Google Kontrolle als KI",
    "published": "2025-05-21T07:48:00+00:00",
    "author": "",
    "text": "photosince – shutterstock.com Chatbots wie ChatGPT haben Google zuletzt oft in den Schatten gestellt – doch der Internet-Riese geht jetzt zum Gegenangriff über. Auf der Entwicklerkonferenz Google I/O zeigte der Konzern seine Vision, wie seine Künstliche Intelligenz die Nutzer im Alltag auf Schritt und Tritt begleiten und ihnen das Leben erleichtern soll. Eine zentrale Rolle spielen dabei auch Kameras von Smartphones und Computer-Brillen, dank denen die KI sehen kann, worauf der Mensch gerade schaut. Das Herzstück des Plans heißt Gemini – Googles Antwort auf ChatGPT und Co. Unter der Haube von Gemini steckt ein Wirrwarr von KI-Modellen für verschiedene Aufgaben von der personalisierten Websuche bis zur automatisierten Kaufberatung. Google-Manager ließen bei der I/O keinen Zweifel an den Ambitionen des Konzerns. “Die ultimative Vision für die Gemini-App ist, sie in ein universelles KI-System umzuwandeln”, sagte etwa der für Künstliche Intelligenz zuständige Topmanager Demis Hassabis. Dieses KI-System soll auf die Nutzer zugeschnitten sein und ihnen seine Dienste proaktiv anbieten, statt nur auf ihre Anfragen zu reagieren. Die Basis für Googles Vorstoß ist die Rolle als seit Jahren dominierende Suchmaschine, die so gut wie alle Informationen im Netz erfasst und einen direkten Draht zu den Nutzern hat. Im Wettbewerb mit den neuen KI-Rivalen bessert Google seine Websuche zugleich mit Künstlicher Intelligenz auf. Die Vision ist, dass man statt einer Liste von Weblinks häufiger ausführlichere Antworten bekommt und auch weitere Nachfragen dazu stellen kann. Den ersten Schritt in diese Richtung machte Google vor einem Jahr mit der KI-Zusammenfassung von Informationen oberhalb der anderen Suchergebnisse. Diese Funktion, die in Deutschland “Übersicht mit KI” heißt, erreicht bereits mehr als 1,5 Milliarden Nutzer, sagte Konzernchef Sundar Pichai. Die nächste Stufe ist der KI-Modus, der ausführlichere und argumentierte Antworten auf Suchanfragen geben kann. So könnte der KI-Modus zum Beispiel lernen, bei der Suche nach einem Hausgerät die Kaufberatung zu übernehmen. Schaut man sich nach einer Wohnung oder Tickets für ein Event um, soll die Software in der Lage sein, eigenständig das Web zu durchsuchen, um die beste Auswahl zu finden. Wenn man das wolle, könnte das Programm in diesem sogenannten “Agent Mode” auch gleich den Besichtigungstermin für ein Apartment buchen. Hat man einen Preisalarm zur Produktsuche eingerichtet, soll Gemini auch zuschlagen können. In einer anderen Demo zeigte Google, wie KI bei der Reparatur eines Fahrrads helfen soll. Dabei kann man Gemini nicht nur nach passenden Ersatzteilen fragen und bitten, sie zu besorgen, sondern auch die Kamera des Smartphones auf einzelne Schrauben richten und fragen, welches Werkzeug man dafür braucht. Damit die Hände frei bleiben, soll diese Rolle die Kamera in Computer-Brillen übernehmen. Google zeigte auf der I/O auch Prototypen schlanker Brillen, die Informationen ins Blickfeld der Nutzer einblenden können. Wann die Geräte auf den Markt kommen könnten, ist allerdings offen. Google beherrscht seit mehr als zwei Jahrzehnten die Internet-Suche. Inzwischen greifen Nutzer aber auch zu KI-Chatbots wie ChatGPT oder Perplexity. Während Google zumindest teilweise immer noch vor allem eine Liste von Weblinks als Ergebnis präsentiert, konzentrieren sich die neuen Rivalen darauf, direkte Antworten zu liefern. Ob Google bereits darunter leidet, ist unklar. Der Konzern verdient sein Geld vor allem mit Werbung im Umfeld der Websuche – und das Geschäft wuchs zuletzt weiter. Zugleich sorgte Apple-Topmanager Eddy Cue zuletzt für ein kleines Erdbeben, als er vor Gericht aussagte, die Google-Anfragen aus dem Safari-Webbrowser des iPhone-Konzerns seien zuletzt erstmals zurückgegangen. Google konterte, von Apple-Geräten insgesamt sehe man weiterhin ein Plus. Auch im KI-Modus waren am Bildschirmrand gegen Geld platzierte Links von Werbekunden zu sehen – die Werbeerlöse müssen schließlich weiter fließen. Den Branchenanalysten Gene Munster machte das skeptisch: “Ich glaube nicht, dass eine in Werbung eingewickelte einfache Antwort das ist, was die Verbraucher wollen.” Die Nutzer sollen die Suche stärker dadurch personalisieren können, dass sie der KI Zugang zu ihren Google-Apps wie Gmail gewähren. Sei man auf Reisen, würde die Software dann etwa den Besuch einer Kunstgalerie empfehlen, weil sie dank abonnierter Newsletter wisse, dass man daran interessiert sei. Aus früheren Suchanfragen könnte sie zum Beispiel auch wissen, dass man in Restaurants bevorzugt draußen sitze. Einige neue Funktionen kommen zunächst nur in den USA heraus oder im experimentellen Bereich Google Labs, der in Deutschland bisher nicht verfügbar ist. Andere werden vorerst im Abo Google AI Ultra angeboten, das es zunächst in den USA zum Preis von rund 250 Dollar im Monat gibt. KI steht auch im Mittelpunkt anderer Google-Ankündigungen bei der I/O. So steigt der Konzern ins Geschäft mit der virtuellen Anprobe ein. Die Software versucht dabei, mit dem Wissen über den Körperbau der Nutzer und das Material der Kleidung so gut wie möglich zu berechnen, wie die Stücke sitzen werden. Mit Veo 3 verbessert Google seine KI-Software, die Videos generiert, so dass sie auch für den professionellen Einsatz geeignet sein soll. Das Modell kann erstmals auch automatisch die passenden Töne zum Bild erzeugen. (dpa/rs) photosince – shutterstock.com Chatbots wie ChatGPT haben Google zuletzt oft in den Schatten gestellt – doch der Internet-Riese geht jetzt zum Gegenangriff über. Auf der Entwicklerkonferenz Google I/O zeigte der Konzern seine Vision, wie seine Künstliche Intelligenz die Nutzer im Alltag auf Schritt und Tritt begleiten und ihnen das Leben erleichtern soll. Eine zentrale Rolle spielen dabei auch Kameras von Smartphones und Computer-Brillen, dank denen die KI sehen kann, worauf der Mensch gerade schaut. Das Herzstück des Plans heißt Gemini – Googles Antwort auf ChatGPT und Co. Unter der Haube von Gemini steckt ein Wirrwarr von KI-Modellen für verschiedene Aufgaben von der personalisierten Websuche bis zur automatisierten Kaufberatung. Google-Manager ließen bei der I/O keinen Zweifel an den Ambitionen des Konzerns. “Die ultimative Vision für die Gemini-App ist, sie in ein universelles KI-System umzuwandeln”, sagte etwa der für Künstliche Intelligenz zuständige Topmanager Demis Hassabis. Dieses KI-System soll auf die Nutzer zugeschnitten sein und ihnen seine Dienste proaktiv anbieten, statt nur auf ihre Anfragen zu reagieren. Die Basis für Googles Vorstoß ist die Rolle als seit Jahren dominierende Suchmaschine, die so gut wie alle Informationen im Netz erfasst und einen direkten Draht zu den Nutzern hat. Im Wettbewerb mit den neuen KI-Rivalen bessert Google seine Websuche zugleich mit Künstlicher Intelligenz auf. Die Vision ist, dass man statt einer Liste von Weblinks häufiger ausführlichere Antworten bekommt und auch weitere Nachfragen dazu stellen kann. Den ersten Schritt in diese Richtung machte Google vor einem Jahr mit der KI-Zusammenfassung von Informationen oberhalb der anderen Suchergebnisse. Diese Funktion, die in Deutschland “Übersicht mit KI” heißt, erreicht bereits mehr als 1,5 Milliarden Nutzer, sagte Konzernchef Sundar Pichai. Die nächste Stufe ist der KI-Modus, der ausführlichere und argumentierte Antworten auf Suchanfragen geben kann. So könnte der KI-Modus zum Beispiel lernen, bei der Suche nach einem Hausgerät die Kaufberatung zu übernehmen. Schaut man sich nach einer Wohnung oder Tickets für ein Event um, soll die Software in der Lage sein, eigenständig das Web zu durchsuchen, um die beste Auswahl zu finden. Wenn man das wolle, könnte das Programm in diesem sogenannten “Agent Mode” auch gleich den Besichtigungstermin für ein Apartment buchen. Hat man einen Preisalarm zur Produktsuche eingerichtet, soll Gemini auch zuschlagen können. In einer anderen Demo zeigte Google, wie KI bei der Reparatur eines Fahrrads helfen soll. Dabei kann man Gemini nicht nur nach passenden Ersatzteilen fragen und bitten, sie zu besorgen, sondern auch die Kamera des Smartphones auf einzelne Schrauben richten und fragen, welches Werkzeug man dafür braucht. Damit die Hände frei bleiben, soll diese Rolle die Kamera in Computer-Brillen übernehmen. Google zeigte auf der I/O auch Prototypen schlanker Brillen, die Informationen ins Blickfeld der Nutzer einblenden können. Wann die Geräte auf den Markt kommen könnten, ist allerdings offen. Google beherrscht seit mehr als zwei Jahrzehnten die Internet-Suche. Inzwischen greifen Nutzer aber auch zu KI-Chatbots wie ChatGPT oder Perplexity. Während Google zumindest teilweise immer noch vor allem eine Liste von Weblinks als Ergebnis präsentiert, konzentrieren sich die neuen Rivalen darauf, direkte Antworten zu liefern. Ob Google bereits darunter leidet, ist unklar. Der Konzern verdient sein Geld vor allem mit Werbung im Umfeld der Websuche – und das Geschäft wuchs zuletzt weiter. Zugleich sorgte Apple-Topmanager Eddy Cue zuletzt für ein kleines Erdbeben, als er vor Gericht aussagte, die Google-Anfragen aus dem Safari-Webbrowser des iPhone-Konzerns seien zuletzt erstmals zurückgegangen. Google konterte, von Apple-Geräten insgesamt sehe man weiterhin ein Plus. Auch im KI-Modus waren am Bildschirmrand gegen Geld platzierte Links von Werbekunden zu sehen – die Werbeerlöse müssen schließlich weiter fließen. Den Branchenanalysten Gene Munster machte das skeptisch: “Ich glaube nicht, dass eine in Werbung eingewickelte einfache Antwort das ist, was die Verbraucher wollen.” Die Nutzer sollen die Suche stärker dadurch personalisieren können, dass sie der KI Zugang zu ihren Google-Apps wie Gmail gewähren. Sei man auf Reisen, würde die Software dann etwa den Besuch einer Kunstgalerie empfehlen, weil sie dank abonnierter Newsletter wisse, dass man daran interessiert sei. Aus früheren Suchanfragen könnte sie zum Beispiel auch wissen, dass man in Restaurants bevorzugt draußen sitze. Einige neue Funktionen kommen zunächst nur in den USA heraus oder im experimentellen Bereich Google Labs, der in Deutschland bisher nicht verfügbar ist. Andere werden vorerst im Abo Google AI Ultra angeboten, das es zunächst in den USA zum Preis von rund 250 Dollar im Monat gibt. KI steht auch im Mittelpunkt anderer Google-Ankündigungen bei der I/O. So steigt der Konzern ins Geschäft mit der virtuellen Anprobe ein. Die Software versucht dabei, mit dem Wissen über den Körperbau der Nutzer und das Material der Kleidung so gut wie möglich zu berechnen, wie die Stücke sitzen werden. Mit Veo 3 verbessert Google seine KI-Software, die Videos generiert, so dass sie auch für den professionellen Einsatz geeignet sein soll. Das Modell kann erstmals auch automatisch die passenden Töne zum Bild erzeugen. (dpa/rs)",
    "source": "cio",
    "crawled_at": "2025-05-27T08:10:55.495557+00:00"
  },
  {
    "url": "https://www.cio.de/article/3991893/china-und-usa-streiten-sich-um-ki-chips.html",
    "title": "China und USA streiten sich um KI-Chips",
    "published": "2025-05-21T07:57:00+00:00",
    "author": "",
    "text": "Anggalih Prasetya – shutterstock.com Im Zollstreit zwischen den USA und China gab es zuletzt eine Atempause – doch nun kommt neuer Ärger rund um den Handel mit KI-Chips auf. Peking protestiert scharf gegen US-Warnungen an Drittstaaten, keine fortschrittlichen Chips des chinesischen Tech-Konzerns Huawei zu kaufen. Das chinesische Handelsministerium bezeichnete eine entsprechende US-Richtlinie als “einseitiges Mobbing und Protektionismus”, das die globale Halbleiterindustrie und Lieferketten ernsthaft beeinträchtige. Die US-Regierung hatte kürzlich Unternehmen weltweit davor gewarnt, die sogenannten Ascend-KI-Chips des Konzerns aus dem südchinesischen Shenzhen zu verwenden. Ihre Nutzung könnte laut Washington gegen US-Exportkontrollen verstoßen. Das Handelsministerium in Peking warf den USA vor, anderen Ländern das Recht auf Entwicklung in Schlüsselbereichen wie Künstlicher Intelligenz und Hochtechnologie zu verwehren. Zudem könnten Organisationen oder Einzelpersonen, die diese US-Maßnahmen umsetzen oder unterstützen, nach chinesischem Recht zur Verantwortung gezogen werden. China forderte die USA auf, ihre “Fehlentscheidungen” umgehend zu korrigieren und internationale Wirtschafts- und Handelsregeln zu respektieren. Man werde die Entwicklungen genau beobachten und “entschlossen Maßnahmen” ergreifen, um die legitimen Rechte und Interessen chinesischer Unternehmen zu schützen. Die USA versuchen schon länger zu verhindern, dass fortschrittliche Chips des US-Konzerns Nvidia auf den chinesischen Markt gelangen. Huawei treibt daher die Entwicklung eigener KI-Chips mit Hochdruck voran. Mit den neuen US-Vorgaben könnte es für Huawei jedoch schwieriger werden, seine Chips in Drittstaaten zu verkaufen. Erst kürzlich hatten die USA und China in Genf eine vorübergehende Einigung zur Reduzierung von Zöllen in ihrem laufenden Handelsstreit erzielt. Die neuen US-Beschränkungen könnten diesen Fortschritt nach Ansicht einiger Beobachter nun gefährden. (dpa/rs) Anggalih Prasetya – shutterstock.com Im Zollstreit zwischen den USA und China gab es zuletzt eine Atempause – doch nun kommt neuer Ärger rund um den Handel mit KI-Chips auf. Peking protestiert scharf gegen US-Warnungen an Drittstaaten, keine fortschrittlichen Chips des chinesischen Tech-Konzerns Huawei zu kaufen. Das chinesische Handelsministerium bezeichnete eine entsprechende US-Richtlinie als “einseitiges Mobbing und Protektionismus”, das die globale Halbleiterindustrie und Lieferketten ernsthaft beeinträchtige. Die US-Regierung hatte kürzlich Unternehmen weltweit davor gewarnt, die sogenannten Ascend-KI-Chips des Konzerns aus dem südchinesischen Shenzhen zu verwenden. Ihre Nutzung könnte laut Washington gegen US-Exportkontrollen verstoßen. Das Handelsministerium in Peking warf den USA vor, anderen Ländern das Recht auf Entwicklung in Schlüsselbereichen wie Künstlicher Intelligenz und Hochtechnologie zu verwehren. Zudem könnten Organisationen oder Einzelpersonen, die diese US-Maßnahmen umsetzen oder unterstützen, nach chinesischem Recht zur Verantwortung gezogen werden. China forderte die USA auf, ihre “Fehlentscheidungen” umgehend zu korrigieren und internationale Wirtschafts- und Handelsregeln zu respektieren. Man werde die Entwicklungen genau beobachten und “entschlossen Maßnahmen” ergreifen, um die legitimen Rechte und Interessen chinesischer Unternehmen zu schützen. Die USA versuchen schon länger zu verhindern, dass fortschrittliche Chips des US-Konzerns Nvidia auf den chinesischen Markt gelangen. Huawei treibt daher die Entwicklung eigener KI-Chips mit Hochdruck voran. Mit den neuen US-Vorgaben könnte es für Huawei jedoch schwieriger werden, seine Chips in Drittstaaten zu verkaufen. Erst kürzlich hatten die USA und China in Genf eine vorübergehende Einigung zur Reduzierung von Zöllen in ihrem laufenden Handelsstreit erzielt. Die neuen US-Beschränkungen könnten diesen Fortschritt nach Ansicht einiger Beobachter nun gefährden. (dpa/rs)",
    "source": "cio",
    "crawled_at": "2025-05-27T08:10:55.689788+00:00"
  },
  {
    "url": "https://www.cio.de/article/3991929/google-zeigt-prototypen-einer-schlanken-ar-brille.html",
    "title": "Google zeigt Prototypen einer schlanken AR-Brille",
    "published": "2025-05-21T09:40:00+00:00",
    "author": "",
    "text": "Ground Picture | shutterstock.com Google hat neue Prototypen von Computer-Brillen vorgestellt, die Informationen ins Blickfeld der Nutzer einblenden können. In der Demonstration tauchten in der schlanken Brille etwa Routenanweisungen und Fotos auf. Auch konnten sich zwei Personen in verschiedenen Sprachen miteinander unterhalten. Die Brille blendete jeweils die Übersetzung in Englisch ein. “Untertitel für die reale Welt”, nennt das Google. Leichte Computer-Brillen mit sogenannter Erweiterter Realität (AR, Augmented Reality) sind seit Jahren ein Traum der Tech-Industrie. Der Konzern entwickelte für die Technik das Betriebssystem Android XR. Die Brillen sind zum Tragen über den gesamten Tag gedacht, betont Google. Neben Kameras haben sie auch ein Mikrofon sowie Lautsprecher und verbinden sich mit dem Smartphone. Die Google-KI Gemini könne damit “die Welt sehen”. Für ein Verbraucherprodukt arbeitet Google mit den Brillen-Anbietern Gentle Monster und Warby Parker zusammen, hieß es bei der Entwicklerkonferenz Google I/O. Unter anderem auch der Facebook-Konzern Meta arbeitet an einer solchen Brille. Auf dem Markt brachte das Unternehmen bisher Kamera-Brillen ohne Display heraus. Sie werden in Kooperation mit dem weltgrößten Brillenkonzern Luxottica unter der Marke Ray-ban verkauft. Auch Facebook-Gründer Mark Zuckerberg betont, der entscheidende Vorteil sei, dass die KI dadurch sehen und hören könne, was die Nutzer sehen und hören – und dadurch besser die Situation verstehe. Prototypen einer Brille mit Display hat Meta auch – sie wirken aber etwas klobiger als die von Google. Bei beiden Brillen ist unter anderem unklar, wie lange die Batterie bei Alltagsnutzung halten würde. Selbst die sparsamsten modernen Chips brauchen für solche Aufgaben relativ viel Strom – und ein Brillengestell hat verständlicherweise wenig Platz für Akkus. Apple forscht ebenfalls schon seit Jahren an Erweiterter Realität, bei der digitale Inhalte für den Nutzer in die reale Umgebung eingeblendet werden. Angesichts des Standes der Technologie bremste Apple jedoch Medienberichten zufolge die Entwicklung von AR-Brillen mit durchsichtigen Gläsern. Stattdessen brachte der Konzern das Headset Vision Pro heraus, bei dem Kameras die reale Umgebung filmen und für die Nutzer auf Displays vor den Augen wiedergeben. In diesem Bild werden dann auch die digitalen Elemente integriert. Mit einem Preis ab knapp 4.000 Euro ist die Brille deutlich teurer als Headsets der Konkurrenz. (dpa/rs) Ground Picture | shutterstock.com Google hat neue Prototypen von Computer-Brillen vorgestellt, die Informationen ins Blickfeld der Nutzer einblenden können. In der Demonstration tauchten in der schlanken Brille etwa Routenanweisungen und Fotos auf. Auch konnten sich zwei Personen in verschiedenen Sprachen miteinander unterhalten. Die Brille blendete jeweils die Übersetzung in Englisch ein. “Untertitel für die reale Welt”, nennt das Google. Leichte Computer-Brillen mit sogenannter Erweiterter Realität (AR, Augmented Reality) sind seit Jahren ein Traum der Tech-Industrie. Der Konzern entwickelte für die Technik das Betriebssystem Android XR. Die Brillen sind zum Tragen über den gesamten Tag gedacht, betont Google. Neben Kameras haben sie auch ein Mikrofon sowie Lautsprecher und verbinden sich mit dem Smartphone. Die Google-KI Gemini könne damit “die Welt sehen”. Für ein Verbraucherprodukt arbeitet Google mit den Brillen-Anbietern Gentle Monster und Warby Parker zusammen, hieß es bei der Entwicklerkonferenz Google I/O. Unter anderem auch der Facebook-Konzern Meta arbeitet an einer solchen Brille. Auf dem Markt brachte das Unternehmen bisher Kamera-Brillen ohne Display heraus. Sie werden in Kooperation mit dem weltgrößten Brillenkonzern Luxottica unter der Marke Ray-ban verkauft. Auch Facebook-Gründer Mark Zuckerberg betont, der entscheidende Vorteil sei, dass die KI dadurch sehen und hören könne, was die Nutzer sehen und hören – und dadurch besser die Situation verstehe. Prototypen einer Brille mit Display hat Meta auch – sie wirken aber etwas klobiger als die von Google. Bei beiden Brillen ist unter anderem unklar, wie lange die Batterie bei Alltagsnutzung halten würde. Selbst die sparsamsten modernen Chips brauchen für solche Aufgaben relativ viel Strom – und ein Brillengestell hat verständlicherweise wenig Platz für Akkus. Apple forscht ebenfalls schon seit Jahren an Erweiterter Realität, bei der digitale Inhalte für den Nutzer in die reale Umgebung eingeblendet werden. Angesichts des Standes der Technologie bremste Apple jedoch Medienberichten zufolge die Entwicklung von AR-Brillen mit durchsichtigen Gläsern. Stattdessen brachte der Konzern das Headset Vision Pro heraus, bei dem Kameras die reale Umgebung filmen und für die Nutzer auf Displays vor den Augen wiedergeben. In diesem Bild werden dann auch die digitalen Elemente integriert. Mit einem Preis ab knapp 4.000 Euro ist die Brille deutlich teurer als Headsets der Konkurrenz. (dpa/rs)",
    "source": "cio",
    "crawled_at": "2025-05-27T08:10:55.859465+00:00"
  },
  {
    "url": "https://www.cio.de/article/3828970/vorkonfigurierte-komplettsysteme-fur-ki-projekte.html",
    "title": "Vorkonfigurierte Komplettsysteme für KI-Projekte",
    "published": "2025-05-21T13:06:24+00:00",
    "author": "",
    "text": "Unternehmen wollen KI und Chatbots immer stärker in ihre Prozesse einbinden. Lokal trainierte Lösungen bieten hier schnelle Erfolge mit wenigen Klicks. Shutterstock.com – PeopleImages.com – Yuri A Eine Krankenhauskette möchte mittels generativer Künstlicher Intelligenz (KI) einen virtuellen Assistenten für ihre Belegschaft erstellen. Der Chatbot soll den Beschäftigten anhand der hauseigenen Informationsbestände zu unterschiedlichsten Fragen Auskunft geben, um ihnen zeitraubende Suchen in Unterlagen und im Intranet zu ersparen: Welche unserer Kliniken hat die größte Erfahrung mit Katarakt-Operationen? Was waren die fünf wichtigsten Punkte im heutigen Rundschreiben der Geschäftsführung? Wie ändert das neue Medizinforschungsgesetz den Ablauf unserer klinischen Studien? Welche unserer Ärzte haben die Zusatzqualifikation für Tropenmedizin? Und wann gibt es in der Kantine wieder Apfelstrudel? Die Klinikkette unseres fiktiven Beispiels hat eine zwanzigköpfige IT-Abteilung, einige der IT-Fachleute haben sich auch schon mit KI-Themen befasst. Das IT-Team hat kürzlich sogar eine Datenwissenschaftlerin angestellt, die den hauseigenen Datenbestand für KI-Einsatzzwecke aufbereiten soll. Aber dem Team fehlt das Know-how für das Training von KI-Basismodellen. Und es fehlt die Zeit, um herauszufinden, wie man die benötigte Hardware- und Software-Infrastruktur für den KI-Betrieb korrekt zusammenstellt, dimensioniert und konfiguriert. Was tun? Großunternehmen können sich ein dediziertes Team leisten, das ein KI-Basismodell trainiert, um es für die eigenen Belange maßzuschneidern. Die meisten Unternehmen bis hin zum gehobenen Mittelstand hingegen haben weder Fachkräfte noch Know-how oder Budget für einen derart aufwendigen Ansatz, das Potenzial von KI zu erschließen. Doch auch sie wissen: Generative KI wird künftig eine zentrale Rolle spielen, um Prozesse zu beschleunigen, neue Services anzubieten – und generell, um wettbewerbsfähig zu bleiben. Ein beliebtes Vorgehen wird deshalb darin bestehen, vortrainierte Modelle mit hauseigenen Datenbeständen für individuelle Einsatzfälle anzupassen. Das KI-Modell einfach in einer Public Cloud zu trainieren und zu betreiben, ist für viele Organisationen dabei keine Option. In einigen Organisationen verbieten Regularien dies, andere wollen die Hoheit über sensible und personenbezogene Daten nicht infrage stellen. Mit Blick auf die Datensouveränität werden Unternehmen deshalb vortrainierte Modelle in aller Regel lokal anpassen. Dafür benötigen sie eine Reihe von Hardware- und Softwarebausteinen, von Servern und Speichern bis hin zu KI-Analysetools. Deren Zusammenstellung zur in sich stimmigen KI-Trainings- und Betriebsumgebung war bislang ein zeitraubendes Unterfangen, oft erschwert durch einen weiteren Umstand: Auf KI spezialisierte Datenwissenschaftler sind keine IT-Betriebsexperten, das IT-Team wiederum müsste sich aber in die Anforderungen der KI-Lösungen erst einarbeiten. Den Aufbau einer KI-Umgebung erleichtern nun aber integrierte, speziell auf den Einsatz generativer KI ausgelegte Komplettpakete aus Hardware, Software und Services. Diese Angebote sind in verschiedenen Leistungsstufen erhältlich, um alles vom Pilotprojekt bis zum Training eines großen KI-Modells mit umfangreicher Datenbasis abzudecken. JETZT WHITEPAPER LESEN UND HPE PRIVATE CLOUD AI VERSTEHEN. Um möglichst schnell Projekterfolge zu erzielen, sollte ein solches KI-Komplettpaket vor allem Blaupausen umfassen, mit denen sich die häufigsten KI-Einsatzfälle mit wenigen Mausklicks verwirklichen lassen. HPE Private Cloud AI – eine Familie von KI-Komplettsystemen, die HPE gemeinsam mit dem KI-Vorreiter NVIDIA entwickelt hat – umfasst zu diesem Zweck neben von NVIDIA vortrainierten KI-Modellen auch sogenannte „Accelerators“ (Lösungsbeschleuniger). Diese ermöglichen es einem IT-Team, mit geringem Aufwand und nur grundlegendem KI-Know-how zügig folgende beliebte Szenarien umzusetzen: 1. Dokumentation: Ob klinische Studie, industrielle Fertigung oder Softwareentwicklung – im Laufe eines Projekts fällt ein Berg von Unterlagen an. Dieser will dann für die Dokumentation ausgewertet und aggregiert sein. Hier kann ein entsprechend trainierter KI-Assistent seine Stärken ausspielen: Er fasst große Dokumentenbestände zusammen und arrangiert die wichtigen Informationen zu einer stimmigen Projektdokumentation. 2. Code-Erzeugung: Bei der Softwareentwicklung können sich Entwicklungsteams heute viel Arbeit ersparen, indem sie Routineschritte an KI-Assistenten übergeben. Das beschleunigt Abläufe deutlich und vermeidet menschliche Fehler. Die Entwickler müssen nur noch die Qualität des erzeugten Codes kontrollieren. Insbesondere für diesen Einsatzfall ist die Zusammenarbeit von HPE mit NVIDIA von Bedeutung: Der Marktführer bei KI-Prozessoren setzt den Maßstab für performante Unterstützung selbst äußerst rechenintensiver Programmier- und KI-Aufgaben. 3. Wissensmanagement: In den Medien ist immer wieder von Fehlern zu lesen, die Chatbots wie ChatGPT machen, wenn man sie als Suchmaschine nutzt. Die Fehlerquelle liegt hier schlicht darin, dass die Datenbasis aus dem Internet stammt: Oft fehlt der Kontext zur Frage, ebenso die Qualitätskontrolle der Daten. Trainiert ein Unternehmen hingegen eine KI mit dem hauseigenen Informationsbestand (Retrieval-Augmented Generation, kurz RAG genannt), dann erweist sich ein KI-Assistent als verlässlicher Detektiv im unternehmenseigenen Wissensbestand. Dank lokalem Training und Betrieb bleibt die Datenhoheit stets gewahrt. 4. Virtueller Assistent für Beschäftigte: Diesem Anwendungsfall sind wir anfangs beim fiktiven Beispiel der Klinikkette schon begegnet. Ein KI-Assistent ist nicht nur in der Lage, Informationen zu finden oder Fragen zu beantworten. Vielmehr kann er auch Meeting-Protokolle oder Jahresberichte zusammenfassen und bei einer Recherche Informationen aggregieren. Jeder Mitarbeiter erhält so seinen eigenen persönlichen Assistenten und kann sich auf die wichtigen Dinge seines Arbeitsbereichs konzentrieren. 5. Kundenservice: Ähnlich wie beim KI-Assistenten für die Belegschaft, lässt sich generative KI auch nutzen, um einen unternehmensspezifischen virtuellen Kundenberater zu etablieren. Auch hier dient die eigene Wissensdatenbank als exklusive Datenbasis. Ein Chatbot für eine Klinikkette zum Beispiel gibt dann Auskunft zu den Spezialisierungen der einzelnen Kliniken, ihren Sprech- und Besuchszeiten oder führt Besucher im Haus zum gewünschten Behandlungszimmer. Auf Fragen ohne direkten Bezug zum Unternehmen gibt er hingegen an, keine Auskunft erteilen zu können. Dies vermeidet bei professionellen KI-Bots jene Halluzinationen, die man aus dem Consumer-Segment kennt. Neben diesen fünf übergreifenden Lösungsbeschleunigern umfasst HPE Private Cloud AI auch noch eine Reihe branchenspezifischer Varianten: für Industrieunternehmen, die öffentliche Hand, den Einzelhandel und Netzbetreiber. So erhalten zum Beispiel Fertigungsunternehmen Blaupausen für die KI-gestützte Qualitätskontrolle, die vorausschauende Wartung des Maschinenparks, die KI-gestützte Optimierung der Lieferkette und Chatbots für den Verkaufsprozess. Zudem ist die einfache Umsetzung zahlreicher weiterer Anwendungsfälle möglich: HPE Private Cloud AI enthält einen KI-Werkzeugkasten, der es Anwenderunternehmen erleichtert, Blaupausen für individuelle KI-Projekte zu erstellen und dann unternehmensweit auszurollen. JETZT ZUM LÖSUNGSBERICHT. Das KI-Modelltraining ist sehr rechenintensiv. Dies gilt auch für Fälle, in denen es „lediglich“ um Anpassung und Finetuning eines bestehenden Basismodells geht. Deshalb baut HPE bei Private Cloud AI auf die enge Kooperation mit KI-Branchenprimus NVIDIA. Gemeinsam mit NVIDIA hat HPE eine skalierbare Lösungsfamilie entwickelt, die alle üblichen Anwendungsfälle hochperformant unterstützt. Die Systeme der Lösungsfamilie gibt es in den „T-Shirt-Größen“ S, M und L, jeweils mit einer Erweiterungsoption: Mittelständische Unternehmen und Organisationen stehen heute häufig vor dem schwierigen Sprung von „Lass uns mal diesen KI-Piloten ausprobieren!“ zu „Wie können wir die folgenden fünf KI-Anwendungsfälle zielstrebig und effizient umsetzen?“ HPE Private Cloud AI ermöglicht es diesen Unternehmen, einen solchen Sprung mit geringem Aufwand zu bewältigen – und beim Einsatz einer Blaupause sogar mit wenigen Mausklicks. Dadurch profitieren Anwender im Unternehmen schnell von den vielfältigen Möglichkeiten generativer KI – und es bleibt trotzdem noch Zeit für einen Apfelstrudel in der Kantine. Mehr über HPE Private Cloud AI erfahren? ZUm LÖSUNGSBERICHT! ZUM WHITEPAPER! Unternehmen wollen KI und Chatbots immer stärker in ihre Prozesse einbinden. Lokal trainierte Lösungen bieten hier schnelle Erfolge mit wenigen Klicks. Shutterstock.com – PeopleImages.com – Yuri A Eine Krankenhauskette möchte mittels generativer Künstlicher Intelligenz (KI) einen virtuellen Assistenten für ihre Belegschaft erstellen. Der Chatbot soll den Beschäftigten anhand der hauseigenen Informationsbestände zu unterschiedlichsten Fragen Auskunft geben, um ihnen zeitraubende Suchen in Unterlagen und im Intranet zu ersparen: Welche unserer Kliniken hat die größte Erfahrung mit Katarakt-Operationen? Was waren die fünf wichtigsten Punkte im heutigen Rundschreiben der Geschäftsführung? Wie ändert das neue Medizinforschungsgesetz den Ablauf unserer klinischen Studien? Welche unserer Ärzte haben die Zusatzqualifikation für Tropenmedizin? Und wann gibt es in der Kantine wieder Apfelstrudel? Die Klinikkette unseres fiktiven Beispiels hat eine zwanzigköpfige IT-Abteilung, einige der IT-Fachleute haben sich auch schon mit KI-Themen befasst. Das IT-Team hat kürzlich sogar eine Datenwissenschaftlerin angestellt, die den hauseigenen Datenbestand für KI-Einsatzzwecke aufbereiten soll. Aber dem Team fehlt das Know-how für das Training von KI-Basismodellen. Und es fehlt die Zeit, um herauszufinden, wie man die benötigte Hardware- und Software-Infrastruktur für den KI-Betrieb korrekt zusammenstellt, dimensioniert und konfiguriert. Was tun? Großunternehmen können sich ein dediziertes Team leisten, das ein KI-Basismodell trainiert, um es für die eigenen Belange maßzuschneidern. Die meisten Unternehmen bis hin zum gehobenen Mittelstand hingegen haben weder Fachkräfte noch Know-how oder Budget für einen derart aufwendigen Ansatz, das Potenzial von KI zu erschließen. Doch auch sie wissen: Generative KI wird künftig eine zentrale Rolle spielen, um Prozesse zu beschleunigen, neue Services anzubieten – und generell, um wettbewerbsfähig zu bleiben. Ein beliebtes Vorgehen wird deshalb darin bestehen, vortrainierte Modelle mit hauseigenen Datenbeständen für individuelle Einsatzfälle anzupassen. Das KI-Modell einfach in einer Public Cloud zu trainieren und zu betreiben, ist für viele Organisationen dabei keine Option. In einigen Organisationen verbieten Regularien dies, andere wollen die Hoheit über sensible und personenbezogene Daten nicht infrage stellen. Mit Blick auf die Datensouveränität werden Unternehmen deshalb vortrainierte Modelle in aller Regel lokal anpassen. Dafür benötigen sie eine Reihe von Hardware- und Softwarebausteinen, von Servern und Speichern bis hin zu KI-Analysetools. Deren Zusammenstellung zur in sich stimmigen KI-Trainings- und Betriebsumgebung war bislang ein zeitraubendes Unterfangen, oft erschwert durch einen weiteren Umstand: Auf KI spezialisierte Datenwissenschaftler sind keine IT-Betriebsexperten, das IT-Team wiederum müsste sich aber in die Anforderungen der KI-Lösungen erst einarbeiten. Den Aufbau einer KI-Umgebung erleichtern nun aber integrierte, speziell auf den Einsatz generativer KI ausgelegte Komplettpakete aus Hardware, Software und Services. Diese Angebote sind in verschiedenen Leistungsstufen erhältlich, um alles vom Pilotprojekt bis zum Training eines großen KI-Modells mit umfangreicher Datenbasis abzudecken. JETZT WHITEPAPER LESEN UND HPE PRIVATE CLOUD AI VERSTEHEN. Um möglichst schnell Projekterfolge zu erzielen, sollte ein solches KI-Komplettpaket vor allem Blaupausen umfassen, mit denen sich die häufigsten KI-Einsatzfälle mit wenigen Mausklicks verwirklichen lassen. HPE Private Cloud AI – eine Familie von KI-Komplettsystemen, die HPE gemeinsam mit dem KI-Vorreiter NVIDIA entwickelt hat – umfasst zu diesem Zweck neben von NVIDIA vortrainierten KI-Modellen auch sogenannte „Accelerators“ (Lösungsbeschleuniger). Diese ermöglichen es einem IT-Team, mit geringem Aufwand und nur grundlegendem KI-Know-how zügig folgende beliebte Szenarien umzusetzen: 1. Dokumentation: Ob klinische Studie, industrielle Fertigung oder Softwareentwicklung – im Laufe eines Projekts fällt ein Berg von Unterlagen an. Dieser will dann für die Dokumentation ausgewertet und aggregiert sein. Hier kann ein entsprechend trainierter KI-Assistent seine Stärken ausspielen: Er fasst große Dokumentenbestände zusammen und arrangiert die wichtigen Informationen zu einer stimmigen Projektdokumentation. 2. Code-Erzeugung: Bei der Softwareentwicklung können sich Entwicklungsteams heute viel Arbeit ersparen, indem sie Routineschritte an KI-Assistenten übergeben. Das beschleunigt Abläufe deutlich und vermeidet menschliche Fehler. Die Entwickler müssen nur noch die Qualität des erzeugten Codes kontrollieren. Insbesondere für diesen Einsatzfall ist die Zusammenarbeit von HPE mit NVIDIA von Bedeutung: Der Marktführer bei KI-Prozessoren setzt den Maßstab für performante Unterstützung selbst äußerst rechenintensiver Programmier- und KI-Aufgaben. 3. Wissensmanagement: In den Medien ist immer wieder von Fehlern zu lesen, die Chatbots wie ChatGPT machen, wenn man sie als Suchmaschine nutzt. Die Fehlerquelle liegt hier schlicht darin, dass die Datenbasis aus dem Internet stammt: Oft fehlt der Kontext zur Frage, ebenso die Qualitätskontrolle der Daten. Trainiert ein Unternehmen hingegen eine KI mit dem hauseigenen Informationsbestand (Retrieval-Augmented Generation, kurz RAG genannt), dann erweist sich ein KI-Assistent als verlässlicher Detektiv im unternehmenseigenen Wissensbestand. Dank lokalem Training und Betrieb bleibt die Datenhoheit stets gewahrt. 4. Virtueller Assistent für Beschäftigte: Diesem Anwendungsfall sind wir anfangs beim fiktiven Beispiel der Klinikkette schon begegnet. Ein KI-Assistent ist nicht nur in der Lage, Informationen zu finden oder Fragen zu beantworten. Vielmehr kann er auch Meeting-Protokolle oder Jahresberichte zusammenfassen und bei einer Recherche Informationen aggregieren. Jeder Mitarbeiter erhält so seinen eigenen persönlichen Assistenten und kann sich auf die wichtigen Dinge seines Arbeitsbereichs konzentrieren. 5. Kundenservice: Ähnlich wie beim KI-Assistenten für die Belegschaft, lässt sich generative KI auch nutzen, um einen unternehmensspezifischen virtuellen Kundenberater zu etablieren. Auch hier dient die eigene Wissensdatenbank als exklusive Datenbasis. Ein Chatbot für eine Klinikkette zum Beispiel gibt dann Auskunft zu den Spezialisierungen der einzelnen Kliniken, ihren Sprech- und Besuchszeiten oder führt Besucher im Haus zum gewünschten Behandlungszimmer. Auf Fragen ohne direkten Bezug zum Unternehmen gibt er hingegen an, keine Auskunft erteilen zu können. Dies vermeidet bei professionellen KI-Bots jene Halluzinationen, die man aus dem Consumer-Segment kennt. Neben diesen fünf übergreifenden Lösungsbeschleunigern umfasst HPE Private Cloud AI auch noch eine Reihe branchenspezifischer Varianten: für Industrieunternehmen, die öffentliche Hand, den Einzelhandel und Netzbetreiber. So erhalten zum Beispiel Fertigungsunternehmen Blaupausen für die KI-gestützte Qualitätskontrolle, die vorausschauende Wartung des Maschinenparks, die KI-gestützte Optimierung der Lieferkette und Chatbots für den Verkaufsprozess. Zudem ist die einfache Umsetzung zahlreicher weiterer Anwendungsfälle möglich: HPE Private Cloud AI enthält einen KI-Werkzeugkasten, der es Anwenderunternehmen erleichtert, Blaupausen für individuelle KI-Projekte zu erstellen und dann unternehmensweit auszurollen. JETZT ZUM LÖSUNGSBERICHT. Das KI-Modelltraining ist sehr rechenintensiv. Dies gilt auch für Fälle, in denen es „lediglich“ um Anpassung und Finetuning eines bestehenden Basismodells geht. Deshalb baut HPE bei Private Cloud AI auf die enge Kooperation mit KI-Branchenprimus NVIDIA. Gemeinsam mit NVIDIA hat HPE eine skalierbare Lösungsfamilie entwickelt, die alle üblichen Anwendungsfälle hochperformant unterstützt. Die Systeme der Lösungsfamilie gibt es in den „T-Shirt-Größen“ S, M und L, jeweils mit einer Erweiterungsoption: Mittelständische Unternehmen und Organisationen stehen heute häufig vor dem schwierigen Sprung von „Lass uns mal diesen KI-Piloten ausprobieren!“ zu „Wie können wir die folgenden fünf KI-Anwendungsfälle zielstrebig und effizient umsetzen?“ HPE Private Cloud AI ermöglicht es diesen Unternehmen, einen solchen Sprung mit geringem Aufwand zu bewältigen – und beim Einsatz einer Blaupause sogar mit wenigen Mausklicks. Dadurch profitieren Anwender im Unternehmen schnell von den vielfältigen Möglichkeiten generativer KI – und es bleibt trotzdem noch Zeit für einen Apfelstrudel in der Kantine. Mehr über HPE Private Cloud AI erfahren? ZUm LÖSUNGSBERICHT! ZUM WHITEPAPER!",
    "source": "cio",
    "crawled_at": "2025-05-27T08:10:55.930619+00:00"
  },
  {
    "url": "https://www.cio.de/article/3819664/zweifel-an-der-public-cloud-wachsen.html",
    "title": "Zweifel an der Public Cloud wachsen",
    "published": "2025-05-22T04:13:00+00:00",
    "author": "",
    "text": "Evgeniyqw – shutterstock.com In den vergangenen Jahren haben sich Unternehmen bemüht, Workloads und Applikationen so schnell wie möglich in die Public Cloud zu verlagern, um Investitionsausgaben zu minimieren und Geld zu sparen. Zunehmend jedoch prüfen CIOs diese Investitionen, ob sie noch vernünftig sind: Steigern sie wirklich die Produktivität und helfen sie bei der IT-Kostensenkung? „Beim Ansturm auf die öffentliche Cloud haben viele Leute nicht über die Preisgestaltung nachgedacht“, berichtet Tracy Woo, Principal Analyst bei Forrester. Das hat Folgen: „Wenn die Ausgaben steigen und die Budgets knapper werden, fragen sie sich, was los ist und wie sie das Schiff in die richtige Richtung lenken können.“ Abonnieren Sie unsere CIO-Newsletter für mehr Einblicke, Hintergründe und Deep Dives aus der CIO-Community. Ron Hollowell, CTO bei der Reinsurance Group of America (RGA), will sich 2025 darauf konzentrieren, die Public Cloud richtig zu dimensionieren. Dies gelinge mit einem höheren Reifegrad der Prozesse rund um Workloads, Verteilungskriterien und Implementierungspraktiken. „Kostenoptimierung und klar definierte Kriterien für die Auswahl der Workloads werden darüber bestimmen, welche Services in die Public Cloud und welche in die Private Cloud gehen“, so der IT-Chef. Als VP für Cloud-Funktionen beim Softwareunternehmen Endava berät Radu Vunvulea CIOs in großen Unternehmen. „In diesem Jahr werden wir häufiger über Hybrid-Cloud, Multi-Cloud und die Rückführung zu On-Premises sprechen“, lautet auch seine Erwartung. Zu den Gründen gehören höhere Kosten (als erwartet). Hinzu kommen Leistungs- und Latenzprobleme, Sicherheits-, Datenschutz- und Compliance-Bedenken sowie regionale Vorschriften zur digitalen Souveränität, die sich darauf auswirken, wo Daten gespeichert, transportiert und verarbeitet werden können. „Der Hauptgrund, um Private Clouds den Vorzug vor Public Clouds zu geben, sind jedoch die Kosten“, sagt Hollowell. Er sieht Public Clouds generell als kosteneffizienteste Lösung für saisonale oder sporadische, bedarfsabhängige Arbeitslasten. „Für Workloads mit konstanteren Kapazitätsanforderungen kann allerdings die Wirtschaftlichkeit von Private Clouds oder Lösungen mit fester Kapazität attraktiver sein.“ Auch für viele andere CIOs seien die Kosten das wichtigste Entscheidungskriterium, ergänzt Vunvulea. Während bis zu 80 Prozent der Enterprise-Systeme, an denen Endava arbeitet, teilweise oder vollständig die öffentliche Cloud nutzen, migrieren etwa 60 Prozent dieser Unternehmen mindestens ein System zurück. „Wir interpretieren das schon als einen Trend“, sagt er. Wohin gehen diese Arbeitslasten? „Es gibt einen erneuten Fokus auf On-Premises, On-Premises Private Cloud oder gehostete Private Clouds, insbesondere da datenintensive Workloads wie generative KI die Cloud-Ausgaben in die Höhe treiben“, berichtet Forrester-Expertin Woo. Die Analysten prognostizieren, dass vier von fünf so genannten Cloud-Leadern ihre Investitionen in Private Clouds in diesem Jahr um rund ein Fünftel steigern werden. Allerdings dreht sich das Jahr 2025 nicht ausschließlich um die Repatriierung . „Gleichzeitig legen auch die Investitionen in Public Clouds zu durch GenAI, andere Anforderungen sowie den Zugang zu neuer Infrastruktur“, prognostiziert Woo. Für das St. Jude’s Research Hospital ist die Public Cloud eine gute Möglichkeit, Wissen in die Hände von Forschern zu geben. Laut CIO Keith Perry betreibt das Krankenhaus Supercomputer vor Ort, um einen Großteil seiner Forschungsdaten zu generieren. Die Übertragung dieser Daten in und aus der öffentlichen Cloud könne laut dem IT-Chef jedoch teuer werden. „Die akademische Gemeinschaft erwartet, dass sich die Daten in der Nähe ihrer Hochleistungsrechner befinden, daher haben alle mit hohen Gebühren zu kämpfen“, erklärt Perry. Woo fügt hinzu, dass Public Clouds für datenintensive Workloads kostspielig sind, da Unternehmen sowohl für gespeicherte als auch für zwischen Verfügbarkeitszonen (Availability Zones), Regionen und Clouds übertragene Daten Gebühren zahlen müssen. Die Anbieter erheben zudem Ausstiegsgebühren für Daten, die eine bestimmte AZ verlassen, sowie für Daten, die in eine bestimmte AZ gelangen. „Für Übertragungen zwischen AZs werden Sie also im Grunde doppelt belastet und diese Übertragungsgebühren können sich wirklich summieren“, erläutert Woo. Auch Vunvulea warnt, dass die Kosten für die Datenübertragung hoch und dass die Datenübertragung sowie -synchronisation komplex sein kann. „Wir haben KI-Projekte gesehen, bei denen etwa 45 Prozent der Cloud-Kosten durch die Übertragung von Daten aus der Public Cloud an einen anderen Standort entstanden sind“, sagt er. Wenn man die kompletten Systeme mit allem, was man rund um den Service braucht, einrichtet, könne die Lösung drei- oder viermal so viel kosten wie ursprünglich veranschlagt. Unternehmen, die eine KI-Lösung aufbauen, müssen mehr als nur den KI-Service berücksichtigen. Um Geheimnisse zu schützen und Zugriffe zu regeln, müssen Vaults hinzugefügt sowie Sicherheitsanwendungen und -richtlinien definiert und konfiguriert werden. Die sichere Speicherung, Datentransformation, Überwachung, das Auditing und eine Compliance-Ebene erhöhen die Komplexität des Systems. Um den KI-Dienst herum muss eine Lösung mit weiteren zehn bis 12 Cloud-Diensten aufgebaut werden, die die Anforderungen eines Enterprise-Systems erfüllen. Auch das geht ins Geld. Unternehmen haben keine große Wahl bei der Cloud, wenn es darum geht, die größeren Basismodelle wie ChatGPT 3.5 und 4.0 zu nutzen. Die erforderliche Rechenleistung wäre zu kostspielig, um sie im eigenen Haus zu reproduzieren, sagt Sid Nag, Experte für Cloud, Edge und AI Infrastructure bei Gartner. Bis 2027 werden jedoch nach Einschätzung der Analysten mehr als 50 Prozent der von Unternehmen genutzten KI-LLMs branchenspezifisch sein. Ihr Vorteil: Sie sind deutlich kleiner als die Allzweck-Grundmodelle und damit attraktiver. Laut Nag erfordern branchenspezifische KI-Modelle weniger Ressourcen für das Training und könnten daher vor Ort, in einer privaten Cloud oder in einer gehosteten privaten Cloud-Infrastruktur ausgeführt werden. Allerdings gibt sich der Gartner-Experte vorsichtig, wenn es um das private Cloud-Hosting oder On-Premises-Hosting geht: „Entscheider werden sich gegen die Idee sträuben, zu den Tagen der CapEx-Investitionen zurückzukehren – es sei denn, es gibt wirklich zwingende Gründe.“ Der Kostenfokus passt zudem nicht immer zu den Leistungsanforderungen oder übergeordneten Zielen. „Die Latenzzeit zwischen dem Instrument, das die Daten erzeugt, und der Rechenleistung, die sie verarbeitet, ist eine wichtige Variable bei der Bestimmung des Datenortes“, berichtet CIO Perry vom Krankenhaus St. Jude. In einigen Fällen benötigt das Instrument eine umgehende Verbindung zu Hochleistungs-Rechenressourcen. „Aufgrund der Latenz zwischen den Forschungsinstrumenten und der öffentlichen Cloud ist es oft nicht sinnvoll, dort Echtzeit-Checks vorzunehmen“, führt der CIO aus. Angesichts der vielen Optionen – auch rund um die Themen Sicherheit, Datenschutz und Souveränität – sowie unzähligen Use Cases ist klar, dass es keinen Königsweg in die Cloud gibt. Daher kommt es darauf an, die notwendige Flexibilität zu trainieren, um sich anpassen zu können. In Zukunft, so CTO Hollowell, „ist es unsere strategische Absicht, Hosting-Entscheidungen durch die Linse der geschäftlichen Anforderungen zu bewerten, anstatt einfach alles in die Public Cloud zu verlagern. “ Applikationen mit konsistenten Kapazitätsanforderungen, die sich mit einer traditionellen Infrastruktur erfüllen lassen, werden in einer privaten Cloud ausgeführt. Alle anderen sind Kandidaten für eine öffentliche Cloud. Für CIO Perry geht es beim Aufbau seiner IT-Infrastruktur vor allem darum, die richtigen Baustoffe zu verwenden. „Public Cloud ist nur eines der Materialien, die wir für die Umsetzung der Architektur benötigen.“ Hier müsse man die Balance finden, doch leider sei die optimale Mischung aus On-Premises, Private Cloud und Public Cloud ein bewegliches Ziel. „Ich kann nicht behaupten, dass alles für immer an der richtigen Stelle ist, weil sich die Technologie ständig weiterentwickelt“, räumt Perry ein. Weil sich Cloud-Technologien verändern, sollten Unternehmen bereit und in der Lage sein, mit der Zeit zu gehen, empfiehlt der IT-Chef: „Denn die Tools, die Sie heute haben, sind vielleicht nicht die, die Sie morgen brauchen.“ (ajf/jd) Evgeniyqw – shutterstock.com In den vergangenen Jahren haben sich Unternehmen bemüht, Workloads und Applikationen so schnell wie möglich in die Public Cloud zu verlagern, um Investitionsausgaben zu minimieren und Geld zu sparen. Zunehmend jedoch prüfen CIOs diese Investitionen, ob sie noch vernünftig sind: Steigern sie wirklich die Produktivität und helfen sie bei der IT-Kostensenkung? „Beim Ansturm auf die öffentliche Cloud haben viele Leute nicht über die Preisgestaltung nachgedacht“, berichtet Tracy Woo, Principal Analyst bei Forrester. Das hat Folgen: „Wenn die Ausgaben steigen und die Budgets knapper werden, fragen sie sich, was los ist und wie sie das Schiff in die richtige Richtung lenken können.“ Abonnieren Sie unsere CIO-Newsletter für mehr Einblicke, Hintergründe und Deep Dives aus der CIO-Community. Ron Hollowell, CTO bei der Reinsurance Group of America (RGA), will sich 2025 darauf konzentrieren, die Public Cloud richtig zu dimensionieren. Dies gelinge mit einem höheren Reifegrad der Prozesse rund um Workloads, Verteilungskriterien und Implementierungspraktiken. „Kostenoptimierung und klar definierte Kriterien für die Auswahl der Workloads werden darüber bestimmen, welche Services in die Public Cloud und welche in die Private Cloud gehen“, so der IT-Chef. Als VP für Cloud-Funktionen beim Softwareunternehmen Endava berät Radu Vunvulea CIOs in großen Unternehmen. „In diesem Jahr werden wir häufiger über Hybrid-Cloud, Multi-Cloud und die Rückführung zu On-Premises sprechen“, lautet auch seine Erwartung. Zu den Gründen gehören höhere Kosten (als erwartet). Hinzu kommen Leistungs- und Latenzprobleme, Sicherheits-, Datenschutz- und Compliance-Bedenken sowie regionale Vorschriften zur digitalen Souveränität, die sich darauf auswirken, wo Daten gespeichert, transportiert und verarbeitet werden können. „Der Hauptgrund, um Private Clouds den Vorzug vor Public Clouds zu geben, sind jedoch die Kosten“, sagt Hollowell. Er sieht Public Clouds generell als kosteneffizienteste Lösung für saisonale oder sporadische, bedarfsabhängige Arbeitslasten. „Für Workloads mit konstanteren Kapazitätsanforderungen kann allerdings die Wirtschaftlichkeit von Private Clouds oder Lösungen mit fester Kapazität attraktiver sein.“ Auch für viele andere CIOs seien die Kosten das wichtigste Entscheidungskriterium, ergänzt Vunvulea. Während bis zu 80 Prozent der Enterprise-Systeme, an denen Endava arbeitet, teilweise oder vollständig die öffentliche Cloud nutzen, migrieren etwa 60 Prozent dieser Unternehmen mindestens ein System zurück. „Wir interpretieren das schon als einen Trend“, sagt er. Wohin gehen diese Arbeitslasten? „Es gibt einen erneuten Fokus auf On-Premises, On-Premises Private Cloud oder gehostete Private Clouds, insbesondere da datenintensive Workloads wie generative KI die Cloud-Ausgaben in die Höhe treiben“, berichtet Forrester-Expertin Woo. Die Analysten prognostizieren, dass vier von fünf so genannten Cloud-Leadern ihre Investitionen in Private Clouds in diesem Jahr um rund ein Fünftel steigern werden. Allerdings dreht sich das Jahr 2025 nicht ausschließlich um die Repatriierung . „Gleichzeitig legen auch die Investitionen in Public Clouds zu durch GenAI, andere Anforderungen sowie den Zugang zu neuer Infrastruktur“, prognostiziert Woo. Für das St. Jude’s Research Hospital ist die Public Cloud eine gute Möglichkeit, Wissen in die Hände von Forschern zu geben. Laut CIO Keith Perry betreibt das Krankenhaus Supercomputer vor Ort, um einen Großteil seiner Forschungsdaten zu generieren. Die Übertragung dieser Daten in und aus der öffentlichen Cloud könne laut dem IT-Chef jedoch teuer werden. „Die akademische Gemeinschaft erwartet, dass sich die Daten in der Nähe ihrer Hochleistungsrechner befinden, daher haben alle mit hohen Gebühren zu kämpfen“, erklärt Perry. Woo fügt hinzu, dass Public Clouds für datenintensive Workloads kostspielig sind, da Unternehmen sowohl für gespeicherte als auch für zwischen Verfügbarkeitszonen (Availability Zones), Regionen und Clouds übertragene Daten Gebühren zahlen müssen. Die Anbieter erheben zudem Ausstiegsgebühren für Daten, die eine bestimmte AZ verlassen, sowie für Daten, die in eine bestimmte AZ gelangen. „Für Übertragungen zwischen AZs werden Sie also im Grunde doppelt belastet und diese Übertragungsgebühren können sich wirklich summieren“, erläutert Woo. Auch Vunvulea warnt, dass die Kosten für die Datenübertragung hoch und dass die Datenübertragung sowie -synchronisation komplex sein kann. „Wir haben KI-Projekte gesehen, bei denen etwa 45 Prozent der Cloud-Kosten durch die Übertragung von Daten aus der Public Cloud an einen anderen Standort entstanden sind“, sagt er. Wenn man die kompletten Systeme mit allem, was man rund um den Service braucht, einrichtet, könne die Lösung drei- oder viermal so viel kosten wie ursprünglich veranschlagt. Unternehmen, die eine KI-Lösung aufbauen, müssen mehr als nur den KI-Service berücksichtigen. Um Geheimnisse zu schützen und Zugriffe zu regeln, müssen Vaults hinzugefügt sowie Sicherheitsanwendungen und -richtlinien definiert und konfiguriert werden. Die sichere Speicherung, Datentransformation, Überwachung, das Auditing und eine Compliance-Ebene erhöhen die Komplexität des Systems. Um den KI-Dienst herum muss eine Lösung mit weiteren zehn bis 12 Cloud-Diensten aufgebaut werden, die die Anforderungen eines Enterprise-Systems erfüllen. Auch das geht ins Geld. Unternehmen haben keine große Wahl bei der Cloud, wenn es darum geht, die größeren Basismodelle wie ChatGPT 3.5 und 4.0 zu nutzen. Die erforderliche Rechenleistung wäre zu kostspielig, um sie im eigenen Haus zu reproduzieren, sagt Sid Nag, Experte für Cloud, Edge und AI Infrastructure bei Gartner. Bis 2027 werden jedoch nach Einschätzung der Analysten mehr als 50 Prozent der von Unternehmen genutzten KI-LLMs branchenspezifisch sein. Ihr Vorteil: Sie sind deutlich kleiner als die Allzweck-Grundmodelle und damit attraktiver. Laut Nag erfordern branchenspezifische KI-Modelle weniger Ressourcen für das Training und könnten daher vor Ort, in einer privaten Cloud oder in einer gehosteten privaten Cloud-Infrastruktur ausgeführt werden. Allerdings gibt sich der Gartner-Experte vorsichtig, wenn es um das private Cloud-Hosting oder On-Premises-Hosting geht: „Entscheider werden sich gegen die Idee sträuben, zu den Tagen der CapEx-Investitionen zurückzukehren – es sei denn, es gibt wirklich zwingende Gründe.“ Der Kostenfokus passt zudem nicht immer zu den Leistungsanforderungen oder übergeordneten Zielen. „Die Latenzzeit zwischen dem Instrument, das die Daten erzeugt, und der Rechenleistung, die sie verarbeitet, ist eine wichtige Variable bei der Bestimmung des Datenortes“, berichtet CIO Perry vom Krankenhaus St. Jude. In einigen Fällen benötigt das Instrument eine umgehende Verbindung zu Hochleistungs-Rechenressourcen. „Aufgrund der Latenz zwischen den Forschungsinstrumenten und der öffentlichen Cloud ist es oft nicht sinnvoll, dort Echtzeit-Checks vorzunehmen“, führt der CIO aus. Angesichts der vielen Optionen – auch rund um die Themen Sicherheit, Datenschutz und Souveränität – sowie unzähligen Use Cases ist klar, dass es keinen Königsweg in die Cloud gibt. Daher kommt es darauf an, die notwendige Flexibilität zu trainieren, um sich anpassen zu können. In Zukunft, so CTO Hollowell, „ist es unsere strategische Absicht, Hosting-Entscheidungen durch die Linse der geschäftlichen Anforderungen zu bewerten, anstatt einfach alles in die Public Cloud zu verlagern. “ Applikationen mit konsistenten Kapazitätsanforderungen, die sich mit einer traditionellen Infrastruktur erfüllen lassen, werden in einer privaten Cloud ausgeführt. Alle anderen sind Kandidaten für eine öffentliche Cloud. Für CIO Perry geht es beim Aufbau seiner IT-Infrastruktur vor allem darum, die richtigen Baustoffe zu verwenden. „Public Cloud ist nur eines der Materialien, die wir für die Umsetzung der Architektur benötigen.“ Hier müsse man die Balance finden, doch leider sei die optimale Mischung aus On-Premises, Private Cloud und Public Cloud ein bewegliches Ziel. „Ich kann nicht behaupten, dass alles für immer an der richtigen Stelle ist, weil sich die Technologie ständig weiterentwickelt“, räumt Perry ein. Weil sich Cloud-Technologien verändern, sollten Unternehmen bereit und in der Lage sein, mit der Zeit zu gehen, empfiehlt der IT-Chef: „Denn die Tools, die Sie heute haben, sind vielleicht nicht die, die Sie morgen brauchen.“ (ajf/jd)",
    "source": "cio",
    "crawled_at": "2025-05-27T08:10:56.012141+00:00"
  },
  {
    "url": "https://www.cio.de/article/3987853/die-zukunft-der-versicherungsbranche-im-zeitalter-von-ki-2.html",
    "title": "Die Zukunft der Versicherungsbranche im Zeitalter von KI",
    "published": "2025-05-22T05:11:00+00:00",
    "author": "",
    "text": "PeopleImages.com – Yuri A – shutterstock.com Die Versicherungsbranche steht vor einem tiefgreifenden Wandel, angetrieben durch technologische Innovationen und sich verändernde Marktbedingungen. Davon gehen zumindest Munich Re und ERGO aus. Im „ Tech Trend Radar 2025 “ beleuchten sie die wichtigsten Trends, die die Branche in den kommenden Jahren prägen werden. Insgesamt identifiziert der Bericht 36 Trends, welche fünf Bereichen zugeordnet werden können: Künstliche Intelligenz (KI) wird als entscheidender Faktor für die Versicherungsbranche angesehen. Technologien wie Generative KI (GenAI), KI-Agenten und synthetische Daten ermöglichen effizientere Prozesse. Diese reichen von der Schadensbearbeitung bis zur Risikobewertung. Darüber hinaus transformiert GenAI die Datenanalyse und verbessert die Personalisierung von Versicherungsprodukten, so die Studienmacher. KI-Agenten, die autonom Aufgaben ausführen, könnten zudem die Effizienz in der Kundenbetreuung und Schadensbearbeitung revolutionieren. Gleichzeitig erfordert die zunehmende Nutzung von KI eine robuste Governance. Nur so lassen sich laut den Experten Risiken wie Verzerrungen und Datenschutzverletzungen minimieren. Die Integration von KI in die Medizin eröffnet ebenfalls neue Möglichkeiten für Versicherer: Digitale Gesundheitslösungen wie elektronische Gesundheitsakten (EHRs) und KI-gestützte Diagnosen verbessern sowohl die Risikobewertung als auch die Schadensbearbeitung, so die Autoren. Personalisierte Medizin, die auf genetischen Profilen basiert, soll präzisere Behandlungen ermöglichen. Das könnte die Kosten im Gesundheitswesen senken. Trotz der Vorteile bleiben Herausforderungen, wie hohe Kosten und Datenschutzbedenken bestehen. Neue Aufgaben für die Versicherungsbranche entstehen laut der Studie durch Energiewende und Klimawandel. Erneuerbare Energien wie Solar- und Windkraft erfordern innovative Versicherungsprodukte, um Risiken wie Naturkatastrophen und technische Ausfälle abzudecken. Gleichzeitig wird die Bedeutung von Klimarisikobewertungen immer größer, um Unternehmen und Gemeinden auf extreme Wetterereignisse vorzubereiten. Darüber hinaus verändert die zunehmende Verbreitung von Elektrofahrzeugen (EVs) und autonomen Fahrzeugen (AVs) die Versicherungslandschaft. EVs bringen neue Risiken wie höhere Reparaturkosten und Cyberangriffe mit sich, bieten aber auch Chancen für maßgeschneiderte Versicherungsprodukte. Autonome Fahrzeuge könnten zudem die Unfallhäufigkeit reduzieren, aber die Haftung von den Fahrern auf die Hersteller verlagern. Das würde neue Versicherungsmodelle erfordern, so die Experten. Die digitale Transformation bringt laut den Autoren neue Bedrohungen mit sich, da Cyberangriffe und Deepfakes Unternehmen vor große Herausforderungen stellen. Versicherer entwickeln daher Lösungen wie die „Digital-Immune-System“-Technologie, um die Cybersicherheit zu verbessern und Risiken zu minimieren. Gleichzeitig wächst die Nachfrage nach Versicherungen für digitale Vermögenswerte wie Kryptowährungen und tokenisierte Immobilien. Technologien wie humanoide Roboter, IoT-Sensoren und erweiterte Realität (XR) verändern ebenfalls traditionelle Branchen. Zudem schaffen sie neue Märkte für Versicherer. Laut den Studienmachern könnten humanoide Roboter hier die Schadensbewertung und Kundenbetreuung revolutionieren, während XR immersive Kundenerlebnisse ermöglicht. Die Landwirtschaft profitiert von Remote-Sensing-Technologien, die die Risikobewertung und Schadensbearbeitung verbessern. Während all diese Innovationen Effizienz und Wachstum versprechen, bringen sie auch Herausforderungen mit sich, wie Versicherer müssen daher laut den Autoren der Studie ein Gleichgewicht zwischen technologischer Innovation und Risikomanagement finden. Nur auf diese Art und Weise ließen sich Vertrauen und Compliance aufrechterhalten. PeopleImages.com – Yuri A – shutterstock.com Die Versicherungsbranche steht vor einem tiefgreifenden Wandel, angetrieben durch technologische Innovationen und sich verändernde Marktbedingungen. Davon gehen zumindest Munich Re und ERGO aus. Im „ Tech Trend Radar 2025 “ beleuchten sie die wichtigsten Trends, die die Branche in den kommenden Jahren prägen werden. Insgesamt identifiziert der Bericht 36 Trends, welche fünf Bereichen zugeordnet werden können: Künstliche Intelligenz (KI) wird als entscheidender Faktor für die Versicherungsbranche angesehen. Technologien wie Generative KI (GenAI), KI-Agenten und synthetische Daten ermöglichen effizientere Prozesse. Diese reichen von der Schadensbearbeitung bis zur Risikobewertung. Darüber hinaus transformiert GenAI die Datenanalyse und verbessert die Personalisierung von Versicherungsprodukten, so die Studienmacher. KI-Agenten, die autonom Aufgaben ausführen, könnten zudem die Effizienz in der Kundenbetreuung und Schadensbearbeitung revolutionieren. Gleichzeitig erfordert die zunehmende Nutzung von KI eine robuste Governance. Nur so lassen sich laut den Experten Risiken wie Verzerrungen und Datenschutzverletzungen minimieren. Die Integration von KI in die Medizin eröffnet ebenfalls neue Möglichkeiten für Versicherer: Digitale Gesundheitslösungen wie elektronische Gesundheitsakten (EHRs) und KI-gestützte Diagnosen verbessern sowohl die Risikobewertung als auch die Schadensbearbeitung, so die Autoren. Personalisierte Medizin, die auf genetischen Profilen basiert, soll präzisere Behandlungen ermöglichen. Das könnte die Kosten im Gesundheitswesen senken. Trotz der Vorteile bleiben Herausforderungen, wie hohe Kosten und Datenschutzbedenken bestehen. Neue Aufgaben für die Versicherungsbranche entstehen laut der Studie durch Energiewende und Klimawandel. Erneuerbare Energien wie Solar- und Windkraft erfordern innovative Versicherungsprodukte, um Risiken wie Naturkatastrophen und technische Ausfälle abzudecken. Gleichzeitig wird die Bedeutung von Klimarisikobewertungen immer größer, um Unternehmen und Gemeinden auf extreme Wetterereignisse vorzubereiten. Darüber hinaus verändert die zunehmende Verbreitung von Elektrofahrzeugen (EVs) und autonomen Fahrzeugen (AVs) die Versicherungslandschaft. EVs bringen neue Risiken wie höhere Reparaturkosten und Cyberangriffe mit sich, bieten aber auch Chancen für maßgeschneiderte Versicherungsprodukte. Autonome Fahrzeuge könnten zudem die Unfallhäufigkeit reduzieren, aber die Haftung von den Fahrern auf die Hersteller verlagern. Das würde neue Versicherungsmodelle erfordern, so die Experten. Die digitale Transformation bringt laut den Autoren neue Bedrohungen mit sich, da Cyberangriffe und Deepfakes Unternehmen vor große Herausforderungen stellen. Versicherer entwickeln daher Lösungen wie die „Digital-Immune-System“-Technologie, um die Cybersicherheit zu verbessern und Risiken zu minimieren. Gleichzeitig wächst die Nachfrage nach Versicherungen für digitale Vermögenswerte wie Kryptowährungen und tokenisierte Immobilien. Technologien wie humanoide Roboter, IoT-Sensoren und erweiterte Realität (XR) verändern ebenfalls traditionelle Branchen. Zudem schaffen sie neue Märkte für Versicherer. Laut den Studienmachern könnten humanoide Roboter hier die Schadensbewertung und Kundenbetreuung revolutionieren, während XR immersive Kundenerlebnisse ermöglicht. Die Landwirtschaft profitiert von Remote-Sensing-Technologien, die die Risikobewertung und Schadensbearbeitung verbessern. Während all diese Innovationen Effizienz und Wachstum versprechen, bringen sie auch Herausforderungen mit sich, wie Versicherer müssen daher laut den Autoren der Studie ein Gleichgewicht zwischen technologischer Innovation und Risikomanagement finden. Nur auf diese Art und Weise ließen sich Vertrauen und Compliance aufrechterhalten.",
    "source": "cio",
    "crawled_at": "2025-05-27T08:10:56.224232+00:00"
  },
  {
    "url": "https://www.cio.de/article/3673449/narzissten-brennen-schneller-aus-2.html",
    "title": "Narzissten brennen schneller aus",
    "published": "2025-05-22T06:11:17+00:00",
    "author": "",
    "text": "Die Ärztin und Gesundheitsberaterin Mirriam Prieß sagt: “Viele ignorieren die ersten Alarmzeichen und halten tatsächlich erst inne, wenn nichts mehr geht.” Foto: Prieß Gerade unter IT-Spezialisten ist die Diagnose Burnout weit verbreitet: Rund die Hälfte der ITler zeigt Anzeichen einer tiefen Erschöpfung. Dr. Mirriam Prieß, Ärztin, Autorin und Beraterin für Gesundheitsmanagement, verrät, wie es gelingen kann, einen echten Dialog zu führen und damit Burnout zu verhindern. C IO.de: Frau Prieß, In Ihrem Buch schreiben Sie, dass die tiefgehende Erschöpfung, die oft Führungskräfte verspüren, darauf zurückzuführen ist, dass viele Menschen nicht “ihr eigenes Leben” führen. Was meinen Sie damit? Mirriam Prieß: Das eigene Leben zu leben bedeutet, so zu leben, wie es dem eigenen Wesen entspricht. Viele leben jedoch vielmehr nach ihrer Prägung – also ihrer Erziehung – und leben eine Vorstellung von sich selbst oder fügen sich äußeren Bedingungen und Anforderungen. Sie haben keinen Kontakt mehr mit sich selbst und wissen nicht, was sie wirklich wollen. Wer mit sich nicht in Kontakt steht, kennt weder sein Maß noch seine Grenzen und kann nicht an der richtigen Stelle “Ja” und “Nein” sagen. Darüber entstehen meist unlösbare innere und äußere Konflikte, an denen sich die Betroffenen immer mehr erschöpfen . Was wären denn solche Konflikte? Mirriam Prieß: Sie können sowohl beruflich wie privat sein. Viele sagen an der falschen Stelle zu lange “Ja”, um dann irgendwann nur noch “Nein” zu sagen. Oder sie entscheiden sich für Bedingungen, mit denen sie anschließend hadern. Wenn ich mich für ein System und eine Rolle – also einen Job – entscheide, dann tue ich dies aus freien Stücken und erkenne die damit verbundenen Realitäten und Bedingungen an. Das Problem ist, dass viele dies nicht tun, und am Ende mit dem System und den Bedingungen kämpfen, denen sie zugestimmt haben. Viele erschöpfen sich auch daran, dem eigenen Anspruch nicht gerecht zu werden , einem ständigen Optimierungszwang zu unterliegen und über die eigene Grenzenlosigkeit auszubrennen. Was heißt das in der Praxis? Mirriam Prieß: Wer das Gefühl hat, im Innen nichts zu sein, der muss im Außen alles sein. Diese unbewusste Form von tiefer Minderwertigkeit findet man bei so genannten narzisstischen Persönlichkeiten, die sich über grenzenlose Leistung und über Superlative definieren. Sie verfolgen das Prinzip “Grenzen sind dazu da, um überschritten zu werden”. Das führt dazu, dass betroffene Führungskräfte sich selbst und ihre Teams verbrennen , denn ihre hohen Maßstäbe legen sie auch an die Mitarbeiter an. Große Unternehmen können das nur kompensieren, weil sie eine so hohe Fluktuation haben: Die Führungskräfte wechseln alle drei Jahre die Position. Meinen Sie damit, dass viele Führungskräfte Narzissten sind? Mirriam Prieß: Viele glauben, dass Narzissmus nur mit Selbstverliebtheit zu tun hat und verkennen das dahinter liegende Drama. Das Ende des Gleichnis von Narziss verdeutlicht es: Indem Narziss sein Spiegelbild im Teich zu berühren versucht, zerfällt es. Hier zeigt sich das tiefe Leid des Narzissten: In der tiefen Überzeugung “Nichts” zu sein, muss er jede Berührung mit sich selbst vermeiden, kann sich selbst nur im Außen suchen, wo er sich durch den Superlativ aus seiner Minderwertigkeit zu retten versucht. So ist es ein häufiges Merkmal, dass Narzissten schillernde Persönlichkeiten sind, die innerhalb kürzester Zeit die Karriereleitern erklimmen. Und dann kommt die Erschöpfung. Aber m erkt man nicht schon irgendwann vorher, dass man gerade sehr erschöpft ist? Mirriam Prieß: Viele ignorieren die ersten Alarmzeichen und halten tatsächlich erst inne, wenn nichts mehr geht. Erst dann gehen sie zum Arzt oder in eine Klinik zur Behandlung. Ich rate allerdings dazu, nur eine kurze Auszeit zu nehmen, die nicht so lang wie möglich sondern nur so lang wie nötig dauert. Das Leben geht weiter – und je länger Sie nicht daran teilnehmen, umso schwerer ist die Rückkehr. Vor diesem Hintergrund ist es wichtig, schon bei der ersten Störung zu reagieren und sich rechtzeitig professionelle Unterstützung zu suchen. Je länger sie warten, umso schwerer und langwieriger die Heilung. Führungskräfte haben auch eine Verantwortung ihren Mitarbeitern gegenüber. Wie kann ein Entscheider feststellen, dass etwas schief läuft? Mirriam Prieß: Es gibt vier verschiedene Phasen der Erschöpfung: die Alarmphase, die Widerstandsphase, die Erschöpfungsphase und die Rückzugsphase. Die Symptome sind von außen schwer wahrzunehmen, denn die, die ausbrennen, sind oft Leistungsträger und erhalten die Fassade aufrecht. Ein klassisches Symptom ist, dass die Mitarbeiter anfangen, sich immer mehr aufzuhalsen, obwohl sie eigentlich schon nicht mehr können. Die Konzentrationsschwierigkeiten kompensieren sie, indem sie – oft heimlich – länger bleiben. Viele, die auf dem Weg nach unten sind, lassen sich immer mal wieder für einen bis zwei Tage krankschreiben. Die Betroffenen ziehen sich sozial immer mehr zurück. Wenn ein Chef das Gefühl hat, dass der Mitarbeiter ein Problem hat, dann sollte er das ansprechen . Wie kann das konkret aussehen? Mirriam Prieß: Er kann zum Beispiel sagen: “Ich sehe deutlich, dass du aus dem Gleichgewicht geraten bist und dich erschöpfst. Ich möchte dich darum bitten, dass du dir Hilfe suchst.” Wichtig ist, dafür einen Zeitraum zu vereinbaren und sich danach mit dem Mitarbeiter wieder zusammen zu setzen. Hat er sich keine Hilfe gesucht, muss man Konsequenzen ziehen. Dies kann so weit gehen, dass man den Mitarbeiter vom Projekt abzieht. Je länger man die Sache laufen lässt, umso größer der Reibungsverlust für alle Beteiligten. Nicht nur für den Betroffenen selbst, sondern auch für das Team und das Unternehmen. Nicht selten erschöpft sich am Ende ein ganzes Team durch den Versuch die Erschöpfung eines Einzelnen zu kompensieren. Ein Vorgesetzter kann auch mit dem Betriebsarzt zusammen arbeiten, oder an Hilfe von außen verweisen. Doch egal wofür sich die Führungskraft entscheidet, gelingen kann dies nur, wenn sie mit dem Mitarbeiter im Dialog ist. Führungskräfte sollten doch ohnehin mit ihren Mitarbeitern im Dialog sein. Mirriam Prieß: Ja. Sollten sie. Die Realität ist leider eine andere. Echter Dialog findet nur in den wenigsten Unternehmen statt. Ein Dialog ist erst dann ein Dialog, wenn man offen für den anderen ist und ihm auf Augenhöhe begegnet. Das ist auch in einer Hierarchie möglich. Ein Vorstand kann der Putzfrau gegenüber auf Augenhöhe begegnen. Viele verkennen dies und monologisieren in gegenseitiger Positionierung vor sich hin. Solange Sie sich rein über Ihre Position definieren, werden Sie dem Mensch Mitarbeiter nicht im Dialog begegnet können. Wie kann man als Chef feststellen, dass man keinen echten Dialog führt? Mirriam Prieß: Viele Führungskräfte reden zu den Mitarbeitern, aber nicht mit ihnen. Ich rate Führungskräften, einen Selbsttest durchzuführen und sich eine Woche lang zu beobachten: Wie häufig verliert man die Augenhöhe – und damit den Dialog -, indem man Befehle verteilt? Sehr häufig führen unterschiedliche Meinungen sofort zu einem gegenseitigem Monolog: Da haut man sich seine eigene Position um die Ohren gehauen, anstatt dem anderen zu begegnen. Ein Dialog ist dadurch gekennzeichnet, dass man die Situation anders verlässt, als man sie begonnen hat. Sei es einem anderen Gedanken, einem anderen Gefühl. Im Dialog zu sein, heißt nicht immer gleicher Meinung zu sein. Aber man sollte offen für den anderen und dessen Meinung sein Sie schreiben, dass Erschöpfung oft auch daher stammt, dass man “Ja” sagt, obwohl man “Nein” meint. Wie ist das im Arbeitsalltag zu lösen? Mirriam Prieß: “Finde zu dir selbst zurück”, 208 Seiten, ISBN: 978-3-517-09249-2, € 16,99, Südwest Verlag. Foto: Südwest Verlag Mirriam Prieß: Nicht nur Einzelpersonen sondern auch viele Unternehmenskulturen kranken daran, dass die Menschen nicht dazu in der Lage sind, sich auf Augenhöhe im “Ja” wie im “Nein” zu begegnen. Dies führt häufig zu einer Kultur des “hintenrums” – da werden sich dann Verbündete gesucht, es wird übereinander geredet, anstatt miteinander, oder aber irgendwann wird die Krankheit als Ausweg genommen und es wird über die eigene Schwäche unbewusst versucht, das zu erreichen, was sich vorher im Dialog nicht zu äußern getraut wurde. Für private wie berufliche Gesundheit ist es notwendig, für sich und seine wesentlichen Bedürfnisse einzustehen – diese jedoch nicht mit dem eigenen Willen zu verwechseln – und vor diesem Hintergrund dazu in der Lage sein, gesunde Kompromisse einzugehen. Zielsicher in die Katastrophe Foto: Johan Larson – shutterstock.com Viele Menschen steuern – bewusst oder weniger bewußt – über Jahre hinweg zielsicher auf den Burnout zu. Werden konsequent die häufigsten 13 Fehler gemacht, ist früher oder später der Burnout garantiert! Allzeit bereit! Foto: Luiz Rocha – shutterstock.com Bei Ihrem Job werden “flexible” Arbeitszeiten und Überstunden als selbstverständlich erwartet, auch Reisetätigkeiten, wechselnde Arbeitsplätze, internationale Zusammenarbeit über mehrere Zeitzonen hinweg und Erreichbarkeit 24 Stunden an sieben Tagen per Blackberry, Handy & Co. Brennen für den Job Foto: VikaSuh – shutterstock.com Ihre Tätigkeit begeistert Sie, Überstunden stören Sie nicht. Sie stehen für Flexibilität, Schnelligkeit und höchste Qualitätsansprüche. Das Team, der Chef, der Auftraggeber und alle anderen können sich stets auf Sie verlassen. Sie sind ehrgeizig, der nächste Schritt zum Projekt-Manager, Team- oder Abteilungsleiter winkt und fordert vollen Einsatz auf gleichbleibend hohem Niveau. Brennen Sie für Ihre Aufgaben, das Projekt, Ihr Team, Ihr Unternehmen – bis Sie ausgebrannt sind. Entspannen? Was ist das? Foto: Nattika – shutterstock.com Signale wie anhaltende Müdigkeit, Unkonzentriertheit, Leistungsabfall, Schlafstörungen sowie die Unfähigkeit abzuschalten und aufzutanken, ignorieren Sie. Bedienen Sie sich bei auftretenden Zipperlein großzügig an Produkten der Pharmaindustrie. Nur nicht wütend werden Foto: CREATISTA – shutterstock.com Kümmern Sie sich auf keinen Fall um Ihre Gefühle. Wut, Ärger, Ängste, das Gefühl von Überforderung oder ständiger Gehetztheit ignorieren Sie, ebenso wie das Schwinden Ihrer Lebensfreude, zunehmende Teilnahmslosigkeit, Sinn- und Lustlosigkeit und Depressionen. Bei zunehmendem Leeregefühl lösen Sie sich von der Idee, dass Arbeit Sie innerlich erfüllen könnte. Immer schön fleißig sein! Foto: nikkytok – shutterstock.com Ineffektiv verbrachte Arbeitszeit kompensieren Sie mit Mehrarbeit. Das vertreibt auch die Langeweile am Wochenende und im Urlaub. Sind Sie Freiberufler, verzichten Sie ganz auf Urlaub. Sie müssen die Aufträge abarbeiten, oder das Geld reicht nicht. Machen Sie möglichst mehrere Dinge gleichzeitig, um Zeit zu sparen. Sagen Sie “Ja” zu jeder neuen Aufgabe. Verzweifelt? Sie doch nicht! Foto: Petronilo G. Dangoy Jr. – shutterstock.com Machen Sie sich unentbehrlich. Auch wenn es unmöglich ist und Sie der Verzweiflung nah sind, versuchen Sie, möglichst alle Erwartungen von Teamkollegen, Auftraggebern, internen und externen Projektmitarbeitern, Vorgesetzten und Ihrer Familie und Freunde zu erfüllen. Am besten übertreffen Sie noch deren Erwartungen. Warnsignale? Foto: Jim Barber – shutterstock.com Verwerfen Sie sämtliche Warnungen, Vorhaltungen, Vorwürfe, Bitten und Sorgen von Ihrer/m Partner/in, Angehörigen oder Kollegen. Ihre Ausreden sollten wasserdicht sein: “Nach diesem Projekt wird alles besser” oder “nur noch dieser Fall”. Oder: “Die Umstände/der Vorgesetzte/der Auftraggeber zwingen mich dazu, ich habe keine Wahl.” Im Hamsterrad Foto: dwori – shutterstock.com Hämmern Sie sich und anderen ein, es geht nicht anders, in Ihrem Job jedenfalls nicht. Wenden Sie sich dennoch auf Drängen anderer an eine professionelle Beratung, werden Sie es sicher verstehen, die Sinnlosigkeit dieser Maßnahme unter Beweis zu stellen. Nur nicht drüber reden! Foto: Camilo Torres – shutterstock.com Gehen Sie auf Distanz zu Menschen, zu denen erstaunlicherweise noch Kontakt besteht. Als Eigenbrötler können Sie leichter die Fassade wahren. Sagen Sie niemandem, wie es Ihnen geht. Gemeinsame Mittags- und Kaffeepausen mit Kollegen sind zeitlich unmöglich, die Zeit mit der Familie wird immer knapper. Jede Minute zählt – zum Arbeiten. Foto: Phatic-Photography – shutterstock.com Streichen Sie sämtliche Hobbys einschließlich sportlicher Betätigungen. Falls Sie doch noch ein Privatleben haben, gestalten Sie die Terminplanung zwischen ihm und dem Job noch engmaschiger, nutzen Sie jede freie Minute. Gesund leben? Maßlos überschätzt! Foto: Gorilla – shutterstock.com Gesundes Essen wird als Zeitkiller abgeschafft zugunsten von Fast Food und belegten Semmeln. Damit Sie überhaupt entspannen und von Ängsten und anderen unangenehmen Gefühlen abschalten können, gönnen Sie sich regelmäßig abends etwas Alkoholisches. Perfektion, Perfektion, Perfektion Foto: CoraMax – shutterstock.com Seien Sie nie zufrieden mit Ihren Ergebnissen, auch wenn andere begeistert sind. Sie sind Ihr strengster Kritiker. Weniger als perfekt kommt für Sie nicht in Frage. Stecken Sie sich zusätzliche Ziele. Erlernen Sie eine Fremdsprache, machen Sie eine berufsbegleitende Ausbildung und laufen Sie Marathon. Probleme? Ach was! Foto: Nomad_Soul – shutterstock.com Lösen Sie keine Konflikte und Probleme grundlegend. Schieben Sie alles vor sich her, damit der Berg von Unerledigtem immer höher wird. Ein Ausstieg ist möglich! Foto: SVLuma – shutterstock.com Falls Sie sich in unserem Text zu stark wiedererkennen, steiegen Sie aus! Je früher, desto besser. Gehen Sie zum Arzt, ändern Sie Ihre Lebensweise, solange es noch früh genug ist. Das raten Ihnen Ruth Hellmich, Rechtsanwältin und Geschäftsführerin von CoachingTraining. Die Ärztin und Gesundheitsberaterin Mirriam Prieß sagt: “Viele ignorieren die ersten Alarmzeichen und halten tatsächlich erst inne, wenn nichts mehr geht.” Foto: Prieß Gerade unter IT-Spezialisten ist die Diagnose Burnout weit verbreitet: Rund die Hälfte der ITler zeigt Anzeichen einer tiefen Erschöpfung. Dr. Mirriam Prieß, Ärztin, Autorin und Beraterin für Gesundheitsmanagement, verrät, wie es gelingen kann, einen echten Dialog zu führen und damit Burnout zu verhindern. C IO.de: Frau Prieß, In Ihrem Buch schreiben Sie, dass die tiefgehende Erschöpfung, die oft Führungskräfte verspüren, darauf zurückzuführen ist, dass viele Menschen nicht “ihr eigenes Leben” führen. Was meinen Sie damit? Mirriam Prieß: Das eigene Leben zu leben bedeutet, so zu leben, wie es dem eigenen Wesen entspricht. Viele leben jedoch vielmehr nach ihrer Prägung – also ihrer Erziehung – und leben eine Vorstellung von sich selbst oder fügen sich äußeren Bedingungen und Anforderungen. Sie haben keinen Kontakt mehr mit sich selbst und wissen nicht, was sie wirklich wollen. Wer mit sich nicht in Kontakt steht, kennt weder sein Maß noch seine Grenzen und kann nicht an der richtigen Stelle “Ja” und “Nein” sagen. Darüber entstehen meist unlösbare innere und äußere Konflikte, an denen sich die Betroffenen immer mehr erschöpfen . Was wären denn solche Konflikte? Mirriam Prieß: Sie können sowohl beruflich wie privat sein. Viele sagen an der falschen Stelle zu lange “Ja”, um dann irgendwann nur noch “Nein” zu sagen. Oder sie entscheiden sich für Bedingungen, mit denen sie anschließend hadern. Wenn ich mich für ein System und eine Rolle – also einen Job – entscheide, dann tue ich dies aus freien Stücken und erkenne die damit verbundenen Realitäten und Bedingungen an. Das Problem ist, dass viele dies nicht tun, und am Ende mit dem System und den Bedingungen kämpfen, denen sie zugestimmt haben. Viele erschöpfen sich auch daran, dem eigenen Anspruch nicht gerecht zu werden , einem ständigen Optimierungszwang zu unterliegen und über die eigene Grenzenlosigkeit auszubrennen. Was heißt das in der Praxis? Mirriam Prieß: Wer das Gefühl hat, im Innen nichts zu sein, der muss im Außen alles sein. Diese unbewusste Form von tiefer Minderwertigkeit findet man bei so genannten narzisstischen Persönlichkeiten, die sich über grenzenlose Leistung und über Superlative definieren. Sie verfolgen das Prinzip “Grenzen sind dazu da, um überschritten zu werden”. Das führt dazu, dass betroffene Führungskräfte sich selbst und ihre Teams verbrennen , denn ihre hohen Maßstäbe legen sie auch an die Mitarbeiter an. Große Unternehmen können das nur kompensieren, weil sie eine so hohe Fluktuation haben: Die Führungskräfte wechseln alle drei Jahre die Position. Meinen Sie damit, dass viele Führungskräfte Narzissten sind? Mirriam Prieß: Viele glauben, dass Narzissmus nur mit Selbstverliebtheit zu tun hat und verkennen das dahinter liegende Drama. Das Ende des Gleichnis von Narziss verdeutlicht es: Indem Narziss sein Spiegelbild im Teich zu berühren versucht, zerfällt es. Hier zeigt sich das tiefe Leid des Narzissten: In der tiefen Überzeugung “Nichts” zu sein, muss er jede Berührung mit sich selbst vermeiden, kann sich selbst nur im Außen suchen, wo er sich durch den Superlativ aus seiner Minderwertigkeit zu retten versucht. So ist es ein häufiges Merkmal, dass Narzissten schillernde Persönlichkeiten sind, die innerhalb kürzester Zeit die Karriereleitern erklimmen. Und dann kommt die Erschöpfung. Aber m erkt man nicht schon irgendwann vorher, dass man gerade sehr erschöpft ist? Mirriam Prieß: Viele ignorieren die ersten Alarmzeichen und halten tatsächlich erst inne, wenn nichts mehr geht. Erst dann gehen sie zum Arzt oder in eine Klinik zur Behandlung. Ich rate allerdings dazu, nur eine kurze Auszeit zu nehmen, die nicht so lang wie möglich sondern nur so lang wie nötig dauert. Das Leben geht weiter – und je länger Sie nicht daran teilnehmen, umso schwerer ist die Rückkehr. Vor diesem Hintergrund ist es wichtig, schon bei der ersten Störung zu reagieren und sich rechtzeitig professionelle Unterstützung zu suchen. Je länger sie warten, umso schwerer und langwieriger die Heilung. Führungskräfte haben auch eine Verantwortung ihren Mitarbeitern gegenüber. Wie kann ein Entscheider feststellen, dass etwas schief läuft? Mirriam Prieß: Es gibt vier verschiedene Phasen der Erschöpfung: die Alarmphase, die Widerstandsphase, die Erschöpfungsphase und die Rückzugsphase. Die Symptome sind von außen schwer wahrzunehmen, denn die, die ausbrennen, sind oft Leistungsträger und erhalten die Fassade aufrecht. Ein klassisches Symptom ist, dass die Mitarbeiter anfangen, sich immer mehr aufzuhalsen, obwohl sie eigentlich schon nicht mehr können. Die Konzentrationsschwierigkeiten kompensieren sie, indem sie – oft heimlich – länger bleiben. Viele, die auf dem Weg nach unten sind, lassen sich immer mal wieder für einen bis zwei Tage krankschreiben. Die Betroffenen ziehen sich sozial immer mehr zurück. Wenn ein Chef das Gefühl hat, dass der Mitarbeiter ein Problem hat, dann sollte er das ansprechen . Wie kann das konkret aussehen? Mirriam Prieß: Er kann zum Beispiel sagen: “Ich sehe deutlich, dass du aus dem Gleichgewicht geraten bist und dich erschöpfst. Ich möchte dich darum bitten, dass du dir Hilfe suchst.” Wichtig ist, dafür einen Zeitraum zu vereinbaren und sich danach mit dem Mitarbeiter wieder zusammen zu setzen. Hat er sich keine Hilfe gesucht, muss man Konsequenzen ziehen. Dies kann so weit gehen, dass man den Mitarbeiter vom Projekt abzieht. Je länger man die Sache laufen lässt, umso größer der Reibungsverlust für alle Beteiligten. Nicht nur für den Betroffenen selbst, sondern auch für das Team und das Unternehmen. Nicht selten erschöpft sich am Ende ein ganzes Team durch den Versuch die Erschöpfung eines Einzelnen zu kompensieren. Ein Vorgesetzter kann auch mit dem Betriebsarzt zusammen arbeiten, oder an Hilfe von außen verweisen. Doch egal wofür sich die Führungskraft entscheidet, gelingen kann dies nur, wenn sie mit dem Mitarbeiter im Dialog ist. Führungskräfte sollten doch ohnehin mit ihren Mitarbeitern im Dialog sein. Mirriam Prieß: Ja. Sollten sie. Die Realität ist leider eine andere. Echter Dialog findet nur in den wenigsten Unternehmen statt. Ein Dialog ist erst dann ein Dialog, wenn man offen für den anderen ist und ihm auf Augenhöhe begegnet. Das ist auch in einer Hierarchie möglich. Ein Vorstand kann der Putzfrau gegenüber auf Augenhöhe begegnen. Viele verkennen dies und monologisieren in gegenseitiger Positionierung vor sich hin. Solange Sie sich rein über Ihre Position definieren, werden Sie dem Mensch Mitarbeiter nicht im Dialog begegnet können. Wie kann man als Chef feststellen, dass man keinen echten Dialog führt? Mirriam Prieß: Viele Führungskräfte reden zu den Mitarbeitern, aber nicht mit ihnen. Ich rate Führungskräften, einen Selbsttest durchzuführen und sich eine Woche lang zu beobachten: Wie häufig verliert man die Augenhöhe – und damit den Dialog -, indem man Befehle verteilt? Sehr häufig führen unterschiedliche Meinungen sofort zu einem gegenseitigem Monolog: Da haut man sich seine eigene Position um die Ohren gehauen, anstatt dem anderen zu begegnen. Ein Dialog ist dadurch gekennzeichnet, dass man die Situation anders verlässt, als man sie begonnen hat. Sei es einem anderen Gedanken, einem anderen Gefühl. Im Dialog zu sein, heißt nicht immer gleicher Meinung zu sein. Aber man sollte offen für den anderen und dessen Meinung sein Sie schreiben, dass Erschöpfung oft auch daher stammt, dass man “Ja” sagt, obwohl man “Nein” meint. Wie ist das im Arbeitsalltag zu lösen? Mirriam Prieß: “Finde zu dir selbst zurück”, 208 Seiten, ISBN: 978-3-517-09249-2, € 16,99, Südwest Verlag. Foto: Südwest Verlag Mirriam Prieß: Nicht nur Einzelpersonen sondern auch viele Unternehmenskulturen kranken daran, dass die Menschen nicht dazu in der Lage sind, sich auf Augenhöhe im “Ja” wie im “Nein” zu begegnen. Dies führt häufig zu einer Kultur des “hintenrums” – da werden sich dann Verbündete gesucht, es wird übereinander geredet, anstatt miteinander, oder aber irgendwann wird die Krankheit als Ausweg genommen und es wird über die eigene Schwäche unbewusst versucht, das zu erreichen, was sich vorher im Dialog nicht zu äußern getraut wurde. Für private wie berufliche Gesundheit ist es notwendig, für sich und seine wesentlichen Bedürfnisse einzustehen – diese jedoch nicht mit dem eigenen Willen zu verwechseln – und vor diesem Hintergrund dazu in der Lage sein, gesunde Kompromisse einzugehen. Zielsicher in die Katastrophe Foto: Johan Larson – shutterstock.com Viele Menschen steuern – bewusst oder weniger bewußt – über Jahre hinweg zielsicher auf den Burnout zu. Werden konsequent die häufigsten 13 Fehler gemacht, ist früher oder später der Burnout garantiert! Allzeit bereit! Foto: Luiz Rocha – shutterstock.com Bei Ihrem Job werden “flexible” Arbeitszeiten und Überstunden als selbstverständlich erwartet, auch Reisetätigkeiten, wechselnde Arbeitsplätze, internationale Zusammenarbeit über mehrere Zeitzonen hinweg und Erreichbarkeit 24 Stunden an sieben Tagen per Blackberry, Handy & Co. Brennen für den Job Foto: VikaSuh – shutterstock.com Ihre Tätigkeit begeistert Sie, Überstunden stören Sie nicht. Sie stehen für Flexibilität, Schnelligkeit und höchste Qualitätsansprüche. Das Team, der Chef, der Auftraggeber und alle anderen können sich stets auf Sie verlassen. Sie sind ehrgeizig, der nächste Schritt zum Projekt-Manager, Team- oder Abteilungsleiter winkt und fordert vollen Einsatz auf gleichbleibend hohem Niveau. Brennen Sie für Ihre Aufgaben, das Projekt, Ihr Team, Ihr Unternehmen – bis Sie ausgebrannt sind. Entspannen? Was ist das? Foto: Nattika – shutterstock.com Signale wie anhaltende Müdigkeit, Unkonzentriertheit, Leistungsabfall, Schlafstörungen sowie die Unfähigkeit abzuschalten und aufzutanken, ignorieren Sie. Bedienen Sie sich bei auftretenden Zipperlein großzügig an Produkten der Pharmaindustrie. Nur nicht wütend werden Foto: CREATISTA – shutterstock.com Kümmern Sie sich auf keinen Fall um Ihre Gefühle. Wut, Ärger, Ängste, das Gefühl von Überforderung oder ständiger Gehetztheit ignorieren Sie, ebenso wie das Schwinden Ihrer Lebensfreude, zunehmende Teilnahmslosigkeit, Sinn- und Lustlosigkeit und Depressionen. Bei zunehmendem Leeregefühl lösen Sie sich von der Idee, dass Arbeit Sie innerlich erfüllen könnte. Immer schön fleißig sein! Foto: nikkytok – shutterstock.com Ineffektiv verbrachte Arbeitszeit kompensieren Sie mit Mehrarbeit. Das vertreibt auch die Langeweile am Wochenende und im Urlaub. Sind Sie Freiberufler, verzichten Sie ganz auf Urlaub. Sie müssen die Aufträge abarbeiten, oder das Geld reicht nicht. Machen Sie möglichst mehrere Dinge gleichzeitig, um Zeit zu sparen. Sagen Sie “Ja” zu jeder neuen Aufgabe. Verzweifelt? Sie doch nicht! Foto: Petronilo G. Dangoy Jr. – shutterstock.com Machen Sie sich unentbehrlich. Auch wenn es unmöglich ist und Sie der Verzweiflung nah sind, versuchen Sie, möglichst alle Erwartungen von Teamkollegen, Auftraggebern, internen und externen Projektmitarbeitern, Vorgesetzten und Ihrer Familie und Freunde zu erfüllen. Am besten übertreffen Sie noch deren Erwartungen. Warnsignale? Foto: Jim Barber – shutterstock.com Verwerfen Sie sämtliche Warnungen, Vorhaltungen, Vorwürfe, Bitten und Sorgen von Ihrer/m Partner/in, Angehörigen oder Kollegen. Ihre Ausreden sollten wasserdicht sein: “Nach diesem Projekt wird alles besser” oder “nur noch dieser Fall”. Oder: “Die Umstände/der Vorgesetzte/der Auftraggeber zwingen mich dazu, ich habe keine Wahl.” Im Hamsterrad Foto: dwori – shutterstock.com Hämmern Sie sich und anderen ein, es geht nicht anders, in Ihrem Job jedenfalls nicht. Wenden Sie sich dennoch auf Drängen anderer an eine professionelle Beratung, werden Sie es sicher verstehen, die Sinnlosigkeit dieser Maßnahme unter Beweis zu stellen. Nur nicht drüber reden! Foto: Camilo Torres – shutterstock.com Gehen Sie auf Distanz zu Menschen, zu denen erstaunlicherweise noch Kontakt besteht. Als Eigenbrötler können Sie leichter die Fassade wahren. Sagen Sie niemandem, wie es Ihnen geht. Gemeinsame Mittags- und Kaffeepausen mit Kollegen sind zeitlich unmöglich, die Zeit mit der Familie wird immer knapper. Jede Minute zählt – zum Arbeiten. Foto: Phatic-Photography – shutterstock.com Streichen Sie sämtliche Hobbys einschließlich sportlicher Betätigungen. Falls Sie doch noch ein Privatleben haben, gestalten Sie die Terminplanung zwischen ihm und dem Job noch engmaschiger, nutzen Sie jede freie Minute. Gesund leben? Maßlos überschätzt! Foto: Gorilla – shutterstock.com Gesundes Essen wird als Zeitkiller abgeschafft zugunsten von Fast Food und belegten Semmeln. Damit Sie überhaupt entspannen und von Ängsten und anderen unangenehmen Gefühlen abschalten können, gönnen Sie sich regelmäßig abends etwas Alkoholisches. Perfektion, Perfektion, Perfektion Foto: CoraMax – shutterstock.com Seien Sie nie zufrieden mit Ihren Ergebnissen, auch wenn andere begeistert sind. Sie sind Ihr strengster Kritiker. Weniger als perfekt kommt für Sie nicht in Frage. Stecken Sie sich zusätzliche Ziele. Erlernen Sie eine Fremdsprache, machen Sie eine berufsbegleitende Ausbildung und laufen Sie Marathon. Probleme? Ach was! Foto: Nomad_Soul – shutterstock.com Lösen Sie keine Konflikte und Probleme grundlegend. Schieben Sie alles vor sich her, damit der Berg von Unerledigtem immer höher wird. Ein Ausstieg ist möglich! Foto: SVLuma – shutterstock.com Falls Sie sich in unserem Text zu stark wiedererkennen, steiegen Sie aus! Je früher, desto besser. Gehen Sie zum Arzt, ändern Sie Ihre Lebensweise, solange es noch früh genug ist. Das raten Ihnen Ruth Hellmich, Rechtsanwältin und Geschäftsführerin von CoachingTraining.",
    "source": "cio",
    "crawled_at": "2025-05-27T08:10:56.317560+00:00"
  },
  {
    "url": "https://www.cio.de/article/3696762/freies-denken-organisieren.html",
    "title": "Innovationsmanagement: Freies Denken organisieren",
    "published": "2025-05-22T07:14:40+00:00",
    "author": "",
    "text": "Anstatt sich auf zufällige Heureka-Momente zu verlassen, soll Innovationsmanagement eine Umgebung schaffen, in der Ideen systematisch gefördert und umgesetzt werden. Foto: Pressmaster – shutterstock.com Innovation ist der entscheidende Faktor für den langfristigen Erfolg eines Unternehmens. Heute mehr denn je. Was einige Großkonzerne schon seit Jahren praktizieren, kommt bislang jedoch eher zögerlich auch in anderen Unternehmen an: ein Innovationsmanagement, das sich nicht auf zufällige Ideen Einzelner stützt, sondern gezielt innovationsfördernde Rahmenbedingungen schafft. Damit gewinnt das ganze Unternehmen an Kreativität und Innovationskraft. Es ebnet den Weg für neue Lösungen und stärkt so seine Wettbewerbsfähigkeit. Wer ein professionelles Innovationsmanagement etablieren will, sollte zunächst klären, was darunter zu verstehen ist. “Innovation” leitet sich aus dem lateinischen “innovare” (erneuern) ab. In der Praxis sieht das so aus: Am Anfang steht eine Idee. Um daraus eine Innovation zu machen, müssen vor allem folgende Kriterien erfüllt sein: die Idee muss neu für das Unternehmen sein; ein Mehrwert sollte von Anfang an ersichtlich sein; für die Umsetzung sollte eine Investition erforderlich sein. Erfüllt ein Vorschlag diese Kriterien, wird er in das Innovationsmanagement aufgenommen. Umgesetzt wird die Innovation in der Regel zunächst als Prototyp, Labor- oder Beta-Phase. Dann folgt die Wertschöpfung: Die Innovation wird intern umgesetzt oder in ein marktfähiges, skalierbares Produkt beziehungsweise eine Dienstleistung überführt. Innovationen zu entwickeln und zu etablieren umfasst somit zwei wesentliche Bereiche: einen kreativen Teil, innerhalb dessen die Beteiligten im Wesentlichen Ideen generieren und auf ihre Sinnhaftigkeit und Umsetzbarkeit abklopfen; und einen operativen Teil, in dem es darum geht, die Ideen zur Reife zu bringen, sie umzusetzen und die Innovation in den Markt einzuführen. Unternehmen, die ein professionelles Innovationsmanagement etablieren möchten, sollten sich vorab einige grundsätzliche Fragen stellen und beantworten. Dazu gehört zu klären, welchen Stellenwert das Innovationsmanagement im Unternehmen einnehmen soll. Hierzu ist es sinnvoll, eine Stabsstelle einzurichten, denn es geht um eine Querschnittsfunktion, die alle Bereiche betrifft. Sie kann nur dann ihre optimale Wirkung entfalten, wenn sie nah an der Führungsebene angesiedelt ist. Es gilt zu klären, mit welchen konkreten Maßnahmen und Prozessen sich eine innovative Kultur fördern und etablieren lässt. Welches Anreizsystem ist damit verbunden und wie soll der generische Innovationsprozess aussehen? Schließlich müssen die damit zusammenhängenden Prozesse möglichst reibungslos in die anderen unternehmerischen Abläufe integriert werden. Offenheit und Transparenz sind entscheidend, damit ein Innovationsprozess die gewünschten Ergebnisse bringt. Alle Mitarbeiterinnen und Mitarbeiter, gleichgültig auf welcher Ebene und in welcher Funktion, müssen die Möglichkeit haben, eigene Ideen einzubringen. Grundmodell des Innovationsmanagements Foto: doubleSlash Net-Business GmbH Aufgabe eines Innovationsmanagers ist es also, innovationsfördernde Prozesse zu entwickeln, aufzusetzen und zu begleiten. Er muss, wenn man so will, das freie, kreative Denken organisieren. Denn das ist kein Selbstläufer, sondern erfordert zielgerichtetes Vorgehen. Lesetipp: Herausforderungen für CIOs – 10 Hürden für Innovation Manager Zunächst muss der Innovationsmanager Strukturen und Prozesse aufbauen. Dabei ist es hilfreich, diese an die bereits im Unternehmen bestehenden Strukturen und Prozesse anzudocken. Das verringert Reibungsverluste und macht es einfacher, die Neuerungen in die täglichen Routinen einfließen zu lassen. Sogenannte Stage/Gate-Phasen bilden das Rückgrat des Innovationsprozesses. Stage bezeichnet die Ausarbeitungsphasen, an deren Ende jeweils ein Gate steht. Dort bewertet das sogenannte Bid Board, ein Team, das je nach Aufgabe unterschiedlich besetzt ist, die Ergebnisse der vorangegangenen Stage-Phase. Innovationsprozess Foto: doubleSlash Jedes Gate hat drei Ausgänge: Pass – die Idee wird als aussichtsreich und gut genug empfunden, um sie in die nächste Stufe zu überführen. Stop – die Idee wird verworfen. Replay – die Idee wird an die Verantwortlichen zurückverwiesen, um bestimmte Aufgaben zu erledigen, ehe sie erneut dem Bid Board vorgestellt wird. Beispielhaft kann man sich an vier Stage/Gate-Phasen orientieren: Phase 1: Die Idee wird geboren. Die Ideengeber definieren, wer Nutznießer der potenziellen Innovation sein könnte und suchen einen unternehmensinternen Sponsor. Die Sponsorin oder der Sponsor stellt Ressourcen für die Weiterführung der Idee zur Verfügung (am Anfang meist Arbeitszeit, gegebenenfalls auch finanzielle Mittel), beziehungsweise stellt deren Freigabe in Aussicht, falls Phase 1 erfolgreich zum Abschluss kommt. Phase 2: Zeit für eine STQB-Betrachtung, also Scope (worum geht es genau?), Time, Quality und Budget. Die Idee gewinnt an Qualität und Tiefe. Es entsteht eine detailliertere Beschreibung des potenziellen Projekts, wie es sich realisieren lässt, welchen Nutzen es bringen kann und mit welchem Ressourceneinsatz zu rechnen ist. Phase 3: die Implementierungsphase. Aus der ursprünglichen Idee wird ein gesondertes Projekt. Je nach Umfang kann es jetzt auch schon mit relativ großem Zeit- und Finanzbudget ausgestattet werden. Phase 4: Rollout. Die Innovation startet intern oder extern in den Markt. In der Regel sind vier Funktionsträger oder Gremien an den Prozessen beteiligt: die Ideengebende Person oder ein Team. Die Sponsorenrolle fördert deren Entwicklung, treibt sie voran und verantwortet die Erfolgskontrolle in den verschiedenen Phasen des Stage/Gate-Prozesses. Die bearbeitende Person entwickelt die Idee federführend weiter. Und das Bid Board beurteilt die Ergebnisse der jeweiligen Phase. Dem Bid Board gehören grundsätzlich Verantwortliche von Unternehmensbereichen und/oder Geschäftsfeldern und die Teamleitung an. Übersteigt das Projekt ein gewisses Level an Aufwand und Relevanz für das Unternehmen, kommt auch die oberste Führungsebene hinzu. Nach der Bewertung der Idee und deren Entwicklung benennt das Bid Board eine Person als Projektleitung , die für die weitere Entwicklung der Innovation verantwortlich ist. Um das Ganze möglichst reibungsfrei in die gewohnte Arbeitsumgebung einzufügen, kann das Innovationsmanagement in ein internes Ticketsystem integriert werden, zu dem alle Mitarbeitenden Zugang haben. Ein neues Ticket zu eröffnen oder auf ein bestehendes zu reagieren, ist ausgesprochen einfach und fester Bestandteil von Arbeitsabläufen. Das Innovationsmanagement ist damit alle offen und jeder kann jedes darin befindliche Ticket kommentieren und beispielsweise dafür “voten”. Das ist mitunter ein hilfreicher Indikator dafür, wie die Belegschaft eine Idee einordnet und bewertet. Ein entscheidender Motivations- und Erfolgsfaktor ist, dass neue Ideen und deren Entwicklung von Anfang an belohnt werden. Ideal ist ein Mix aus intrinsischen und extrinsischen Motivatoren. Intrinsische können sein: Freude am Entwickeln und Teilen von Ideen; die Möglichkeit, unabhängig von der hierarchischen Stellung im Unternehmen mitzugestalten und sich einzubringen; Kommentare von Kolleginnen und Kollegen und die Anerkennung durch die Belegschaft. Zu den extrinsischen Motivatoren zählen etwa Gutscheine, Boni oder sonstige Geldzuwendungen, die sich nach jedem erfolgreich abgeschlossenen Gate steigern sollten. Große Unternehmen und Konzerne beteiligen zum Beispiel Mitarbeitende, die Innovationen anstoßen, indem sie einen bestimmten Teil des ersten Jahresumsatzes bekommen, den das Unternehmen mit ihrer Innovation erzielt. Die Gretchenfrage: Funktioniert das im Arbeitsalltag? Die klare Antwort: Ja, sehr gut sogar. Oft steuern Mitarbeitende zunächst überwiegend Ideen zur Optimierung ihres eigenen Arbeitsplatzes und ihrer Arbeitsumgebung ein. Der Gewinn für ein Unternehmen ist klar: Wenn viele Ideen umgesetzt werden, fördert das den Zusammenhalt und das Wir-Gefühl. Die Mitarbeitenden merken: Ich kann etwas bewegen. Wesentliche Einflussfelder auf die Innovationskultur Foto: doubleSlash Net-Business GmbH Ein strukturierter Innovationsprozess kann immenses Motivationspotenzial entfalten: Mitarbeitende, die ihre eigenen Ideen während ihrer Arbeitszeit entwickeln und vorantreiben – und dafür auch noch belohnt werden –, arbeiten damit an Dingen, für die sie sich besonders begeistern. Übrigens: Die Parallelen zur digitalen Transformation und der vielzitierten neuen Unternehmenskultur sind offensichtlich. Denn auch für ein Innovationsmanagement gilt: Die Unternehmensleitung muss den Sinn sehen und die Neuerungen aktiv unterstützen. Tipps für ein erfolgreiches Innovationsmanagement: Gestalten Sie Ihren Innovationsprozess absolut frei von Hierarchien, sie behindern Kreativität. Pflegen Sie maximale Transparenz. Jede Entscheidung muss anhand klarer Kriterien nachvollziehbar sein. Etablieren Sie klar strukturierte, offene Prozesse. Integrieren Sie ein Bonussystem, das sehr früh ansetzt. Sorgen Sie für eine niedrige Einstiegshürde. Innovation lebt nicht zuletzt von der Schwarmintelligenz. Mitmachen muss deshalb einfach sein. Wichtig: Innovationskraft ist primär eine Frage von richtiger und guter Unternehmensführung. Heutzutage gibt es bereits zahlreiche Studiengänge mit Schwerpunkt Innovationsmanagement . Das zeigt, wie wichtig ein Innovationsmanagement für Unternehmen heute schon ist und es dürfte an Bedeutung noch gewinnen. Es kann auch sinnvoll sein, die Innovationsmanagement-Funktion intern zu besetzen und etwa über ein entsprechendes berufsbegleitendes Studium abzubilden. Das hat den Vorteil, dass die Prozesse und Abläufe im Unternehmen schon bekannt sind und es damit leichter fallen dürfte, die passenden Prozesse aufzusetzen. So entstehen innovative Ideen Foto: Stauke – Fotolia.com Die besten Ideengeber im Unternehmen sind nicht die Führungskräfte, sondern die Mitarbeiter und die Kunden, sagt Anne M. Schüller. 1. Ist-Analyse: Foto: Sergej Khackimullin – Fotolia.com Beleuchten Sie die zu optimierende Situation beziehungsweise das zu lösende Problem aus verschiedenen Perspektiven, vor allem aber aus der Sicht des Kunden. Machen Sie dazu Kunden- und Konkurrenzbeobachtungen sowie Interviews mit Mitarbeitern und Externen. Auch Branchenfremde können sinnvolle Beiträge liefern. 2. Ziel-Definition: Foto: Radim Strojek – Fotolia.com Wo wollen Sie hin, was soll am Ende des Prozesses erreicht sein? Dies muss deutlich werden, damit die Ideen-Generierung eine Richtung bekommt. Gehen Sie dabei von kundenrelevanten, differenzierenden Merkmalen aus: Was können wir für unsere Kunden besser, schneller, einfacher, billiger machen. Formulieren Sie all das schriftlich. 3. Zusammenstellung des Teams: Foto: Maximilian Haupt – Fotolia.com Dazu gehören insbesondere die Mitarbeiter, die von der späteren Umsetzung betroffen sind. Damit minimieren Sie von vorne herein aufkommende Widerstände. Sorgen Sie für Visionäre, Querdenker, Missionare, Macher, Kundenbotschafter und Bedenkenträger im Team ebenso wie für Experten und Laien. Mischen Sie alt und jung, Männer und Frauen. Briefen Sie das Team sorgfältig. Ein geschulter Moderator kann helfen, die Prozessschritte zielgerichtet zu steuern. 4. Ideen-Generierung: Foto: chrisharvey – Fotolia.com Begeben Sie sich an einen neutralen, störungsfreien, inspirierenden Ort und setzen Sie passende Kreativitätstechniken ein. Sorgen Sie am Anfang für gute Laune und ein Kreativ-Warm-up. Zeiteinheiten von 30 bis 60 Minuten sind optimal. Hören Sie nicht zu schnell auf, in dieser frühen Phase benötigen Sie ein Maximum an Ideen. Speichern Sie alle Ideen. Und beachten Sie die drei goldenen Regeln einer Kreativ-Sitzung: – Quantität vor Qualität, Inspiration ist erwünscht – alle Teilnehmer sind gleichberechtigt, keine Hierarchie – keinerlei Kritik, weder positiver noch negativer Art 5. Ideen-Bewertung und -Selektion: Foto: Arcurs – Fotolia.com Benutzen Sie jeweils passende Bewertungs- und Selektionstechniken, um die gefundenen Ideen zu verdichten, zu kombinieren und die Spreu vom Weizen zu trennen. Dies kann ein separates Bewertungsteam tun, dem auch Kunden angehören. Erstellen Sie eine Prioritäten-Liste, sortieren Sie nach Marktfähigkeit, Machbarkeit, Zeithorizont, Wirtschaftlichkeit und Nichtkopierbarkeit. Dabei kommt es erfahrungsgemäß zu weiteren Ideen. Am Ende dieses Prozesses verbleiben einige wenige aussichtsreiche Favoriten. Geben Sie diesen Namen und definieren Sie das weitere Vorgehen, beispielsweise in Form eines Projekts. 6. Implementierung: Foto: peppi18 – Fotolia.com Sorgen Sie zunächst für interne Akzeptanz, vor allem bei den ‚betroffenen‘ Mitarbeitern. Dies erfolgt am besten durch Involvieren und frühzeitige, regelmäßige, offene Kommunikation. Stellen Sie die notwendigen Ressourcen bereit. Kommunizieren Sie aktiv mit dem Markt, insbesondere mit den anvisierten Zielgruppen und mit der Presse. Bringen Sie Ihre Idee beziehungsweise Innovation zügig in den Markt, und zwar zum richtigen Zeitpunkt. Experimentieren Sie und testen Sie Varianten. Lassen Sie die Kunden schließlich mitentscheiden. 7. Kontrolle und Optimierung: Foto: MR.LIGHTMAN – Fotolia.com Vergleichen Sie die Ergebnisse mit Ihrer Zieldefinition. Holen Sie sich Feedback vom Kunden, hören Sie dabei auch auf die leisen Töne und die kritischen Hinweise. Optimieren Sie kontinuierlich, das heißt: Beginnen Sie diesen Prozess von vorn. Sorgen Sie für einen regelmäßigen Nachschub an unverbrauchten, außergewöhnlichen Ideen. Anstatt sich auf zufällige Heureka-Momente zu verlassen, soll Innovationsmanagement eine Umgebung schaffen, in der Ideen systematisch gefördert und umgesetzt werden. Foto: Pressmaster – shutterstock.com Innovation ist der entscheidende Faktor für den langfristigen Erfolg eines Unternehmens. Heute mehr denn je. Was einige Großkonzerne schon seit Jahren praktizieren, kommt bislang jedoch eher zögerlich auch in anderen Unternehmen an: ein Innovationsmanagement, das sich nicht auf zufällige Ideen Einzelner stützt, sondern gezielt innovationsfördernde Rahmenbedingungen schafft. Damit gewinnt das ganze Unternehmen an Kreativität und Innovationskraft. Es ebnet den Weg für neue Lösungen und stärkt so seine Wettbewerbsfähigkeit. Wer ein professionelles Innovationsmanagement etablieren will, sollte zunächst klären, was darunter zu verstehen ist. “Innovation” leitet sich aus dem lateinischen “innovare” (erneuern) ab. In der Praxis sieht das so aus: Am Anfang steht eine Idee. Um daraus eine Innovation zu machen, müssen vor allem folgende Kriterien erfüllt sein: die Idee muss neu für das Unternehmen sein; ein Mehrwert sollte von Anfang an ersichtlich sein; für die Umsetzung sollte eine Investition erforderlich sein. Erfüllt ein Vorschlag diese Kriterien, wird er in das Innovationsmanagement aufgenommen. Umgesetzt wird die Innovation in der Regel zunächst als Prototyp, Labor- oder Beta-Phase. Dann folgt die Wertschöpfung: Die Innovation wird intern umgesetzt oder in ein marktfähiges, skalierbares Produkt beziehungsweise eine Dienstleistung überführt. Innovationen zu entwickeln und zu etablieren umfasst somit zwei wesentliche Bereiche: einen kreativen Teil, innerhalb dessen die Beteiligten im Wesentlichen Ideen generieren und auf ihre Sinnhaftigkeit und Umsetzbarkeit abklopfen; und einen operativen Teil, in dem es darum geht, die Ideen zur Reife zu bringen, sie umzusetzen und die Innovation in den Markt einzuführen. Unternehmen, die ein professionelles Innovationsmanagement etablieren möchten, sollten sich vorab einige grundsätzliche Fragen stellen und beantworten. Dazu gehört zu klären, welchen Stellenwert das Innovationsmanagement im Unternehmen einnehmen soll. Hierzu ist es sinnvoll, eine Stabsstelle einzurichten, denn es geht um eine Querschnittsfunktion, die alle Bereiche betrifft. Sie kann nur dann ihre optimale Wirkung entfalten, wenn sie nah an der Führungsebene angesiedelt ist. Es gilt zu klären, mit welchen konkreten Maßnahmen und Prozessen sich eine innovative Kultur fördern und etablieren lässt. Welches Anreizsystem ist damit verbunden und wie soll der generische Innovationsprozess aussehen? Schließlich müssen die damit zusammenhängenden Prozesse möglichst reibungslos in die anderen unternehmerischen Abläufe integriert werden. Offenheit und Transparenz sind entscheidend, damit ein Innovationsprozess die gewünschten Ergebnisse bringt. Alle Mitarbeiterinnen und Mitarbeiter, gleichgültig auf welcher Ebene und in welcher Funktion, müssen die Möglichkeit haben, eigene Ideen einzubringen. Grundmodell des Innovationsmanagements Foto: doubleSlash Net-Business GmbH Aufgabe eines Innovationsmanagers ist es also, innovationsfördernde Prozesse zu entwickeln, aufzusetzen und zu begleiten. Er muss, wenn man so will, das freie, kreative Denken organisieren. Denn das ist kein Selbstläufer, sondern erfordert zielgerichtetes Vorgehen. Lesetipp: Herausforderungen für CIOs – 10 Hürden für Innovation Manager Zunächst muss der Innovationsmanager Strukturen und Prozesse aufbauen. Dabei ist es hilfreich, diese an die bereits im Unternehmen bestehenden Strukturen und Prozesse anzudocken. Das verringert Reibungsverluste und macht es einfacher, die Neuerungen in die täglichen Routinen einfließen zu lassen. Sogenannte Stage/Gate-Phasen bilden das Rückgrat des Innovationsprozesses. Stage bezeichnet die Ausarbeitungsphasen, an deren Ende jeweils ein Gate steht. Dort bewertet das sogenannte Bid Board, ein Team, das je nach Aufgabe unterschiedlich besetzt ist, die Ergebnisse der vorangegangenen Stage-Phase. Innovationsprozess Foto: doubleSlash Jedes Gate hat drei Ausgänge: Pass – die Idee wird als aussichtsreich und gut genug empfunden, um sie in die nächste Stufe zu überführen. Stop – die Idee wird verworfen. Replay – die Idee wird an die Verantwortlichen zurückverwiesen, um bestimmte Aufgaben zu erledigen, ehe sie erneut dem Bid Board vorgestellt wird. Beispielhaft kann man sich an vier Stage/Gate-Phasen orientieren: Phase 1: Die Idee wird geboren. Die Ideengeber definieren, wer Nutznießer der potenziellen Innovation sein könnte und suchen einen unternehmensinternen Sponsor. Die Sponsorin oder der Sponsor stellt Ressourcen für die Weiterführung der Idee zur Verfügung (am Anfang meist Arbeitszeit, gegebenenfalls auch finanzielle Mittel), beziehungsweise stellt deren Freigabe in Aussicht, falls Phase 1 erfolgreich zum Abschluss kommt. Phase 2: Zeit für eine STQB-Betrachtung, also Scope (worum geht es genau?), Time, Quality und Budget. Die Idee gewinnt an Qualität und Tiefe. Es entsteht eine detailliertere Beschreibung des potenziellen Projekts, wie es sich realisieren lässt, welchen Nutzen es bringen kann und mit welchem Ressourceneinsatz zu rechnen ist. Phase 3: die Implementierungsphase. Aus der ursprünglichen Idee wird ein gesondertes Projekt. Je nach Umfang kann es jetzt auch schon mit relativ großem Zeit- und Finanzbudget ausgestattet werden. Phase 4: Rollout. Die Innovation startet intern oder extern in den Markt. In der Regel sind vier Funktionsträger oder Gremien an den Prozessen beteiligt: die Ideengebende Person oder ein Team. Die Sponsorenrolle fördert deren Entwicklung, treibt sie voran und verantwortet die Erfolgskontrolle in den verschiedenen Phasen des Stage/Gate-Prozesses. Die bearbeitende Person entwickelt die Idee federführend weiter. Und das Bid Board beurteilt die Ergebnisse der jeweiligen Phase. Dem Bid Board gehören grundsätzlich Verantwortliche von Unternehmensbereichen und/oder Geschäftsfeldern und die Teamleitung an. Übersteigt das Projekt ein gewisses Level an Aufwand und Relevanz für das Unternehmen, kommt auch die oberste Führungsebene hinzu. Nach der Bewertung der Idee und deren Entwicklung benennt das Bid Board eine Person als Projektleitung , die für die weitere Entwicklung der Innovation verantwortlich ist. Um das Ganze möglichst reibungsfrei in die gewohnte Arbeitsumgebung einzufügen, kann das Innovationsmanagement in ein internes Ticketsystem integriert werden, zu dem alle Mitarbeitenden Zugang haben. Ein neues Ticket zu eröffnen oder auf ein bestehendes zu reagieren, ist ausgesprochen einfach und fester Bestandteil von Arbeitsabläufen. Das Innovationsmanagement ist damit alle offen und jeder kann jedes darin befindliche Ticket kommentieren und beispielsweise dafür “voten”. Das ist mitunter ein hilfreicher Indikator dafür, wie die Belegschaft eine Idee einordnet und bewertet. Ein entscheidender Motivations- und Erfolgsfaktor ist, dass neue Ideen und deren Entwicklung von Anfang an belohnt werden. Ideal ist ein Mix aus intrinsischen und extrinsischen Motivatoren. Intrinsische können sein: Freude am Entwickeln und Teilen von Ideen; die Möglichkeit, unabhängig von der hierarchischen Stellung im Unternehmen mitzugestalten und sich einzubringen; Kommentare von Kolleginnen und Kollegen und die Anerkennung durch die Belegschaft. Zu den extrinsischen Motivatoren zählen etwa Gutscheine, Boni oder sonstige Geldzuwendungen, die sich nach jedem erfolgreich abgeschlossenen Gate steigern sollten. Große Unternehmen und Konzerne beteiligen zum Beispiel Mitarbeitende, die Innovationen anstoßen, indem sie einen bestimmten Teil des ersten Jahresumsatzes bekommen, den das Unternehmen mit ihrer Innovation erzielt. Die Gretchenfrage: Funktioniert das im Arbeitsalltag? Die klare Antwort: Ja, sehr gut sogar. Oft steuern Mitarbeitende zunächst überwiegend Ideen zur Optimierung ihres eigenen Arbeitsplatzes und ihrer Arbeitsumgebung ein. Der Gewinn für ein Unternehmen ist klar: Wenn viele Ideen umgesetzt werden, fördert das den Zusammenhalt und das Wir-Gefühl. Die Mitarbeitenden merken: Ich kann etwas bewegen. Wesentliche Einflussfelder auf die Innovationskultur Foto: doubleSlash Net-Business GmbH Ein strukturierter Innovationsprozess kann immenses Motivationspotenzial entfalten: Mitarbeitende, die ihre eigenen Ideen während ihrer Arbeitszeit entwickeln und vorantreiben – und dafür auch noch belohnt werden –, arbeiten damit an Dingen, für die sie sich besonders begeistern. Übrigens: Die Parallelen zur digitalen Transformation und der vielzitierten neuen Unternehmenskultur sind offensichtlich. Denn auch für ein Innovationsmanagement gilt: Die Unternehmensleitung muss den Sinn sehen und die Neuerungen aktiv unterstützen. Tipps für ein erfolgreiches Innovationsmanagement: Gestalten Sie Ihren Innovationsprozess absolut frei von Hierarchien, sie behindern Kreativität. Pflegen Sie maximale Transparenz. Jede Entscheidung muss anhand klarer Kriterien nachvollziehbar sein. Etablieren Sie klar strukturierte, offene Prozesse. Integrieren Sie ein Bonussystem, das sehr früh ansetzt. Sorgen Sie für eine niedrige Einstiegshürde. Innovation lebt nicht zuletzt von der Schwarmintelligenz. Mitmachen muss deshalb einfach sein. Wichtig: Innovationskraft ist primär eine Frage von richtiger und guter Unternehmensführung. Heutzutage gibt es bereits zahlreiche Studiengänge mit Schwerpunkt Innovationsmanagement . Das zeigt, wie wichtig ein Innovationsmanagement für Unternehmen heute schon ist und es dürfte an Bedeutung noch gewinnen. Es kann auch sinnvoll sein, die Innovationsmanagement-Funktion intern zu besetzen und etwa über ein entsprechendes berufsbegleitendes Studium abzubilden. Das hat den Vorteil, dass die Prozesse und Abläufe im Unternehmen schon bekannt sind und es damit leichter fallen dürfte, die passenden Prozesse aufzusetzen. So entstehen innovative Ideen Foto: Stauke – Fotolia.com Die besten Ideengeber im Unternehmen sind nicht die Führungskräfte, sondern die Mitarbeiter und die Kunden, sagt Anne M. Schüller. 1. Ist-Analyse: Foto: Sergej Khackimullin – Fotolia.com Beleuchten Sie die zu optimierende Situation beziehungsweise das zu lösende Problem aus verschiedenen Perspektiven, vor allem aber aus der Sicht des Kunden. Machen Sie dazu Kunden- und Konkurrenzbeobachtungen sowie Interviews mit Mitarbeitern und Externen. Auch Branchenfremde können sinnvolle Beiträge liefern. 2. Ziel-Definition: Foto: Radim Strojek – Fotolia.com Wo wollen Sie hin, was soll am Ende des Prozesses erreicht sein? Dies muss deutlich werden, damit die Ideen-Generierung eine Richtung bekommt. Gehen Sie dabei von kundenrelevanten, differenzierenden Merkmalen aus: Was können wir für unsere Kunden besser, schneller, einfacher, billiger machen. Formulieren Sie all das schriftlich. 3. Zusammenstellung des Teams: Foto: Maximilian Haupt – Fotolia.com Dazu gehören insbesondere die Mitarbeiter, die von der späteren Umsetzung betroffen sind. Damit minimieren Sie von vorne herein aufkommende Widerstände. Sorgen Sie für Visionäre, Querdenker, Missionare, Macher, Kundenbotschafter und Bedenkenträger im Team ebenso wie für Experten und Laien. Mischen Sie alt und jung, Männer und Frauen. Briefen Sie das Team sorgfältig. Ein geschulter Moderator kann helfen, die Prozessschritte zielgerichtet zu steuern. 4. Ideen-Generierung: Foto: chrisharvey – Fotolia.com Begeben Sie sich an einen neutralen, störungsfreien, inspirierenden Ort und setzen Sie passende Kreativitätstechniken ein. Sorgen Sie am Anfang für gute Laune und ein Kreativ-Warm-up. Zeiteinheiten von 30 bis 60 Minuten sind optimal. Hören Sie nicht zu schnell auf, in dieser frühen Phase benötigen Sie ein Maximum an Ideen. Speichern Sie alle Ideen. Und beachten Sie die drei goldenen Regeln einer Kreativ-Sitzung: – Quantität vor Qualität, Inspiration ist erwünscht – alle Teilnehmer sind gleichberechtigt, keine Hierarchie – keinerlei Kritik, weder positiver noch negativer Art 5. Ideen-Bewertung und -Selektion: Foto: Arcurs – Fotolia.com Benutzen Sie jeweils passende Bewertungs- und Selektionstechniken, um die gefundenen Ideen zu verdichten, zu kombinieren und die Spreu vom Weizen zu trennen. Dies kann ein separates Bewertungsteam tun, dem auch Kunden angehören. Erstellen Sie eine Prioritäten-Liste, sortieren Sie nach Marktfähigkeit, Machbarkeit, Zeithorizont, Wirtschaftlichkeit und Nichtkopierbarkeit. Dabei kommt es erfahrungsgemäß zu weiteren Ideen. Am Ende dieses Prozesses verbleiben einige wenige aussichtsreiche Favoriten. Geben Sie diesen Namen und definieren Sie das weitere Vorgehen, beispielsweise in Form eines Projekts. 6. Implementierung: Foto: peppi18 – Fotolia.com Sorgen Sie zunächst für interne Akzeptanz, vor allem bei den ‚betroffenen‘ Mitarbeitern. Dies erfolgt am besten durch Involvieren und frühzeitige, regelmäßige, offene Kommunikation. Stellen Sie die notwendigen Ressourcen bereit. Kommunizieren Sie aktiv mit dem Markt, insbesondere mit den anvisierten Zielgruppen und mit der Presse. Bringen Sie Ihre Idee beziehungsweise Innovation zügig in den Markt, und zwar zum richtigen Zeitpunkt. Experimentieren Sie und testen Sie Varianten. Lassen Sie die Kunden schließlich mitentscheiden. 7. Kontrolle und Optimierung: Foto: MR.LIGHTMAN – Fotolia.com Vergleichen Sie die Ergebnisse mit Ihrer Zieldefinition. Holen Sie sich Feedback vom Kunden, hören Sie dabei auch auf die leisen Töne und die kritischen Hinweise. Optimieren Sie kontinuierlich, das heißt: Beginnen Sie diesen Prozess von vorn. Sorgen Sie für einen regelmäßigen Nachschub an unverbrauchten, außergewöhnlichen Ideen.",
    "source": "cio",
    "crawled_at": "2025-05-27T08:10:56.447674+00:00"
  },
  {
    "url": "https://www.cio.de/article/3993125/wenn-ki-den-journalismus-ersetzt.html",
    "title": "Wenn KI den Journalismus ersetzt",
    "published": "2025-05-22T07:32:00+00:00",
    "author": "",
    "text": "Yeko Photo Studio – shutterstock.com Deutsche Zeitungsverlage warnen vor einem Ausverkauf journalistischer Inhalte durch Künstliche Intelligenz. Wenn KI-Systeme Verlagsinhalte ersetzten und dabei keiner effektiven Regulierung unterlägen, sei nicht nur das Geschäftsmodell des Journalismus in Gefahr, sondern auch die freie, professionelle Berichterstattung als Pfeiler der Demokratie, sagte der Vorsitzende des Verbands Bayerischer Zeitungsverleger (VBZV), Andreas Scherer, in Brüssel. Die großen KI-Plattformen trainierten mit Inhalten der Verlage ihre Systeme und nutzten sie für eigene Geschäftsmodelle, kritisierte Scherer. “Die automatisierte Aufbereitung und Darstellung journalistischer Inhalte ersetzt den Besuch originärer Presseangebote. Ein schleichender Substanzverlust für die Presse. Und für die Pressefreiheit.” Der Europa-Politiker und CSU-Parteivize Manfred Weber betonte zum Jahrestreffen des VZBV einer Mitteilung zufolge die Bedeutung der freien Presse: “Eine lebendige und vielfältige Presselandschaft ist Kernbestandteil des European Way of Life. Ich bin stolz auf unsere bayerischen Zeitungsverlage”, sagte der Fraktionschef der Europäischen Volkspartei (EVP) im EU-Parlament. Bei den turnusmäßigen Wahlen des Verbands wurde Scherer (Mediengruppe Pressedruck, Augsburg) als Erster Vorsitzender für weitere zwei Jahre im Amt bestätigt. Ebenfalls wiedergewählt wurde der Zweite Vorsitzende Laurent Fischer ( Nordbayerischer Kurier , Bayreuth). Zum VBZV als Interessenvertretung der Branche zählen nach Verbandsangaben 33 bayerische Zeitungsverlage sowie zudem digitale Tochterunternehmen und persönliche Mitglieder. (dpa/rs) Yeko Photo Studio – shutterstock.com Deutsche Zeitungsverlage warnen vor einem Ausverkauf journalistischer Inhalte durch Künstliche Intelligenz. Wenn KI-Systeme Verlagsinhalte ersetzten und dabei keiner effektiven Regulierung unterlägen, sei nicht nur das Geschäftsmodell des Journalismus in Gefahr, sondern auch die freie, professionelle Berichterstattung als Pfeiler der Demokratie, sagte der Vorsitzende des Verbands Bayerischer Zeitungsverleger (VBZV), Andreas Scherer, in Brüssel. Die großen KI-Plattformen trainierten mit Inhalten der Verlage ihre Systeme und nutzten sie für eigene Geschäftsmodelle, kritisierte Scherer. “Die automatisierte Aufbereitung und Darstellung journalistischer Inhalte ersetzt den Besuch originärer Presseangebote. Ein schleichender Substanzverlust für die Presse. Und für die Pressefreiheit.” Der Europa-Politiker und CSU-Parteivize Manfred Weber betonte zum Jahrestreffen des VZBV einer Mitteilung zufolge die Bedeutung der freien Presse: “Eine lebendige und vielfältige Presselandschaft ist Kernbestandteil des European Way of Life. Ich bin stolz auf unsere bayerischen Zeitungsverlage”, sagte der Fraktionschef der Europäischen Volkspartei (EVP) im EU-Parlament. Bei den turnusmäßigen Wahlen des Verbands wurde Scherer (Mediengruppe Pressedruck, Augsburg) als Erster Vorsitzender für weitere zwei Jahre im Amt bestätigt. Ebenfalls wiedergewählt wurde der Zweite Vorsitzende Laurent Fischer ( Nordbayerischer Kurier , Bayreuth). Zum VBZV als Interessenvertretung der Branche zählen nach Verbandsangaben 33 bayerische Zeitungsverlage sowie zudem digitale Tochterunternehmen und persönliche Mitglieder. (dpa/rs)",
    "source": "cio",
    "crawled_at": "2025-05-27T08:10:56.541140+00:00"
  },
  {
    "url": "https://www.cio.de/article/3993141/berlin-will-verbraucher-besser-vor-fake-shops-schutzen.html",
    "title": "Berlin will Verbraucher besser vor Fake-Shops schützen",
    "published": "2025-05-22T07:58:56+00:00",
    "author": "",
    "text": "fizkes – shutterstock.com Das Land Berlin will Verbraucher besser vor betrügerischen Online-Shops schützen und setzt sich im Bund für gesetzliche Änderungen ein. Verbraucherschutzsenatorin Felor Badenberg sieht in den Fake-Shops, die zunehmend professionell agieren, ein wachsendes Problem. “Sie bewirken wirtschaftliche Schäden für Verbraucher und beschädigen zudem auch das Vertrauen in den digitalen Handel”, sagte die CDU-Politikerin der Deutschen Presse-Agentur. Bei der Konferenz der Länder-Verbraucherschutzminister, die derzeit in Berlin läuft, gehört das Thema für sie als Vorsitzende zu den Schwerpunkten. Für die Beratungen kündigte Badenberg einen Antrag an. Ziel ist ein besserer Schutz für Verbraucher, indem Regelungslücken beseitigt werden. “Vermittlungsdienste, seien es Online-Suchmaschinen, Vergleichsportale oder Online-Marktplätze haften nur in Ausnahmefällen», erklärte die Senatorin. “Das Ziel unseres Beschlussvorschlags ist es deshalb, diese Vermittlungsdienste stärker in die Pflicht zu nehmen und die behördliche Rechtsdurchsetzung zur Abschaltung von Fake-Shop-Webseiten zu stärken.” Laut Badenberg sind nach Zahlen von Verbraucherschutzzentralen im Jahr 2024 monatlich 1.600 neue Fake-Shops entstanden. Kunden erhalten nach Bestellungen mangelhafte Ware – oder auch gar keine Sendung. Häufig würden Käuferdaten gestohlen oder auch missbraucht, schilderte Badenberg. Nach einer aktuellen Umfrage der Auskunftei Schufa lägen die Schäden bei jedem vierten Betroffenen zwischen 1.000 und 10.000 Euro. (dpa/rs) fizkes – shutterstock.com Das Land Berlin will Verbraucher besser vor betrügerischen Online-Shops schützen und setzt sich im Bund für gesetzliche Änderungen ein. Verbraucherschutzsenatorin Felor Badenberg sieht in den Fake-Shops, die zunehmend professionell agieren, ein wachsendes Problem. “Sie bewirken wirtschaftliche Schäden für Verbraucher und beschädigen zudem auch das Vertrauen in den digitalen Handel”, sagte die CDU-Politikerin der Deutschen Presse-Agentur. Bei der Konferenz der Länder-Verbraucherschutzminister, die derzeit in Berlin läuft, gehört das Thema für sie als Vorsitzende zu den Schwerpunkten. Für die Beratungen kündigte Badenberg einen Antrag an. Ziel ist ein besserer Schutz für Verbraucher, indem Regelungslücken beseitigt werden. “Vermittlungsdienste, seien es Online-Suchmaschinen, Vergleichsportale oder Online-Marktplätze haften nur in Ausnahmefällen», erklärte die Senatorin. “Das Ziel unseres Beschlussvorschlags ist es deshalb, diese Vermittlungsdienste stärker in die Pflicht zu nehmen und die behördliche Rechtsdurchsetzung zur Abschaltung von Fake-Shop-Webseiten zu stärken.” Laut Badenberg sind nach Zahlen von Verbraucherschutzzentralen im Jahr 2024 monatlich 1.600 neue Fake-Shops entstanden. Kunden erhalten nach Bestellungen mangelhafte Ware – oder auch gar keine Sendung. Häufig würden Käuferdaten gestohlen oder auch missbraucht, schilderte Badenberg. Nach einer aktuellen Umfrage der Auskunftei Schufa lägen die Schäden bei jedem vierten Betroffenen zwischen 1.000 und 10.000 Euro. (dpa/rs)",
    "source": "cio",
    "crawled_at": "2025-05-27T08:10:56.757865+00:00"
  },
  {
    "url": "https://www.cio.de/article/3993193/cyberkriminelle-werden-immer-besser.html",
    "title": "Cyberkriminelle werden immer besser",
    "published": "2025-05-22T08:57:10+00:00",
    "author": "",
    "text": "Syda Productions – shutterstock.com Deutschlands Sicherheitsbehörden sehen sich immer versierter arbeitenden Cyberkriminellen gegenüber. Die “Tool-Box”, die zum Einsatz komme, sei sehr breit angelegt, sagte der Vizepräsident des Bundesamtes für Verfassungsschutz (BfV), Sinan Selen, bei einer Konferenz zur Cybersicherheit in Potsdam. Er sehe ein “ganzheitliches Vorgehen”, das “Spionage, Sabotage, Desinformation gleichermaßen bedient”. Was Deutschland dagegenzusetzen hätte, sei vor allem ein pragmatischer Ansatz in der Zusammenarbeit. “Wir müssen ‘hemdsärmeliger’ werden”, führte Selen aus. Es gehe darum, die Fähigkeiten verschiedener stellen gut und partnerschaftlich miteinander zu vernetzen. Diese Partnerschaft beziehe sich nicht nur auf die klassischen Strafverfolgungsbehörden, sondern setze sich fort bei den Unternehmen, der Industrie oder gesellschaftlichen Gruppen, die von Cyberattacken betroffen sind. Nur so könne man dieser langfristigen Bedrohungslage effizient begegnen. Der Präsident des Bundeskriminalamts (BKA), Holger Münch, schob nach, dass dafür aber auch die Rahmenbedingung bei den Behörden geschaffen werden müssten. “Wenn man da aber rumkrebst und 5.000 Euro nicht bekommt für einen bestimmten PC, den man braucht, dann wird es schwierig”, sagte er in Potsdam. Es komme bei der Mitarbeitergewinnung nicht darauf an, mit dem “Gehalt von Microsoft mithalten” zu können. Es kommt darauf an, dass die Menschen zufrieden nach Hause gehen mit dem Gefühl einem sinnerfüllten Job nachzugehen. (dpa/rs) Syda Productions – shutterstock.com Deutschlands Sicherheitsbehörden sehen sich immer versierter arbeitenden Cyberkriminellen gegenüber. Die “Tool-Box”, die zum Einsatz komme, sei sehr breit angelegt, sagte der Vizepräsident des Bundesamtes für Verfassungsschutz (BfV), Sinan Selen, bei einer Konferenz zur Cybersicherheit in Potsdam. Er sehe ein “ganzheitliches Vorgehen”, das “Spionage, Sabotage, Desinformation gleichermaßen bedient”. Was Deutschland dagegenzusetzen hätte, sei vor allem ein pragmatischer Ansatz in der Zusammenarbeit. “Wir müssen ‘hemdsärmeliger’ werden”, führte Selen aus. Es gehe darum, die Fähigkeiten verschiedener stellen gut und partnerschaftlich miteinander zu vernetzen. Diese Partnerschaft beziehe sich nicht nur auf die klassischen Strafverfolgungsbehörden, sondern setze sich fort bei den Unternehmen, der Industrie oder gesellschaftlichen Gruppen, die von Cyberattacken betroffen sind. Nur so könne man dieser langfristigen Bedrohungslage effizient begegnen. Der Präsident des Bundeskriminalamts (BKA), Holger Münch, schob nach, dass dafür aber auch die Rahmenbedingung bei den Behörden geschaffen werden müssten. “Wenn man da aber rumkrebst und 5.000 Euro nicht bekommt für einen bestimmten PC, den man braucht, dann wird es schwierig”, sagte er in Potsdam. Es komme bei der Mitarbeitergewinnung nicht darauf an, mit dem “Gehalt von Microsoft mithalten” zu können. Es kommt darauf an, dass die Menschen zufrieden nach Hause gehen mit dem Gefühl einem sinnerfüllten Job nachzugehen. (dpa/rs)",
    "source": "cio",
    "crawled_at": "2025-05-27T08:10:56.836880+00:00"
  },
  {
    "url": "https://www.cio.de/article/3993217/jony-ive-soll-technik-fur-chatgpt-entwickeln.html",
    "title": "Jony Ive soll Technik für ChatGPT entwickeln",
    "published": "2025-05-22T09:09:00+00:00",
    "author": "",
    "text": "Die ChatGPT-Entwicklerfirma OpenAI holt den einstigen iPhone-Designer Jony Ive an Bord. Man habe bereits vor zwei Jahren angefangen, über neue Geräte für die Ära Künstlicher Intelligenz nachzudenken und daran zu arbeiten, teilten Ive und OpenAI-Chef Sam Altman mit. Jetzt erwirbt OpenAI das von Ive dafür mitgegründete Unternehmen mit dem Namen io. OpenAI lasse sich den Neuzugang insgesamt fast 6,5 Milliarden Dollar kosten, berichteten der Finanzdienst Bloomberg und das Wall Street Journal . Ive war jahrelang Chefdesigner von Apple und arbeitete seit Mitte der 90er Jahre eng mit Gründer Steve Jobs zusammen, bis zu dessen Tod 2011. In dieser Funktion verantwortete Ive das Design mehrerer Generationen von Apple-Geräten, von Mac-Computern über iPods bis hin zu iPhone und iPad. Vor allem das iPhone prägte das Aussehen von Smartphones entscheidend. Ive verließ Apple 2019 und gründete die eigene Firm LoveFrom . Über seine Projekte seitdem wurde nicht viel bekannt. Bei der vor einem Jahr zusätzlich gegründeten Firma io schlossen sich ihm unter anderem die Designerin Evans Hankey, die bis 2023 Ives Nachfolgerin bei Apple war, sowie Tang Tan an, der bis zum vergangenen Jahr das iPhone-Design verantwortete. Da auch Apple neue Geräte für das KI-Zeitalter brauchen dürfte, könnten die drei bei OpenAI mit der Zeit direkt mit ihrem früheren Arbeitgeber konkurrieren. Bei einem Auftritt vor OpenAI-Mitarbeitern sagten Altman und Ive dem Wall Street Journal zufolge, beim ersten Projekt gehe es um ein Gerät, das die Umgebung von Nutzern und deren Leben erfasse. Es sei als eine Ergänzung für Smartphones und Laptops gedacht. Der Kaufpreis für io liege bei fünf Milliarden Dollar in Form von OpenAI-Aktien, berichtete Bloomberg. Zudem habe OpenAI bereits Ende vergangenen Jahres einen Anteil von 23 Prozent an io erworben, wodurch die Gesamtinvestition nahezu 6,5 Milliarden Dollar erreiche. OpenAI ist nicht an der Börse notiert. In diesen Fällen gilt meist die Bewertung des Unternehmens aus Finanzierungsrunden. (dpa/rs) Die ChatGPT-Entwicklerfirma OpenAI holt den einstigen iPhone-Designer Jony Ive an Bord. Man habe bereits vor zwei Jahren angefangen, über neue Geräte für die Ära Künstlicher Intelligenz nachzudenken und daran zu arbeiten, teilten Ive und OpenAI-Chef Sam Altman mit. Jetzt erwirbt OpenAI das von Ive dafür mitgegründete Unternehmen mit dem Namen io. OpenAI lasse sich den Neuzugang insgesamt fast 6,5 Milliarden Dollar kosten, berichteten der Finanzdienst Bloomberg und das Wall Street Journal . Ive war jahrelang Chefdesigner von Apple und arbeitete seit Mitte der 90er Jahre eng mit Gründer Steve Jobs zusammen, bis zu dessen Tod 2011. In dieser Funktion verantwortete Ive das Design mehrerer Generationen von Apple-Geräten, von Mac-Computern über iPods bis hin zu iPhone und iPad. Vor allem das iPhone prägte das Aussehen von Smartphones entscheidend. Ive verließ Apple 2019 und gründete die eigene Firm LoveFrom . Über seine Projekte seitdem wurde nicht viel bekannt. Bei der vor einem Jahr zusätzlich gegründeten Firma io schlossen sich ihm unter anderem die Designerin Evans Hankey, die bis 2023 Ives Nachfolgerin bei Apple war, sowie Tang Tan an, der bis zum vergangenen Jahr das iPhone-Design verantwortete. Da auch Apple neue Geräte für das KI-Zeitalter brauchen dürfte, könnten die drei bei OpenAI mit der Zeit direkt mit ihrem früheren Arbeitgeber konkurrieren. Bei einem Auftritt vor OpenAI-Mitarbeitern sagten Altman und Ive dem Wall Street Journal zufolge, beim ersten Projekt gehe es um ein Gerät, das die Umgebung von Nutzern und deren Leben erfasse. Es sei als eine Ergänzung für Smartphones und Laptops gedacht. Der Kaufpreis für io liege bei fünf Milliarden Dollar in Form von OpenAI-Aktien, berichtete Bloomberg. Zudem habe OpenAI bereits Ende vergangenen Jahres einen Anteil von 23 Prozent an io erworben, wodurch die Gesamtinvestition nahezu 6,5 Milliarden Dollar erreiche. OpenAI ist nicht an der Börse notiert. In diesen Fällen gilt meist die Bewertung des Unternehmens aus Finanzierungsrunden. (dpa/rs)",
    "source": "cio",
    "crawled_at": "2025-05-27T08:10:56.928547+00:00"
  },
  {
    "url": "https://www.cio.de/article/3993223/russische-cyber-kampagne-in-nato-staaten-aufgedeckt-2.html",
    "title": "Russische Cyber-Kampagne in Nato-Staaten aufgedeckt",
    "published": "2025-05-22T09:20:00+00:00",
    "author": "",
    "text": "Andrey_Popov – shutterstock.com Westliche Geheimdienste haben nach britischen Angaben eine Cyber-Kampagne Russlands aufgedeckt, die gegen logistische und technologische Ziele in Nato-Staaten gerichtet ist. Wie das britische National Cyber Security Centre mitteilte, soll die Einheit 26165 des russischen Geheimdienstes GRU seit 2022 eine Kampagne gegen staatliche und private Organisationen durchgeführt haben. Dabei sollen auch solche ins Visier geraten sein, die mit der Koordination und Lieferung von Hilfsgütern für die Ukraine befasst sind. Betroffen waren demnach die Bereiche Verteidigung, IT-Dienstleistungen sowie Systeme zum Verkehrsmanagement im See- und Luftverkehr – einschließlich Häfen und Flughäfen in mehreren Nato-Staaten, darunter auch Deutschland. Zum Einsatz kamen bei der auch als APT 28 bezeichneten Einheit demnach eine Mischung aus Techniken wie das Erraten von Zugangsdaten, Phishing sowie die Ausnutzung von Berechtigungen innerhalb von Microsoft-Exchange-Postfächern. Außerdem seien mit dem Internet verbundene Kameras an ukrainischen Grenzübergängen und in der Nähe militärischer Einrichtungen ins Visier genommen worden, um Hilfslieferungen für die Ukraine zu überwachen und nachzuverfolgen. Verantwortliche bei Technologie- und Logistikunternehmen sollten unverzüglich Maßnahmen ergreifen, um sich zu schützen, hieß es in der Mitteilung. Dazu gehöre eine erhöhte Wachsamkeit, Multifaktorauthentifizierung und das rasche Aufspielen von Security-Updates. Das National Cyber Security Centre in Großbritannien gehört zum Geheimdienst GCHQ. Zu den an der Aufdeckung beteiligten Behörden zählen auch der Bundesnachrichtendienst, das Bundesamt für Verfassungsschutz, das Bundesamt für Sicherheit in der Informationstechnik sowie Dienste aus den USA, Tschechien, Polen, Australien, Kanada, Dänemark, Estland, Frankreich und den Niederlanden. (dpa) Andrey_Popov – shutterstock.com Westliche Geheimdienste haben nach britischen Angaben eine Cyber-Kampagne Russlands aufgedeckt, die gegen logistische und technologische Ziele in Nato-Staaten gerichtet ist. Wie das britische National Cyber Security Centre mitteilte, soll die Einheit 26165 des russischen Geheimdienstes GRU seit 2022 eine Kampagne gegen staatliche und private Organisationen durchgeführt haben. Dabei sollen auch solche ins Visier geraten sein, die mit der Koordination und Lieferung von Hilfsgütern für die Ukraine befasst sind. Betroffen waren demnach die Bereiche Verteidigung, IT-Dienstleistungen sowie Systeme zum Verkehrsmanagement im See- und Luftverkehr – einschließlich Häfen und Flughäfen in mehreren Nato-Staaten, darunter auch Deutschland. Zum Einsatz kamen bei der auch als APT 28 bezeichneten Einheit demnach eine Mischung aus Techniken wie das Erraten von Zugangsdaten, Phishing sowie die Ausnutzung von Berechtigungen innerhalb von Microsoft-Exchange-Postfächern. Außerdem seien mit dem Internet verbundene Kameras an ukrainischen Grenzübergängen und in der Nähe militärischer Einrichtungen ins Visier genommen worden, um Hilfslieferungen für die Ukraine zu überwachen und nachzuverfolgen. Verantwortliche bei Technologie- und Logistikunternehmen sollten unverzüglich Maßnahmen ergreifen, um sich zu schützen, hieß es in der Mitteilung. Dazu gehöre eine erhöhte Wachsamkeit, Multifaktorauthentifizierung und das rasche Aufspielen von Security-Updates. Das National Cyber Security Centre in Großbritannien gehört zum Geheimdienst GCHQ. Zu den an der Aufdeckung beteiligten Behörden zählen auch der Bundesnachrichtendienst, das Bundesamt für Verfassungsschutz, das Bundesamt für Sicherheit in der Informationstechnik sowie Dienste aus den USA, Tschechien, Polen, Australien, Kanada, Dänemark, Estland, Frankreich und den Niederlanden. (dpa)",
    "source": "cio",
    "crawled_at": "2025-05-27T08:10:57.008507+00:00"
  },
  {
    "url": "https://www.cio.de/article/3993232/indischer-partner-ubernimmt-insolventen-motorradbauer-ktm.html",
    "title": "Indischer Partner übernimmt insolventen Motorradbauer KTM",
    "published": "2025-05-22T09:30:00+00:00",
    "author": "",
    "text": "Raimo Bergroth – shutterstock.com Die indische Bajaj Auto International Holdings B.V. übernimmt die Mehrheit an dem insolventen österreichischen Motorradhersteller KTM. Im Gegenzug stellt Bajaj rund 600 Millionen Euro zur Verfügung und verhindert so die Abwicklung von KTM. Das teilte die KTM-Mutter Pierer Mobility mit. Bajaj, ein Hersteller von Motorrädern und Auto-Rikschas, war schon bislang an KTM beteiligt. Durch die Verpfändung weiterer Unternehmensanteile übernimmt Bajaj nun die Mehrheit, wie Pierer Mobility mitteilte. KTM, der ehemals größte europäische Motorradbauer, war im November durch einen starken Rückgang der Nachfrage und hohen Lagerbeständen in die Insolvenz geschlittert. Die Produktion in Mattinghofen nahe der bayerischen Grenze wurde seitdem heruntergefahren. “Heute haben wir die Chance bekommen, die Geschichte von KTM fortzuschreiben”, sagte KTM-Vorstand Gottfried Neumeister. Er kündigte an, dass die aktuellen Produktionsstandorte, inklusive des Stammwerkes in Mattinghofen, auch in Zukunft bestehen sollen. Die Schulden belaufen sich auf rund zwei Milliarden Euro. Die Gläubiger räumten der KTM AG und zwei ebenfalls insolventen Konzerngesellschaften eine Frist bis Freitag ein, um davon 30 Prozent – etwa 600 Millionen Euro – zu bezahlen. Andernfalls drohte der Abverkauf des Firmenvermögens im Rahmen eines Konkursverfahrens. Im Zuge der Übernahme von KTM durch Bajaj werde sich der bislang dominierende Eigentümer Stefan Pierer als Vorstand der Pierer Mobility AG zurückziehen, hieß es in einer Mitteilung der Konzernmutter. (dpa/rs) Raimo Bergroth – shutterstock.com Die indische Bajaj Auto International Holdings B.V. übernimmt die Mehrheit an dem insolventen österreichischen Motorradhersteller KTM. Im Gegenzug stellt Bajaj rund 600 Millionen Euro zur Verfügung und verhindert so die Abwicklung von KTM. Das teilte die KTM-Mutter Pierer Mobility mit. Bajaj, ein Hersteller von Motorrädern und Auto-Rikschas, war schon bislang an KTM beteiligt. Durch die Verpfändung weiterer Unternehmensanteile übernimmt Bajaj nun die Mehrheit, wie Pierer Mobility mitteilte. KTM, der ehemals größte europäische Motorradbauer, war im November durch einen starken Rückgang der Nachfrage und hohen Lagerbeständen in die Insolvenz geschlittert. Die Produktion in Mattinghofen nahe der bayerischen Grenze wurde seitdem heruntergefahren. “Heute haben wir die Chance bekommen, die Geschichte von KTM fortzuschreiben”, sagte KTM-Vorstand Gottfried Neumeister. Er kündigte an, dass die aktuellen Produktionsstandorte, inklusive des Stammwerkes in Mattinghofen, auch in Zukunft bestehen sollen. Die Schulden belaufen sich auf rund zwei Milliarden Euro. Die Gläubiger räumten der KTM AG und zwei ebenfalls insolventen Konzerngesellschaften eine Frist bis Freitag ein, um davon 30 Prozent – etwa 600 Millionen Euro – zu bezahlen. Andernfalls drohte der Abverkauf des Firmenvermögens im Rahmen eines Konkursverfahrens. Im Zuge der Übernahme von KTM durch Bajaj werde sich der bislang dominierende Eigentümer Stefan Pierer als Vorstand der Pierer Mobility AG zurückziehen, hieß es in einer Mitteilung der Konzernmutter. (dpa/rs)",
    "source": "cio",
    "crawled_at": "2025-05-27T08:10:57.246925+00:00"
  },
  {
    "url": "https://www.cio.de/article/3824567/tipps-fur-die-richtige-datenstrategie-2.html",
    "title": "Tipps für die richtige Datenstrategie",
    "published": "2025-05-22T09:34:10+00:00",
    "author": "",
    "text": "alphaspirit.it/Shutterstock Wie funktionieren Datenstrategien und brauchen Unternehmen so etwas überhaupt? Diese Frage beschäftigt heute viele Verantwortliche in den Unternehmen. Gleichzeitig stehen sie zunehmend unter Druck, wettbewerbsfähig und innovativ zu bleiben. Ein Schlüsselfaktor, dieses Ziels zu erreichen, ist die effektive Nutzung von Daten: Sie erlauben es, Effizienzreserven in Prozessen zu erkennen, Kunden besser zu verstehen, um Produkte und Dienstleistungen anzupassen oder gar neue Angebote zu entwickeln. Besteht Konsens darüber, was man mit den Daten erreichen möchte, so lässt sich daraus eine Datenstrategie ableiten – also ein konkreter Handlungsrahmen, um Maßnahmen zu strukturieren und das übergeordnete Ziel, den “Nordstern”, zu verfolgen. Aus vielen verschiedenen Einzelentscheidungen in unterschiedlichen Unternehmensbereichen entsteht mit einer Datenstrategie ein kohärentes Bestreben, ein gemeinsames Ziel zu erreichen. Im Beispiel betrachten wir ein Unternehmen, das das Ziel verfolgt, der führende Online-Optiker zu sein: Um Brillen erfolgreich online verkaufen zu können, muss das Unternehmen Daten aus unterschiedlichen Quellen zusammenführen, angefangen bei den Produktdaten von den Glas- und Rahmenproduzenten über Marketingdaten bis hin zu medizinischen Daten von Kunden oder Informationen über die Auslastung von Lagern und Fertigungskapazitäten. Darüber hinaus muss der Online-Optiker eine erhebliche Menge an Fachwissen von Optikern in seinen Produktdaten kodieren. Dieses Fachwissen bestimmt beispielsweise die optimale Brillengröße, wobei Faktoren wie die Sehkraft des Kunden und die Geometrie der Gläser berücksichtigt werden. Durch die Kodierung dieses Wissens in den Produktdaten kann das Unternehmen sicherstellen, dass die Kunden die richtige Brille erhalten. Auf Basis all dieser Daten können die verschiedenen am Prozess beteiligten Abteilungen – Beschaffung, Produktion und E-Commerce – nahtlos zusammenarbeiten, um ein hochwertiges Ergebnis zu liefern, die Materialeinsatzplanung zu optimieren und Prognosen für zukünftige Entwicklungen zu erstellen. Bei einer Datenstrategie geht es nicht nur darum, Daten zu verwalten, sondern darum, wie Geschäftswissen am besten in Daten gespeichert und durch sie verstanden werden kann. Begleitet wird eine Datenstrategie von einer geeigneten Organisationskultur, die Mechanismen für den Ausgleich der Bedürfnisse verschiedener Interessengruppen bereithält und dabei unter anderem die Zusammenarbeit und den Wissensaustausch fördert. Ohne eine Datenstrategie zur Strukturierung unterschiedlicher Bemühungen bleibt in jeder Organisation ab einer gewissen Größe beziehungsweise Komplexität die Wertschöpfung aus Daten weit hinter den Möglichkeiten zurück. Daten werden dann im Wesentlichen nur lokal genutzt oder entlang relativ starrer Pfade aggregiert. Die Folge: Die Agilität des Unternehmens in Bezug auf notwendige Veränderungen bleibt gehemmt. Fehlt eine solche Strategie, können auch technische Konzepte und Architekturen diesen Wert kaum steigern. Eine gut durchdachte Datenstrategie kann auf unterschiedlichste Weisen formuliert sein. Sie umfasst eine Vielzahl verschiedener Facetten wie zum Beispiel Verfügbarkeit, Auffindbarkeit, Sicherheit, Schutz personenbezogener Daten, Kostenkontrolle, etc. Aus einer Vielzahl datenbezogener Projekte lassen sich jedoch vier Schlüsselaspekte identifizieren, die die Grundlage für eine Datenstrategie bilden: Identität, Bitemporalität, Vernetzung und Föderalismus. Ein sehr konkretes Beispiel, nämlich Markenlogos, verdeutlichen diese vier Elemente einer Datenstrategie: Identifiziert wird die Marke und erst darüber das Logo in einer konkreten Ausprägung (zu Beispiel Dateiformat oder Auflösung). Die Daten für Marke und Logo sind offensichtlich miteinander vernetzt, wie schon aus der Identifikation deutlich wird. Bei einem Wechsel des Logos beispielsweise bei einem Re-Branding kann so sichergestellt werden, dass die Referenz Bestand hat. Die Berücksichtigung der Bitemporalität stellt sicher, dass der Logowechsel in allen beteiligten Systemen zu einem definierten Zeitpunkt umgesetzt wird: Die Bitemporalität berücksichtigt Benachrichtigungen über zu erwartende Änderungen und erlaubt hier die Abfrage zukünftiger Inhalte, um die neuen Logos vorbereitend cachen zu können. Umgekehrt kann auch eine in die Vergangenheit gerichtete Abfrage sinnvoll sein, typischerweise aber eher bei Inhaltsstoffen, Preisen, Lieferbedingungen, etc. als bei einem Markenlogo. Die Festlegung, welche Marken es gibt, wie die Formate identifiziert werden, etc. kann nicht allein der Einkauf oder das Marketing festlegen. Dafür braucht es die notwendige Vernetzung . Diese Entscheidungen müssen durch eine gemeinsame Autorität festgelegt werden, eine Institution im föderalen System der Datenstrategie. Wie essentiell eine Datenstrategie für Unternehmen ist, beweist auch das Phänomen Produktdaten. Sie haben viele Quellen, beispielsweise die eigene Produktentwicklung, aber auch „fremde“ Hersteller und Zwischenhändler. Sie sind wesentlicher Bestandteil wichtiger Geschäftsprozesse, werden in den unterschiedlichsten Abteilungen benötigt und sie werden in einer Vielzahl von Systemen genutzt: Wenn nicht klar ist, was Produktdaten identifizieren, in welchem Zusammenhang sie miteinander stehen und welche Regeln für ihre Domänen übergreifende Bereitstellung gelten, entsteht aus ihnen ein undurchdringlicher Datensumpf, der weder produktiv noch analytisch sinnvoll eingesetzt werden kann. Das gilt umso mehr, je größer und differenzierter ein Unternehmen ist. Viele große Unternehmen betreiben schließlich zahlreiche E-Commerce-Systeme, etliche Produktionsstraßen in unterschiedlichen Ländern und managen verschiedene Marken und Produktkategorien. Eine Datenstrategie legt ferner fest, wie Unternehmen das Wissen um ihre Produkte, Services, Prozesse und Geschäftsmodelle codieren. Damit werden Lösungen möglich, die auch eine automatisierte Entscheidungsunterstützung erlauben. Dazu kurz zurück zu unserem Online-Optiker: Um Brillen online zu verkaufen, muss viel Optikerfachwissen codiert werden, damit der Kunde bei der Konfiguration seiner Brille nicht gravierende Fehler macht. Die optimale Größe der Gleitsicht-Brillengläser hängt nämlich unter anderem von der Sehstärke und der Glasgeometrie ab. Um erfolgreich Brillen online zu verkaufen, muss dieses Erfahrungswissen von Optikern in den Produktdaten codiert werden, und die verschiedenen Zuständigkeiten (Beschaffung, Produktion, eCommerce) müssen diese Daten pflegen, verbinden und nutzen. Ein Wissensgraph (Knowledge Graph) erfasst die Bedeutung der Daten und spielt eine besondere Rolle bei der Identifikation und der Vernetzung der Daten: Das dreischichtige Wissensgraph-Modell nach Dave McComb erweitert einen typischerweise zweischichtigen Blick auf Schemata beziehungsweise Klassen einerseits und Daten beziehungsweise Instanzen andererseits. McComb führt eine mittlere Ebene ein, die eine Zwitter-Rolle einnimmt und bezeichnet diese drei Ebenen als Konzepte, Kategorien und Daten. Ganz praktisch hat Katariina Kari, Lead Ontologist bei Inter Ikea Systems, mit Ihrem Team einen solchen Knowledge Graph eingeführt. An diesem Beispiel orientieren wir uns, übertragen das aber auf das Online-Optiker-Beispiel. Die Integration der Kategorien und insbesondere der Daten in die gesamte Landschaft erfolgt über die Referenz auf die übergeordneten Ebenen, so dass eine Vernetzung darüber möglich ist. Es können also beispielsweise alle Fassungen mit der Steg-Farbe Tortoise verknüpft werden. Über Ähnlichkeiten können beispielsweise ähnliche Produkte im eCommerce-System vorgeschlagen werden. Das zurzeit viel diskutierte Konzept Data Mesh von Zhamak Dehghani, Technologiedirektorin des IT-Beratungsunternehmens ThoughtWorks ist nichts anderes als die konkrete Ausprägung einer Datenstrategie. Dieses soziotechnische Konzept basiert auf den vier Prinzipien Domain Ownership, Daten als Produkt, Self-Service-Datenplattform und föderierte Governance. Wir setzen dieses Konzept in Relation zu den vier Schlüsselaspekten Identität, Bitemporalität, Vernetzung und Föderalismus. Je nach Business-Anforderungen und Komplexität der Datenströme in einem Unternehmen kann ein Data-Mesh die sinnvollste Realisierung einer Datenstrategie darstellen. Allzu oft wird dabei vor allem die technische und weniger die soziologische Seite betont. Wir sehen aber auch, dass die vier Prinzipien Domain Ownership, Data as a Product, Self Service Data Platform und Federated Governance wenig konkrete Orientierung geben: Was enthält ein Data Product? Wie steht es zu anderen Data Products in Verbindung? Was soll eine Self Service Data Platform ermöglichen? Hier kommen wir zurück zu den vier Schlüsselaspekten einer Datenstrategie: Identität, Bitemporalität, Vernetzung und Föderalismus. Diese Schlüsselaspekte fokussieren die Datenstrategie auf konkrete Punkte und können so beispielsweise der Realisierung eines Data Mesh Struktur geben: Welche Identitäten werden in den Datenprodukten exponiert? Welche Datenprodukte müssen gemeinsame Identitäten referenzieren, um Vernetzung zu ermöglichen? Müssen Datenprodukte nur „für den Moment“ realisiert werden oder für einen Blick nach vorne oder zurück – Stichwort Bitemporalität. Und über allem thront die Frage: Wer hat die Kompetenz, Entitäten zu identifizieren? Kompetenz bedeutet dabei sowohl das fachliche, technische und gestalterische Wissen als auch den allgemein anerkannten Auftrag zur Gestaltung der entsprechenden Informationsräume. Der Data Mesh Ansatz bezieht das föderale Prinzip explizit auf Governance, also auf die Verwaltung inklusive der Gestaltung der Verwaltung. Wir gehen mit unserem Verständnis von Föderalismus darüber hinaus und verstehen darunter explizit auch die Gestaltung der Datenräume: Auch die Erstellung und Pflege der Konzepte, Kategorien und Daten in einem Knowledge Graphen wird als föderale Struktur organisiert: Für die oberste Schicht, die Konzepte, ist eine zentrale Gestaltung notwendig. Die Ebene der Kategorien kann aufgebrochen und lokaler realisiert werden. Insbesondere können verschiedene Teilbereiche der zweiten Ebene von unterschiedlichen Teams verwaltet werden. Die Daten-Ebene entsteht dann wirklich lokal in den Domänen und unterliegt dem jeweiligen Owner eines Data Products. In Anerkennung von Peter Druckers “Culture eats strategy for breakfast” ist auch für eine erfolgreiche Datenstrategie eine entsprechende Kultur quasi zwingende Voraussetzung. (Unternehmens-) Kultur umfasst die immateriellen Grundlagen gestaltender Leistungen einer Organisation. In Bezug auf die Daten-Kultur stellt sich also beispielsweise die Frage der Ausgestaltung der föderalen Strukturen: Betont eine Organisation eher zentrale Verantwortung oder lokale Verantwortung? Entsprechen föderale Ebenen auch hierarchischen Ebenen, werden Entscheidungen also über Führungskräfte eskaliert oder werden kompetente, das heißt entscheidungsfähige, Gremien auf andere Weise zusammengesetzt? Wie wird die dezentralisierte Kompetenz der Domänen ausbalanciert im Vergleich mit zentral bereitgestellten Plattformen, die mit möglichst geringer Lernkurve für die Nutzer aus den Domänen zu verwenden sind, dafür aber mit erheblichem Aufwand betrieben werden müssen. Unternehmen, die ihre Datenstrategie überdenken, sollten einen Nordstern entwickeln, dann aber sehr pragmatisch vorgehen. Der Nordstern steht für das Zielbild, das angestrebt wird: Will man Effizienz steigern, auf der Basis von Erkenntnissen aus den vorhandenen Daten Produkte oder Services verbessern und neue Geschäftsfelder erschließen? Wenn das Ziel einer Datenstrategie und entsprechender Initiativen nicht klar ist, dann ist die Realisierung zum Scheitern verurteilt. Erst wenn die Richtung klar ist, können praktisch realisierbare Schritte zum Erfolg führen. Die Organisation kann behutsam verändert werden, um beispielsweise föderale Governance-Strukturen aufzubauen, eine zentrale Steuerung des obersten Ontology-Layers realisiert und im Wechselspiel mit den Domänen angepasst und verbessert werden. Die Domänen müssen in die Lage versetzt werden, eigenständig Datenprodukte realisieren zu können, bei zentraler Definition der Policies, die für alle gelten müssen, beispielsweise in Bezug auf Identitäts- und Zugriffsmanagement. Und hier, beim Schaffen einer Plattform – geplant oder emergent als Ergebnis nur lose koordinierter Initiativen zur Reduktion des Kommunikations-Overheads – nähert sich die Datenstrategie der klassischen IT-Strategie, insbesondere in Bezug auf Cloud-Architekturen. Wettbewerbsfähigkeit durch Innovation braucht eine gut durchdachte Datenstrategie. Durch die Orientierung an den Schlüsselaspekten Identität, Bitemporalität, Vernetzung und Föderalismus können Unternehmen das Potenzial ihrer Daten erschließen und fundierte Entscheidungen treffen. Dabei geht es nicht nur um das Sammeln und Analysieren von Daten, sondern um die Schaffung einer Kultur der datengesteuerten Entscheidungsfindung. Sie erfordert die Fähigkeit, ein Gleichgewicht zwischen Zentralisierung und Dezentralisierung herzustellen. Dabei wird ein Kernelement unserer Gesellschaft, der Föderalismus, zum strukturierenden Element. alphaspirit.it/Shutterstock Wie funktionieren Datenstrategien und brauchen Unternehmen so etwas überhaupt? Diese Frage beschäftigt heute viele Verantwortliche in den Unternehmen. Gleichzeitig stehen sie zunehmend unter Druck, wettbewerbsfähig und innovativ zu bleiben. Ein Schlüsselfaktor, dieses Ziels zu erreichen, ist die effektive Nutzung von Daten: Sie erlauben es, Effizienzreserven in Prozessen zu erkennen, Kunden besser zu verstehen, um Produkte und Dienstleistungen anzupassen oder gar neue Angebote zu entwickeln. Besteht Konsens darüber, was man mit den Daten erreichen möchte, so lässt sich daraus eine Datenstrategie ableiten – also ein konkreter Handlungsrahmen, um Maßnahmen zu strukturieren und das übergeordnete Ziel, den “Nordstern”, zu verfolgen. Aus vielen verschiedenen Einzelentscheidungen in unterschiedlichen Unternehmensbereichen entsteht mit einer Datenstrategie ein kohärentes Bestreben, ein gemeinsames Ziel zu erreichen. Im Beispiel betrachten wir ein Unternehmen, das das Ziel verfolgt, der führende Online-Optiker zu sein: Um Brillen erfolgreich online verkaufen zu können, muss das Unternehmen Daten aus unterschiedlichen Quellen zusammenführen, angefangen bei den Produktdaten von den Glas- und Rahmenproduzenten über Marketingdaten bis hin zu medizinischen Daten von Kunden oder Informationen über die Auslastung von Lagern und Fertigungskapazitäten. Darüber hinaus muss der Online-Optiker eine erhebliche Menge an Fachwissen von Optikern in seinen Produktdaten kodieren. Dieses Fachwissen bestimmt beispielsweise die optimale Brillengröße, wobei Faktoren wie die Sehkraft des Kunden und die Geometrie der Gläser berücksichtigt werden. Durch die Kodierung dieses Wissens in den Produktdaten kann das Unternehmen sicherstellen, dass die Kunden die richtige Brille erhalten. Auf Basis all dieser Daten können die verschiedenen am Prozess beteiligten Abteilungen – Beschaffung, Produktion und E-Commerce – nahtlos zusammenarbeiten, um ein hochwertiges Ergebnis zu liefern, die Materialeinsatzplanung zu optimieren und Prognosen für zukünftige Entwicklungen zu erstellen. Bei einer Datenstrategie geht es nicht nur darum, Daten zu verwalten, sondern darum, wie Geschäftswissen am besten in Daten gespeichert und durch sie verstanden werden kann. Begleitet wird eine Datenstrategie von einer geeigneten Organisationskultur, die Mechanismen für den Ausgleich der Bedürfnisse verschiedener Interessengruppen bereithält und dabei unter anderem die Zusammenarbeit und den Wissensaustausch fördert. Ohne eine Datenstrategie zur Strukturierung unterschiedlicher Bemühungen bleibt in jeder Organisation ab einer gewissen Größe beziehungsweise Komplexität die Wertschöpfung aus Daten weit hinter den Möglichkeiten zurück. Daten werden dann im Wesentlichen nur lokal genutzt oder entlang relativ starrer Pfade aggregiert. Die Folge: Die Agilität des Unternehmens in Bezug auf notwendige Veränderungen bleibt gehemmt. Fehlt eine solche Strategie, können auch technische Konzepte und Architekturen diesen Wert kaum steigern. Eine gut durchdachte Datenstrategie kann auf unterschiedlichste Weisen formuliert sein. Sie umfasst eine Vielzahl verschiedener Facetten wie zum Beispiel Verfügbarkeit, Auffindbarkeit, Sicherheit, Schutz personenbezogener Daten, Kostenkontrolle, etc. Aus einer Vielzahl datenbezogener Projekte lassen sich jedoch vier Schlüsselaspekte identifizieren, die die Grundlage für eine Datenstrategie bilden: Identität, Bitemporalität, Vernetzung und Föderalismus. Ein sehr konkretes Beispiel, nämlich Markenlogos, verdeutlichen diese vier Elemente einer Datenstrategie: Identifiziert wird die Marke und erst darüber das Logo in einer konkreten Ausprägung (zu Beispiel Dateiformat oder Auflösung). Die Daten für Marke und Logo sind offensichtlich miteinander vernetzt, wie schon aus der Identifikation deutlich wird. Bei einem Wechsel des Logos beispielsweise bei einem Re-Branding kann so sichergestellt werden, dass die Referenz Bestand hat. Die Berücksichtigung der Bitemporalität stellt sicher, dass der Logowechsel in allen beteiligten Systemen zu einem definierten Zeitpunkt umgesetzt wird: Die Bitemporalität berücksichtigt Benachrichtigungen über zu erwartende Änderungen und erlaubt hier die Abfrage zukünftiger Inhalte, um die neuen Logos vorbereitend cachen zu können. Umgekehrt kann auch eine in die Vergangenheit gerichtete Abfrage sinnvoll sein, typischerweise aber eher bei Inhaltsstoffen, Preisen, Lieferbedingungen, etc. als bei einem Markenlogo. Die Festlegung, welche Marken es gibt, wie die Formate identifiziert werden, etc. kann nicht allein der Einkauf oder das Marketing festlegen. Dafür braucht es die notwendige Vernetzung . Diese Entscheidungen müssen durch eine gemeinsame Autorität festgelegt werden, eine Institution im föderalen System der Datenstrategie. Wie essentiell eine Datenstrategie für Unternehmen ist, beweist auch das Phänomen Produktdaten. Sie haben viele Quellen, beispielsweise die eigene Produktentwicklung, aber auch „fremde“ Hersteller und Zwischenhändler. Sie sind wesentlicher Bestandteil wichtiger Geschäftsprozesse, werden in den unterschiedlichsten Abteilungen benötigt und sie werden in einer Vielzahl von Systemen genutzt: Wenn nicht klar ist, was Produktdaten identifizieren, in welchem Zusammenhang sie miteinander stehen und welche Regeln für ihre Domänen übergreifende Bereitstellung gelten, entsteht aus ihnen ein undurchdringlicher Datensumpf, der weder produktiv noch analytisch sinnvoll eingesetzt werden kann. Das gilt umso mehr, je größer und differenzierter ein Unternehmen ist. Viele große Unternehmen betreiben schließlich zahlreiche E-Commerce-Systeme, etliche Produktionsstraßen in unterschiedlichen Ländern und managen verschiedene Marken und Produktkategorien. Eine Datenstrategie legt ferner fest, wie Unternehmen das Wissen um ihre Produkte, Services, Prozesse und Geschäftsmodelle codieren. Damit werden Lösungen möglich, die auch eine automatisierte Entscheidungsunterstützung erlauben. Dazu kurz zurück zu unserem Online-Optiker: Um Brillen online zu verkaufen, muss viel Optikerfachwissen codiert werden, damit der Kunde bei der Konfiguration seiner Brille nicht gravierende Fehler macht. Die optimale Größe der Gleitsicht-Brillengläser hängt nämlich unter anderem von der Sehstärke und der Glasgeometrie ab. Um erfolgreich Brillen online zu verkaufen, muss dieses Erfahrungswissen von Optikern in den Produktdaten codiert werden, und die verschiedenen Zuständigkeiten (Beschaffung, Produktion, eCommerce) müssen diese Daten pflegen, verbinden und nutzen. Ein Wissensgraph (Knowledge Graph) erfasst die Bedeutung der Daten und spielt eine besondere Rolle bei der Identifikation und der Vernetzung der Daten: Das dreischichtige Wissensgraph-Modell nach Dave McComb erweitert einen typischerweise zweischichtigen Blick auf Schemata beziehungsweise Klassen einerseits und Daten beziehungsweise Instanzen andererseits. McComb führt eine mittlere Ebene ein, die eine Zwitter-Rolle einnimmt und bezeichnet diese drei Ebenen als Konzepte, Kategorien und Daten. Ganz praktisch hat Katariina Kari, Lead Ontologist bei Inter Ikea Systems, mit Ihrem Team einen solchen Knowledge Graph eingeführt. An diesem Beispiel orientieren wir uns, übertragen das aber auf das Online-Optiker-Beispiel. Die Integration der Kategorien und insbesondere der Daten in die gesamte Landschaft erfolgt über die Referenz auf die übergeordneten Ebenen, so dass eine Vernetzung darüber möglich ist. Es können also beispielsweise alle Fassungen mit der Steg-Farbe Tortoise verknüpft werden. Über Ähnlichkeiten können beispielsweise ähnliche Produkte im eCommerce-System vorgeschlagen werden. Das zurzeit viel diskutierte Konzept Data Mesh von Zhamak Dehghani, Technologiedirektorin des IT-Beratungsunternehmens ThoughtWorks ist nichts anderes als die konkrete Ausprägung einer Datenstrategie. Dieses soziotechnische Konzept basiert auf den vier Prinzipien Domain Ownership, Daten als Produkt, Self-Service-Datenplattform und föderierte Governance. Wir setzen dieses Konzept in Relation zu den vier Schlüsselaspekten Identität, Bitemporalität, Vernetzung und Föderalismus. Je nach Business-Anforderungen und Komplexität der Datenströme in einem Unternehmen kann ein Data-Mesh die sinnvollste Realisierung einer Datenstrategie darstellen. Allzu oft wird dabei vor allem die technische und weniger die soziologische Seite betont. Wir sehen aber auch, dass die vier Prinzipien Domain Ownership, Data as a Product, Self Service Data Platform und Federated Governance wenig konkrete Orientierung geben: Was enthält ein Data Product? Wie steht es zu anderen Data Products in Verbindung? Was soll eine Self Service Data Platform ermöglichen? Hier kommen wir zurück zu den vier Schlüsselaspekten einer Datenstrategie: Identität, Bitemporalität, Vernetzung und Föderalismus. Diese Schlüsselaspekte fokussieren die Datenstrategie auf konkrete Punkte und können so beispielsweise der Realisierung eines Data Mesh Struktur geben: Welche Identitäten werden in den Datenprodukten exponiert? Welche Datenprodukte müssen gemeinsame Identitäten referenzieren, um Vernetzung zu ermöglichen? Müssen Datenprodukte nur „für den Moment“ realisiert werden oder für einen Blick nach vorne oder zurück – Stichwort Bitemporalität. Und über allem thront die Frage: Wer hat die Kompetenz, Entitäten zu identifizieren? Kompetenz bedeutet dabei sowohl das fachliche, technische und gestalterische Wissen als auch den allgemein anerkannten Auftrag zur Gestaltung der entsprechenden Informationsräume. Der Data Mesh Ansatz bezieht das föderale Prinzip explizit auf Governance, also auf die Verwaltung inklusive der Gestaltung der Verwaltung. Wir gehen mit unserem Verständnis von Föderalismus darüber hinaus und verstehen darunter explizit auch die Gestaltung der Datenräume: Auch die Erstellung und Pflege der Konzepte, Kategorien und Daten in einem Knowledge Graphen wird als föderale Struktur organisiert: Für die oberste Schicht, die Konzepte, ist eine zentrale Gestaltung notwendig. Die Ebene der Kategorien kann aufgebrochen und lokaler realisiert werden. Insbesondere können verschiedene Teilbereiche der zweiten Ebene von unterschiedlichen Teams verwaltet werden. Die Daten-Ebene entsteht dann wirklich lokal in den Domänen und unterliegt dem jeweiligen Owner eines Data Products. In Anerkennung von Peter Druckers “Culture eats strategy for breakfast” ist auch für eine erfolgreiche Datenstrategie eine entsprechende Kultur quasi zwingende Voraussetzung. (Unternehmens-) Kultur umfasst die immateriellen Grundlagen gestaltender Leistungen einer Organisation. In Bezug auf die Daten-Kultur stellt sich also beispielsweise die Frage der Ausgestaltung der föderalen Strukturen: Betont eine Organisation eher zentrale Verantwortung oder lokale Verantwortung? Entsprechen föderale Ebenen auch hierarchischen Ebenen, werden Entscheidungen also über Führungskräfte eskaliert oder werden kompetente, das heißt entscheidungsfähige, Gremien auf andere Weise zusammengesetzt? Wie wird die dezentralisierte Kompetenz der Domänen ausbalanciert im Vergleich mit zentral bereitgestellten Plattformen, die mit möglichst geringer Lernkurve für die Nutzer aus den Domänen zu verwenden sind, dafür aber mit erheblichem Aufwand betrieben werden müssen. Unternehmen, die ihre Datenstrategie überdenken, sollten einen Nordstern entwickeln, dann aber sehr pragmatisch vorgehen. Der Nordstern steht für das Zielbild, das angestrebt wird: Will man Effizienz steigern, auf der Basis von Erkenntnissen aus den vorhandenen Daten Produkte oder Services verbessern und neue Geschäftsfelder erschließen? Wenn das Ziel einer Datenstrategie und entsprechender Initiativen nicht klar ist, dann ist die Realisierung zum Scheitern verurteilt. Erst wenn die Richtung klar ist, können praktisch realisierbare Schritte zum Erfolg führen. Die Organisation kann behutsam verändert werden, um beispielsweise föderale Governance-Strukturen aufzubauen, eine zentrale Steuerung des obersten Ontology-Layers realisiert und im Wechselspiel mit den Domänen angepasst und verbessert werden. Die Domänen müssen in die Lage versetzt werden, eigenständig Datenprodukte realisieren zu können, bei zentraler Definition der Policies, die für alle gelten müssen, beispielsweise in Bezug auf Identitäts- und Zugriffsmanagement. Und hier, beim Schaffen einer Plattform – geplant oder emergent als Ergebnis nur lose koordinierter Initiativen zur Reduktion des Kommunikations-Overheads – nähert sich die Datenstrategie der klassischen IT-Strategie, insbesondere in Bezug auf Cloud-Architekturen. Wettbewerbsfähigkeit durch Innovation braucht eine gut durchdachte Datenstrategie. Durch die Orientierung an den Schlüsselaspekten Identität, Bitemporalität, Vernetzung und Föderalismus können Unternehmen das Potenzial ihrer Daten erschließen und fundierte Entscheidungen treffen. Dabei geht es nicht nur um das Sammeln und Analysieren von Daten, sondern um die Schaffung einer Kultur der datengesteuerten Entscheidungsfindung. Sie erfordert die Fähigkeit, ein Gleichgewicht zwischen Zentralisierung und Dezentralisierung herzustellen. Dabei wird ein Kernelement unserer Gesellschaft, der Föderalismus, zum strukturierenden Element.",
    "source": "cio",
    "crawled_at": "2025-05-27T08:10:57.334622+00:00"
  },
  {
    "url": "https://www.cio.de/article/3854433/s-4hana-mit-einer-hybrid-cloud-und-ki-das-potenzial-von-daten-ausschopfen.html",
    "title": "Mit Hybrid Cloud und KI das Potenzial von Daten ausschöpfen",
    "published": "2025-05-22T10:14:12+00:00",
    "author": "",
    "text": "Die Kenntnis aller Optionen hilft, die richtige Entscheidung für den zukünftigen Betrieb von SAP in der Cloud zu treffen. Dragana Gordic – Shutterstock.com Die Frage, auf welcher Plattform und mit welchem Bereitstellungsmodell SAP-ERP-Systeme zukünftig betrieben werden, ist für IT-Entscheider nach wie vor von weitreichender Bedeutung. 2027 läuft der Mainstream Support für SAP ECC aus. 2030 soll auch der kostenpflichtige Extended Support für diese Version enden und Verlängerungsoptionen bis 2033 kursieren bereits. Obwohl die neue ERP-Lösung bereits 2015 vorgestellt wurde, gehen Schätzungen davon aus, dass heute erst 30 Prozent der SAP-Anwender – wenn überhaupt – S4/HANA produktiv nutzen. Was bremst die wichtige Software-Migration? Die S/4HANA-Migration ist für viele Unternehmen ein strategisches Muss, doch die Entscheidungen zur Umsetzung gestaltet sich oft zäh. Nicht fehlendes Know-how oder mangelnder Wille sind die Hauptbremsklötze, sondern vielmehr eine Kombination aus unklarem Business Case und wahrgenommener Komplexität. Viele Entscheider sehen sich außerstande, den direkten geschäftlichen Nutzen der Migration zu quantifizieren, um den Aufwand und die tiefgreifenden Veränderungen in Prozessen und Strukturen rechtfertigen zu können. Das eigentliche Problem ist jedoch der Druck der SAP-Verantwortlichen, im Zuge der Migration die heute bei den Kunden eingesetzten IT-Plattformen in die SAP-Cloud zu überführen. Dieses Momentum verstärkt die Unsicherheit und Komplexität für Projektentscheider erheblich. In der Folge gehen die Marktforscher von Gartner davon aus, dass im Jahr 2030 rund 40 Prozent der SAP-Kunden nach wie vor nicht umgestiegen sein werden ( zum Bericht ). Es ist daher fraglich, ob SAP an den bisherigen Terminen festhalten kann. Die Migration auf S/4HANA konkurriert inzwischen mit der Einführung von KI und hybriden Cloud-Architekturen, wenn es um die wichtigsten IT-Prioritäten in den Unternehmen geht. KI-Lösungen benötigen Zugang zu einer Vielzahl von Datenquellen, deren Integration, Kontrolle, Souveränität, Sicherheit und geringe Latenz gemanagt werden muss. Daher ist eine Hybrid-Cloud-Strategie nicht nur hilfreich, sondern essenzielle Voraussetzung für die erfolgreiche Implementierung von KI. Die Hybrid Cloud hat sich als Standardbetriebsmodell für viele Unternehmen etabliert. HPE SAP S4/HANA kann den betriebswirtschaftlichen Teil der Datenbasis für die KI-Strategie von Unternehmen liefern. Die Annahme, dass die SAP-Cloud mit ihren KI-Tools automatisch die optimale Lösung für die oft erheblich umfangreicheren und vielfältigeren KI-Usecases darstellt, ist jedoch nicht selbstverständlich. Innovative KI-Anwendungen greifen häufig auf ein breiteres Datenspektrum zurück, als nur auf primäre SAP-Daten. Deshalb spielen hybride Konzepte, die Kombinationen beliebiger Datenquellen ermöglichen, die zentrale Rolle. Im Fokus stehen dabei hochsensible Daten, die in der Regel on-premise vorgehalten werden. Diese sollen auch der KI zur Verfügung stehen, jedoch streng kontrolliert. Flexible Datenintegration ist der Schlüssel. Um unterschiedliche Datenquellen flexibel integrieren zu können, sind offene hybride Strukturen notwendig. Der Cloud-only-Ansatz der SAP reicht nicht mehr aus. Die Unterscheidung zwischen on-premise und Cloud ist dann nicht mehr relevant, da sie gemeinsam eine moderne Hybrid-Cloud-Strategie bilden. MEHR ÜBER LÖSUNGEN ERFAHREN! Ein kritischer Punkt beim zukünftigen SAP-Betriebsmodell ist die Kontrolle über Daten und Systeme. Manche Verantwortlichen befürchten, dass Anbieter von Off-Premise-Clouds den Zugriff des Kunden mit einem einzigen Schnitt beenden könnten. Bei On-Premise-Konzepten liegt die Kontrolle beim Kunden: Er behält immer den physischen Zugang und Zugriff auf seine Systeme – das ist in der Public Cloud nicht möglich. Obwohl beide Szenarien theoretischer Natur sind, unterscheiden sie sich in der gefühlten Souveränität erheblich. Gerade in der aktuellen geopolitischen Lage äußern deutsche Unternehmen vermehrt Bedenken, sensible Daten auf Systemen ausländischer Technologiekonzerne zu speichern. Mit dem Fokus auf in alle Richtungen offene hybride Konzepte entscheiden sich SAP-Kunden häufig für Cloud-Optionen ohne SAP RISE. „Die S4/HANA-Migration muss nicht zwangsläufig in einem RISE with SAP-Vertrag oder in der SAP-Cloud enden. Kunden haben die Wahl zu mehr Offenheit und mehr Optionen“, beschreibt Albrecht Munz, verantwortlich für die Geschäftsentwicklung im SAP-Markt bei Hewlett Packard Enterprise (HPE), die Situation. Ein Blick in den Investitionsreport 2024 der Deutschsprachigen SAP-Anwendergruppe e.V. (DSAG) zeigt : 61 Prozent der Unternehmen lehnen RISE with SAP ab, was sogar ein Anstieg gegenüber 2022 bedeutet. Warum ist die Begeisterung für RISE with SAP im ERP-Bereich weiterhin gering? Munz kennt die offenen Fragen aus vielen Diskussionen: HPE ist einer der führenden Anbieter von Informationstechnologie und auf kundenzentrische Cloud- und Service-Strategien fokussiert. Mit HPE GreenLake für SAP profitieren Unternehmen von einer hybriden S/4HANA-Lösung, die Edge-Computing, On-Premise-Flexibilität und Hyperscaler-Skalierbarkeit kombiniert. Verantwortliche behalten so die IT-Kontrolle und Entscheidungsfreiheit. HPE GreenLake bietet vollständig verwaltete Hybrid-Cloud-Services für On-Premise- und Off-Premise-Umgebungen. HPE HPE GreenLake steht für die flexible Integration verschiedener Cloud Services. Mit HPE Private Cloud AI Stack und der HPE GreenLake Cloud Platform lassen sich erste produktive KI-Anwendungsfälle einfach und schnell umsetzen. Damit können Unternehmen ihre KI-Strategien unabhängig von anbieterspezifischen Restriktionen realisieren und die umfassenden Vorteile einer hybriden Cloud-Umgebung nutzen. Die global agierende Würth-Gruppe (40 Mrd. Euro Umsatz) bevorzugt on-premise für ihre großen SAP-Kernsysteme. Um flexibel zu bleiben, nutzt sie Off-Premise-Services. Mit HPE GreenLake hat Würth eine Lösung gefunden, die diese Anforderungen vereinen kann ( Video-Interview , Laufzeit 2:32 Min). Ausschlaggebend für Würth war die enorme Skalierbarkeit der Intel x86-basierten Plattform, also technisch-wirtschaftliche Argumente. Schließlich betreibt ein Konzern dieser Größenordnung ein SAP-BW-System mit rund 32 TB Speicher, das man nicht gerne aus der Hand gibt. EPL Ltd., ein globaler Verpackungsspezialist, entschied sich für HPE GreenLake für SAP, um Cloud-Agilität mit IT-Souveränität zu kombinieren ( Case Study ). ZUR CASE STUDY! HPE GreenLake für SAP überzeugt auch HPE-Partner für deren Kunden. Die Davidoff Öttinger Gruppe, unterstützt von Bechtle AG, integriert ihre globale Wertschöpfungskette – von Tabakfeldern bis zu Flagship-Stores – mit dieser Lösung. HPE GreenLake ermöglicht die Verwaltung des gesamten Systems als Cloud Experience im eigenen Rechenzentrum ( Case Study ). Unabhängig vom Betriebsmodell ist die Verfügbarkeit einer hochskalierbaren und standardisierten IT-Plattform Voraussetzung für einen wirtschaftlichen SAP-Betrieb. Alle Unternehmensgrößen sollten mit einer einheitlichen Technologiebasis abdeckbar sein. Mehrere Betriebssysteme wegen unterschiedlicher Skalierungs- und Sicherheitsanforderungen betreiben zu müssen, ist teuer und unflexibel. Diese x86-basierte Plattform wurde in den letzten Jahren im Rahmen von Co-Engineering-Projekten zwischen SAP, Intel und HPE entwickelt bzw. weiterentwickelt. Von der kleinsten SAP-Instanz bis hin zu den größten heute gebauten und SAP-zertifizierten Serversystemen sind somit alle Leistungsanforderungen ohne Systembrüche abdeckbar. Mit den SAP-Entscheidungen sollten Unternehmen ihre KI-Strategie und Hybrid-Cloud-Konzepte sowie deren Konsequenzen geklärt haben. Dies betrifft sowohl Plattformen als auch Bereitstellungsmodelle. Darüber hinaus sollte die Migration zu SAP S/4HANA auch in Zukunft Plattform- und Anbieterflexibilität gewährleisten. Treffen Sie fundierte SAP-Entscheidungen. HPE GreenLake zeigt Ihnen neue Möglichkeiten auf. Erkunden Sie unsere Lösungen online oder kontaktieren Sie Ihren persönlichen Ansprechpartner bei HPE. JETZT ENTDECKEN! Die Kenntnis aller Optionen hilft, die richtige Entscheidung für den zukünftigen Betrieb von SAP in der Cloud zu treffen. Dragana Gordic – Shutterstock.com Die Frage, auf welcher Plattform und mit welchem Bereitstellungsmodell SAP-ERP-Systeme zukünftig betrieben werden, ist für IT-Entscheider nach wie vor von weitreichender Bedeutung. 2027 läuft der Mainstream Support für SAP ECC aus. 2030 soll auch der kostenpflichtige Extended Support für diese Version enden und Verlängerungsoptionen bis 2033 kursieren bereits. Obwohl die neue ERP-Lösung bereits 2015 vorgestellt wurde, gehen Schätzungen davon aus, dass heute erst 30 Prozent der SAP-Anwender – wenn überhaupt – S4/HANA produktiv nutzen. Was bremst die wichtige Software-Migration? Die S/4HANA-Migration ist für viele Unternehmen ein strategisches Muss, doch die Entscheidungen zur Umsetzung gestaltet sich oft zäh. Nicht fehlendes Know-how oder mangelnder Wille sind die Hauptbremsklötze, sondern vielmehr eine Kombination aus unklarem Business Case und wahrgenommener Komplexität. Viele Entscheider sehen sich außerstande, den direkten geschäftlichen Nutzen der Migration zu quantifizieren, um den Aufwand und die tiefgreifenden Veränderungen in Prozessen und Strukturen rechtfertigen zu können. Das eigentliche Problem ist jedoch der Druck der SAP-Verantwortlichen, im Zuge der Migration die heute bei den Kunden eingesetzten IT-Plattformen in die SAP-Cloud zu überführen. Dieses Momentum verstärkt die Unsicherheit und Komplexität für Projektentscheider erheblich. In der Folge gehen die Marktforscher von Gartner davon aus, dass im Jahr 2030 rund 40 Prozent der SAP-Kunden nach wie vor nicht umgestiegen sein werden ( zum Bericht ). Es ist daher fraglich, ob SAP an den bisherigen Terminen festhalten kann. Die Migration auf S/4HANA konkurriert inzwischen mit der Einführung von KI und hybriden Cloud-Architekturen, wenn es um die wichtigsten IT-Prioritäten in den Unternehmen geht. KI-Lösungen benötigen Zugang zu einer Vielzahl von Datenquellen, deren Integration, Kontrolle, Souveränität, Sicherheit und geringe Latenz gemanagt werden muss. Daher ist eine Hybrid-Cloud-Strategie nicht nur hilfreich, sondern essenzielle Voraussetzung für die erfolgreiche Implementierung von KI. Die Hybrid Cloud hat sich als Standardbetriebsmodell für viele Unternehmen etabliert. HPE SAP S4/HANA kann den betriebswirtschaftlichen Teil der Datenbasis für die KI-Strategie von Unternehmen liefern. Die Annahme, dass die SAP-Cloud mit ihren KI-Tools automatisch die optimale Lösung für die oft erheblich umfangreicheren und vielfältigeren KI-Usecases darstellt, ist jedoch nicht selbstverständlich. Innovative KI-Anwendungen greifen häufig auf ein breiteres Datenspektrum zurück, als nur auf primäre SAP-Daten. Deshalb spielen hybride Konzepte, die Kombinationen beliebiger Datenquellen ermöglichen, die zentrale Rolle. Im Fokus stehen dabei hochsensible Daten, die in der Regel on-premise vorgehalten werden. Diese sollen auch der KI zur Verfügung stehen, jedoch streng kontrolliert. Flexible Datenintegration ist der Schlüssel. Um unterschiedliche Datenquellen flexibel integrieren zu können, sind offene hybride Strukturen notwendig. Der Cloud-only-Ansatz der SAP reicht nicht mehr aus. Die Unterscheidung zwischen on-premise und Cloud ist dann nicht mehr relevant, da sie gemeinsam eine moderne Hybrid-Cloud-Strategie bilden. MEHR ÜBER LÖSUNGEN ERFAHREN! Ein kritischer Punkt beim zukünftigen SAP-Betriebsmodell ist die Kontrolle über Daten und Systeme. Manche Verantwortlichen befürchten, dass Anbieter von Off-Premise-Clouds den Zugriff des Kunden mit einem einzigen Schnitt beenden könnten. Bei On-Premise-Konzepten liegt die Kontrolle beim Kunden: Er behält immer den physischen Zugang und Zugriff auf seine Systeme – das ist in der Public Cloud nicht möglich. Obwohl beide Szenarien theoretischer Natur sind, unterscheiden sie sich in der gefühlten Souveränität erheblich. Gerade in der aktuellen geopolitischen Lage äußern deutsche Unternehmen vermehrt Bedenken, sensible Daten auf Systemen ausländischer Technologiekonzerne zu speichern. Mit dem Fokus auf in alle Richtungen offene hybride Konzepte entscheiden sich SAP-Kunden häufig für Cloud-Optionen ohne SAP RISE. „Die S4/HANA-Migration muss nicht zwangsläufig in einem RISE with SAP-Vertrag oder in der SAP-Cloud enden. Kunden haben die Wahl zu mehr Offenheit und mehr Optionen“, beschreibt Albrecht Munz, verantwortlich für die Geschäftsentwicklung im SAP-Markt bei Hewlett Packard Enterprise (HPE), die Situation. Ein Blick in den Investitionsreport 2024 der Deutschsprachigen SAP-Anwendergruppe e.V. (DSAG) zeigt : 61 Prozent der Unternehmen lehnen RISE with SAP ab, was sogar ein Anstieg gegenüber 2022 bedeutet. Warum ist die Begeisterung für RISE with SAP im ERP-Bereich weiterhin gering? Munz kennt die offenen Fragen aus vielen Diskussionen: HPE ist einer der führenden Anbieter von Informationstechnologie und auf kundenzentrische Cloud- und Service-Strategien fokussiert. Mit HPE GreenLake für SAP profitieren Unternehmen von einer hybriden S/4HANA-Lösung, die Edge-Computing, On-Premise-Flexibilität und Hyperscaler-Skalierbarkeit kombiniert. Verantwortliche behalten so die IT-Kontrolle und Entscheidungsfreiheit. HPE GreenLake bietet vollständig verwaltete Hybrid-Cloud-Services für On-Premise- und Off-Premise-Umgebungen. HPE HPE GreenLake steht für die flexible Integration verschiedener Cloud Services. Mit HPE Private Cloud AI Stack und der HPE GreenLake Cloud Platform lassen sich erste produktive KI-Anwendungsfälle einfach und schnell umsetzen. Damit können Unternehmen ihre KI-Strategien unabhängig von anbieterspezifischen Restriktionen realisieren und die umfassenden Vorteile einer hybriden Cloud-Umgebung nutzen. Die global agierende Würth-Gruppe (40 Mrd. Euro Umsatz) bevorzugt on-premise für ihre großen SAP-Kernsysteme. Um flexibel zu bleiben, nutzt sie Off-Premise-Services. Mit HPE GreenLake hat Würth eine Lösung gefunden, die diese Anforderungen vereinen kann ( Video-Interview , Laufzeit 2:32 Min). Ausschlaggebend für Würth war die enorme Skalierbarkeit der Intel x86-basierten Plattform, also technisch-wirtschaftliche Argumente. Schließlich betreibt ein Konzern dieser Größenordnung ein SAP-BW-System mit rund 32 TB Speicher, das man nicht gerne aus der Hand gibt. EPL Ltd., ein globaler Verpackungsspezialist, entschied sich für HPE GreenLake für SAP, um Cloud-Agilität mit IT-Souveränität zu kombinieren ( Case Study ). ZUR CASE STUDY! HPE GreenLake für SAP überzeugt auch HPE-Partner für deren Kunden. Die Davidoff Öttinger Gruppe, unterstützt von Bechtle AG, integriert ihre globale Wertschöpfungskette – von Tabakfeldern bis zu Flagship-Stores – mit dieser Lösung. HPE GreenLake ermöglicht die Verwaltung des gesamten Systems als Cloud Experience im eigenen Rechenzentrum ( Case Study ). Unabhängig vom Betriebsmodell ist die Verfügbarkeit einer hochskalierbaren und standardisierten IT-Plattform Voraussetzung für einen wirtschaftlichen SAP-Betrieb. Alle Unternehmensgrößen sollten mit einer einheitlichen Technologiebasis abdeckbar sein. Mehrere Betriebssysteme wegen unterschiedlicher Skalierungs- und Sicherheitsanforderungen betreiben zu müssen, ist teuer und unflexibel. Diese x86-basierte Plattform wurde in den letzten Jahren im Rahmen von Co-Engineering-Projekten zwischen SAP, Intel und HPE entwickelt bzw. weiterentwickelt. Von der kleinsten SAP-Instanz bis hin zu den größten heute gebauten und SAP-zertifizierten Serversystemen sind somit alle Leistungsanforderungen ohne Systembrüche abdeckbar. Mit den SAP-Entscheidungen sollten Unternehmen ihre KI-Strategie und Hybrid-Cloud-Konzepte sowie deren Konsequenzen geklärt haben. Dies betrifft sowohl Plattformen als auch Bereitstellungsmodelle. Darüber hinaus sollte die Migration zu SAP S/4HANA auch in Zukunft Plattform- und Anbieterflexibilität gewährleisten. Treffen Sie fundierte SAP-Entscheidungen. HPE GreenLake zeigt Ihnen neue Möglichkeiten auf. Erkunden Sie unsere Lösungen online oder kontaktieren Sie Ihren persönlichen Ansprechpartner bei HPE. JETZT ENTDECKEN!",
    "source": "cio",
    "crawled_at": "2025-05-27T08:10:57.549263+00:00"
  },
  {
    "url": "https://www.cio.de/article/3990582/karriere-ohne-umweg-warum-vielfalt-neue-wege-braucht.html",
    "title": "Karriere ohne Umweg? Warum Vielfalt neue Wege braucht",
    "published": "2025-05-23T04:37:00+00:00",
    "author": "",
    "text": "Quereinsteiger mit unkonventionellen Lebensläufen können eine bereicherung für Teams und Unternehmen sein. Wenn es um die Repräsentation von Frauen in der Tech-Branche geht, ist noch einiges zu tun. Zu diesem Schluss kommt der Nash Squared Leadership Report. Demnach sind lediglich 14 Prozent der IT-Führungskräfte weiblich. In Deutschland lag 2023 der Anteil aller Frauen in leitenden Stellungen bei 28 Prozent. Im europäischen Vergleich liegen wir damit im unteren Drittel der EU-Mitgliedstaaten . Diese Zahlen stehen dabei nicht nur für soziale Ungerechtigkeit, sie bezeugen auch eine Verkennung von wirtschaftlichem Potential. Denn Unternehmen mit diversen Führungsteams erzielen nachweislich höhere Gewinne, wie die McKinsey-Studie „Diversity Matters even more “ belegt. Abonnieren Sie unserer CIO-Newsetter für mehr spannende Einschätzungen, Hintergründe und Analysen aus der CIO-Community. Die Untersuchung kam zu dem Ergebnis, dass europäische Unternehmen mit Frauen in Führungsteams eine bis zu 62 Prozent höhere Chance auf überdurchschnittlichen wirtschaftlichen Erfolg haben. Die Gründe dafür liegen in einer breiteren Perspektivenvielfalt und stärkeren Innovationskraft. Was können Unternehmen im Tech-Bereich also tun, um ihre Teams diverser aufzustellen? Die Standardvorstellung von beruflichem Erfolg ist oftmals, dass dieser einfach das Resultat eines klaren, aufeinander aufbauenden Karrierewegs ist – inklusive eines erkennbaren Plans. Doch das ist heute längst nicht mehr der Fall und war es vielleicht nie. Karrierewege sind nicht immer strikt geplant und verlaufen ganz sicherlich nicht linear. In einer sich schnell wandelnden Branche ist jedoch genau diese starre Sichtweise zunehmend ein Hindernis. Gerade Brüche im Lebenslauf eröffnen neue Chancen, fördern kreative Lösungen und stärken die Anpassungsfähigkeit. Dennoch besteht in vielen Unternehmen, gerade im Hinblick auf Führungspositionen, weiterhin der Druck, Karriere entlang eines vorhersehbaren Musters zu planen. In Bewerbungsgesprächen wird oft gefragt: „Wo sehen Sie sich in fünf Jahren?“ Ein solcher Erwartungsdruck kann jedoch dazu führen, dass Menschen Chancen nicht wahrnehmen, die außerhalb des ursprünglichen Plans liegen. Statt starrer Aufstiegsmodelle wäre es sinnvoller, Entwicklungskriterien neu zu definieren – etwa in den Bereichen Teamkultur, Flexibilität und Weiterbildungsangebote. Gerade im Tech-Bereich, in dem der Markt groß istund die Erwartungen an Innovation entsprechend hoch sind, lohnt es sich, auf unkonventionellen Wegen zu gehen. Wer beispielsweise eine Zeit lang Care-Arbeit übernommen hat – sei es die Betreuung von Kindern oder die Pflege von Angehörigen – entwickelt Fähigkeiten wie Multitasking, Projekt- und Zeitmanagement, Krisenbewältigung und emotionale Intelligenz, die in Führungspositionen essenziell sind. Ebenso erweitern Menschen mit einer fachfremden Ausbildung den Blickwinkel um wertvolle Perspektiven: Wer etwa aus der Geisteswissenschaft in den Tech-Bereich wechselt, bringt oft analytisches Denken, ausgeprägte Kommunikationsfähigkeiten und interdisziplinäre Problemlösungskompetenz mit. Diese Vielfalt an Erfahrungen stärkt Unternehmen nicht nur in ihrer Innovationskraft, sondern fördert auch eine Kultur, die Flexibilität und Lernbereitschaft als essenzielle Erfolgsfaktoren begreift. Gleichzeitig reicht es nicht, bei der Auswahl an Talenten nur auf den arbeitsbezogenen Lebenslauf zu achten. Unternehmen müssen Raum schaffen für nicht-geradlinigen Erfolg, damit Talente bleiben. Das heißt zum Beispiel, traditionelle Karrierestrukturen aufzuweichen für Menschen, die außerhalb des Berufs zusätzlich Verantwortung übernehmen – sei es für Familie, Angehörige oder ehrenamtliches Engagement. Die Tech-Branche verliert wertvolle Talente, wenn sie ausschließlich jene fördert, die einem durchgängigen, ununterbrochenen Karrierepfad folgen können und ihre Leben ausschließlich der Arbeit widmen. Entscheidend können auch Mentoring-Programme sein: Aus eigener Erfahrung zeigt sich, dass gerade junge Frauen in der männerdominierten Tech-Welt dazu neigen, Chancen weniger als solche zu erkennen. Mentoren und Mentorinnen können hier Vorbild sein oder ermutigen, aus der Komfortzone herauszutreten und alternative Karrierewege einzuschlagen. Zu diesem Zweck ist es aber auch wichtig, ehrlich zu kommunizieren. Empowerment gelingt nur durch realistische Vorbilder: Die Idee, dass alles gleichzeitig und perfekt machbar ist – Karriere, Familie, Selbstverwirklichung – ist eine Illusion, die junge Menschen unter Druck setzt. Deshalb sollten etwaige Coachs auch die Herausforderungen und Abstriche offen zur Sprache bringen. Dies schafft realistische Erwartungen und verhindert das Gefühl, ständig hinter den Erwartungen zurückzubleiben. Tech-Unternehmen können stark von diversen Teams profitieren. Doch um dies zu erreichen, müssen die richtigen Weichen gestellt werden: Unternehmen sollten nicht nur das Potential nicht-linearer Karrierewege erkennen, sie sollten auch Raum für nicht-linearen Erfolg schaffen. Karriere sollte weniger als Leiter und mehr als persönlicher Entwicklungsweg betrachtet werden, bei dem Umwege oder unerwartete Chancen eine große Rolle spielen. Erfolg lässt sich nicht immer mit klar definierten Schritten in Form von Titeln und Positionen verbinden. Offenheit für verschiedene Wege, transparente Unterstützung durch Mentoren und Mentorinnen und flexible Arbeitsmodelle sind entscheidend, um die Innovationskraft der Tech-Branche weiter zu stärken. (jd) Quereinsteiger mit unkonventionellen Lebensläufen können eine bereicherung für Teams und Unternehmen sein. Wenn es um die Repräsentation von Frauen in der Tech-Branche geht, ist noch einiges zu tun. Zu diesem Schluss kommt der Nash Squared Leadership Report. Demnach sind lediglich 14 Prozent der IT-Führungskräfte weiblich. In Deutschland lag 2023 der Anteil aller Frauen in leitenden Stellungen bei 28 Prozent. Im europäischen Vergleich liegen wir damit im unteren Drittel der EU-Mitgliedstaaten . Diese Zahlen stehen dabei nicht nur für soziale Ungerechtigkeit, sie bezeugen auch eine Verkennung von wirtschaftlichem Potential. Denn Unternehmen mit diversen Führungsteams erzielen nachweislich höhere Gewinne, wie die McKinsey-Studie „Diversity Matters even more “ belegt. Abonnieren Sie unserer CIO-Newsetter für mehr spannende Einschätzungen, Hintergründe und Analysen aus der CIO-Community. Die Untersuchung kam zu dem Ergebnis, dass europäische Unternehmen mit Frauen in Führungsteams eine bis zu 62 Prozent höhere Chance auf überdurchschnittlichen wirtschaftlichen Erfolg haben. Die Gründe dafür liegen in einer breiteren Perspektivenvielfalt und stärkeren Innovationskraft. Was können Unternehmen im Tech-Bereich also tun, um ihre Teams diverser aufzustellen? Die Standardvorstellung von beruflichem Erfolg ist oftmals, dass dieser einfach das Resultat eines klaren, aufeinander aufbauenden Karrierewegs ist – inklusive eines erkennbaren Plans. Doch das ist heute längst nicht mehr der Fall und war es vielleicht nie. Karrierewege sind nicht immer strikt geplant und verlaufen ganz sicherlich nicht linear. In einer sich schnell wandelnden Branche ist jedoch genau diese starre Sichtweise zunehmend ein Hindernis. Gerade Brüche im Lebenslauf eröffnen neue Chancen, fördern kreative Lösungen und stärken die Anpassungsfähigkeit. Dennoch besteht in vielen Unternehmen, gerade im Hinblick auf Führungspositionen, weiterhin der Druck, Karriere entlang eines vorhersehbaren Musters zu planen. In Bewerbungsgesprächen wird oft gefragt: „Wo sehen Sie sich in fünf Jahren?“ Ein solcher Erwartungsdruck kann jedoch dazu führen, dass Menschen Chancen nicht wahrnehmen, die außerhalb des ursprünglichen Plans liegen. Statt starrer Aufstiegsmodelle wäre es sinnvoller, Entwicklungskriterien neu zu definieren – etwa in den Bereichen Teamkultur, Flexibilität und Weiterbildungsangebote. Gerade im Tech-Bereich, in dem der Markt groß istund die Erwartungen an Innovation entsprechend hoch sind, lohnt es sich, auf unkonventionellen Wegen zu gehen. Wer beispielsweise eine Zeit lang Care-Arbeit übernommen hat – sei es die Betreuung von Kindern oder die Pflege von Angehörigen – entwickelt Fähigkeiten wie Multitasking, Projekt- und Zeitmanagement, Krisenbewältigung und emotionale Intelligenz, die in Führungspositionen essenziell sind. Ebenso erweitern Menschen mit einer fachfremden Ausbildung den Blickwinkel um wertvolle Perspektiven: Wer etwa aus der Geisteswissenschaft in den Tech-Bereich wechselt, bringt oft analytisches Denken, ausgeprägte Kommunikationsfähigkeiten und interdisziplinäre Problemlösungskompetenz mit. Diese Vielfalt an Erfahrungen stärkt Unternehmen nicht nur in ihrer Innovationskraft, sondern fördert auch eine Kultur, die Flexibilität und Lernbereitschaft als essenzielle Erfolgsfaktoren begreift. Gleichzeitig reicht es nicht, bei der Auswahl an Talenten nur auf den arbeitsbezogenen Lebenslauf zu achten. Unternehmen müssen Raum schaffen für nicht-geradlinigen Erfolg, damit Talente bleiben. Das heißt zum Beispiel, traditionelle Karrierestrukturen aufzuweichen für Menschen, die außerhalb des Berufs zusätzlich Verantwortung übernehmen – sei es für Familie, Angehörige oder ehrenamtliches Engagement. Die Tech-Branche verliert wertvolle Talente, wenn sie ausschließlich jene fördert, die einem durchgängigen, ununterbrochenen Karrierepfad folgen können und ihre Leben ausschließlich der Arbeit widmen. Entscheidend können auch Mentoring-Programme sein: Aus eigener Erfahrung zeigt sich, dass gerade junge Frauen in der männerdominierten Tech-Welt dazu neigen, Chancen weniger als solche zu erkennen. Mentoren und Mentorinnen können hier Vorbild sein oder ermutigen, aus der Komfortzone herauszutreten und alternative Karrierewege einzuschlagen. Zu diesem Zweck ist es aber auch wichtig, ehrlich zu kommunizieren. Empowerment gelingt nur durch realistische Vorbilder: Die Idee, dass alles gleichzeitig und perfekt machbar ist – Karriere, Familie, Selbstverwirklichung – ist eine Illusion, die junge Menschen unter Druck setzt. Deshalb sollten etwaige Coachs auch die Herausforderungen und Abstriche offen zur Sprache bringen. Dies schafft realistische Erwartungen und verhindert das Gefühl, ständig hinter den Erwartungen zurückzubleiben. Tech-Unternehmen können stark von diversen Teams profitieren. Doch um dies zu erreichen, müssen die richtigen Weichen gestellt werden: Unternehmen sollten nicht nur das Potential nicht-linearer Karrierewege erkennen, sie sollten auch Raum für nicht-linearen Erfolg schaffen. Karriere sollte weniger als Leiter und mehr als persönlicher Entwicklungsweg betrachtet werden, bei dem Umwege oder unerwartete Chancen eine große Rolle spielen. Erfolg lässt sich nicht immer mit klar definierten Schritten in Form von Titeln und Positionen verbinden. Offenheit für verschiedene Wege, transparente Unterstützung durch Mentoren und Mentorinnen und flexible Arbeitsmodelle sind entscheidend, um die Innovationskraft der Tech-Branche weiter zu stärken. (jd)",
    "source": "cio",
    "crawled_at": "2025-05-27T08:10:57.766156+00:00"
  },
  {
    "url": "https://www.cio.de/article/3689539/der-schluessel-zum-ki-erfolg.html",
    "title": "Was ist organisationales Lernen?",
    "published": "2025-05-23T06:10:01+00:00",
    "author": "",
    "text": "Zu den Prinzipien organisationalen Lernens gehört es, dass KI und Mensch zusammenarbeiten und sich gegenseitig ergänzen. So entsteht für das Unternehmen ein Mehrwert. Foto: Lightspring – shutterstock.com Die Erfolge in Projekten zu maschinellem Lernen oder künstlicher Intelligenz (KI) zeigen sich in vielen Unternehmen nur eingeschränkt, wenn überhaupt. Experten glauben den Grund zu kennen: Die Betriebe versäumen es, ihre Erfahrungen über die gesamte Organisation hinweg zu teilen und für weitere Vorhaben zu nutzen. So gelingt es vielleicht, mithilfe von KI eine manuelle Aufgabe zu automatisieren oder bessere Vorhersagen für einzelne Abläufe zu treffen. Doch die wenigsten schaffen es, Erfahrungen aus ihren KI-Projekten in der Breite zu nutzen, um sich nach und nach zu transformieren. So führen Unternehmen nur in Ausnahmefällen formale Strukturen ein, um ihre KI-Learnings systematisch zu erfassen und für andere bereitzustellen. Einer aktuellen Studie von MIT Sloan Management Review und Boston Consulting Group zufolge zogen im vergangenen Jahr nur elf Prozent der befragten Betriebe einen signifikanten Nutzen aus ihren KI-Initiativen. Ein gern genommenes Beispiel für ungenutzte Chancen ist die Bewertung von Kreditanträgen in der Finanzwirtschaft, die durch maschinelles Lernen deutlich optimiert werden könnte. Die Kriterien sind festlegbar und lassen sich algorithmisch abbilden, die Zahl der Kreditsachbearbeiter könnte gesenkt werden. Dort die Kosten zu reduzieren, ist natürlich ein sensibles Thema. Die Mitarbeiter werden zögern, daran mitzuarbeiten und sich so potenziell um den eigenen Job zu bringen. Untätig zu bleiben ist aber für Banken mittelfristig keine Option, denn dort geht es um viel mehr als die Verbesserung eines Detailprozesses. Aus den Daten rund um Kreditanträge lassen sich viele Informationen gewinnen, die für das Geschäft insgesamt relevant sind. Eine Bank kann zum Beispiel Kundengruppen besser segmentieren und unterversorgte Bereiche aufspüren. Dort ließen sich Kunden dann mit besonderen Angeboten ködern, was zu einer Ausweitung des Geschäfts insgesamt führen würde. Oder die Bank könnte die Daten nutzen, um mehr über die Beweggründe zu erfahren, warum bestimmte Menschen keinen Kredit aufnehmen wollen. “Möglichweise fürchten ja einige, dass allein schon das Bemühen darum auf Kosten ihrer Kreditwürdigkeit gehen könnte”, sagt Sam Ransbotham, Professor für Informationssysteme an der Carroll School of Management des Boston College und einer der Autoren der MIT-Sloan-Studie. Das ließe sich ändern, indem den Interessenten eine risikofreie Prüfung zugesichert würde, die sich garantiert nicht auf ihre Kreditwürdigkeit auswirkt. “Es geht also nicht um eine platte Automatisierung des gewohnten Kreditprozesses, sondern um dessen grundlegende Erneuerung”, sagt Ransbotham. KI würde also den Einstieg in eine neue, vielversprechende Ära der Kreditwürdigkeitsprüfung weisen, Erfolge könnten dem Unternehmen signifikantes Wachstumspotenzial bescheren. Mit hoher Wahrscheinlichkeit würde sich dann zeigen, dass die Mitarbeiter – Veränderungsfähigkeit und -bereitschaft vorausgesetzt – die neue Technologie nutzen und sich damit viel interessantere berufliche Perspektiven eröffnen könnten. Ransbotham sieht daher CIOs nicht so sehr in der Pflicht, bereits bestehende Abläufe effizienter zu gestalten. KI und ML böten ihnen vielmehr die Chance, Dinge anders und besser zu erledigen, der Hebel für zusätzliche Wertschöpfung sei groß. In der Studie von MIT Sloan und Boston Consulting, für die 3.000 Manager in aller Welt befragt wurden, wird deutlich, unter welchen Umständen die erfolgreichen elf Prozent “signifikante finanzielle Vorteile” durch KI erzielt haben. Dort wurde die Technik nicht für simple Automatisierung herangezogen, sondern in die übergeordnete Geschäftsstrategie eingebettet. Diese Unternehmen haben Wege gefunden, um Mensch und KI zusammenzuführen, so dass sich Mitarbeiter und Technik optimal ergänzen. “Wir haben herausgefunden: Wenn sich Unternehmen mit organisationalem Lernen beschäftigen und entsprechend ausrichten, steigt die Wahrscheinlichkeit um ein Vielfaches, dass sie zu diesen elf Prozent der Erfolgreichen gehören”, sagt Ransbotham. Ein imposantes Beispiel für den Nutzen von KI liefert derzeit der Pharmazie- und Konsumgüterkonzern Johnson & Johnson, der Ende Januar seinen Impfstoff für COVID-19 ankündigte. Das Vakzin kann mit nur einer Impfung verabreicht werden und muss anders als die Alternative von Pfizer und Biontech nicht extrem heruntergekühlt werden. Laut Johnson & Johnson unterbindet der Impfstoff zwar nur in 66 Prozent der Fälle Infektionen, aber er verhindert zu 85 Prozent schwere und zu nahezu 100 Prozent tödliche Verläufe. CIO Jim Swanson sagt, den Impfstoff hätte es ohne KI nicht gegeben. Vor acht oder neun Monaten habe Johnson & Johnson noch zwei Wochen dafür gebraucht, eine Charge irgendeines Impfstoffs herzustellen, sagt er. Jetzt würden zwei Chargen pro Woche fertig, eine vierfache Verbesserung also. “Wir haben KI für jedes Detail eingesetzt, das reichte vom Fermentationsprozess bis hin zu den betriebswirtschaftlichen Kalkulationen”, sagt er. “All die analytischen Details summieren sich am Ende zu unserem Ergebnis.” Vor allem die verbesserte Zusammenarbeit über mehrere Fachbereiche hinweg habe den Prozess beschleunigt, berichtet Swanson. Die Data Scientists bei Johnson & Johnson beherrschten nicht nur Tools und Technik, sondern immer auch fachliche Aspekte im Forschungsbereich oder der Supply Chain . Doch die schlagzeilenträchtige Impfstoffentwicklung ist längst nicht alles. Johnson & Johnson nutzt KI inzwischen generell dazu, neue Geschäftsmöglichkeiten zu erschließen. Lösungen auf der Basis von maschinellem Lernen helfen beispielsweise Augenärzten, anhand von Netzhaut-Scans Glaukome zu finden. Zudem nutzt der Pharmariese KI für Operationsroboter in der Chirurgie: “Man hat eine viel höhere Präzision und bessere Verfahren”, lautet das Fazit des CIO. Auch die Abläufe vor und nach einem Eingriff ließen sich verbessern: “Man kann KI so einsetzen, dass Patienten die exakt richtige Behandlung bekommen, so dass ihre Genesung bestmöglich unterstützt wird.” Auch für Hautpflegemittel der Produktreihe “Avena” setzt der Konzern auf KI. Kunden fotografieren ihre Haut und erhalten anhand dessen eine personalisierte Produktempfehlung. Johnson & Johnson nutzt diese Bilder im Sinne des organisationalen Lernens auch, um generell herauszufinden, welche Hautprobleme bestimmte Menschengruppen haben. “Dieses Daten-Feedback von Seiten der Kunden hilft uns, die besseren Produkte zu kreieren”, sagt der CIO. Natürlich ist das nur möglich, wenn die vorhandene Daten-Infrastruktur Privacy und Sicherheit garantiert – die Basisvoraussetzung dafür, dass bei Johnson & Johnson überhaupt viele verschiedene Menschen mit diesen Daten arbeiten können. “Wenn man Daten nicht sicher teilen kann, kann man sie gar nicht teilen”, postuliert Swanson. Oft müsse man sie anonymisieren, um sich auf bestimmte Phänotypen zu konzentrieren – zum Beispiel auf Altersgruppen mit bestimmten Erkrankungen. Der letzte und wichtigste Teil der organisationalen Lernstrategie von Johnson & Johnson betrifft den Aufbau von kollektivem Know-how. “Wenn man sich mit der Nutzung von Daten nicht auskennt, kommt man nicht weiter”, sagt Swanson. Wissenschaftler aus Forschung und Entwicklung, kaufmännisches Personal und Supply-Chain-Professionals würden sich daher gleichermaßen damit beschäftigen. “Wir haben einen Data-Science-Beirat gegründet, den ich gemeinsam mit unserem Forschungschef leite. Wir beide haben entschieden, KI dezentral in unseren Geschäftsbereichen auszurollen.” Noch wichtiger sei, dass die KI-Strategie von der Konzernspitze gestützt werde. “Wir sind uns einig darin, dass wir Technologie im Allgemeinen und KI im Besonderen zum Kern unseres Unternehmens machen wollen. Das ist nichts, was Sie nebenbei machen können”, sagt Swanson. Anand Rao, Partner und Global AI Leader bei PricewaterhouseCoopers, hält das Vorgehen für vorbildlich. Johnson & Johnson gehöre zu den Konzernen, die KI im gesamten Unternehmen so verankern würden, dass sie von möglichst vielen Mitarbeitern genutzt werde – auch von solchen, die keinen technischen oder analytischen Hintergrund hätten. “Unternehmen werden mit KI keinen RoI erzielen, wenn ihre Leute nicht gut geschult, gecoacht und gemanagt werden”, sagt Rao. “Ziel muss es sein, dass nicht nur Einzelpersonen oder Kleingruppen, sondern die gesamte Organisation lernt.” Wichtig sei es Mitarbeiter zu haben, die “mehrsprachig” in dem Sinne sind, dass sie die geschäftliche Seite genauso wie die Software und die KI-Algorithmen verstehen. Alternativ dazu gebe es Sinn, ein Team so zusammenzustellen, dass beide Perspektiven eingebracht würden. Das sei eine große Herausforderung, so Rao. “Es ist schwierig, Menschen mit unterschiedlichen Denkweisen dazu zu bringen zusammenzuarbeiten.” Ein anderes Unternehmen, das sich das Prinzip des organisationalen Lernens zu Herzen nimmt, ist Genpact, ein globales Professional-Services-Unternehmen. Seine Wurzeln liegen im General-Electrics-(GE-)Konzern, der Genpact 2005 mit etwa 100.000 Mitarbeitern und einem Jahresumsatz von 3,5 Milliarden US-Dollar ausgegründet hatte. Als die Pandemie zuschlug, brachen Genpacts Einnahmen weg und das Unternehmen hätte eigentlich Tausende Mitarbeiter entlassen müssen, da viele Kunden von der Krise stark in Mitleidenschaft gezogen worden waren, berichtet Gianni Giacomelli, Chief Innovation Officer des Unternehmens. “Stattdessen waren wir in der Lage, sehr schnell auf neue Marktanforderungen zu reagieren und unser Personal in kürzester Zeit umzuschulen”, sagt Giacomelli, der im Unternehmen auch für Mitarbeitertraining und -entwicklung zuständig ist. “Manchmal dauerte es nur ein paar Wochen, um sie in neue Jobs zu bringen. Dadurch haben wir es tatsächlich geschafft, im Vergleich zu unseren Mitbewerbern zu wachsen, sogar während COVID-19.” Die Umschulung wurde durch gezielten Technologie-Einsatz möglich. Genpact nutzte Process Mining, Natural Language Processing (NLP) und Netzwerkanalysen, um herauszufinden wie Dinge im Unternehmen tatsächlich erledigt werden und, wer über welche Fähigkeiten und welches Fachwissen verfügt und wo es Ungereimtheiten in den Abläufen gibt. Die so gewonnenen Informationen halfen dabei, das Personal besser einzusetzen. Sobald ein Mitarbeiter eine andere neue Rolle übernommen hatte, ermöglichten KI-Systeme ihm eine schnelle Einarbeitung, indem sie den Prozess für die jeweiligen Aufgaben beschrieben oder die jeweilige Person mit relevanten Experten verbanden. “Dadurch konnten wir viel schneller auf die neuen Bedingungen reagieren, mit denen wir aufgrund der Pandemie konfrontiert waren”, sagt Giacomelli. Mit den neuen Technologien bekommt Genpact in den Griff, was viele Jahre lang nicht nur hier, sondern auch in vielen anderen Unternehmen schiefging: das Wissensmanagement. Vor fünf Jahren lag die Misserfolgsrate entsprechender Programme laut dem Knowledge Management Institute bei etwa 50 Prozent. Aber aufgrund erheblicher Verbesserungen bei KI-Technologien im allgemeinen und NLP im Besonderen hat sich die Situation dramatisch verändert. “In den letzten zwei, drei Jahren ist die Qualität der von Maschinen selbst erstellten Ontologien viel besser geworden”, sagt Giacomelli. “Was man zurückbekommt, ist viel präziser.” KI ist eine große Hilfe, um organisationales Wissen in Dokumenten, Geschäftsprozessen und auch in den Köpfen aufzustöbern. Bei Genpact ist das nicht allein die Domäne der IT-Abteilung. Laut Kathleen Featheringham, Direktorin für KI-Strategie und Training bei Booz Allen Hamilton, entscheidet sich in der Qualität des Rollouts, ob es einen relevanten RoI gibt oder nicht. “KI ist die vierte industrielle Revolution”, sagt sie. “Sie verändert das Spiel grundlegend. Es geht hier nicht um ein IT-Problem, alle Rollen entwickeln sich weiter.” Die KI-gestützte Unternehmenstransformation erfordere eine Neubewertung der Leistungsziele, des Mitarbeitertrainingszielen und auch der gesamten Vision. Sei das nicht der Fall und es gebe keinen Konsens über das Vorgehen, könnten das die Mitarbeiter sehr übelnehmen, warnt Featheringham. Zu den Prinzipien organisationalen Lernens gehört es, dass KI und Mensch zusammenarbeiten und sich gegenseitig ergänzen. “Gelingt eine Kooperation, in der Maschinen tun, was sie gut können, und Menschen ihre Intuition und ihr Wissen einbringen, wird man einen großen geschäftlichen Nutzen sehen”, ist Judith Hurwitz überzeugt, Präsidentin und Gründerin von Hurwitz and Associates sowie Autorin von inzwischen zehn Büchern zu Themen wie Führung, Technologie und Analytics. Was ist Value Stream Mapping? Foto: 3rdtimeluckystudio – shutterstock.com Value Stream Mapping ist eine Lean-Management-Technik. Das sollten Sie über die Wertstromanalyse wissen. Was ist IT Business Alignment? Foto: fotogestoeber – shutterstock.com IT-Investitionen müssen zur Unternehmensentwicklung beitragen. IT Alignment bezeichnet dazu die gegenseitige Ausrichtung von Geschäfts- und IT-Stategien. Was sind Serious Games? Foto: TU Köln Screenshot: Welten der Werkstoffe Serious Games sollen Lernen durch Videospiele attraktiver machen. erfahren Sie, wie es funktioniert und welche Ansätze dahinterstecken. Was ist Intelligent Wargaming? Foto: Gorodenkoff – shutterstock.com Intelligent Wargaming nutzt Echtzeitanalysen und Techniken wie Machine Learning zur Unternehmenssteuerung. Auch der CIO ist dabei gefordert. Was ist Agilität? Foto: Andrey_Popov – shutterstock.com Der Begriff Agilität beschreibt sowohl ein methodisches Vorgehen als auch die Gestaltung der Firmenkultur. Ein Überblick. Was sind technische Schulden? Foto: hatoriz – shutterstock.com Technical Debt – zu Deutsch technische Schulden – kann die Innovationskraft und den monetären Erfolg Ihres Unternehmens gefährden. Was ist Outstaffing? Foto: Viesinsh – shutterstock.com Die Outsourcing-Variante Outstaffing stellt einen neuen Weg für die strategische Entwicklung von Unternehmenssoftware dar. Das müssen Sie wissen. Was ist Environmental Social Governance? Foto: Mameraman – shutterstock.com Ab 2023 müssen sich viele Unternehmen in der EU an ESG-Kriterien halten. Wir erklären die Hintergründe und Richtlinien. Was ist Transformational Leadership? Foto: nullplus – shutterstock.com Transformational Leadership fördert Eigenverantwortung und inspiriert Mitarbeiter, Veränderungen und Innovationen im Unternehmen voranzutreiben. Was ist Change Management? Foto: Alex from the Rock – shutterstock.com Was versteht man unter Change Management und wie unterscheidet es sich zur Organisationsentwicklung? Welche Methoden es im Veränderungsmanagement gibt, lesen Sie hier. Was ist ein Citizen Developer? Foto: NDAB Creativity – shutterstock.com Citizen Developer nehmen bei der digitalen Transformation von Unternehmen eine wichtige Rolle ein. Was man darunter versteht, lesen Sie hier. Was ist Operations Management? Foto: Pixparts – shutterstock.com In Zeiten der Digitalisierung kann es für ein Unternehmen entscheidend sein, wie gut es Business- und IT-Prozesse in Einklang bringt. Zwei Wege führen zum Ziel. Was ist Design Thinking? Foto: REDPIXEL.PL – shutterstock.com Design Thinking hilft Unternehmen, kundenorientierte Ideen und Ansätze zu kreieren. Die Methode eignet sich auch für sehr komplexe Probleme. Was ist Servant Leadership? Foto: Jacob Lund – shutterstock.com Servant Leader dienen ihrem Umfeld und helfen anderen dabei, zu wachsen. Dieses Führungsverständnis ist nicht nur im agilen Umfeld beliebt. Projektmanagement-Methoden im Vergleich Foto: NicoElNino – shutterstock.com Damit ein IT-Projekt nicht scheitert, sollte die richtige Methode bereits in Vorfeld gewählt werden. Eine Erklärung verschiedener Methoden mit Anwendungsfällen sowie eine Tabelle, die durch den Auswahlprozess leitet. Was ist Business Intelligence? Foto: SFIO CRACHO – shutterstock.com Business Intelligence (BI) verwandelt Daten in Insights und hilft bei der Entscheidungsfindung im Unternehmen. Wir sagen Ihnen, was Sie zum Thema wissen müssen. Was ist Contract Lifecycle Management? Foto: fizkes – shutterstock.com Erfahren Sie, was Contract Lifecycle Management (CLM) ist und welche Unternehmensbereiche davon profitieren können. Was ist Arbeitnehmerüberlassung? Foto: Alexander Supertramp – shutterstock.com 27.10.2022 Von Matthias RuffMatthias Ruff (Autor) Auf Arbeitnehmerüberlassung greifen Unternehmen zurück, damit Scheinselbständigkeit kein Thema wird. Das sollten Sie beachten. Was ist ein Statement of Work? Foto: wutzkohphoto – shutterstock.com Das Statement of Work (SoW) sorgt in der Projektarbeit für Klarheit. Warum das Dokument wichtig ist und was man beim Verfassen beachten sollte. Was ist Compliance? Foto: Arcady – shutterstock.com Was versteht man unter Compliance? Welche Verfahren und Anforderungen gibt es an Unternehmen? Wie die Einhaltung der Compliance verbessert werden kann, lesen Sie hier. Was ist Controlling? Foto: Roman Samborskyi – shutterstock.com Lesen Sie, was sich hinter dem Begriff Controlling verbirgt, welche Aufgaben ein Controller wahrnimmt, worauf Unternehmen achten sollten und wie die Zukunft des Controllings aussieht. Was ist ein kooperativer Führungsstil? Foto: NDAB Creativity – shutterstock.com Wer kooperativ führt, kommuniziert mit seinen Mitarbeitern auf Augenhöhe und teilt Verantwortung. Dieser Führungsstil hat in Corona-Zeiten Auftrieb erhalten. Was ist Total Quality Management? Foto: greenbutterfly – shutterstock.com Total Quality Management – TQM – unterstützt Unternehmen dabei, sich auf die kontinuierliche Verbesserung von Prozessen und Produkten zu fokussieren. Was ist New Work? Foto: Jacob Lund – shutterstock.com Die Corona-Pandemie hat das Thema New Work befeuert. Doch das Konzept umfasst viel mehr als flexibles Arbeiten und neue Büroräume mit Kickertisch. Was macht ein Solution Architect? Foto: Kutlayev Dmitry – shutterstock.com Der Solution Architect nimmt eine entscheidende Rolle im Unternehmen ein. Lesen Sie, warum. Was ist Gamification? Foto: Pixel-Shot – shutterstock.com Was hat das “Moorhuhn” mit einer Whisky-Marke zu tun? Schon Ende des vergangenen Jahrtausends nutzten Unternehmen spielerische Elemente für ihre Zwecke. Inzwischen hat Gamification Einzug in den Alltag gehalten. Was ist ein Business-Analyst? Foto: SFIO CRACHO – shutterstock.com Mit Datenanalysen unterstützen Business-Analysten Unternehmen dabei, Prozesse, Produkte, Services und Software zu verbessern. Was ist GitOps? Foto: iunewind – shutterstock.com GitOps wendet die Methoden von DevOps und CI/CD für die Bereitstellung von IT-Infrastruktur an. Das müssen Sie zum Thema wissen. Was ist Data Literacy? Foto: Khosro – shutterstock.com Mit Daten umzugehen, sie auszuwerten, zu interpretieren und als Entscheidungsgrundlage zu nutzen, bedarf einer entscheidenden Kernkompetenz: Data Literacy. Was ist Laterale Führung? Foto: Altrendo Images – shutterstock.com Laterale Führung bezeichnet einen unkonventionellen Führungsstil. Klassische, hierarchisch geprägte Führungsinstrumente stehen dabei nicht zur Verfügung. Was ist ITIL? Foto: RoseRodionova – shutterstock.com Das Regelwerk ITIL beschreibt Best Practices für die Bereitstellung von IT-Services. Es soll zu einer stabilen IT-Umgebung beitragen, die Wachstum, Skalierbarkeit und Change ermöglicht. Was ist Workforce Management? Foto: Blue Planet Studio – shutterstock.com Workforce Management ist über die Jahre zu einem komplexen Framework für Personalverwaltung und Budgetierung avanciert. Das sollten Sie zum Thema wissen. Was ist eine Prozessorganisation? Foto: NicoElNino – shutterstock.com So bauen Sie eine Prozessorganisation in fünf Schritten auf. Von der Definition der Rollen bis zur Verknüpfung mit der IT-Organisation. Eine Tabelle zeigt den Ablauf an einem Beispiel. Was ist organisationales Lernen? Foto: Lightspring – shutterstock.com Viele Unternehmen setzen im Kleinen auf KI, versäumen es aber, formale Prozesse einzuführen, damit die gesamte Organisation lernen und sich schneller transformieren kann. Zu den Prinzipien organisationalen Lernens gehört es, dass KI und Mensch zusammenarbeiten und sich gegenseitig ergänzen. So entsteht für das Unternehmen ein Mehrwert. Foto: Lightspring – shutterstock.com Die Erfolge in Projekten zu maschinellem Lernen oder künstlicher Intelligenz (KI) zeigen sich in vielen Unternehmen nur eingeschränkt, wenn überhaupt. Experten glauben den Grund zu kennen: Die Betriebe versäumen es, ihre Erfahrungen über die gesamte Organisation hinweg zu teilen und für weitere Vorhaben zu nutzen. So gelingt es vielleicht, mithilfe von KI eine manuelle Aufgabe zu automatisieren oder bessere Vorhersagen für einzelne Abläufe zu treffen. Doch die wenigsten schaffen es, Erfahrungen aus ihren KI-Projekten in der Breite zu nutzen, um sich nach und nach zu transformieren. So führen Unternehmen nur in Ausnahmefällen formale Strukturen ein, um ihre KI-Learnings systematisch zu erfassen und für andere bereitzustellen. Einer aktuellen Studie von MIT Sloan Management Review und Boston Consulting Group zufolge zogen im vergangenen Jahr nur elf Prozent der befragten Betriebe einen signifikanten Nutzen aus ihren KI-Initiativen. Ein gern genommenes Beispiel für ungenutzte Chancen ist die Bewertung von Kreditanträgen in der Finanzwirtschaft, die durch maschinelles Lernen deutlich optimiert werden könnte. Die Kriterien sind festlegbar und lassen sich algorithmisch abbilden, die Zahl der Kreditsachbearbeiter könnte gesenkt werden. Dort die Kosten zu reduzieren, ist natürlich ein sensibles Thema. Die Mitarbeiter werden zögern, daran mitzuarbeiten und sich so potenziell um den eigenen Job zu bringen. Untätig zu bleiben ist aber für Banken mittelfristig keine Option, denn dort geht es um viel mehr als die Verbesserung eines Detailprozesses. Aus den Daten rund um Kreditanträge lassen sich viele Informationen gewinnen, die für das Geschäft insgesamt relevant sind. Eine Bank kann zum Beispiel Kundengruppen besser segmentieren und unterversorgte Bereiche aufspüren. Dort ließen sich Kunden dann mit besonderen Angeboten ködern, was zu einer Ausweitung des Geschäfts insgesamt führen würde. Oder die Bank könnte die Daten nutzen, um mehr über die Beweggründe zu erfahren, warum bestimmte Menschen keinen Kredit aufnehmen wollen. “Möglichweise fürchten ja einige, dass allein schon das Bemühen darum auf Kosten ihrer Kreditwürdigkeit gehen könnte”, sagt Sam Ransbotham, Professor für Informationssysteme an der Carroll School of Management des Boston College und einer der Autoren der MIT-Sloan-Studie. Das ließe sich ändern, indem den Interessenten eine risikofreie Prüfung zugesichert würde, die sich garantiert nicht auf ihre Kreditwürdigkeit auswirkt. “Es geht also nicht um eine platte Automatisierung des gewohnten Kreditprozesses, sondern um dessen grundlegende Erneuerung”, sagt Ransbotham. KI würde also den Einstieg in eine neue, vielversprechende Ära der Kreditwürdigkeitsprüfung weisen, Erfolge könnten dem Unternehmen signifikantes Wachstumspotenzial bescheren. Mit hoher Wahrscheinlichkeit würde sich dann zeigen, dass die Mitarbeiter – Veränderungsfähigkeit und -bereitschaft vorausgesetzt – die neue Technologie nutzen und sich damit viel interessantere berufliche Perspektiven eröffnen könnten. Ransbotham sieht daher CIOs nicht so sehr in der Pflicht, bereits bestehende Abläufe effizienter zu gestalten. KI und ML böten ihnen vielmehr die Chance, Dinge anders und besser zu erledigen, der Hebel für zusätzliche Wertschöpfung sei groß. In der Studie von MIT Sloan und Boston Consulting, für die 3.000 Manager in aller Welt befragt wurden, wird deutlich, unter welchen Umständen die erfolgreichen elf Prozent “signifikante finanzielle Vorteile” durch KI erzielt haben. Dort wurde die Technik nicht für simple Automatisierung herangezogen, sondern in die übergeordnete Geschäftsstrategie eingebettet. Diese Unternehmen haben Wege gefunden, um Mensch und KI zusammenzuführen, so dass sich Mitarbeiter und Technik optimal ergänzen. “Wir haben herausgefunden: Wenn sich Unternehmen mit organisationalem Lernen beschäftigen und entsprechend ausrichten, steigt die Wahrscheinlichkeit um ein Vielfaches, dass sie zu diesen elf Prozent der Erfolgreichen gehören”, sagt Ransbotham. Ein imposantes Beispiel für den Nutzen von KI liefert derzeit der Pharmazie- und Konsumgüterkonzern Johnson & Johnson, der Ende Januar seinen Impfstoff für COVID-19 ankündigte. Das Vakzin kann mit nur einer Impfung verabreicht werden und muss anders als die Alternative von Pfizer und Biontech nicht extrem heruntergekühlt werden. Laut Johnson & Johnson unterbindet der Impfstoff zwar nur in 66 Prozent der Fälle Infektionen, aber er verhindert zu 85 Prozent schwere und zu nahezu 100 Prozent tödliche Verläufe. CIO Jim Swanson sagt, den Impfstoff hätte es ohne KI nicht gegeben. Vor acht oder neun Monaten habe Johnson & Johnson noch zwei Wochen dafür gebraucht, eine Charge irgendeines Impfstoffs herzustellen, sagt er. Jetzt würden zwei Chargen pro Woche fertig, eine vierfache Verbesserung also. “Wir haben KI für jedes Detail eingesetzt, das reichte vom Fermentationsprozess bis hin zu den betriebswirtschaftlichen Kalkulationen”, sagt er. “All die analytischen Details summieren sich am Ende zu unserem Ergebnis.” Vor allem die verbesserte Zusammenarbeit über mehrere Fachbereiche hinweg habe den Prozess beschleunigt, berichtet Swanson. Die Data Scientists bei Johnson & Johnson beherrschten nicht nur Tools und Technik, sondern immer auch fachliche Aspekte im Forschungsbereich oder der Supply Chain . Doch die schlagzeilenträchtige Impfstoffentwicklung ist längst nicht alles. Johnson & Johnson nutzt KI inzwischen generell dazu, neue Geschäftsmöglichkeiten zu erschließen. Lösungen auf der Basis von maschinellem Lernen helfen beispielsweise Augenärzten, anhand von Netzhaut-Scans Glaukome zu finden. Zudem nutzt der Pharmariese KI für Operationsroboter in der Chirurgie: “Man hat eine viel höhere Präzision und bessere Verfahren”, lautet das Fazit des CIO. Auch die Abläufe vor und nach einem Eingriff ließen sich verbessern: “Man kann KI so einsetzen, dass Patienten die exakt richtige Behandlung bekommen, so dass ihre Genesung bestmöglich unterstützt wird.” Auch für Hautpflegemittel der Produktreihe “Avena” setzt der Konzern auf KI. Kunden fotografieren ihre Haut und erhalten anhand dessen eine personalisierte Produktempfehlung. Johnson & Johnson nutzt diese Bilder im Sinne des organisationalen Lernens auch, um generell herauszufinden, welche Hautprobleme bestimmte Menschengruppen haben. “Dieses Daten-Feedback von Seiten der Kunden hilft uns, die besseren Produkte zu kreieren”, sagt der CIO. Natürlich ist das nur möglich, wenn die vorhandene Daten-Infrastruktur Privacy und Sicherheit garantiert – die Basisvoraussetzung dafür, dass bei Johnson & Johnson überhaupt viele verschiedene Menschen mit diesen Daten arbeiten können. “Wenn man Daten nicht sicher teilen kann, kann man sie gar nicht teilen”, postuliert Swanson. Oft müsse man sie anonymisieren, um sich auf bestimmte Phänotypen zu konzentrieren – zum Beispiel auf Altersgruppen mit bestimmten Erkrankungen. Der letzte und wichtigste Teil der organisationalen Lernstrategie von Johnson & Johnson betrifft den Aufbau von kollektivem Know-how. “Wenn man sich mit der Nutzung von Daten nicht auskennt, kommt man nicht weiter”, sagt Swanson. Wissenschaftler aus Forschung und Entwicklung, kaufmännisches Personal und Supply-Chain-Professionals würden sich daher gleichermaßen damit beschäftigen. “Wir haben einen Data-Science-Beirat gegründet, den ich gemeinsam mit unserem Forschungschef leite. Wir beide haben entschieden, KI dezentral in unseren Geschäftsbereichen auszurollen.” Noch wichtiger sei, dass die KI-Strategie von der Konzernspitze gestützt werde. “Wir sind uns einig darin, dass wir Technologie im Allgemeinen und KI im Besonderen zum Kern unseres Unternehmens machen wollen. Das ist nichts, was Sie nebenbei machen können”, sagt Swanson. Anand Rao, Partner und Global AI Leader bei PricewaterhouseCoopers, hält das Vorgehen für vorbildlich. Johnson & Johnson gehöre zu den Konzernen, die KI im gesamten Unternehmen so verankern würden, dass sie von möglichst vielen Mitarbeitern genutzt werde – auch von solchen, die keinen technischen oder analytischen Hintergrund hätten. “Unternehmen werden mit KI keinen RoI erzielen, wenn ihre Leute nicht gut geschult, gecoacht und gemanagt werden”, sagt Rao. “Ziel muss es sein, dass nicht nur Einzelpersonen oder Kleingruppen, sondern die gesamte Organisation lernt.” Wichtig sei es Mitarbeiter zu haben, die “mehrsprachig” in dem Sinne sind, dass sie die geschäftliche Seite genauso wie die Software und die KI-Algorithmen verstehen. Alternativ dazu gebe es Sinn, ein Team so zusammenzustellen, dass beide Perspektiven eingebracht würden. Das sei eine große Herausforderung, so Rao. “Es ist schwierig, Menschen mit unterschiedlichen Denkweisen dazu zu bringen zusammenzuarbeiten.” Ein anderes Unternehmen, das sich das Prinzip des organisationalen Lernens zu Herzen nimmt, ist Genpact, ein globales Professional-Services-Unternehmen. Seine Wurzeln liegen im General-Electrics-(GE-)Konzern, der Genpact 2005 mit etwa 100.000 Mitarbeitern und einem Jahresumsatz von 3,5 Milliarden US-Dollar ausgegründet hatte. Als die Pandemie zuschlug, brachen Genpacts Einnahmen weg und das Unternehmen hätte eigentlich Tausende Mitarbeiter entlassen müssen, da viele Kunden von der Krise stark in Mitleidenschaft gezogen worden waren, berichtet Gianni Giacomelli, Chief Innovation Officer des Unternehmens. “Stattdessen waren wir in der Lage, sehr schnell auf neue Marktanforderungen zu reagieren und unser Personal in kürzester Zeit umzuschulen”, sagt Giacomelli, der im Unternehmen auch für Mitarbeitertraining und -entwicklung zuständig ist. “Manchmal dauerte es nur ein paar Wochen, um sie in neue Jobs zu bringen. Dadurch haben wir es tatsächlich geschafft, im Vergleich zu unseren Mitbewerbern zu wachsen, sogar während COVID-19.” Die Umschulung wurde durch gezielten Technologie-Einsatz möglich. Genpact nutzte Process Mining, Natural Language Processing (NLP) und Netzwerkanalysen, um herauszufinden wie Dinge im Unternehmen tatsächlich erledigt werden und, wer über welche Fähigkeiten und welches Fachwissen verfügt und wo es Ungereimtheiten in den Abläufen gibt. Die so gewonnenen Informationen halfen dabei, das Personal besser einzusetzen. Sobald ein Mitarbeiter eine andere neue Rolle übernommen hatte, ermöglichten KI-Systeme ihm eine schnelle Einarbeitung, indem sie den Prozess für die jeweiligen Aufgaben beschrieben oder die jeweilige Person mit relevanten Experten verbanden. “Dadurch konnten wir viel schneller auf die neuen Bedingungen reagieren, mit denen wir aufgrund der Pandemie konfrontiert waren”, sagt Giacomelli. Mit den neuen Technologien bekommt Genpact in den Griff, was viele Jahre lang nicht nur hier, sondern auch in vielen anderen Unternehmen schiefging: das Wissensmanagement. Vor fünf Jahren lag die Misserfolgsrate entsprechender Programme laut dem Knowledge Management Institute bei etwa 50 Prozent. Aber aufgrund erheblicher Verbesserungen bei KI-Technologien im allgemeinen und NLP im Besonderen hat sich die Situation dramatisch verändert. “In den letzten zwei, drei Jahren ist die Qualität der von Maschinen selbst erstellten Ontologien viel besser geworden”, sagt Giacomelli. “Was man zurückbekommt, ist viel präziser.” KI ist eine große Hilfe, um organisationales Wissen in Dokumenten, Geschäftsprozessen und auch in den Köpfen aufzustöbern. Bei Genpact ist das nicht allein die Domäne der IT-Abteilung. Laut Kathleen Featheringham, Direktorin für KI-Strategie und Training bei Booz Allen Hamilton, entscheidet sich in der Qualität des Rollouts, ob es einen relevanten RoI gibt oder nicht. “KI ist die vierte industrielle Revolution”, sagt sie. “Sie verändert das Spiel grundlegend. Es geht hier nicht um ein IT-Problem, alle Rollen entwickeln sich weiter.” Die KI-gestützte Unternehmenstransformation erfordere eine Neubewertung der Leistungsziele, des Mitarbeitertrainingszielen und auch der gesamten Vision. Sei das nicht der Fall und es gebe keinen Konsens über das Vorgehen, könnten das die Mitarbeiter sehr übelnehmen, warnt Featheringham. Zu den Prinzipien organisationalen Lernens gehört es, dass KI und Mensch zusammenarbeiten und sich gegenseitig ergänzen. “Gelingt eine Kooperation, in der Maschinen tun, was sie gut können, und Menschen ihre Intuition und ihr Wissen einbringen, wird man einen großen geschäftlichen Nutzen sehen”, ist Judith Hurwitz überzeugt, Präsidentin und Gründerin von Hurwitz and Associates sowie Autorin von inzwischen zehn Büchern zu Themen wie Führung, Technologie und Analytics. Was ist Value Stream Mapping? Foto: 3rdtimeluckystudio – shutterstock.com Value Stream Mapping ist eine Lean-Management-Technik. Das sollten Sie über die Wertstromanalyse wissen. Was ist IT Business Alignment? Foto: fotogestoeber – shutterstock.com IT-Investitionen müssen zur Unternehmensentwicklung beitragen. IT Alignment bezeichnet dazu die gegenseitige Ausrichtung von Geschäfts- und IT-Stategien. Was sind Serious Games? Foto: TU Köln Screenshot: Welten der Werkstoffe Serious Games sollen Lernen durch Videospiele attraktiver machen. erfahren Sie, wie es funktioniert und welche Ansätze dahinterstecken. Was ist Intelligent Wargaming? Foto: Gorodenkoff – shutterstock.com Intelligent Wargaming nutzt Echtzeitanalysen und Techniken wie Machine Learning zur Unternehmenssteuerung. Auch der CIO ist dabei gefordert. Was ist Agilität? Foto: Andrey_Popov – shutterstock.com Der Begriff Agilität beschreibt sowohl ein methodisches Vorgehen als auch die Gestaltung der Firmenkultur. Ein Überblick. Was sind technische Schulden? Foto: hatoriz – shutterstock.com Technical Debt – zu Deutsch technische Schulden – kann die Innovationskraft und den monetären Erfolg Ihres Unternehmens gefährden. Was ist Outstaffing? Foto: Viesinsh – shutterstock.com Die Outsourcing-Variante Outstaffing stellt einen neuen Weg für die strategische Entwicklung von Unternehmenssoftware dar. Das müssen Sie wissen. Was ist Environmental Social Governance? Foto: Mameraman – shutterstock.com Ab 2023 müssen sich viele Unternehmen in der EU an ESG-Kriterien halten. Wir erklären die Hintergründe und Richtlinien. Was ist Transformational Leadership? Foto: nullplus – shutterstock.com Transformational Leadership fördert Eigenverantwortung und inspiriert Mitarbeiter, Veränderungen und Innovationen im Unternehmen voranzutreiben. Was ist Change Management? Foto: Alex from the Rock – shutterstock.com Was versteht man unter Change Management und wie unterscheidet es sich zur Organisationsentwicklung? Welche Methoden es im Veränderungsmanagement gibt, lesen Sie hier. Was ist ein Citizen Developer? Foto: NDAB Creativity – shutterstock.com Citizen Developer nehmen bei der digitalen Transformation von Unternehmen eine wichtige Rolle ein. Was man darunter versteht, lesen Sie hier. Was ist Operations Management? Foto: Pixparts – shutterstock.com In Zeiten der Digitalisierung kann es für ein Unternehmen entscheidend sein, wie gut es Business- und IT-Prozesse in Einklang bringt. Zwei Wege führen zum Ziel. Was ist Design Thinking? Foto: REDPIXEL.PL – shutterstock.com Design Thinking hilft Unternehmen, kundenorientierte Ideen und Ansätze zu kreieren. Die Methode eignet sich auch für sehr komplexe Probleme. Was ist Servant Leadership? Foto: Jacob Lund – shutterstock.com Servant Leader dienen ihrem Umfeld und helfen anderen dabei, zu wachsen. Dieses Führungsverständnis ist nicht nur im agilen Umfeld beliebt. Projektmanagement-Methoden im Vergleich Foto: NicoElNino – shutterstock.com Damit ein IT-Projekt nicht scheitert, sollte die richtige Methode bereits in Vorfeld gewählt werden. Eine Erklärung verschiedener Methoden mit Anwendungsfällen sowie eine Tabelle, die durch den Auswahlprozess leitet. Was ist Business Intelligence? Foto: SFIO CRACHO – shutterstock.com Business Intelligence (BI) verwandelt Daten in Insights und hilft bei der Entscheidungsfindung im Unternehmen. Wir sagen Ihnen, was Sie zum Thema wissen müssen. Was ist Contract Lifecycle Management? Foto: fizkes – shutterstock.com Erfahren Sie, was Contract Lifecycle Management (CLM) ist und welche Unternehmensbereiche davon profitieren können. Was ist Arbeitnehmerüberlassung? Foto: Alexander Supertramp – shutterstock.com 27.10.2022 Von Matthias RuffMatthias Ruff (Autor) Auf Arbeitnehmerüberlassung greifen Unternehmen zurück, damit Scheinselbständigkeit kein Thema wird. Das sollten Sie beachten. Was ist ein Statement of Work? Foto: wutzkohphoto – shutterstock.com Das Statement of Work (SoW) sorgt in der Projektarbeit für Klarheit. Warum das Dokument wichtig ist und was man beim Verfassen beachten sollte. Was ist Compliance? Foto: Arcady – shutterstock.com Was versteht man unter Compliance? Welche Verfahren und Anforderungen gibt es an Unternehmen? Wie die Einhaltung der Compliance verbessert werden kann, lesen Sie hier. Was ist Controlling? Foto: Roman Samborskyi – shutterstock.com Lesen Sie, was sich hinter dem Begriff Controlling verbirgt, welche Aufgaben ein Controller wahrnimmt, worauf Unternehmen achten sollten und wie die Zukunft des Controllings aussieht. Was ist ein kooperativer Führungsstil? Foto: NDAB Creativity – shutterstock.com Wer kooperativ führt, kommuniziert mit seinen Mitarbeitern auf Augenhöhe und teilt Verantwortung. Dieser Führungsstil hat in Corona-Zeiten Auftrieb erhalten. Was ist Total Quality Management? Foto: greenbutterfly – shutterstock.com Total Quality Management – TQM – unterstützt Unternehmen dabei, sich auf die kontinuierliche Verbesserung von Prozessen und Produkten zu fokussieren. Was ist New Work? Foto: Jacob Lund – shutterstock.com Die Corona-Pandemie hat das Thema New Work befeuert. Doch das Konzept umfasst viel mehr als flexibles Arbeiten und neue Büroräume mit Kickertisch. Was macht ein Solution Architect? Foto: Kutlayev Dmitry – shutterstock.com Der Solution Architect nimmt eine entscheidende Rolle im Unternehmen ein. Lesen Sie, warum. Was ist Gamification? Foto: Pixel-Shot – shutterstock.com Was hat das “Moorhuhn” mit einer Whisky-Marke zu tun? Schon Ende des vergangenen Jahrtausends nutzten Unternehmen spielerische Elemente für ihre Zwecke. Inzwischen hat Gamification Einzug in den Alltag gehalten. Was ist ein Business-Analyst? Foto: SFIO CRACHO – shutterstock.com Mit Datenanalysen unterstützen Business-Analysten Unternehmen dabei, Prozesse, Produkte, Services und Software zu verbessern. Was ist GitOps? Foto: iunewind – shutterstock.com GitOps wendet die Methoden von DevOps und CI/CD für die Bereitstellung von IT-Infrastruktur an. Das müssen Sie zum Thema wissen. Was ist Data Literacy? Foto: Khosro – shutterstock.com Mit Daten umzugehen, sie auszuwerten, zu interpretieren und als Entscheidungsgrundlage zu nutzen, bedarf einer entscheidenden Kernkompetenz: Data Literacy. Was ist Laterale Führung? Foto: Altrendo Images – shutterstock.com Laterale Führung bezeichnet einen unkonventionellen Führungsstil. Klassische, hierarchisch geprägte Führungsinstrumente stehen dabei nicht zur Verfügung. Was ist ITIL? Foto: RoseRodionova – shutterstock.com Das Regelwerk ITIL beschreibt Best Practices für die Bereitstellung von IT-Services. Es soll zu einer stabilen IT-Umgebung beitragen, die Wachstum, Skalierbarkeit und Change ermöglicht. Was ist Workforce Management? Foto: Blue Planet Studio – shutterstock.com Workforce Management ist über die Jahre zu einem komplexen Framework für Personalverwaltung und Budgetierung avanciert. Das sollten Sie zum Thema wissen. Was ist eine Prozessorganisation? Foto: NicoElNino – shutterstock.com So bauen Sie eine Prozessorganisation in fünf Schritten auf. Von der Definition der Rollen bis zur Verknüpfung mit der IT-Organisation. Eine Tabelle zeigt den Ablauf an einem Beispiel. Was ist organisationales Lernen? Foto: Lightspring – shutterstock.com Viele Unternehmen setzen im Kleinen auf KI, versäumen es aber, formale Prozesse einzuführen, damit die gesamte Organisation lernen und sich schneller transformieren kann.",
    "source": "cio",
    "crawled_at": "2025-05-27T08:10:57.867033+00:00"
  },
  {
    "url": "https://www.cio.de/article/3991986/gewerbetreibender-versus-freiberufler-was-bin-ich-und-was-darf-ich-sein-2.html",
    "title": "Gewerbetreibender versus Freiberufler – Was bin ich und was darf ich sein?",
    "published": "2025-05-23T06:23:40+00:00",
    "author": "",
    "text": "Tupungato – shutterstock.com Grundsätzlich unterliegen Selbständige, die mit ihrer Unternehmung Gewinne erzielen möchten, der Gewerbeordnung . Es gibt aber Ausnahmen für bestimmte Berufsgruppen und Tätigkeiten. Freiberufler wie Künstler, Journalisten, Ärzte, Rechtsanwälte oder Steuerberater sind von der Pflicht ausgenommen, ein Gewerbe anzumelden. Ebenso Selbständige, die in der Urproduktion arbeiten, also in der Land- und Forstwirtschaft, der Fischerei oder dem Bergbau. Kapitalgesellschaften hingegen werden vom Finanzamt per se immer als Gewerbe eingestuft, ganz unabhängig von der konkreten Tätigkeit. Was zunächst eindeutig klingt, ist bei näherer Betrachtung gar nicht so klar. Die Abgrenzungen verschwimmen häufig, denn nicht nur Künstler und Journalisten können als freiberuflich gelten. Eine freiberufliche Tätigkeit definiert sich nämlich auch durch ihr Tätigkeitsprofil. Sie ist demnach eine selbständig ausgeübte wissenschaftliche, künstlerische, schriftstellerische, unterrichtende oder erzieherische Tätigkeit, die sich durch Professionalität, Gemeinwohlpflicht, Selbstkontrolle und Eigenverantwortlichkeit auszeichnet. In der IT herrscht generell große Unsicherheit. Der Grund: Die Rechtslage ist nicht eindeutig und es gibt viele Einzelfallentscheidungen, die sich von Finanzamt zu Finanzamt unterscheiden. Gemäß der Rechtsprechung des Bundesfinanzhofs (BFH) muss ein IT-Berater das Diplom einer der Katalogberufe besitzen, um als Freiberufler im Tätigkeitsfeld der Informatik anerkannt zu werden: Dies sind Ingenieure oder beratende Betriebswirte. Ohne einen solchen Abschluss muss der IT-Spezialist plausibel nachweisen, dass er die Kenntnisse anderweitig erworben hat. Beim Nachweis ist zu beachten, dass die Tätigkeit möglichst “ingenieurmäßig” sein muss. Das Bundeswirtschaftsministerium schreibt dazu: „Eine freiberufliche Tätigkeit im Sinne von Paragraf 18 Absatz 1 Nr. 1 Satz 2 EstG übt auch aus, wer einem dem Ingenieurberuf ähnlichen Beruf nachgeht. Der ähnliche Beruf muss dem Beruf des Ingenieurs sowohl hinsichtlich der erforderlichen Berufsausbildung als auch hinsichtlich der tatsächlich entfalteten Tätigkeit im Wesentlichen gleichen (ständige Rechtsprechung, vgl. nur BFH-Urteil vom 9. Februar 2006 IV R 27/05, BFH/NV 2006, 1270, m.w.N.).“ Bundesfinanzhof: Urteil vom 22.09.2009 – VIII R 79/06. Ein weiteres Kriterium für eine Freiberuflichkeit im Bereich der IT ist der Arbeitsbereich. Die IHK formuliert dazu: “Von der freiberuflichen Tätigkeit umfasst sind jedoch nur die Beratung und die Anfertigung von Entwürfen oder Gutachten. Die Herstellung, Bearbeitung und der Vertrieb von Sachgütern sind hingegen gewerbliche Tätigkeiten und müssen beim Gewerbeamt angemeldet werden.” Betriebsprüfer nehmen diese Abgrenzungsschwierigkeiten immer häufiger als Anlass für Prüfungen. Ein Beraterwechsel, ein Umzug oder eine Steuererklärung sind Auslöser für Prüfverfahren. Am Ende entscheidet das Finanzamt, sollte es zu einer Betriebsprüfung kommen. Und das kann böse enden, wenn die Finanzbeamten in der Tätigkeit keine Anhaltspunkte für eine Freiberuflichkeit sehen. Dann muss die Gewerbesteuer nachgezahlt werden. Wer also glaubt, eine freiberufliche Tätigkeit auszuüben, muss dies dem Finanzamt belegen, zum Beispiel durch Arbeitsproben. Ein Austausch mit dem Steuerberater oder einem Rechtsanwalt kann hier auch helfen und Sicherheit bringen. Tätigkeitsbeschreibungen sollten Hand und Fuß haben, sich an Formulierungen orientieren und nicht selbst geschrieben werden. Wichtig ist es, sich bereits im Vorfeld zu informieren, wie die Chancen stehen, freiberuflich eingestuft zu werden. Hierbei ist es wichtig zu prüfen, wie die Ausbildungssituation aussieht und welche Tätigkeit auch konkret nachgewiesen werden kann. Tupungato – shutterstock.com Grundsätzlich unterliegen Selbständige, die mit ihrer Unternehmung Gewinne erzielen möchten, der Gewerbeordnung . Es gibt aber Ausnahmen für bestimmte Berufsgruppen und Tätigkeiten. Freiberufler wie Künstler, Journalisten, Ärzte, Rechtsanwälte oder Steuerberater sind von der Pflicht ausgenommen, ein Gewerbe anzumelden. Ebenso Selbständige, die in der Urproduktion arbeiten, also in der Land- und Forstwirtschaft, der Fischerei oder dem Bergbau. Kapitalgesellschaften hingegen werden vom Finanzamt per se immer als Gewerbe eingestuft, ganz unabhängig von der konkreten Tätigkeit. Was zunächst eindeutig klingt, ist bei näherer Betrachtung gar nicht so klar. Die Abgrenzungen verschwimmen häufig, denn nicht nur Künstler und Journalisten können als freiberuflich gelten. Eine freiberufliche Tätigkeit definiert sich nämlich auch durch ihr Tätigkeitsprofil. Sie ist demnach eine selbständig ausgeübte wissenschaftliche, künstlerische, schriftstellerische, unterrichtende oder erzieherische Tätigkeit, die sich durch Professionalität, Gemeinwohlpflicht, Selbstkontrolle und Eigenverantwortlichkeit auszeichnet. In der IT herrscht generell große Unsicherheit. Der Grund: Die Rechtslage ist nicht eindeutig und es gibt viele Einzelfallentscheidungen, die sich von Finanzamt zu Finanzamt unterscheiden. Gemäß der Rechtsprechung des Bundesfinanzhofs (BFH) muss ein IT-Berater das Diplom einer der Katalogberufe besitzen, um als Freiberufler im Tätigkeitsfeld der Informatik anerkannt zu werden: Dies sind Ingenieure oder beratende Betriebswirte. Ohne einen solchen Abschluss muss der IT-Spezialist plausibel nachweisen, dass er die Kenntnisse anderweitig erworben hat. Beim Nachweis ist zu beachten, dass die Tätigkeit möglichst “ingenieurmäßig” sein muss. Das Bundeswirtschaftsministerium schreibt dazu: „Eine freiberufliche Tätigkeit im Sinne von Paragraf 18 Absatz 1 Nr. 1 Satz 2 EstG übt auch aus, wer einem dem Ingenieurberuf ähnlichen Beruf nachgeht. Der ähnliche Beruf muss dem Beruf des Ingenieurs sowohl hinsichtlich der erforderlichen Berufsausbildung als auch hinsichtlich der tatsächlich entfalteten Tätigkeit im Wesentlichen gleichen (ständige Rechtsprechung, vgl. nur BFH-Urteil vom 9. Februar 2006 IV R 27/05, BFH/NV 2006, 1270, m.w.N.).“ Bundesfinanzhof: Urteil vom 22.09.2009 – VIII R 79/06. Ein weiteres Kriterium für eine Freiberuflichkeit im Bereich der IT ist der Arbeitsbereich. Die IHK formuliert dazu: “Von der freiberuflichen Tätigkeit umfasst sind jedoch nur die Beratung und die Anfertigung von Entwürfen oder Gutachten. Die Herstellung, Bearbeitung und der Vertrieb von Sachgütern sind hingegen gewerbliche Tätigkeiten und müssen beim Gewerbeamt angemeldet werden.” Betriebsprüfer nehmen diese Abgrenzungsschwierigkeiten immer häufiger als Anlass für Prüfungen. Ein Beraterwechsel, ein Umzug oder eine Steuererklärung sind Auslöser für Prüfverfahren. Am Ende entscheidet das Finanzamt, sollte es zu einer Betriebsprüfung kommen. Und das kann böse enden, wenn die Finanzbeamten in der Tätigkeit keine Anhaltspunkte für eine Freiberuflichkeit sehen. Dann muss die Gewerbesteuer nachgezahlt werden. Wer also glaubt, eine freiberufliche Tätigkeit auszuüben, muss dies dem Finanzamt belegen, zum Beispiel durch Arbeitsproben. Ein Austausch mit dem Steuerberater oder einem Rechtsanwalt kann hier auch helfen und Sicherheit bringen. Tätigkeitsbeschreibungen sollten Hand und Fuß haben, sich an Formulierungen orientieren und nicht selbst geschrieben werden. Wichtig ist es, sich bereits im Vorfeld zu informieren, wie die Chancen stehen, freiberuflich eingestuft zu werden. Hierbei ist es wichtig zu prüfen, wie die Ausbildungssituation aussieht und welche Tätigkeit auch konkret nachgewiesen werden kann.",
    "source": "cio",
    "crawled_at": "2025-05-27T08:10:57.969111+00:00"
  },
  {
    "url": "https://www.cio.de/article/3683138/agiles-projektmanagement-faq.html",
    "title": "Was Sie über agiles Projektmanagement wissen müssen",
    "published": "2025-05-23T06:56:43+00:00",
    "author": "",
    "text": "Agil durchstarten? Unsere FAQ vermittelt agiles Grundlagenwissen. Foto: Pixel-Shot – shutterstock.com Egal ob Sie Agile -Greenhorn oder -Veteran sind: Die folgenden zehn Fragen und ihre jeweiligen Antworten geben einen Überblick über das grundlegende Wissen zum Thema. So können Sie ja nach Bedarf agil durchstarten oder ihr Wissen auffrischen. Das Wörtchen ‘agile’ entstammt dem relativ weiten Feld des Projektmanagements und bezeichnet eine Methode desselbigen. Hierbei sollen kurze Entwicklungszyklen – auch ‘Sprints’ genannt – die kontinuierliche Verbesserung bei der Entwicklung eines Produkts oder Services gewährleisten. Methoden des stufenweisen Projektmanagements existieren bereits seit 1957. Die erste tiefgehende Diskussion zum Thema Agile wurde in den 1970er Jahren von Winston Royce angestoßen, der damals ein Thesenpapier zur Entwicklung umfassender Software-Systeme veröffentlicht hat. Im Jahr 2001 wurde schließlich das sogenannte ‘ agile manifesto’ veröffentlicht, eine “formelle Proklamation von zwölf Grundprinzipien für einen iterativen Ansatz zur Softwareentwicklung, der den Menschen in den Mittelpunkt stellt”. Veröffentlicht wurde dieser von 17 Developern, die sich zusammengefunden hatten, um auf Grundlage ihrer gemeinsamen Erfahrungen leichtgewichtige Entwicklungsmethoden zu diskutieren. Die ebenfalls hieraus entstandenen zwölf Grundprinzipien bilden bis heute die Basis für agiles Projektmanagement : 1. Kundenzufriedenheit hat stets oberste Priorität. Diese wird durch eine schnelle und fortwährende Auslieferung erreicht. 2. Sich verändernde Rahmenbedingungen werden in jeder Stufe des Entwicklungsprozesses mit einbezogen, um den Kunden mit einem Wettbewerbsvorteil auszustatten. 3. Ein Produkt oder Service wird mit höherer Frequenz ausgeliefert. 4. Stakeholder und Entwickler arbeiten auf täglicher Basis eng zusammen. 5. Alle Stakeholder und Teammitglieder bleiben stets motiviert, um optimale Projektergebnisse zu gewährleisten. Die Teams werden mit allen notwendigen Tools unterstützt. Darüber hinaus genießen sie das Vertrauen, dass die Projektziele erreicht werden. 6. Face-to-Face-Meetings sind die effizienteste und effektivste Form, um den Projekterfolg sicher zu stellen. 7. Ein fertiges, funktionierendes Produkt ist das ultimative Messinstrument für Erfolg. 8. Eine nachhaltige Entwicklung wird durch agile Prozesse gewährleistet, wodurch die Entwicklungsteams und Stakeholder dazu befähigt werden, ein konstantes Tempo zu halten. 9. Die Agilität wird durch einen fortlaufenden Fokus auf technische Exzellenz und angemessenes Design gesteigert. 10. Simplizität ist ein wesentliches Element. 11. Sich selbst organisierende Teams entwickeln mit hoher Wahrscheinlichkeit die besten Architekturen und Designs und werden den Anforderungen am ehesten gerecht. 12. Die Teams überprüfen ihre Arbeit in regelmäßigen Intervallen und verbessern die Effizienz durch Feintuning. Obwohl das Agile-Prinzip originär der Software -Industrie entstammt, haben inzwischen viele Branchen das Agile-Prinzip für die Entwicklung ihrer Produkte und Services übernommen. Warum? In erster Linie wegen der höchst kollaborativen und effizienzsteigernden Wirkung dieser Methode. Auch in den Bereichen Marketing , Bauwesen, Bildung und Finanzwesen wird längst agil gearbeitet. Ursprünglich sollte der Ansatz den Prozess der Softwareentwicklung vereinheitlichen und verbessern, um schneller auf Probleme und/oder Fehler reagieren zu können. Im Gegensatz zum traditionellen “ Wasserfallmodell ” befähigt der agile Ansatz Entwickler und Teams durch iterative und interaktive Sprints ein besseres Produkt abzuliefern. Mit den steigenden Erwartungen der Kunden wird es immer wichtiger Projektmanager zu verpflichten, die die beste Methodik zur Ausführung eines Projekts kennen und auch umsetzen. Nur so kann ein Wettbewerbsvorteil erlangt werden. Die traditionellen – eher schwerfälligen – Methoden des Projektmanagements erfordern in der Regel, dass das komplette Team in jeder Phase des Projekts zu einem Meeting zusammenkommen muss und jedes einzelne Projektziel diskutiert wird. Beim agilen Ansatz setzt man hingegen auf kleinere, fokussiertere Teams, die sich in regelmäßigen Abständen zusammenfinden, um ganz spezifische Ziele in Angriff zu nehmen. Das Resultat: kurzfristige Änderungen lassen sich schneller realisieren. Die Teams sind also agiler, flexibler und effizienter, wodurch sich die Wahrscheinlichkeit erhöht, dass sie die vom Kunden gesteckten Ziele auch erreichen – insbesondere dann, wenn sich dessen Bedürfnisse ändern. Das Agile -Prinzip stattet die Teams mit einem Mechanismus aus, der die schnelle Wiederholung in sich geschlossener Prozesse, die Isolation von Problemen und die Erreichung spezifischer Ziele ermöglicht. Und zwar vor allem schnell. Das ist in der Regel fruchtbarer, als auf das Ende einer unter Umständen langwierigen Projektphase warten zu müssen, nur um dann herauszufinden, welche Ziele verpasst wurden. Agile ist inzwischen extrem populär geworden und hat sich rasant verbreitet. Die Methodik bietet für Projektteams, Projektleiter, Kunden und Stakeholder viele Vorteile . Hier die wichtigsten im Überblick: Schnellere Auslieferung von Lösungen Weniger Ausschuss durch Minimierung von Ressourcen Erhöhte Flexibilität und Anpassungsfähigkeit Erhöhte Erfolgsaussichten durch stärkere Fokussierung Schnellere Reaktionszeiten Schnelleres Identifizieren von Problemen und Fehlern Optimierter Entwicklungsprozess Leichteres, übersichtlicheres Framework Optimale Projektkontrolle Erhöhte Fokussierung auf spezifische Kundenbedürfnisse Mehr Kollaboration und Feedback Natürlich eignet sich der Agile-Ansatz nicht für jedes Projekt gleichermaßen. Warum? Darum: Während des Entwicklungsprozesses fokussiert der Agile-Ansatz Entwickler, Projektteams und Kundenziele – aber nicht notwendigerweise die (End) User Experience. Wegen seiner weniger formellen und flexibleren Prozesse hat es agile unter Umständen in großen, traditionell geprägten Konzernen schwer. Es besteht die Möglichkeit, Hybrid-Lösungen zu erzeugen. Das kann dafür sorgen, dass die Flexibilität weiter erhöht wird und ist im Einzelfall eventuell empfehlenswert. Um herauszufinden, welche Methode(n) am besten geeignet sind, empfiehlt sich Due Diligence . Innerhalb des “Agile-Universums” gibt es etliche populäre Ansätze und Methoden. Hier eine Übersicht – geordnet nach Beliebtheit: Scrum Kanban Lean Dynamic System Development Model Extreme Programming Crystal Adaptive software development Agile Unified Process Crystal Clear methods Disciplined agile delivery Feature-driven development Scrumban Rapid Application Development In einem von zunehmenden Wettbewerb und Geschwindigkeit geprägten Business-Umfeld bietet Agile zahlreiche Vorteile – bei gleichzeitig überschaubaren Nachteilen. Dass die Methodik mittlerweile in zahlreichen Branchen zum Einsatz kommt, spricht für ihre Attraktivität. Agile ist also alles andere als ein vorübergehender Trend – Zukunftssicherheit gewährleistet. Accenture über das agile Unternehmen Foto: Accenture Die Unternehmensberatung Accenture hat eine schematische Darstellung eines agilen Unternehmens erstellt und beschreibt die Auswirkungen auf das IT Operating Model. Neun Charakteristika Foto: Accenture Für Accenture zeichnet sich ein agiles Unternehmen durch neun Charakteristika aus. Die Rolle von Technology Labs Foto: Accenture Accenture rät zum Einführen von Technology Labs. Die IT soll aktiv in die Produktentwicklung einbezogen werden. Sicherheitsmaßnahmen Foto: Accenture Sicherheit will Accenture sowohl Technologie-seitig (Endgeräte) als auch Non-IT-seitig verstanden wissen. Multi-Speed IT Foto: Accenture Multi-Speed IT bezieht sich nicht nur auf agile IT, sondern auch auf Legacys. Unternehmen müssen ihre IT transformieren. Agil durchstarten? Unsere FAQ vermittelt agiles Grundlagenwissen. Foto: Pixel-Shot – shutterstock.com Egal ob Sie Agile -Greenhorn oder -Veteran sind: Die folgenden zehn Fragen und ihre jeweiligen Antworten geben einen Überblick über das grundlegende Wissen zum Thema. So können Sie ja nach Bedarf agil durchstarten oder ihr Wissen auffrischen. Das Wörtchen ‘agile’ entstammt dem relativ weiten Feld des Projektmanagements und bezeichnet eine Methode desselbigen. Hierbei sollen kurze Entwicklungszyklen – auch ‘Sprints’ genannt – die kontinuierliche Verbesserung bei der Entwicklung eines Produkts oder Services gewährleisten. Methoden des stufenweisen Projektmanagements existieren bereits seit 1957. Die erste tiefgehende Diskussion zum Thema Agile wurde in den 1970er Jahren von Winston Royce angestoßen, der damals ein Thesenpapier zur Entwicklung umfassender Software-Systeme veröffentlicht hat. Im Jahr 2001 wurde schließlich das sogenannte ‘ agile manifesto’ veröffentlicht, eine “formelle Proklamation von zwölf Grundprinzipien für einen iterativen Ansatz zur Softwareentwicklung, der den Menschen in den Mittelpunkt stellt”. Veröffentlicht wurde dieser von 17 Developern, die sich zusammengefunden hatten, um auf Grundlage ihrer gemeinsamen Erfahrungen leichtgewichtige Entwicklungsmethoden zu diskutieren. Die ebenfalls hieraus entstandenen zwölf Grundprinzipien bilden bis heute die Basis für agiles Projektmanagement : 1. Kundenzufriedenheit hat stets oberste Priorität. Diese wird durch eine schnelle und fortwährende Auslieferung erreicht. 2. Sich verändernde Rahmenbedingungen werden in jeder Stufe des Entwicklungsprozesses mit einbezogen, um den Kunden mit einem Wettbewerbsvorteil auszustatten. 3. Ein Produkt oder Service wird mit höherer Frequenz ausgeliefert. 4. Stakeholder und Entwickler arbeiten auf täglicher Basis eng zusammen. 5. Alle Stakeholder und Teammitglieder bleiben stets motiviert, um optimale Projektergebnisse zu gewährleisten. Die Teams werden mit allen notwendigen Tools unterstützt. Darüber hinaus genießen sie das Vertrauen, dass die Projektziele erreicht werden. 6. Face-to-Face-Meetings sind die effizienteste und effektivste Form, um den Projekterfolg sicher zu stellen. 7. Ein fertiges, funktionierendes Produkt ist das ultimative Messinstrument für Erfolg. 8. Eine nachhaltige Entwicklung wird durch agile Prozesse gewährleistet, wodurch die Entwicklungsteams und Stakeholder dazu befähigt werden, ein konstantes Tempo zu halten. 9. Die Agilität wird durch einen fortlaufenden Fokus auf technische Exzellenz und angemessenes Design gesteigert. 10. Simplizität ist ein wesentliches Element. 11. Sich selbst organisierende Teams entwickeln mit hoher Wahrscheinlichkeit die besten Architekturen und Designs und werden den Anforderungen am ehesten gerecht. 12. Die Teams überprüfen ihre Arbeit in regelmäßigen Intervallen und verbessern die Effizienz durch Feintuning. Obwohl das Agile-Prinzip originär der Software -Industrie entstammt, haben inzwischen viele Branchen das Agile-Prinzip für die Entwicklung ihrer Produkte und Services übernommen. Warum? In erster Linie wegen der höchst kollaborativen und effizienzsteigernden Wirkung dieser Methode. Auch in den Bereichen Marketing , Bauwesen, Bildung und Finanzwesen wird längst agil gearbeitet. Ursprünglich sollte der Ansatz den Prozess der Softwareentwicklung vereinheitlichen und verbessern, um schneller auf Probleme und/oder Fehler reagieren zu können. Im Gegensatz zum traditionellen “ Wasserfallmodell ” befähigt der agile Ansatz Entwickler und Teams durch iterative und interaktive Sprints ein besseres Produkt abzuliefern. Mit den steigenden Erwartungen der Kunden wird es immer wichtiger Projektmanager zu verpflichten, die die beste Methodik zur Ausführung eines Projekts kennen und auch umsetzen. Nur so kann ein Wettbewerbsvorteil erlangt werden. Die traditionellen – eher schwerfälligen – Methoden des Projektmanagements erfordern in der Regel, dass das komplette Team in jeder Phase des Projekts zu einem Meeting zusammenkommen muss und jedes einzelne Projektziel diskutiert wird. Beim agilen Ansatz setzt man hingegen auf kleinere, fokussiertere Teams, die sich in regelmäßigen Abständen zusammenfinden, um ganz spezifische Ziele in Angriff zu nehmen. Das Resultat: kurzfristige Änderungen lassen sich schneller realisieren. Die Teams sind also agiler, flexibler und effizienter, wodurch sich die Wahrscheinlichkeit erhöht, dass sie die vom Kunden gesteckten Ziele auch erreichen – insbesondere dann, wenn sich dessen Bedürfnisse ändern. Das Agile -Prinzip stattet die Teams mit einem Mechanismus aus, der die schnelle Wiederholung in sich geschlossener Prozesse, die Isolation von Problemen und die Erreichung spezifischer Ziele ermöglicht. Und zwar vor allem schnell. Das ist in der Regel fruchtbarer, als auf das Ende einer unter Umständen langwierigen Projektphase warten zu müssen, nur um dann herauszufinden, welche Ziele verpasst wurden. Agile ist inzwischen extrem populär geworden und hat sich rasant verbreitet. Die Methodik bietet für Projektteams, Projektleiter, Kunden und Stakeholder viele Vorteile . Hier die wichtigsten im Überblick: Schnellere Auslieferung von Lösungen Weniger Ausschuss durch Minimierung von Ressourcen Erhöhte Flexibilität und Anpassungsfähigkeit Erhöhte Erfolgsaussichten durch stärkere Fokussierung Schnellere Reaktionszeiten Schnelleres Identifizieren von Problemen und Fehlern Optimierter Entwicklungsprozess Leichteres, übersichtlicheres Framework Optimale Projektkontrolle Erhöhte Fokussierung auf spezifische Kundenbedürfnisse Mehr Kollaboration und Feedback Natürlich eignet sich der Agile-Ansatz nicht für jedes Projekt gleichermaßen. Warum? Darum: Während des Entwicklungsprozesses fokussiert der Agile-Ansatz Entwickler, Projektteams und Kundenziele – aber nicht notwendigerweise die (End) User Experience. Wegen seiner weniger formellen und flexibleren Prozesse hat es agile unter Umständen in großen, traditionell geprägten Konzernen schwer. Es besteht die Möglichkeit, Hybrid-Lösungen zu erzeugen. Das kann dafür sorgen, dass die Flexibilität weiter erhöht wird und ist im Einzelfall eventuell empfehlenswert. Um herauszufinden, welche Methode(n) am besten geeignet sind, empfiehlt sich Due Diligence . Innerhalb des “Agile-Universums” gibt es etliche populäre Ansätze und Methoden. Hier eine Übersicht – geordnet nach Beliebtheit: Scrum Kanban Lean Dynamic System Development Model Extreme Programming Crystal Adaptive software development Agile Unified Process Crystal Clear methods Disciplined agile delivery Feature-driven development Scrumban Rapid Application Development In einem von zunehmenden Wettbewerb und Geschwindigkeit geprägten Business-Umfeld bietet Agile zahlreiche Vorteile – bei gleichzeitig überschaubaren Nachteilen. Dass die Methodik mittlerweile in zahlreichen Branchen zum Einsatz kommt, spricht für ihre Attraktivität. Agile ist also alles andere als ein vorübergehender Trend – Zukunftssicherheit gewährleistet. Accenture über das agile Unternehmen Foto: Accenture Die Unternehmensberatung Accenture hat eine schematische Darstellung eines agilen Unternehmens erstellt und beschreibt die Auswirkungen auf das IT Operating Model. Neun Charakteristika Foto: Accenture Für Accenture zeichnet sich ein agiles Unternehmen durch neun Charakteristika aus. Die Rolle von Technology Labs Foto: Accenture Accenture rät zum Einführen von Technology Labs. Die IT soll aktiv in die Produktentwicklung einbezogen werden. Sicherheitsmaßnahmen Foto: Accenture Sicherheit will Accenture sowohl Technologie-seitig (Endgeräte) als auch Non-IT-seitig verstanden wissen. Multi-Speed IT Foto: Accenture Multi-Speed IT bezieht sich nicht nur auf agile IT, sondern auch auf Legacys. Unternehmen müssen ihre IT transformieren.",
    "source": "cio",
    "crawled_at": "2025-05-27T08:10:58.055105+00:00"
  },
  {
    "url": "https://www.cio.de/article/3684673/die-cios-der-dax-40-konzerne.html",
    "title": "Die CIOs der DAX-40-Konzerne",
    "published": "2025-05-25T10:51:53+00:00",
    "author": "",
    "text": "Andreas Hubert Foto: Adidas Andreas Hubert ist seit Februar 2021 Group CIO von Adidas. Catherine Jestin ist CIO und Executive VP Digital und Information Management bei Airbus. Foto: Airbus Seit März 2020 hat Catherine Jestin den CIO-Posten bei Airbus SE inne. Im Juli 2021 wurde sie zudem zum Executive Vice President Digital and Information Management berufen. Olav Spiegel ist CIO der Allianz SE. Foto: Allianz Seit 1. November 2023 hat der Versicherungskonzern Allianz mit Olav Spiegel einen neuen Group Chief Information Officer an Bord. Er folgt auf Ralf Schneider. mehr erfahren BASF hat keinen CIO mehr. Foto: 360b – shutterstock.com Nachdem Stefan Beck zum SVP Digitalization of Workspace and Collaboration aufgestiegen ist wird BASF die Rolle des Chief Information Officer (CIO) nicht weiter beibehalten. Bijoy Sagar ist CIO der Bayer AG. Foto: Bayer AG Bijoy Sagar ist seit 1. Juni 2020 Leiter IT und Digitale Transformation bei Bayer . Er soll die Digitalisierung des Pharmakonzerns vorantreiben und die begonnene Neuaufstellung der IT ans Ziel führen. Sagar wird an den Finanzvorstand Wolfgang Nickl berichten. Annette Hamann ist CIO von Baiersdorf. Foto: Beiersdorf Annette Hamann ist CIO und Managing Director BSS IT bei der Hamburger Beiersdorf AG . Alexander Buresch ist CIO der BMW Group. Foto: BMW AG Der Nachfolger von Klaus Straub im Amt des CIO der BMW Group heißt Alexander Buresch. Der Wirtschaftswissenschaftler ist seit mehr als 20 Jahren für tätig und war zuletzt Vice President Corporate Strategy and Planning. Intern wird erwartet, dass Buresch die von Klaus Straub verfolgte IT-Strategie fortführt. Stefan Haverkock ist CIO bei Brenntag. Foto: Brenntag Stefan Haverkock ist seit Januar 2019 VP IT Corporate & EMEA beim Chemiedistributor Brenntag. Er wechselte 2016 in das Unternehmen, nachdem er sieben Jahre bei Baustoffhersteller Knauf in verschiedenen leitenden IT-Positionen gearbeitet hatte. Haverkock berichtet an den CEO des Unternehmens. Heiko Burdack ist CTO der Commerzbank. Foto: Heiko Burdack Der CIO der Signal Iduna Gruppe, Heiko Burdack, wechselte zum 1. Februar 2023 als Chief Technology Officer zur Commerzbank. mehr erfahren Walter Grüner ist CIO bei Covestro. Foto: Covestro Walter Grüner ist seit Mai 2019 Head of Information Technology beim Chemieunternehmen Covestro in Leverkusen. Er berichtet direkt an den CFO Thomas Toepfer. Zuvor war Grüner seit 2013 als Group CIO bei der Kion Group AG tätig. Beim Frankfurter Anbieter von Gabelstapler und Lagertechnik hat er die Globalisierung der IT und die Digitalisierung vorangetrieben. Daimler Truck AG Mit Wirkung zum 1. Juni 2025 übernimmt Raghavendra Vaidya die Position des Chief Information Officer bei Daimler Truck. Er tritt die Nachfolge von Marcus Claesson an, der das Unternehmen auf eigenen Wunsch verlässt. mehr erfahren Bernd Leukert ist seit 2020 im Vorstand der Deutschen Bank. Foto: Mario Andreya Bernd Leukert wurde am 1. Januar 2020 Vorstand für Technologie, Daten und Innovation der Deutschen Bank . Von 2014 bis 2019 war Leukert Technikvorstand bei SAP , wo er 1994 seine Karriere begann. Christoph Böhm ist CIO der Deutschen Börse. Foto: COMPUTERWOCHE/Foto Vogt CIO und COO der Deutsche Börse AG ist seit November 2018 Christoph Böhm . Er wechselt von der SAP AG, wo er als Senior Vice President, Global Cloud Services, arbeitet. Der promovierte Elektroingenieur Böhm war von April 2011 bis Oktober 2014 CIO bei Vodafone. Er kam damals als CEO von der Active Billing GmbH & Co. KG, einer Tochtergesellschaft der Deutschen Telekom. Davor arbeitete er in führenden Positionen bei der Signal Iduna-Gruppe, der Deutschen Post AG und AT&T. Vorgänger Andreas Preuß geht voraussichtlich im Mai 2019 in den Ruhestand. Bernd Gemein ist CIO im Bereich PeP der Deutschen Post. Foto: Deutsche Post Seit September 2018 ist Bernd Gemein CIO für den Unternehmensbereich Post, E-Commerce, Parcel (PeP) bei der Deutschen Post DHL. Gemein berichtet an PeP-COO Tobias Meyer. Zu seinen wichtigsten anstehenden Aufgaben sagte Gemein, derzeit sei vor allem wichtig, eine positive Ergebnisentwicklung in den Jahren 2019 und 2020 sicherzustellen. Dazu gehöre die weitere Verbesserung der Produktivität und der indirekten Kosten sowie des Ertragsmanagements im Post- und Paketgeschäft. Peter Leukert ist CIO der Deutschen Telekom. Foto: Deutsche Telekom Sprecher der Geschäftsführung der Deutsche Telekom IT GmbH und damit CIO ist seit Januar 2017 Peter Leukert. Er wechselt von Motive Partners – einem Fintech Start-up, das er selbst mit gegründet hat. Zuvor war Leukert CIO der Commerzbank und von NYSE Euronext. 2011 wurde er zum “CIO des Jahres” gewählt. Zum 1. September 2025 wechselt Leukert als Chief Digital Officer zu BT. Sebastian Weber ist CTO von Eon. Foto: Eon Seit 1. Juli 2021 verantwortet Sebastian Weber als CTO bei Eon den IT-Betrieb. Er soll auch die digitalen Plattformen des Konzerns ausbauen. Zudem hat er gemeinsam mit Christopher d’Arcy in einer Doppelspitze die Geschäftsführung der IT-Tochter Eon Digital Technology GmbH übernommen. Beide berichten direkt an Digitalvorständin Victoria Ossadnik. Ingo Elfering ist CIO der Fresenius Gruppe. Foto: Fresenius Seit Juli 2020 besetzt Ingo Elfering den neu geschaffenen CIO-Posten bei der Fresenius Gruppe . Der gelernte Wirtschaftsinformatiker soll die globalen IT-Aktivitäten des Konzerns koordinieren und weiterentwickeln. Zudem übernimmt er die Leitung der IT-Dienstleistungstochter Fresenius Digital Technology. Elfering berichtet an Finanzvorstand Rachel Empey. Jürgen Stoffel ist CIO der Hannover Rück. Foto: Hannover Rück SE Hannover Rück: Jürgen Stoffel ist CIO beim weltweit drittgrößten Rückversicherer. Der bisherige CIO Fuchs ging 2014 in den Ruhestand. mehr erfahren Dennis Lentz ist CIO bei HeidelbergCement. Foto: HeidelbergCement Bereits seit Januar 2017 ist Dennis Lentz neuer Director Group IT/CIO beim Baustoffkonzern HeidelbergCement AG. Zuvor war er unter anderem Project Leader bei der Unternehmensberatung Boston Consulting und Project Leader und Leiter Supply Chain Management in Deutschland bei der HeidelbergCement AG. Michael Nilles ist CDIO von Henkel. Foto: Henkel Henkel hat Michael Nilles am 1. Oktober 2019 zum Chief Digital and Information Officer (CDIO) ernannt. Er berichtet direkt an Carsten Knobel, CEO von Henkel. In seiner Position ist Nilles für die Bereiche Digital, IT, Geschäftsprozessmanagement und Corporate Venture Capital verantwortlich. Harsha Deshmukh ist CIO bei Infineon. Foto: Infineon Technologies AG Seit dem Dezember 2021 ist Harsha Deshmukh CIO bei Infineon . Der IT-Chef kommt aus den eigenen Reihen. Er soll unter anderem die IT-Landschaft weiterentwickeln und die Kundenansprache verbessern. mehr erfahren Katrin Lehmann ist Group CIO bei Mercedes-Benz. Foto: Mercedes-Benz Als CIO der Mercedes-Benz Group AG und der Mercedes-Benz AG verantwortet Katrin Lehmann die globale IT für alle Geschäftsbereiche, Marken und Märkte und berichtet direkt an den CEO. mehr erfahren Merck Healthcare-CIO Alessandro de Luca. Foto: Hasan Baran Özkan Merck besetzt Anfang Dezember 2021 im Senior Leadership Team vier Positionen neu. Dazu zählt auch die Beförderung von Alessandro de Luca. Der bisherige CIO Healthcare hatte interimsmäßig als Group CIO gearbeitet und wird diese Funktion dauerhaft übernehmen. Gleichzeitig ist de Luca Leiter Information Technology. Er berichtet an Marcus Kuhnert, der als Chief Financial Officer (CFO) in der Geschäftsleitung sitzt. Lutz Seidenfaden ist CIO bei MTU Aero Engines Foto: Lutz Seidenfaden Lutz Seidenfaden ist seit Juni 2020 CIO (SVP Information Technology) beim Münchner Treibwerk-Hersteller MTU Aero Engines. Seidenfaden kommt von Industrieunternehmen Festo, wo er zuletzt die Stelle des Head of IT Services besetzte. Seine Vorgängerin Pamela Herget-Wehlitz wechselte zur Personalberatung JBH-Herget als Managing Partner. Robin Johnson ist CIO bei Munich Re. Foto: Maersk Robin Johnson ist seit April 2017 CIO beim Münchener Rückversicherer Munich Re . Er übernahm damit als Nachfolger von Rainer Janßen die Leitung des Zentralbereichs Information Technology. Zuvor arbeitete Johnson als CIO bei Maersk Line und Head of Maersk Group Infrastructure Services in Kopenhagen. Vor seinem Wechsel zu Maersk arbeitete Johnson von 2008 bis 2012 als Global CIO beim US-Computerhersteller Dell in Austin, Texas. Mattias Ulbrich ist CIO von Porsche. Foto: Porsche Mattias Ulbrich hat seit 1. September 2018 den CIO-Posten beim Automobilbauer Porsche inne. Seit 2019 ist er zudem Geschäftsführer der IT-Tochter Porsche Digital. Davor hatte der Manager verschiedene leitende IT-Positionen bei Audi, Volkswagen und Seat inne. Johannes Lattwein ist im Vorstand der Porsche Automobil Holding SE für IT zuständig. Foto: Porsche Automobil Holding SE Johannes Lattwein ist seit Februar 2022 Mitglied des Vorstands der Porsche Automobil Holding SE und zuständig für Finanzen und IT. Stephan Hützen ist CIO von Qiagen. Foto: Qiagen Stephan Hützen ist Vice President Global IT bei Qiagen. Das Unternehmen bietet Probenvorbereitungs- und Testtechnologien für die molekulare Diagnostik, akademische Forschung, pharmazeutische Industrie und angewandte Testverfahren an. Christian Niederhagemann ist CIO bei Rheinmetall. Foto: Gea Group Die Geschäfte der Rheinmetall IT Solutions GmbH werden seit September 2024 durch Christian Niederhagemann (CIO) geführt. Florian Roth ist Chief Digital und Information Officer bei SAP. Foto: SAP Florian Roth ist seit Januar 2019 Chief Digital und Information Officer der SAP SE in Walldorf und berichtet direkt an Sabine Bendiek, Chief People & Operating Officer und Mitglied des SAP Vorstandes. In seiner Funktion als Chief Digital und Information Officer (CDIO) vertritt er die Intelligent Enterprise Solutions (IES) Organisation als Trusted Advisor und ist verantwortlich für die IT-Strategie und deren Umsetzung. Roth ist seit 2005 bei SAP tätig und hatte vor seiner jetzigen Funktion verschiedene Führungspositionen in den Bereichen Finanzen, Service und Support sowie Global Business Operations inne. Torsten Müller ist CIO von Sartorius. Foto: Torsten Müller Seit November 2018 ist Torsten Müller Head of Information Technology (CIO) beim Pharma- und Laborzulieferer Sartorius AG mit Sitz in Göttingen. Zuvor war er Chief Digital Officer und Chief Information Officer sowie Mitglied der Geschäftsleitung der Versicherung Helvetia Deutschland in Frankfurt. Hanna Hennig ist CIO von Siemens. Foto: Siemens AG Hanna Hennig ist seit Januar 2020 CIO der Siemens AG . Sie kommt von Osram. Beim Lichtkonzern war Sie seit Juli 2018 CIO. Davor arbeitete Sie bei E.ON. Dort war sie seit Dezember 2013 als Geschäftsführerin der E.ON Business Services GmbH in München für die weltweite Versorgung von IT-Dienstleistungen der E.ON und Uniper Gruppe verantwortlich. Kian Mossanen ist CIO von Siemens Energy. Foto: Frank Erpinar Siemens Energy : Kian Mossanen hat 2020 die IT-Leitung der neuen Energie-Tochter des Siemens-Konzerns übernommen. mehr erfahren Siemens-Healthineers-CIO Stefan Henkel Foto: Foto Vogt Stefan Henkel ist seit 2016 Head of IT von Siemens Healthineers. Der Manager ist bereits seit 1996 im Siemens-Konzern tätig und hatte zuvor diverse IT-Führungspositionen bei Siemens und Siemens Healthcare inne. Stefan Tittel ist CIO von Symrise. Foto: Symrise Stefan Tittel ist seit 2018 CIO und Corporate Vice President Group IT von Kosmetikhersteller Symrise. Davor hatte er die CIO-Posten beim dänischen Elektronikhersteller NKT und dem Logistikunternehmen CWS inne. Hauke Stars ist CIO im Volkswagen-Konzern. Foto: Volkswagen AG Im Konzernvorstand von Volkswagen hat Hauke Stars im Februar 2022 das Ressort IT und Organisation übernommen. mehr erfahren Karsten Rech ist CIO von Vonovia. Foto: Vonovia Karsten Rech ist seit 2015 CIO und Process Office des Wohnungskonzerns Vonovia SE . Seit 2005 war er CIO der Deutsche Annington. Rech sammelte Erfahrung als Geschäftsführer und Aufsichtsrat diverser Tochtergesellschaften. Seine Schwerpunkte liegen im IT-Management, der Geschäftsprozessoptimierung und der Post Merger Integration. Meg Greenhouse verantwortet die IT-Infrastruktur bei Zalando. Foto: Zalando SE Meg Greenhouse ist SVP Zalando Technology Foundation und verantwortet die IT-Infrastruktur des Unternehmens. Dazu gehören unter anderem die Digital Workplace-Lösungen zur Verbesserung des Arbeitsalltages, Finanzlösungen, zentrale Datenplattformen und die Informationssicherheit aller virtuellen Vermögenswerte von Zalando. Meg Greenhouse startete im September 2017 als VP Corporate Technology bei Zalando. Andreas Hubert Foto: Adidas Andreas Hubert ist seit Februar 2021 Group CIO von Adidas. Catherine Jestin ist CIO und Executive VP Digital und Information Management bei Airbus. Foto: Airbus Seit März 2020 hat Catherine Jestin den CIO-Posten bei Airbus SE inne. Im Juli 2021 wurde sie zudem zum Executive Vice President Digital and Information Management berufen. Olav Spiegel ist CIO der Allianz SE. Foto: Allianz Seit 1. November 2023 hat der Versicherungskonzern Allianz mit Olav Spiegel einen neuen Group Chief Information Officer an Bord. Er folgt auf Ralf Schneider. mehr erfahren BASF hat keinen CIO mehr. Foto: 360b – shutterstock.com Nachdem Stefan Beck zum SVP Digitalization of Workspace and Collaboration aufgestiegen ist wird BASF die Rolle des Chief Information Officer (CIO) nicht weiter beibehalten. Bijoy Sagar ist CIO der Bayer AG. Foto: Bayer AG Bijoy Sagar ist seit 1. Juni 2020 Leiter IT und Digitale Transformation bei Bayer . Er soll die Digitalisierung des Pharmakonzerns vorantreiben und die begonnene Neuaufstellung der IT ans Ziel führen. Sagar wird an den Finanzvorstand Wolfgang Nickl berichten. Annette Hamann ist CIO von Baiersdorf. Foto: Beiersdorf Annette Hamann ist CIO und Managing Director BSS IT bei der Hamburger Beiersdorf AG . Alexander Buresch ist CIO der BMW Group. Foto: BMW AG Der Nachfolger von Klaus Straub im Amt des CIO der BMW Group heißt Alexander Buresch. Der Wirtschaftswissenschaftler ist seit mehr als 20 Jahren für tätig und war zuletzt Vice President Corporate Strategy and Planning. Intern wird erwartet, dass Buresch die von Klaus Straub verfolgte IT-Strategie fortführt. Stefan Haverkock ist CIO bei Brenntag. Foto: Brenntag Stefan Haverkock ist seit Januar 2019 VP IT Corporate & EMEA beim Chemiedistributor Brenntag. Er wechselte 2016 in das Unternehmen, nachdem er sieben Jahre bei Baustoffhersteller Knauf in verschiedenen leitenden IT-Positionen gearbeitet hatte. Haverkock berichtet an den CEO des Unternehmens. Heiko Burdack ist CTO der Commerzbank. Foto: Heiko Burdack Der CIO der Signal Iduna Gruppe, Heiko Burdack, wechselte zum 1. Februar 2023 als Chief Technology Officer zur Commerzbank. mehr erfahren Walter Grüner ist CIO bei Covestro. Foto: Covestro Walter Grüner ist seit Mai 2019 Head of Information Technology beim Chemieunternehmen Covestro in Leverkusen. Er berichtet direkt an den CFO Thomas Toepfer. Zuvor war Grüner seit 2013 als Group CIO bei der Kion Group AG tätig. Beim Frankfurter Anbieter von Gabelstapler und Lagertechnik hat er die Globalisierung der IT und die Digitalisierung vorangetrieben. Daimler Truck AG Mit Wirkung zum 1. Juni 2025 übernimmt Raghavendra Vaidya die Position des Chief Information Officer bei Daimler Truck. Er tritt die Nachfolge von Marcus Claesson an, der das Unternehmen auf eigenen Wunsch verlässt. mehr erfahren Bernd Leukert ist seit 2020 im Vorstand der Deutschen Bank. Foto: Mario Andreya Bernd Leukert wurde am 1. Januar 2020 Vorstand für Technologie, Daten und Innovation der Deutschen Bank . Von 2014 bis 2019 war Leukert Technikvorstand bei SAP , wo er 1994 seine Karriere begann. Christoph Böhm ist CIO der Deutschen Börse. Foto: COMPUTERWOCHE/Foto Vogt CIO und COO der Deutsche Börse AG ist seit November 2018 Christoph Böhm . Er wechselt von der SAP AG, wo er als Senior Vice President, Global Cloud Services, arbeitet. Der promovierte Elektroingenieur Böhm war von April 2011 bis Oktober 2014 CIO bei Vodafone. Er kam damals als CEO von der Active Billing GmbH & Co. KG, einer Tochtergesellschaft der Deutschen Telekom. Davor arbeitete er in führenden Positionen bei der Signal Iduna-Gruppe, der Deutschen Post AG und AT&T. Vorgänger Andreas Preuß geht voraussichtlich im Mai 2019 in den Ruhestand. Bernd Gemein ist CIO im Bereich PeP der Deutschen Post. Foto: Deutsche Post Seit September 2018 ist Bernd Gemein CIO für den Unternehmensbereich Post, E-Commerce, Parcel (PeP) bei der Deutschen Post DHL. Gemein berichtet an PeP-COO Tobias Meyer. Zu seinen wichtigsten anstehenden Aufgaben sagte Gemein, derzeit sei vor allem wichtig, eine positive Ergebnisentwicklung in den Jahren 2019 und 2020 sicherzustellen. Dazu gehöre die weitere Verbesserung der Produktivität und der indirekten Kosten sowie des Ertragsmanagements im Post- und Paketgeschäft. Peter Leukert ist CIO der Deutschen Telekom. Foto: Deutsche Telekom Sprecher der Geschäftsführung der Deutsche Telekom IT GmbH und damit CIO ist seit Januar 2017 Peter Leukert. Er wechselt von Motive Partners – einem Fintech Start-up, das er selbst mit gegründet hat. Zuvor war Leukert CIO der Commerzbank und von NYSE Euronext. 2011 wurde er zum “CIO des Jahres” gewählt. Zum 1. September 2025 wechselt Leukert als Chief Digital Officer zu BT. Sebastian Weber ist CTO von Eon. Foto: Eon Seit 1. Juli 2021 verantwortet Sebastian Weber als CTO bei Eon den IT-Betrieb. Er soll auch die digitalen Plattformen des Konzerns ausbauen. Zudem hat er gemeinsam mit Christopher d’Arcy in einer Doppelspitze die Geschäftsführung der IT-Tochter Eon Digital Technology GmbH übernommen. Beide berichten direkt an Digitalvorständin Victoria Ossadnik. Ingo Elfering ist CIO der Fresenius Gruppe. Foto: Fresenius Seit Juli 2020 besetzt Ingo Elfering den neu geschaffenen CIO-Posten bei der Fresenius Gruppe . Der gelernte Wirtschaftsinformatiker soll die globalen IT-Aktivitäten des Konzerns koordinieren und weiterentwickeln. Zudem übernimmt er die Leitung der IT-Dienstleistungstochter Fresenius Digital Technology. Elfering berichtet an Finanzvorstand Rachel Empey. Jürgen Stoffel ist CIO der Hannover Rück. Foto: Hannover Rück SE Hannover Rück: Jürgen Stoffel ist CIO beim weltweit drittgrößten Rückversicherer. Der bisherige CIO Fuchs ging 2014 in den Ruhestand. mehr erfahren Dennis Lentz ist CIO bei HeidelbergCement. Foto: HeidelbergCement Bereits seit Januar 2017 ist Dennis Lentz neuer Director Group IT/CIO beim Baustoffkonzern HeidelbergCement AG. Zuvor war er unter anderem Project Leader bei der Unternehmensberatung Boston Consulting und Project Leader und Leiter Supply Chain Management in Deutschland bei der HeidelbergCement AG. Michael Nilles ist CDIO von Henkel. Foto: Henkel Henkel hat Michael Nilles am 1. Oktober 2019 zum Chief Digital and Information Officer (CDIO) ernannt. Er berichtet direkt an Carsten Knobel, CEO von Henkel. In seiner Position ist Nilles für die Bereiche Digital, IT, Geschäftsprozessmanagement und Corporate Venture Capital verantwortlich. Harsha Deshmukh ist CIO bei Infineon. Foto: Infineon Technologies AG Seit dem Dezember 2021 ist Harsha Deshmukh CIO bei Infineon . Der IT-Chef kommt aus den eigenen Reihen. Er soll unter anderem die IT-Landschaft weiterentwickeln und die Kundenansprache verbessern. mehr erfahren Katrin Lehmann ist Group CIO bei Mercedes-Benz. Foto: Mercedes-Benz Als CIO der Mercedes-Benz Group AG und der Mercedes-Benz AG verantwortet Katrin Lehmann die globale IT für alle Geschäftsbereiche, Marken und Märkte und berichtet direkt an den CEO. mehr erfahren Merck Healthcare-CIO Alessandro de Luca. Foto: Hasan Baran Özkan Merck besetzt Anfang Dezember 2021 im Senior Leadership Team vier Positionen neu. Dazu zählt auch die Beförderung von Alessandro de Luca. Der bisherige CIO Healthcare hatte interimsmäßig als Group CIO gearbeitet und wird diese Funktion dauerhaft übernehmen. Gleichzeitig ist de Luca Leiter Information Technology. Er berichtet an Marcus Kuhnert, der als Chief Financial Officer (CFO) in der Geschäftsleitung sitzt. Lutz Seidenfaden ist CIO bei MTU Aero Engines Foto: Lutz Seidenfaden Lutz Seidenfaden ist seit Juni 2020 CIO (SVP Information Technology) beim Münchner Treibwerk-Hersteller MTU Aero Engines. Seidenfaden kommt von Industrieunternehmen Festo, wo er zuletzt die Stelle des Head of IT Services besetzte. Seine Vorgängerin Pamela Herget-Wehlitz wechselte zur Personalberatung JBH-Herget als Managing Partner. Robin Johnson ist CIO bei Munich Re. Foto: Maersk Robin Johnson ist seit April 2017 CIO beim Münchener Rückversicherer Munich Re . Er übernahm damit als Nachfolger von Rainer Janßen die Leitung des Zentralbereichs Information Technology. Zuvor arbeitete Johnson als CIO bei Maersk Line und Head of Maersk Group Infrastructure Services in Kopenhagen. Vor seinem Wechsel zu Maersk arbeitete Johnson von 2008 bis 2012 als Global CIO beim US-Computerhersteller Dell in Austin, Texas. Mattias Ulbrich ist CIO von Porsche. Foto: Porsche Mattias Ulbrich hat seit 1. September 2018 den CIO-Posten beim Automobilbauer Porsche inne. Seit 2019 ist er zudem Geschäftsführer der IT-Tochter Porsche Digital. Davor hatte der Manager verschiedene leitende IT-Positionen bei Audi, Volkswagen und Seat inne. Johannes Lattwein ist im Vorstand der Porsche Automobil Holding SE für IT zuständig. Foto: Porsche Automobil Holding SE Johannes Lattwein ist seit Februar 2022 Mitglied des Vorstands der Porsche Automobil Holding SE und zuständig für Finanzen und IT. Stephan Hützen ist CIO von Qiagen. Foto: Qiagen Stephan Hützen ist Vice President Global IT bei Qiagen. Das Unternehmen bietet Probenvorbereitungs- und Testtechnologien für die molekulare Diagnostik, akademische Forschung, pharmazeutische Industrie und angewandte Testverfahren an. Christian Niederhagemann ist CIO bei Rheinmetall. Foto: Gea Group Die Geschäfte der Rheinmetall IT Solutions GmbH werden seit September 2024 durch Christian Niederhagemann (CIO) geführt. Florian Roth ist Chief Digital und Information Officer bei SAP. Foto: SAP Florian Roth ist seit Januar 2019 Chief Digital und Information Officer der SAP SE in Walldorf und berichtet direkt an Sabine Bendiek, Chief People & Operating Officer und Mitglied des SAP Vorstandes. In seiner Funktion als Chief Digital und Information Officer (CDIO) vertritt er die Intelligent Enterprise Solutions (IES) Organisation als Trusted Advisor und ist verantwortlich für die IT-Strategie und deren Umsetzung. Roth ist seit 2005 bei SAP tätig und hatte vor seiner jetzigen Funktion verschiedene Führungspositionen in den Bereichen Finanzen, Service und Support sowie Global Business Operations inne. Torsten Müller ist CIO von Sartorius. Foto: Torsten Müller Seit November 2018 ist Torsten Müller Head of Information Technology (CIO) beim Pharma- und Laborzulieferer Sartorius AG mit Sitz in Göttingen. Zuvor war er Chief Digital Officer und Chief Information Officer sowie Mitglied der Geschäftsleitung der Versicherung Helvetia Deutschland in Frankfurt. Hanna Hennig ist CIO von Siemens. Foto: Siemens AG Hanna Hennig ist seit Januar 2020 CIO der Siemens AG . Sie kommt von Osram. Beim Lichtkonzern war Sie seit Juli 2018 CIO. Davor arbeitete Sie bei E.ON. Dort war sie seit Dezember 2013 als Geschäftsführerin der E.ON Business Services GmbH in München für die weltweite Versorgung von IT-Dienstleistungen der E.ON und Uniper Gruppe verantwortlich. Kian Mossanen ist CIO von Siemens Energy. Foto: Frank Erpinar Siemens Energy : Kian Mossanen hat 2020 die IT-Leitung der neuen Energie-Tochter des Siemens-Konzerns übernommen. mehr erfahren Siemens-Healthineers-CIO Stefan Henkel Foto: Foto Vogt Stefan Henkel ist seit 2016 Head of IT von Siemens Healthineers. Der Manager ist bereits seit 1996 im Siemens-Konzern tätig und hatte zuvor diverse IT-Führungspositionen bei Siemens und Siemens Healthcare inne. Stefan Tittel ist CIO von Symrise. Foto: Symrise Stefan Tittel ist seit 2018 CIO und Corporate Vice President Group IT von Kosmetikhersteller Symrise. Davor hatte er die CIO-Posten beim dänischen Elektronikhersteller NKT und dem Logistikunternehmen CWS inne. Hauke Stars ist CIO im Volkswagen-Konzern. Foto: Volkswagen AG Im Konzernvorstand von Volkswagen hat Hauke Stars im Februar 2022 das Ressort IT und Organisation übernommen. mehr erfahren Karsten Rech ist CIO von Vonovia. Foto: Vonovia Karsten Rech ist seit 2015 CIO und Process Office des Wohnungskonzerns Vonovia SE . Seit 2005 war er CIO der Deutsche Annington. Rech sammelte Erfahrung als Geschäftsführer und Aufsichtsrat diverser Tochtergesellschaften. Seine Schwerpunkte liegen im IT-Management, der Geschäftsprozessoptimierung und der Post Merger Integration. Meg Greenhouse verantwortet die IT-Infrastruktur bei Zalando. Foto: Zalando SE Meg Greenhouse ist SVP Zalando Technology Foundation und verantwortet die IT-Infrastruktur des Unternehmens. Dazu gehören unter anderem die Digital Workplace-Lösungen zur Verbesserung des Arbeitsalltages, Finanzlösungen, zentrale Datenplattformen und die Informationssicherheit aller virtuellen Vermögenswerte von Zalando. Meg Greenhouse startete im September 2017 als VP Corporate Technology bei Zalando.",
    "source": "cio",
    "crawled_at": "2025-05-27T08:10:58.314817+00:00"
  },
  {
    "url": "https://www.cio.de/article/3661554/die-top-cios-der-automobil-industrie.html",
    "title": "Die Top-CIOs der Automobil-Industrie",
    "published": "2025-05-25T10:53:32+00:00",
    "author": "",
    "text": "Daimler Truck AG Mit Wirkung zum 1. Juni 2025 übernimmt Raghavendra Vaidya die Position des CIO bei Daimler Truck. Er tritt die Nachfolge von Marcus Claesson an, der das Unternehmen auf eigenen Wunsch verlässt. mehr erfahren Mercedes-Benz Seit März 2025 verantwortet Rouven Rüdenauer die IT von Mercedes-Benz Vans. Er stieg innerhalb des Konzerns auf. mehr erfahren Michael Stening Skoda Nach zwei Jahren im Amt kehrt Skoda-CIO Alexander Eisl zum MAN-Konzern zurück und übergibt die IT-Leitung an Michael Stening. mehr erfahren Frank Erpinar Seit Januar 2025 ist Thomas Buck Group CIO bei der ZF Group. Er war zuvor Group CIO bei Vitesco Technologies und bei Continental als Automotive CIO tätig. Petra Clemens Foto: Cariad Seit Oktober 2024 leitet Petra Clemens die IT von Cariad, der Software-Tochter von Volkswagen. Sie kommt vom Eisenbahnlogistiker VTG. mehr erfahren Katrin Lehmann Foto: Mercedes-Benz Als CIO der Mercedes-Benz Group AG und der Mercedes-Benz AG verantwortet Katrin Lehmann die globale IT für alle Geschäftsbereiche, Marken und Märkte und berichtet direkt an den CEO. mehr erfahren Volker Schwarz Foto: GKN Automotive Limited Der langjährige Rheinmetall-CIO Volker Schwarz ist seit Januar 2024 CIO beim Automobilzulieferer GKN Automotive. mehr erfahren Falko Morlock Foto: Dürr AG Seit 1. September ist Falko Morlock CIO des schwäbischen Maschinen- und Anlagenbauers Dürr AG. mehr erfahren Martin Hofmann ist CTO und CIO bei Volta Trucks. Foto: Raimar von Wienskowski Martin Hofmann, vormals CIO von VW, geht nach dreijähriger Zwischenstation bei Salesforce als CTO und CIO zum schwedischen Automobil-Startup Volta Trucks. mehr erfahren Simon Blankenstein ist CIO der Huf Group. Foto: Johnson Controls Seit Oktober 2022 verantwortet Blankenstein als CIO die IT der Huf Group. Er berichtet an den CFO. Zu seinen wichtigsten Aufgaben gehört der weltweite Rollout von SAP S/4 HANA. mehr erfahren Saskia Kohlhaas ist CO bei IAV. Foto: Saskia Kohlhaas IAV Saskia Kohlhaas ist seit November 2021 Senior Vice President Information Technology beim Engineering-Dienstleister der Automobilindustrie IAV. Ihr Vorgänger beim Engineering-Dienstleister für die Automobilindustrie, Christian Müller-Bagehl, hat sich als Senior Consultant in Berlin selbstständig gemacht. mehr erfahren Sebastian Stoll ist CIO der FEV Group. Foto: Sebastian Stoll Seit 1. Juni 2021 ist Sebastian Stoll CIO und Group Vice President IT der FEV Gruppe. Er hat den Posten von Andreas Engels übernommen , der beim Kölner Compliance-Startup Kerberos eingestiegen ist. Stoll berichtet an CFO Jürgen Koopsingraven. Der neue CIO will zum einen die von Engels begonnene Implementierung von SAP S/4 Hana weiterführen. Zum anderen soll die IT-Sicherheit von FEV gestärkt werden. Im Zuge dessen forciert Stoll auch die Cloud-Migration und das Sourcing optimieren. In einem weiteren großen Projekt soll Stoll die IT auf digitale Geschäftsmodelle ausrichten. mehr erfahren Alexander Buresch ist CIO der BMW Group. Foto: BMW Group Der Nachfolger von Klaus Straub im Amt des CIO der BMW Group heißt Alexander Buresch. Er trat das Amt zum 1. Januar 2020 an. Der Wirtschaftswissenschaftler ist seit über 20 Jahren für BMW tätig und war zuletzt Vice President Corporate Strategy and Planning. Intern wird erwartet, dass Buresch die von Klaus Straub verfolgte IT-Strategie fortführt. mehr erfahren André Wehner ist CIO von MAN Truck & Bus. Foto: MAN Truck & Bus Am 1. Juni 2021 hat André Wehner den CIO-Posten bei MAN Truck & Bus übernommen. Als IT-Chef verantwortet Wehner die weltweite IT des Nutzfahrzeugherstellers. Dazu zählen auch Produktionswerke, Logistikzentren und die eigenen Landesvertriebsgesellschaften. Sein Vorgänger Stephan Fingerling geht als Geschäftsführer zur Group IT Services GmbH, der IT-Tochter der Volkswagen Gruppe. Vor seinem Wechsel zum Münchner Nutzfahrzeughersteller war Wehner CDO bei Skoda Auto. In der neu geschaffenen Stelle kümmerte er sich dort seit 2016 um Unternehmensentwicklung. mehr erfahren Maik Krüger wechselt von BMW zu Dräxlmaier. Foto: BMW Am 1. April trat Maik Krüger die Position des CIO bei Dräxlmaier an. Der studierte Wirtschaftsinformatiker war jahrelang in führenden IT-Positionen bei BMW tätig, zuletzt zeichnete er für die IT des Shop-Floors verantwortlich. Der designierte CIO hat sich für den neuen Arbeitgeber entschieden, weil es ihm imponiert habe, “wie exzellent das Familienunternehmen mit seiner Internationalität und seinem Produktportfolio aufgestellt ist”. Michael Simon ist CIO der VW Group Retail Deutschland GmbH. Foto: Simon Seit 1. Juli 2019 ist Michael Simon Leiter Zentral IT und CIO der Volkswagen Retail Group. Er berichtet an die Geschäftsführung. Zuvor war der studierte Informatiker seit 2015 Leiter IT bei der Weiss Umwelttechnik GmbH. Insgesamt bringt er Erfahrung aus drei Jahrzehnten als Fach- und Führungskraft in der IT mit, unter anderem bei der Salzgitter AG Group. Michael Hilzinger wechselt von Klöckner zu Knorr-Bremse. Foto: Foto Vogt Michael Hilzinger, bisher Group CIO beim Stahlhändler Klöckner in Duisburg, ist seit Juli 2019 CIO beim Bremsen-Spezialisten Knorr-Bremse in München und damit Nachfolger von Helmut Draxler . Bernd Süßmann ist Head of Corporate IT bei der SAS Automotive. Foto: SAS Automotive Bernd Süßmann ist seit September 2018 Head of Corporate IT bei der SAS Automotive in Karlsruhe, einem Joint Venture zwischen Continental and Faurecia. Er trägt dort die Gesamtverantwortung für die IT, führt dabei 80 Mitarbeiter und berichtet an den CFO des Unternehmens, Ekkehard Klautke. Bernhard Pluhatsch ist Head of IT bei Magna Powertrain Transmission Systems. Foto: Magna Bernhard Pluhatsch ist seit Oktober 2018 Head of IT, Transmission Systems bei Magna Powertrain Transmission Systems (MPT TS) in Untergruppenbach bei Heilbronn. Er kommt von der Leoni AG, wo er von 2002 bis 2018 Vice President IT Infrastruktur war. Leoni ist Hersteller von Drähten, Kabeln und Bordnetz-Systemen in Nürnberg. Ex-Porsche-CIO Sven Lorenz ist CPO im Volkswagen-Konzern. Foto: Porsche Sven Lorenz, fast 17 Jahre lang CIO beim Sportwagenhersteller Porsche in Stuttgart-Zuffenhausen, hat eine neue Aufgabe im VW-Konzern übernommen: Mit Wirkung zum Oktober 2018 wurde er Chief Process Officer. Die Stelle ist neu. Als CPO verantwortet Lorenz die konzernweite, also marken- und bereichsübergreifende Prozessharmonisierung, zwischen IT und Fachbereichen. Hintergrund: Mattias Ulbrich, Ex-CIO der Audi AG, wurde im September 2018 neuer CIO bei Porsche. Felix Willing ist CIO bei Hella. Foto: Hella Felix Willing hat Anfang Januar 2018 die Leitung des Bereichs Information Management beim Automobilzulieferer Hella GmbH & Co. KGaA im nordrhein-westfälischen Lippstadt übernommen. In dieser Position fungiert er zugleich als CIO für den globalen Hella Konzern. Zuletzt war er CIO beim Windturbinenbauer Nordex Acciona Windpower AG in Hamburg. Frank Loydl ist CIO der Audi AG. Foto: Audi AG CIO der Audi AG und damit Nachfolger von Mattias Ulbrich ist seit Februar 2018 Frank Loydl. Seit 2016 verantwortete er im Konzern die Software-Entwicklung. Ab 2009 war er bei T-Systems das Delivery Management für den Kunden Volkswagen AG zuständig. Diese Aufgabe übernahm Loydl 2013 schließlich direkt für den Automobilkonzern. Thomas Külpp arbeitet seit 27 Jahren bei Opel – nun als CIO der Opel Automobile GmbH. Foto: Opel Seit Anfang August 2017 ist Thomas Külpp CIO beim Autobauer Opel Automobile GmbH in Rüsselsheim. Zuvor war er bei Opel Director Sales & Marketing. Külpp hat Maschinenbau an der University of Applied Sciences in Wiesbaden studiert und als Diplom-Ingenieur abgeschlossen. Er arbeitet bereits seit 27 Jahren in verschiedenen Positionen bei Opel. Daimler Truck AG Mit Wirkung zum 1. Juni 2025 übernimmt Raghavendra Vaidya die Position des CIO bei Daimler Truck. Er tritt die Nachfolge von Marcus Claesson an, der das Unternehmen auf eigenen Wunsch verlässt. mehr erfahren Mercedes-Benz Seit März 2025 verantwortet Rouven Rüdenauer die IT von Mercedes-Benz Vans. Er stieg innerhalb des Konzerns auf. mehr erfahren Michael Stening Skoda Nach zwei Jahren im Amt kehrt Skoda-CIO Alexander Eisl zum MAN-Konzern zurück und übergibt die IT-Leitung an Michael Stening. mehr erfahren Frank Erpinar Seit Januar 2025 ist Thomas Buck Group CIO bei der ZF Group. Er war zuvor Group CIO bei Vitesco Technologies und bei Continental als Automotive CIO tätig. Petra Clemens Foto: Cariad Seit Oktober 2024 leitet Petra Clemens die IT von Cariad, der Software-Tochter von Volkswagen. Sie kommt vom Eisenbahnlogistiker VTG. mehr erfahren Katrin Lehmann Foto: Mercedes-Benz Als CIO der Mercedes-Benz Group AG und der Mercedes-Benz AG verantwortet Katrin Lehmann die globale IT für alle Geschäftsbereiche, Marken und Märkte und berichtet direkt an den CEO. mehr erfahren Volker Schwarz Foto: GKN Automotive Limited Der langjährige Rheinmetall-CIO Volker Schwarz ist seit Januar 2024 CIO beim Automobilzulieferer GKN Automotive. mehr erfahren Falko Morlock Foto: Dürr AG Seit 1. September ist Falko Morlock CIO des schwäbischen Maschinen- und Anlagenbauers Dürr AG. mehr erfahren Martin Hofmann ist CTO und CIO bei Volta Trucks. Foto: Raimar von Wienskowski Martin Hofmann, vormals CIO von VW, geht nach dreijähriger Zwischenstation bei Salesforce als CTO und CIO zum schwedischen Automobil-Startup Volta Trucks. mehr erfahren Simon Blankenstein ist CIO der Huf Group. Foto: Johnson Controls Seit Oktober 2022 verantwortet Blankenstein als CIO die IT der Huf Group. Er berichtet an den CFO. Zu seinen wichtigsten Aufgaben gehört der weltweite Rollout von SAP S/4 HANA. mehr erfahren Saskia Kohlhaas ist CO bei IAV. Foto: Saskia Kohlhaas IAV Saskia Kohlhaas ist seit November 2021 Senior Vice President Information Technology beim Engineering-Dienstleister der Automobilindustrie IAV. Ihr Vorgänger beim Engineering-Dienstleister für die Automobilindustrie, Christian Müller-Bagehl, hat sich als Senior Consultant in Berlin selbstständig gemacht. mehr erfahren Sebastian Stoll ist CIO der FEV Group. Foto: Sebastian Stoll Seit 1. Juni 2021 ist Sebastian Stoll CIO und Group Vice President IT der FEV Gruppe. Er hat den Posten von Andreas Engels übernommen , der beim Kölner Compliance-Startup Kerberos eingestiegen ist. Stoll berichtet an CFO Jürgen Koopsingraven. Der neue CIO will zum einen die von Engels begonnene Implementierung von SAP S/4 Hana weiterführen. Zum anderen soll die IT-Sicherheit von FEV gestärkt werden. Im Zuge dessen forciert Stoll auch die Cloud-Migration und das Sourcing optimieren. In einem weiteren großen Projekt soll Stoll die IT auf digitale Geschäftsmodelle ausrichten. mehr erfahren Alexander Buresch ist CIO der BMW Group. Foto: BMW Group Der Nachfolger von Klaus Straub im Amt des CIO der BMW Group heißt Alexander Buresch. Er trat das Amt zum 1. Januar 2020 an. Der Wirtschaftswissenschaftler ist seit über 20 Jahren für BMW tätig und war zuletzt Vice President Corporate Strategy and Planning. Intern wird erwartet, dass Buresch die von Klaus Straub verfolgte IT-Strategie fortführt. mehr erfahren André Wehner ist CIO von MAN Truck & Bus. Foto: MAN Truck & Bus Am 1. Juni 2021 hat André Wehner den CIO-Posten bei MAN Truck & Bus übernommen. Als IT-Chef verantwortet Wehner die weltweite IT des Nutzfahrzeugherstellers. Dazu zählen auch Produktionswerke, Logistikzentren und die eigenen Landesvertriebsgesellschaften. Sein Vorgänger Stephan Fingerling geht als Geschäftsführer zur Group IT Services GmbH, der IT-Tochter der Volkswagen Gruppe. Vor seinem Wechsel zum Münchner Nutzfahrzeughersteller war Wehner CDO bei Skoda Auto. In der neu geschaffenen Stelle kümmerte er sich dort seit 2016 um Unternehmensentwicklung. mehr erfahren Maik Krüger wechselt von BMW zu Dräxlmaier. Foto: BMW Am 1. April trat Maik Krüger die Position des CIO bei Dräxlmaier an. Der studierte Wirtschaftsinformatiker war jahrelang in führenden IT-Positionen bei BMW tätig, zuletzt zeichnete er für die IT des Shop-Floors verantwortlich. Der designierte CIO hat sich für den neuen Arbeitgeber entschieden, weil es ihm imponiert habe, “wie exzellent das Familienunternehmen mit seiner Internationalität und seinem Produktportfolio aufgestellt ist”. Michael Simon ist CIO der VW Group Retail Deutschland GmbH. Foto: Simon Seit 1. Juli 2019 ist Michael Simon Leiter Zentral IT und CIO der Volkswagen Retail Group. Er berichtet an die Geschäftsführung. Zuvor war der studierte Informatiker seit 2015 Leiter IT bei der Weiss Umwelttechnik GmbH. Insgesamt bringt er Erfahrung aus drei Jahrzehnten als Fach- und Führungskraft in der IT mit, unter anderem bei der Salzgitter AG Group. Michael Hilzinger wechselt von Klöckner zu Knorr-Bremse. Foto: Foto Vogt Michael Hilzinger, bisher Group CIO beim Stahlhändler Klöckner in Duisburg, ist seit Juli 2019 CIO beim Bremsen-Spezialisten Knorr-Bremse in München und damit Nachfolger von Helmut Draxler . Bernd Süßmann ist Head of Corporate IT bei der SAS Automotive. Foto: SAS Automotive Bernd Süßmann ist seit September 2018 Head of Corporate IT bei der SAS Automotive in Karlsruhe, einem Joint Venture zwischen Continental and Faurecia. Er trägt dort die Gesamtverantwortung für die IT, führt dabei 80 Mitarbeiter und berichtet an den CFO des Unternehmens, Ekkehard Klautke. Bernhard Pluhatsch ist Head of IT bei Magna Powertrain Transmission Systems. Foto: Magna Bernhard Pluhatsch ist seit Oktober 2018 Head of IT, Transmission Systems bei Magna Powertrain Transmission Systems (MPT TS) in Untergruppenbach bei Heilbronn. Er kommt von der Leoni AG, wo er von 2002 bis 2018 Vice President IT Infrastruktur war. Leoni ist Hersteller von Drähten, Kabeln und Bordnetz-Systemen in Nürnberg. Ex-Porsche-CIO Sven Lorenz ist CPO im Volkswagen-Konzern. Foto: Porsche Sven Lorenz, fast 17 Jahre lang CIO beim Sportwagenhersteller Porsche in Stuttgart-Zuffenhausen, hat eine neue Aufgabe im VW-Konzern übernommen: Mit Wirkung zum Oktober 2018 wurde er Chief Process Officer. Die Stelle ist neu. Als CPO verantwortet Lorenz die konzernweite, also marken- und bereichsübergreifende Prozessharmonisierung, zwischen IT und Fachbereichen. Hintergrund: Mattias Ulbrich, Ex-CIO der Audi AG, wurde im September 2018 neuer CIO bei Porsche. Felix Willing ist CIO bei Hella. Foto: Hella Felix Willing hat Anfang Januar 2018 die Leitung des Bereichs Information Management beim Automobilzulieferer Hella GmbH & Co. KGaA im nordrhein-westfälischen Lippstadt übernommen. In dieser Position fungiert er zugleich als CIO für den globalen Hella Konzern. Zuletzt war er CIO beim Windturbinenbauer Nordex Acciona Windpower AG in Hamburg. Frank Loydl ist CIO der Audi AG. Foto: Audi AG CIO der Audi AG und damit Nachfolger von Mattias Ulbrich ist seit Februar 2018 Frank Loydl. Seit 2016 verantwortete er im Konzern die Software-Entwicklung. Ab 2009 war er bei T-Systems das Delivery Management für den Kunden Volkswagen AG zuständig. Diese Aufgabe übernahm Loydl 2013 schließlich direkt für den Automobilkonzern. Thomas Külpp arbeitet seit 27 Jahren bei Opel – nun als CIO der Opel Automobile GmbH. Foto: Opel Seit Anfang August 2017 ist Thomas Külpp CIO beim Autobauer Opel Automobile GmbH in Rüsselsheim. Zuvor war er bei Opel Director Sales & Marketing. Külpp hat Maschinenbau an der University of Applied Sciences in Wiesbaden studiert und als Diplom-Ingenieur abgeschlossen. Er arbeitet bereits seit 27 Jahren in verschiedenen Positionen bei Opel.",
    "source": "cio",
    "crawled_at": "2025-05-27T08:10:58.405956+00:00"
  },
  {
    "url": "https://www.cio.de/article/3993385/bei-der-dkb-ubernimmt-der-ki-agent.html",
    "title": "Bei der DKB übernimmt der KI-Agent",
    "published": "2025-05-26T03:30:00+00:00",
    "author": "",
    "text": "DKB „Mit der IT-Strategie, die wir seit mehreren Jahren verfolgen, schaffen wir uns zunehmend mehr Freiheitsgrade, um uns in den Frontend-Systemen zu differenzieren“, berichtet Arnulf Keese, IT-Vorstand der Deutschen Kreditbank (DKB). Das bewerkstelligt das Finanzinstitut über einen API-Layer, der die Kernbank-Systeme im Backend und dem Frontendbereich verbindet. (Lesen Sie mehr dazu: „ IT-Vorstand Arnulf Keese: DKB teilt die IT in Schichten auf “) Diese Zwischenebene hat die DKB-IT laut Keese seither weiter ausgebaut, skaliert und für weitere Anwendungsfälle in der Bank genutzt. Einer dieser Use Cases ist die DKB-App sowie die 2024 gelaunchte neue Website samt Banking für die Endkunden. Keese: „Im Herbst 2024 haben wir die Legacy-Anwendungen im Frontend, die bis dahin noch parallel betrieben wurden, abgeschaltet und laufen seitdem komplett auf dem neuen Cloud-nativen technischen Stack, der von den Fortschritten der Hyperscaler-Architekturen profitiert.“ Die DKB verfolgt eine Multi-Cloud-Strategie – auch um frei entscheiden zu können, was auf welcher Plattform läuft. Ein Team aus Data Scientists arbeitet bereits seit Jahren an KI-Use-Cases innerhalb der DKB, so der IT-Vorstand: „So haben wir etwa vor einigen Jahren eine automatische Rechnungserkennung für die Buchhaltung entwickelt – da waren wir noch weit weg vom Kunden, haben aber viel gelernt, was das Training von Modellen angeht“, so Keese. Damals sei der Aufwand für das Training noch hoch gewesen. Heute böten die verfügbaren Foundational Models wesentlich mehr Möglichkeiten, schnell gute Ergebnisse zu erzielen. Abonnieren Sie unsere CIO-Newsletter für mehr spannende Interviews, Deep Dives und Best Practices aus der CIO-Community. In einem nächsten Schritt hat das Team aus E-Mails von Kunden mit Hilfe selbsttrainierter Modelle Emotionen herauslesen können. „Ziel war es, früh zu erkennen, ob ein Kunde im Customer-Service-Kontakt einen Notfall, ein allgemeines Problem, oder nur eine Frage hat, um die Anfrage anschließend in die richtigen Kanäle im Callcenter weiterleiten zu können.“ Für die DKB reduzierte das laut Keese den Aufwand, möglichst schnell die möglichst beste Antwort zu liefern – und die Kunden erhielten rascher Auskunft. Diese Lehrjahre haben der DKB geholfen, das Fundament für den „Digital Agent“ zu schaffen. Keese: „Wir müssen auf die Daten zugreifen können und brauchen dafür die richtigen Prozesse und Skills bei den Mitarbeitenden.“ Diese Grundlagenarbeit mündet in immer mehr Use Cases, die ohne das Fundament nicht funktionieren würden. Der KI-basierte Agent ist in der Microsoft-Azure-Welt entstanden. „Als wir vor eineinhalb Jahren angefangen haben, den KI-Agenten aufzubauen, waren die LLMs von ChatGPT dort am weitesten fortgeschritten“, so Keese. Heute hat die Bank zusätzlich mit Amazon Bedrock den Grundstein dafür gelegt, über mehrere Systeme hinweg operieren und entscheiden zu können, welches Sprachmodell wofür eingesetzt wird, um den Digital Agent betreiben zu können. Dabei spielen zum einen Anforderungen hinsichtlich der Resilienz eine Rolle. Zum anderen will die DKB in der Lage sein, im Hinblick auf die rasant fortschreitenden Innovationen im LLM-Markt immer auf dem besten Modell arbeiten zu können. „Daher haben wir intern auch eine hohe Wertschöpfungstiefe um das GPT herumgebaut, um etwa die Logik zu definieren, wie die Kundenanfragen bewertet werden oder welche Rohdatenquellen in die Antwort miteinfließen“, berichtet der Manager. Die DKB-IT wollte so sicherstellen, dass die von der KI ausgegebenen Antworten den Ansprüchen der Bank genügen. Keese sagt ganz klar an: „Die Antworten müssen korrekt sein, die Position des Hauses vertreten und sich auf den Sachverhalt beschränken. Wenn jemand beispielsweise den Agenten fragt, welche Aktien er kaufen soll, dann darf eine Bank dazu nichts sagen.“ Ein Beispiel: Fragt ein Kunde etwas zu den AGBs, könnte das Modell den Originaltext der AGBs zurückgeben. Da es sich dabei aber um juristische Texte handelt, sind sie nicht immer einfach verständlich. Dagegen sind einfache Antworten aus den FAQs des Finanzinstituts womöglich juristisch nicht korrekt. Die richtige Mischung aus den Fakten der AGBs und der Verständlichkeit der FAQs stellt die DKB-IT laut Keese mit der in den Agenten eingebauten Logik sicher. „Wenn ein Kunde eine Frage hat, wollen wir eine möglichst hohe Quote an fallabschließenden Antworten im allerersten Kundenkontakt.“ Wenn der Kunde das Gefühl habe, nur drei Textbausteine zusammengewürfelt zu bekommen, sei das frustrierend für ihn und ineffizient für die Bank. Keese: „Der Vorteil bei LLMs ist, dass, selbst wenn man dem Bot drei Textbausteine gibt, macht er daraus eine zusammenhängende Antwort in guter Sprache – und auf Wunsch auch in mehreren Sprachen.“ Der Agent kennt laut Keese auf Basis datenschutzrechtlicher Anforderungen die persönlichen Finanzprodukte der Kunden. Zudem greift er überwiegend auf bestehende Wissensbausteine zurück und ist mit diesen gezielt verbunden. Die Voraussetzung dafür ist eine interne Wissensplattform mit allen Informationen, die auch die realen Kundenbetreuer aktuell in ihrem Arbeitsalltag nutzen. Angereichert ist das Wissen des KI-Supports durch FAQs, Website-Daten und bestehende Textbausteine. Ende 2023 hatte sich die DKB-IT vorgenommen, den digitalen Agenten für die E-Mail-basierte Kundenkommunikation zu entwickeln. „Ziel war, bei Lastspitzen von Kundenanfragen gewohnt schnell und zielführend Auskunft geben zu können“, präzisiert der IT-Vorstand. Gerade bei Standardthemen, die keine ausführliche Beratung erfordern, wollte man die Kundschaft möglichst schnell zu gewünschten Ergebnis führen und den Kundendienst entlasten – dafür brauchte es Automatisierung. Nach einem Vergleich verschiedener LLMs und über 50 Chatbots am Markt fiel die Wahl auf ChatGPT als Sprachmodell. Der Chatbot wurde größtenteils inhouse selbst entwickelt, um den Datenfluss für die oben beschriebene Detailtiefe und Verständlichkeit in den Antworten zu gewährleisten. Im ersten Halbjahr 2024 begannen erste Pilotversuche. Nachdem anfängliche Schwierigkeiten überwunden sowie Governance und Regulatorik implementiert waren, begannen im Sommer 2024 die ersten Tests im Feld samt Verbesserungs-Iterationen auf Basis von Nutzerfeedback. Anschließend wurde die Lösung scharf geschaltet. „Da haben wir uns Use Case für Use Case vorgearbeitet und sind kurz vor Weihnachten 2024 in den vollständigen Rollout reingekommen“, beschreibt der IT-Chef sein Vorgehen. Im Laufe des Jahres 2025 werde er komplett ausgerollt. Mit dem Rollout des Tools startete die DKB in den öffentlich zugänglichen FAQs. Anschließend hatten eingeloggte Kunden darauf Zugriff und in einem dritten Schritt wurde es auf der Webseite und in die App implementiert. Zudem können Kunden innerhalb des Kontos Fragen etwa zu ihrem Account stellen. Für den Datenschutz sorgt das Finanzhaus, indem der Agent in einer geschützten Umgebung in einer EU-Souveränitätszone von Microsoft agiert. „Wichtiges Grundprinzip dabei ist, dass alles, was die Kunden uns fragen und was wir über den Agenten antworten, in keiner Weise in das Training der Modelle einfließt. Das ist garantiert und vertraglich mit dem Partner abgesichert“, führt Keese aus. Das LLM so nutzen zu können, ohne dabei das Modell zu trainieren, sei sehr wichtig, gerade im Umfeld von Bankgeheimnissen. Der „Lackmustest“ für die Güte des Chatbots ist für den IT-Chef die Zeit, bis der Kunde einen menschlichen Ansprechpartner will. Bei dem Digital Agent merke die DKB-IT in der anonymisierten Auswertung und stichprobenartigen Umfragen, dass die Interaktionsrate mit den Kunden hoch und die Aufforderung nach einem menschlichen Kontakt niedrig ist, was darauf schließen lasse, dass er einen zufriedenstellenden Job macht. „Das Besondere an dem Chatbot ist, dass sich die Kunden in einem echten Dialog befinden, der unendlich weitergeführt werden kann und sich aus allen relevanten, aktuell in der Bank verfügbaren Informationen speist“, führt der IT-Vorstand aus. Die meisten anderen Bot-Dialoge seien sehr regelbasiert in Wenn-Dann-Schleifen konzipiert und nach drei Fragen durchlaufen, danach müsse ein Mensch kontaktiert werden. „Wo wir gerade noch dran sind, ist die Dokumentenprüfung, wenn der Kunde bestimmte Produkte haben will. Hier experimentieren wir mit Teilautomatisierung – etwa bei der Überprüfung von Gehaltsnachweisen“, berichtet Keese. Dabei gehe es vor allem um Schnelligkeit, damit die Kunden möglichst früh eine Zusage für das angefragte Produkt erhielten. Solche Dinge seien insofern wichtig, weil die DKB laut Keese eine Tech-Bank ist und sein will. „Darum begleiten wir technologische Trends, investieren seit Jahren in Data Science und KI – und dadurch rollen wir jetzt immer mehr große und kleine Use Cases aus.“ Das forciere auch insgesamt den Fortschritt im Unternehmen. In vielen Abteilungen probierten Kolleginnen und Kollegen, Prozesse mit KI zu vereinfachen. „Das ist der Prozess der Demokratisierung”, zieht der IT-Chef Bilanz. “Da passiert viel an Stellen, die von außen vielleicht weniger einsehbar sind – etwa im Bereich ESG. Dort gibt es Bergeweise standardisierte Dokumente, wie etwa Energieausweise, bei denen es sträflich wäre, die Erkennung und Einsortierung nicht durch Automatisierung zu vereinfachen.“ Bei allen Effizienzgewinnen durch Automatisierung sei es jedoch wichtig, auch wegen regulatorischer Anforderungen, dass die Entscheidung am Ende immer noch ein Mensch trifft. Seit Mai 2025 hat die DKB zudem eine direkte Innovationskooperation mit OpenAI gestartet. Ein konkretes Projekt dieser Partnerschaft ist die Einführung einer KI-Sprachsteuerung im Banking, die den 5,8 Millionen Kundinnen und Kunden der Direktbank einen smarten Zugang zu Banking-Services ermöglichen soll. Zudem stellt OpenAI die Technologie zur Verfügung, um Agentic AI Workflows zu implementieren. Damit soll die komplexe Dokumentenverarbeitung und damit verbundene Prozesse für die Mitarbeitenden vereinfacht werden. DKB „Mit der IT-Strategie, die wir seit mehreren Jahren verfolgen, schaffen wir uns zunehmend mehr Freiheitsgrade, um uns in den Frontend-Systemen zu differenzieren“, berichtet Arnulf Keese, IT-Vorstand der Deutschen Kreditbank (DKB). Das bewerkstelligt das Finanzinstitut über einen API-Layer, der die Kernbank-Systeme im Backend und dem Frontendbereich verbindet. (Lesen Sie mehr dazu: „ IT-Vorstand Arnulf Keese: DKB teilt die IT in Schichten auf “) Diese Zwischenebene hat die DKB-IT laut Keese seither weiter ausgebaut, skaliert und für weitere Anwendungsfälle in der Bank genutzt. Einer dieser Use Cases ist die DKB-App sowie die 2024 gelaunchte neue Website samt Banking für die Endkunden. Keese: „Im Herbst 2024 haben wir die Legacy-Anwendungen im Frontend, die bis dahin noch parallel betrieben wurden, abgeschaltet und laufen seitdem komplett auf dem neuen Cloud-nativen technischen Stack, der von den Fortschritten der Hyperscaler-Architekturen profitiert.“ Die DKB verfolgt eine Multi-Cloud-Strategie – auch um frei entscheiden zu können, was auf welcher Plattform läuft. Ein Team aus Data Scientists arbeitet bereits seit Jahren an KI-Use-Cases innerhalb der DKB, so der IT-Vorstand: „So haben wir etwa vor einigen Jahren eine automatische Rechnungserkennung für die Buchhaltung entwickelt – da waren wir noch weit weg vom Kunden, haben aber viel gelernt, was das Training von Modellen angeht“, so Keese. Damals sei der Aufwand für das Training noch hoch gewesen. Heute böten die verfügbaren Foundational Models wesentlich mehr Möglichkeiten, schnell gute Ergebnisse zu erzielen. Abonnieren Sie unsere CIO-Newsletter für mehr spannende Interviews, Deep Dives und Best Practices aus der CIO-Community. In einem nächsten Schritt hat das Team aus E-Mails von Kunden mit Hilfe selbsttrainierter Modelle Emotionen herauslesen können. „Ziel war es, früh zu erkennen, ob ein Kunde im Customer-Service-Kontakt einen Notfall, ein allgemeines Problem, oder nur eine Frage hat, um die Anfrage anschließend in die richtigen Kanäle im Callcenter weiterleiten zu können.“ Für die DKB reduzierte das laut Keese den Aufwand, möglichst schnell die möglichst beste Antwort zu liefern – und die Kunden erhielten rascher Auskunft. Diese Lehrjahre haben der DKB geholfen, das Fundament für den „Digital Agent“ zu schaffen. Keese: „Wir müssen auf die Daten zugreifen können und brauchen dafür die richtigen Prozesse und Skills bei den Mitarbeitenden.“ Diese Grundlagenarbeit mündet in immer mehr Use Cases, die ohne das Fundament nicht funktionieren würden. Der KI-basierte Agent ist in der Microsoft-Azure-Welt entstanden. „Als wir vor eineinhalb Jahren angefangen haben, den KI-Agenten aufzubauen, waren die LLMs von ChatGPT dort am weitesten fortgeschritten“, so Keese. Heute hat die Bank zusätzlich mit Amazon Bedrock den Grundstein dafür gelegt, über mehrere Systeme hinweg operieren und entscheiden zu können, welches Sprachmodell wofür eingesetzt wird, um den Digital Agent betreiben zu können. Dabei spielen zum einen Anforderungen hinsichtlich der Resilienz eine Rolle. Zum anderen will die DKB in der Lage sein, im Hinblick auf die rasant fortschreitenden Innovationen im LLM-Markt immer auf dem besten Modell arbeiten zu können. „Daher haben wir intern auch eine hohe Wertschöpfungstiefe um das GPT herumgebaut, um etwa die Logik zu definieren, wie die Kundenanfragen bewertet werden oder welche Rohdatenquellen in die Antwort miteinfließen“, berichtet der Manager. Die DKB-IT wollte so sicherstellen, dass die von der KI ausgegebenen Antworten den Ansprüchen der Bank genügen. Keese sagt ganz klar an: „Die Antworten müssen korrekt sein, die Position des Hauses vertreten und sich auf den Sachverhalt beschränken. Wenn jemand beispielsweise den Agenten fragt, welche Aktien er kaufen soll, dann darf eine Bank dazu nichts sagen.“ Ein Beispiel: Fragt ein Kunde etwas zu den AGBs, könnte das Modell den Originaltext der AGBs zurückgeben. Da es sich dabei aber um juristische Texte handelt, sind sie nicht immer einfach verständlich. Dagegen sind einfache Antworten aus den FAQs des Finanzinstituts womöglich juristisch nicht korrekt. Die richtige Mischung aus den Fakten der AGBs und der Verständlichkeit der FAQs stellt die DKB-IT laut Keese mit der in den Agenten eingebauten Logik sicher. „Wenn ein Kunde eine Frage hat, wollen wir eine möglichst hohe Quote an fallabschließenden Antworten im allerersten Kundenkontakt.“ Wenn der Kunde das Gefühl habe, nur drei Textbausteine zusammengewürfelt zu bekommen, sei das frustrierend für ihn und ineffizient für die Bank. Keese: „Der Vorteil bei LLMs ist, dass, selbst wenn man dem Bot drei Textbausteine gibt, macht er daraus eine zusammenhängende Antwort in guter Sprache – und auf Wunsch auch in mehreren Sprachen.“ Der Agent kennt laut Keese auf Basis datenschutzrechtlicher Anforderungen die persönlichen Finanzprodukte der Kunden. Zudem greift er überwiegend auf bestehende Wissensbausteine zurück und ist mit diesen gezielt verbunden. Die Voraussetzung dafür ist eine interne Wissensplattform mit allen Informationen, die auch die realen Kundenbetreuer aktuell in ihrem Arbeitsalltag nutzen. Angereichert ist das Wissen des KI-Supports durch FAQs, Website-Daten und bestehende Textbausteine. Ende 2023 hatte sich die DKB-IT vorgenommen, den digitalen Agenten für die E-Mail-basierte Kundenkommunikation zu entwickeln. „Ziel war, bei Lastspitzen von Kundenanfragen gewohnt schnell und zielführend Auskunft geben zu können“, präzisiert der IT-Vorstand. Gerade bei Standardthemen, die keine ausführliche Beratung erfordern, wollte man die Kundschaft möglichst schnell zu gewünschten Ergebnis führen und den Kundendienst entlasten – dafür brauchte es Automatisierung. Nach einem Vergleich verschiedener LLMs und über 50 Chatbots am Markt fiel die Wahl auf ChatGPT als Sprachmodell. Der Chatbot wurde größtenteils inhouse selbst entwickelt, um den Datenfluss für die oben beschriebene Detailtiefe und Verständlichkeit in den Antworten zu gewährleisten. Im ersten Halbjahr 2024 begannen erste Pilotversuche. Nachdem anfängliche Schwierigkeiten überwunden sowie Governance und Regulatorik implementiert waren, begannen im Sommer 2024 die ersten Tests im Feld samt Verbesserungs-Iterationen auf Basis von Nutzerfeedback. Anschließend wurde die Lösung scharf geschaltet. „Da haben wir uns Use Case für Use Case vorgearbeitet und sind kurz vor Weihnachten 2024 in den vollständigen Rollout reingekommen“, beschreibt der IT-Chef sein Vorgehen. Im Laufe des Jahres 2025 werde er komplett ausgerollt. Mit dem Rollout des Tools startete die DKB in den öffentlich zugänglichen FAQs. Anschließend hatten eingeloggte Kunden darauf Zugriff und in einem dritten Schritt wurde es auf der Webseite und in die App implementiert. Zudem können Kunden innerhalb des Kontos Fragen etwa zu ihrem Account stellen. Für den Datenschutz sorgt das Finanzhaus, indem der Agent in einer geschützten Umgebung in einer EU-Souveränitätszone von Microsoft agiert. „Wichtiges Grundprinzip dabei ist, dass alles, was die Kunden uns fragen und was wir über den Agenten antworten, in keiner Weise in das Training der Modelle einfließt. Das ist garantiert und vertraglich mit dem Partner abgesichert“, führt Keese aus. Das LLM so nutzen zu können, ohne dabei das Modell zu trainieren, sei sehr wichtig, gerade im Umfeld von Bankgeheimnissen. Der „Lackmustest“ für die Güte des Chatbots ist für den IT-Chef die Zeit, bis der Kunde einen menschlichen Ansprechpartner will. Bei dem Digital Agent merke die DKB-IT in der anonymisierten Auswertung und stichprobenartigen Umfragen, dass die Interaktionsrate mit den Kunden hoch und die Aufforderung nach einem menschlichen Kontakt niedrig ist, was darauf schließen lasse, dass er einen zufriedenstellenden Job macht. „Das Besondere an dem Chatbot ist, dass sich die Kunden in einem echten Dialog befinden, der unendlich weitergeführt werden kann und sich aus allen relevanten, aktuell in der Bank verfügbaren Informationen speist“, führt der IT-Vorstand aus. Die meisten anderen Bot-Dialoge seien sehr regelbasiert in Wenn-Dann-Schleifen konzipiert und nach drei Fragen durchlaufen, danach müsse ein Mensch kontaktiert werden. „Wo wir gerade noch dran sind, ist die Dokumentenprüfung, wenn der Kunde bestimmte Produkte haben will. Hier experimentieren wir mit Teilautomatisierung – etwa bei der Überprüfung von Gehaltsnachweisen“, berichtet Keese. Dabei gehe es vor allem um Schnelligkeit, damit die Kunden möglichst früh eine Zusage für das angefragte Produkt erhielten. Solche Dinge seien insofern wichtig, weil die DKB laut Keese eine Tech-Bank ist und sein will. „Darum begleiten wir technologische Trends, investieren seit Jahren in Data Science und KI – und dadurch rollen wir jetzt immer mehr große und kleine Use Cases aus.“ Das forciere auch insgesamt den Fortschritt im Unternehmen. In vielen Abteilungen probierten Kolleginnen und Kollegen, Prozesse mit KI zu vereinfachen. „Das ist der Prozess der Demokratisierung”, zieht der IT-Chef Bilanz. “Da passiert viel an Stellen, die von außen vielleicht weniger einsehbar sind – etwa im Bereich ESG. Dort gibt es Bergeweise standardisierte Dokumente, wie etwa Energieausweise, bei denen es sträflich wäre, die Erkennung und Einsortierung nicht durch Automatisierung zu vereinfachen.“ Bei allen Effizienzgewinnen durch Automatisierung sei es jedoch wichtig, auch wegen regulatorischer Anforderungen, dass die Entscheidung am Ende immer noch ein Mensch trifft. Seit Mai 2025 hat die DKB zudem eine direkte Innovationskooperation mit OpenAI gestartet. Ein konkretes Projekt dieser Partnerschaft ist die Einführung einer KI-Sprachsteuerung im Banking, die den 5,8 Millionen Kundinnen und Kunden der Direktbank einen smarten Zugang zu Banking-Services ermöglichen soll. Zudem stellt OpenAI die Technologie zur Verfügung, um Agentic AI Workflows zu implementieren. Damit soll die komplexe Dokumentenverarbeitung und damit verbundene Prozesse für die Mitarbeitenden vereinfacht werden.",
    "source": "cio",
    "crawled_at": "2025-05-27T08:10:58.510949+00:00"
  },
  {
    "url": "https://www.cio.de/article/3994135/raghavendra-vaidya-wird-cio-von-daimler-truck.html",
    "title": "Raghavendra Vaidya wird CIO von Daimler Truck",
    "published": "2025-05-26T04:13:00+00:00",
    "author": "",
    "text": "Daimler Truck Ab Juni 2025 ist Raghavendra Vaidya Chief Information Officer (CIO) von Daimler Truck. Er ist bereits seit 2016 im Daimler-Konzern tätig. Vaidya folgt auf Marcus Claesson, der das Unternehmen auf eigenen Wunsch verlässt. „Wir freuen uns, Raghavendra Vaidya in unserem Executive Team zu begrüßen“, kommentiert Andreas Gorbach, Mitglied des Vorstands der Daimler Truck AG undverantwortlich für Truck Technology, Vaidyas Ernennung. Mit einer über 25-jährigen Karriere in verschiedenen IT-Positionen bringe er Erfahrung und Know-how, strategische Vision sowie Führungskompetenz mit, um das Unternehmen in eine datenbasierte Zukunft zu führen. Abonnieren Sie unsere CIO-Newsletter für mehr spannende Personalien, Einblicke und Hintergründe aus der CIO-Community. Derzeit ist Vaidya als Managing Director und CEO des Daimler Truck Innovation Center India (DTICI) tätig, ein Posten, den er 2021 antrat. Zuvor war der Manager fünf Jahre SVP IT bei Mercedes-Benz Research and Development India. Bis zu seinem Eintritt in den Daimler-Konzern hatte Vaidya verschiedene Führungspositionen in mehreren Geschäftsbereichen von General Electric inne. Marcus Claesson verlässt das Unternehmen nach rund fünfeinhalb Jahren als IT-Chef auf eigenen Wunsch. Daimler Truck Vaidyas Vorgänger Marcus Claesson war seit 2019 CIO des Nutzfahrzeugherstellers. Auch er kam aus dem Daimler-Konzern. Vor dem Einstieg bei Daimler Trucks war der Manager zwei Jahre CIO von Daimler Commercial Vehicles. „Ich danke Marcus für seinen Beitrag zu unserem neuen IT-Setup nach dem Spin-Off von der ehemaligen Daimler AG“, verabschiedet Gorbach den scheidenden IT-Chef und ergänzt: „Marcus hat eine Herkules-Aufgabe gemeistert, indem er eine eigenständige IT aufgebaut hat, was große Transformationsschritte beinhaltet hat. Zudem hat er die Fahrzeugkonnektivität über alle Marken hinweg maßgeblich vorangetrieben und dabei unter anderem den Meilenstein von mehr als einer Million vernetzten Fahrzeugen erreicht.“ Sie haben Informationen zu Jobwechseln in der CIO-Community? Dann schreiben Sie uns via: info@cio.de Daimler Truck ist seit Ende 2021 ein eigenständiges Unternehmen, das durch die Abspaltung der Daimler Truck AG von der Daimler AG entstand. Der Nutzfahrzeughersteller hat seinen Hauptsitz in Leinfelden-Echterdingen in Baden-Württemberg und unterhält rund 40 Standorte weltweit. 2024 erwirtschaftete das Unternehmen 54,1 Milliarden Euro Umsatz und beschäftigte etwa 103.000 Menschen. Daimler Truck Ab Juni 2025 ist Raghavendra Vaidya Chief Information Officer (CIO) von Daimler Truck. Er ist bereits seit 2016 im Daimler-Konzern tätig. Vaidya folgt auf Marcus Claesson, der das Unternehmen auf eigenen Wunsch verlässt. „Wir freuen uns, Raghavendra Vaidya in unserem Executive Team zu begrüßen“, kommentiert Andreas Gorbach, Mitglied des Vorstands der Daimler Truck AG undverantwortlich für Truck Technology, Vaidyas Ernennung. Mit einer über 25-jährigen Karriere in verschiedenen IT-Positionen bringe er Erfahrung und Know-how, strategische Vision sowie Führungskompetenz mit, um das Unternehmen in eine datenbasierte Zukunft zu führen. Abonnieren Sie unsere CIO-Newsletter für mehr spannende Personalien, Einblicke und Hintergründe aus der CIO-Community. Derzeit ist Vaidya als Managing Director und CEO des Daimler Truck Innovation Center India (DTICI) tätig, ein Posten, den er 2021 antrat. Zuvor war der Manager fünf Jahre SVP IT bei Mercedes-Benz Research and Development India. Bis zu seinem Eintritt in den Daimler-Konzern hatte Vaidya verschiedene Führungspositionen in mehreren Geschäftsbereichen von General Electric inne. Marcus Claesson verlässt das Unternehmen nach rund fünfeinhalb Jahren als IT-Chef auf eigenen Wunsch. Daimler Truck Vaidyas Vorgänger Marcus Claesson war seit 2019 CIO des Nutzfahrzeugherstellers. Auch er kam aus dem Daimler-Konzern. Vor dem Einstieg bei Daimler Trucks war der Manager zwei Jahre CIO von Daimler Commercial Vehicles. „Ich danke Marcus für seinen Beitrag zu unserem neuen IT-Setup nach dem Spin-Off von der ehemaligen Daimler AG“, verabschiedet Gorbach den scheidenden IT-Chef und ergänzt: „Marcus hat eine Herkules-Aufgabe gemeistert, indem er eine eigenständige IT aufgebaut hat, was große Transformationsschritte beinhaltet hat. Zudem hat er die Fahrzeugkonnektivität über alle Marken hinweg maßgeblich vorangetrieben und dabei unter anderem den Meilenstein von mehr als einer Million vernetzten Fahrzeugen erreicht.“ Sie haben Informationen zu Jobwechseln in der CIO-Community? Dann schreiben Sie uns via: info@cio.de Daimler Truck ist seit Ende 2021 ein eigenständiges Unternehmen, das durch die Abspaltung der Daimler Truck AG von der Daimler AG entstand. Der Nutzfahrzeughersteller hat seinen Hauptsitz in Leinfelden-Echterdingen in Baden-Württemberg und unterhält rund 40 Standorte weltweit. 2024 erwirtschaftete das Unternehmen 54,1 Milliarden Euro Umsatz und beschäftigte etwa 103.000 Menschen.",
    "source": "cio",
    "crawled_at": "2025-05-27T08:10:58.592188+00:00"
  },
  {
    "url": "https://www.cio.de/article/3991917/dell-pro-16-plus-im-test-ki-laptop-mit-grosem-display-2.html",
    "title": "Dell Pro 16 Plus im Test: KI-Laptop mit großem Display",
    "published": "2025-05-26T05:11:00+00:00",
    "author": "",
    "text": "Thomas Rau Auch unter neuem Namen zeigt das Business-Notebook von Dell im Test die bekannten Kernkompetenzen: Das Pro 16 Plus ist ein rundum solide verarbeiteter, zuverlässiger Business-Laptop. Der neue Lunar-Lake-Prozessor macht den Copilot+PC KI- und damit zukunftstauglich. Bei Rechenleistung, Akkulaufzeit und Bildqualität schneidet das Notebook ordentlich ab, ragt aber in keiner Disziplin heraus. Das macht ihn zum Allrounder für den Business-Einsatz besonders in größeren Unternehmen, auf die das Pro 16 Plus bei Ausstattung und Reparaturfähigkeit zugeschnitten ist. Vor allem, wer bei der Büroarbeit eine große Bildschirmfläche für Excel-Tabellen und Powerpoint-Präsentationen benötigt, darf beim 16-Zoll-Notebooks zugreifen. Weitere Profi-Notebooks für unterwegs, das Home-Office oder Büro finden Sie in unserem großen Vergleichs-Test der besten Business-Laptops . Mit dem Pro 16 Plus läutet Dell eine neue Ära bei seinen Notebooks ein: Verschwunden sind die bekannten Markennamen XPS, Inspiron, Latitude und Precision. Ab jetzt heißen die Laptops für Privatanwender Dell, die Business-Geräte Dell Pro und die High-End- und Workstation-Varianten Dell Pro Max. Innerhalb der jeweiligen Serien gibt es die Ausstattungsstufen Base, Plus und Premium. Das Dell Pro 16 Plus lässt sich somit als Business-Notebook der oberen Mittelklasse und als Nachfolger der Latitude-7000er-Serie einordnen. Beim Gehäusedesign hat sich wenig getan: Gegenüber dem Vorgänger 7650 bekommt das Pro 16 Plus eine breitere Tastatur inklusive Nummernblock. Das hellgraue Aluminiumgehäuse versprüht statt Chefetagen-Chic die businesskonforme Eleganz eines Großraumbüros. Aber genau dort soll das Pro 16 Plus seinen Platz finden als produktive Arbeitsmaschine mit großem Display und einem Prozessor aus Intels Lunar-Lake-Generation: Diese Kombination ist bei Copilot+PCs noch recht einzigartig. Denn die sparsamen und recheneffizienten Intel-Prozessoren werden bislang vor allem in ultramobilen 13- und 14-Zoll-Laptops eingesetzt – in 16-Zoll-Modellen sind sie noch selten. Thomas Rau Wie bei Dell üblich, gibt es das Pro 16 Plus in zahlreichen Ausstattungsvarianten, deren Preise bei rund 1600 Euro beginnen. Das Testgerät mit Intel Core Ultra 7 268V, 32B RAM, 1-TB-SSD und 16-Zoll-Bildschirm mit FHD+ kostet rund 2350 Euro. Der Prozessor bietet gegenüber dem vor allem in Consumer-Notebooks häufig zu findenden Core Ultra 7 258V einen etwas höheren Turbo-Takt sowie eine minimal schnellere NPU und CPU-Grafik. Wichtiger fürs Dell Pro ist, dass er Intels vPro-Technik unterstützt, womit sich das Notebook im Unternehmen leichter administrieren und besser schützen lässt. Leistungstests zeigen keinen Unterschied zwischen dem 268V und einem 258V mit der gleichen mittleren Leistungsaufnahme von 25 Watt. Minimal schneller ist das Dell-Notebook lediglich im Vergleich zu Lunar-Lake-Laptops, in denen ein 258V nur rund 20 Watt verbrauchen darf – aber auch dann nur bei CPU-lastigen Aufgaben wie Rendering oder Fotobearbeitung. Insgesamt bietet das Dell Pro ein ausgewogenes Rechentempo bei allen business-relevanten Anwendungen: Im PC Mark 10 ist es ähnlich leistungsstark wie Notebooks mit dem deutlich leistungshungrigerem Core Ultra 7 155H aus der Meteor-Lake-Generation, hat aber aufgrund der verbesserten internen GPU Arc 140V Vorteile bei grafiklastigen Rendering- und Videoschnitt-Programmen. Im System-Benchmark Crossmark hängt es Notebooks mit einem Prozessor aus der Vorgängergeneration um rund 15 Prozent ab. Beim Vergleich mit ARM-Notebooks, die einen Snapdragon X Elite einsetzen, zeigt das Dell Pro das gleiche Verhalten wie alle Lunar-Lake-Laptops: Bei hoher CPU-Last ist es dem Qualcomm-Prozessor klar unterlegen, benötigt ein Programm nur wenige Kerne, liegt es vorne. Am deutlichsten erweist sich das im beliebten, aber wenig praxisnahem Prozessor-Benchmark Cinebench R24: Beim Multi-Core-Test fehlen dem Dell Pro 16 Plus rund 20 Prozent auf Notebooks mit dem Snapdragon X Elite E78, beim Single-Core-Test ist es genau andersherum. In der Praxis fällt dieser Unterschied vor allem bei Office-Tests auf, wo das Dell Pro stärker bei Word, aber schwächer bei Excel ist: Insgesamt liegen Snapdragon und Lunar Lake beim Büroeinsatz aber gleichauf. Gleiches gilt für die Recheneffizienz, wo beide Konkurrenten rund 23 Cinebench-Punkte pro Watt erreichen: Die Snapdragon-Notebooks mit X Elite sind schneller, verbrauchen aber minimal mehr, bei Lunar-Lake-Laptops ist es umgekehrt. Als Copilot+PC erfüllt das Dell Pro 16 Plus dank der NPU des Intel-Prozessors die KI-Vorgaben von Microsoft. Im KI-Benchmark Procyon AI Computer Vision schneidet es aber etwas schlechter ab als die meisten anderen KI-Notebooks mit Lunar Lake oder Snapdragon-Prozessor. Thomas Rau Im Arbeitsalltag mit dem Dell Pro fällt störend auf, dass der Lüfter oft aktiv ist – selbst, wenn nur geringe Rechenleistung gefordert ist. Zwar bleibt das Betriebsgeräusch unter Last gemessen etwas niedriger als bei anderen Notebooks mit Lunar Lake. Die sind aber häufig ganz still, während das Dell fast immer hörbar arbeitet und damit in einer sehr ruhigen Arbeitsumgebung auffällt. Das große Dell Pro 16 Plus bietet viele Anschlüsse wie Thunderbolt 4, USB Typ-A, Micro-SD-Kartenleser und HDMI-Ausgang – optimal für ein Schreibtisch-Gerät, da sich so viele Peripheriegeräte ohne Adapter oder Docking-Station nutzen lassen. Ein Ethernet-Port fehlt, dafür gibt es WLAN mit dem aktuellen Standard Wi-Fi 7. Optional lässt sich das Dell-Notebook mit einem Smartcard-Leser und einem 5G-Modem inklusive Nano-SIM-Einschub ausstatten. Die Kamera löst mit 1440p auf und eignet sich daher sehr gut für Video-Meetings. Die Linse können Sie mit einer mechanischen Abdeckung im Displaydeckel verschließen. Zudem arbeitet die Kamera mit einem Näherungssensor, um den Sperrbildschirm zu aktivieren, wenn Sie sich vom Notebook entfernen und die Displayhelligkeit zu reduzieren, wenn Sie nicht auf den Bildschirm schauen. Servicetechniker erleichtert Dell das Reparieren: Die acht Gehäuseschrauben sind verliersicher und fallen daher nicht sofort heraus, wenn Sie sie aufdrehen. Zudem besitzt das Pro 16 Plus laut Dell als erstes Notebook modulare Typ-C-Ports: Sie sind verschraubt statt verlötet und lassen sich deswegen einfacher ersetzen. Selbst sollten Sie das aber nicht probieren, denn dazu muss die Platine ausgebaut werden, weil sich die Schrauben der USB-C-Module auf deren Unterseite befinden. Thomas Rau Mit einem Gewicht von knapp unter zwei Kilogramm, gehört das Notebook nicht zu den leichtesten 16-Zoll-Modellen. Trotzdem lässt es sich auf kürzeren Strecken bequem transportieren – zum Beispiel zwischen Wohnung und Büro oder innerhalb des Unternehmens. Die Akkulaufzeit geht in Ordnung: Im WLAN-Test erreicht das Dell-Notebook eine Laufzeit von über 14 Stunden, im Office-Einsatz sind es 12 Stunden. Mit einem größeren Akku würde die Ausdauer noch deutlich besser ausfallen, da das Pro 16 mit einer Leistungsaufnahme von unter vier Watt im Akkubetrieb sehr sparsam arbeitet – vor allem, weil es ein LCD-Display statt OLED nutzt. Doch sein Akku fasst nur 55 Wattstunden, mit größerem Akku laufen Lunar-Lake-Laptops zwei bis vier Stunden länger. Das passt aber zum Einsatzzweck des 16-Zöllers: Er ist für den gelegentlichen Akkubetrieb gedacht, nicht als ultramobiler Laptop, mit dem Sie einen ganzen Tag unterwegs arbeiten. Mit Standardeinstellungen lädt das Notebook sehr gemächlich: Nach einer Stunde an der Steckdose ist es nur zu 51 Prozent geladen – das wiederum verlängert die Lebensdauer des Akkus. Thomas Rau Beim Bildschirm können Sie zwischen Displayvarianten mit und ohne Touchscreen wählen und bei der Auflösung zwischen FHD+ und QHD+. Die Auflösung des Testmodells beträgt 1920 x 1200 und ist damit sinnvoll für den Büroalltag. Ebenso alltagstauglich für den Einsatz am Schreibtisch sind die Messergebnisse bei Helligkeit, Kontrast und Ausleuchtung – die Werte sind nicht überragend, aber absolut in Ordnung für Word, Excel und Powerpoint. Das Dell Pro 16 Plus ist aber kein Laptop, den Sie sich wegen der Bildqualität kaufen sollten. Denn die mäßige Farbwiedergabe mit geringer Farbraumabdeckung und Farbtreue disqualifiziert es für ambitionierte Foto- oder Videobearbeitung. Andere Laptops mit LCD bieten eine höhere Maximalhelligkeit und lassen sich daher unter verschiedenen Lichtbedingungen flexibler nutzen. Der Vorteil beim Dell-Notebook ist dafür seine entspiegelte Bildschirmoberfläche. Der Nummernblock rechts in der Tastatur erleichtert die schnelle Eingabe von Zahlen und dürfte daher Excel-Arbeiter begeistern – zumal diese Tasten fast genauso groß sind wie in der Haupt-Tastatur. Beim Layout fällt die zweizeilige, aber schmale Enter-Taste auf, die Pfeiltasten sind nicht abgesetzt. Auf der Tastatur lässt sich angenehm tippen, denn sie ist sehr stabil eingebaut, die Tasten verfügen über einen klaren Druckpunkt und einen guten Hub. Besonders leise ist sie aber nicht. Auch das große Touchpad gibt eine deutlich spürbare Klick-Rückmeldung, auf der rechten Seite fühlt es sich aber etwas schwammig an. Thomas Rau Auch unter neuem Namen zeigt das Business-Notebook von Dell im Test die bekannten Kernkompetenzen: Das Pro 16 Plus ist ein rundum solide verarbeiteter, zuverlässiger Business-Laptop. Der neue Lunar-Lake-Prozessor macht den Copilot+PC KI- und damit zukunftstauglich. Bei Rechenleistung, Akkulaufzeit und Bildqualität schneidet das Notebook ordentlich ab, ragt aber in keiner Disziplin heraus. Das macht ihn zum Allrounder für den Business-Einsatz besonders in größeren Unternehmen, auf die das Pro 16 Plus bei Ausstattung und Reparaturfähigkeit zugeschnitten ist. Vor allem, wer bei der Büroarbeit eine große Bildschirmfläche für Excel-Tabellen und Powerpoint-Präsentationen benötigt, darf beim 16-Zoll-Notebooks zugreifen. Weitere Profi-Notebooks für unterwegs, das Home-Office oder Büro finden Sie in unserem großen Vergleichs-Test der besten Business-Laptops . Mit dem Pro 16 Plus läutet Dell eine neue Ära bei seinen Notebooks ein: Verschwunden sind die bekannten Markennamen XPS, Inspiron, Latitude und Precision. Ab jetzt heißen die Laptops für Privatanwender Dell, die Business-Geräte Dell Pro und die High-End- und Workstation-Varianten Dell Pro Max. Innerhalb der jeweiligen Serien gibt es die Ausstattungsstufen Base, Plus und Premium. Das Dell Pro 16 Plus lässt sich somit als Business-Notebook der oberen Mittelklasse und als Nachfolger der Latitude-7000er-Serie einordnen. Beim Gehäusedesign hat sich wenig getan: Gegenüber dem Vorgänger 7650 bekommt das Pro 16 Plus eine breitere Tastatur inklusive Nummernblock. Das hellgraue Aluminiumgehäuse versprüht statt Chefetagen-Chic die businesskonforme Eleganz eines Großraumbüros. Aber genau dort soll das Pro 16 Plus seinen Platz finden als produktive Arbeitsmaschine mit großem Display und einem Prozessor aus Intels Lunar-Lake-Generation: Diese Kombination ist bei Copilot+PCs noch recht einzigartig. Denn die sparsamen und recheneffizienten Intel-Prozessoren werden bislang vor allem in ultramobilen 13- und 14-Zoll-Laptops eingesetzt – in 16-Zoll-Modellen sind sie noch selten. Thomas Rau Wie bei Dell üblich, gibt es das Pro 16 Plus in zahlreichen Ausstattungsvarianten, deren Preise bei rund 1600 Euro beginnen. Das Testgerät mit Intel Core Ultra 7 268V, 32B RAM, 1-TB-SSD und 16-Zoll-Bildschirm mit FHD+ kostet rund 2350 Euro. Der Prozessor bietet gegenüber dem vor allem in Consumer-Notebooks häufig zu findenden Core Ultra 7 258V einen etwas höheren Turbo-Takt sowie eine minimal schnellere NPU und CPU-Grafik. Wichtiger fürs Dell Pro ist, dass er Intels vPro-Technik unterstützt, womit sich das Notebook im Unternehmen leichter administrieren und besser schützen lässt. Leistungstests zeigen keinen Unterschied zwischen dem 268V und einem 258V mit der gleichen mittleren Leistungsaufnahme von 25 Watt. Minimal schneller ist das Dell-Notebook lediglich im Vergleich zu Lunar-Lake-Laptops, in denen ein 258V nur rund 20 Watt verbrauchen darf – aber auch dann nur bei CPU-lastigen Aufgaben wie Rendering oder Fotobearbeitung. Insgesamt bietet das Dell Pro ein ausgewogenes Rechentempo bei allen business-relevanten Anwendungen: Im PC Mark 10 ist es ähnlich leistungsstark wie Notebooks mit dem deutlich leistungshungrigerem Core Ultra 7 155H aus der Meteor-Lake-Generation, hat aber aufgrund der verbesserten internen GPU Arc 140V Vorteile bei grafiklastigen Rendering- und Videoschnitt-Programmen. Im System-Benchmark Crossmark hängt es Notebooks mit einem Prozessor aus der Vorgängergeneration um rund 15 Prozent ab. Beim Vergleich mit ARM-Notebooks, die einen Snapdragon X Elite einsetzen, zeigt das Dell Pro das gleiche Verhalten wie alle Lunar-Lake-Laptops: Bei hoher CPU-Last ist es dem Qualcomm-Prozessor klar unterlegen, benötigt ein Programm nur wenige Kerne, liegt es vorne. Am deutlichsten erweist sich das im beliebten, aber wenig praxisnahem Prozessor-Benchmark Cinebench R24: Beim Multi-Core-Test fehlen dem Dell Pro 16 Plus rund 20 Prozent auf Notebooks mit dem Snapdragon X Elite E78, beim Single-Core-Test ist es genau andersherum. In der Praxis fällt dieser Unterschied vor allem bei Office-Tests auf, wo das Dell Pro stärker bei Word, aber schwächer bei Excel ist: Insgesamt liegen Snapdragon und Lunar Lake beim Büroeinsatz aber gleichauf. Gleiches gilt für die Recheneffizienz, wo beide Konkurrenten rund 23 Cinebench-Punkte pro Watt erreichen: Die Snapdragon-Notebooks mit X Elite sind schneller, verbrauchen aber minimal mehr, bei Lunar-Lake-Laptops ist es umgekehrt. Als Copilot+PC erfüllt das Dell Pro 16 Plus dank der NPU des Intel-Prozessors die KI-Vorgaben von Microsoft. Im KI-Benchmark Procyon AI Computer Vision schneidet es aber etwas schlechter ab als die meisten anderen KI-Notebooks mit Lunar Lake oder Snapdragon-Prozessor. Thomas Rau Im Arbeitsalltag mit dem Dell Pro fällt störend auf, dass der Lüfter oft aktiv ist – selbst, wenn nur geringe Rechenleistung gefordert ist. Zwar bleibt das Betriebsgeräusch unter Last gemessen etwas niedriger als bei anderen Notebooks mit Lunar Lake. Die sind aber häufig ganz still, während das Dell fast immer hörbar arbeitet und damit in einer sehr ruhigen Arbeitsumgebung auffällt. Das große Dell Pro 16 Plus bietet viele Anschlüsse wie Thunderbolt 4, USB Typ-A, Micro-SD-Kartenleser und HDMI-Ausgang – optimal für ein Schreibtisch-Gerät, da sich so viele Peripheriegeräte ohne Adapter oder Docking-Station nutzen lassen. Ein Ethernet-Port fehlt, dafür gibt es WLAN mit dem aktuellen Standard Wi-Fi 7. Optional lässt sich das Dell-Notebook mit einem Smartcard-Leser und einem 5G-Modem inklusive Nano-SIM-Einschub ausstatten. Die Kamera löst mit 1440p auf und eignet sich daher sehr gut für Video-Meetings. Die Linse können Sie mit einer mechanischen Abdeckung im Displaydeckel verschließen. Zudem arbeitet die Kamera mit einem Näherungssensor, um den Sperrbildschirm zu aktivieren, wenn Sie sich vom Notebook entfernen und die Displayhelligkeit zu reduzieren, wenn Sie nicht auf den Bildschirm schauen. Servicetechniker erleichtert Dell das Reparieren: Die acht Gehäuseschrauben sind verliersicher und fallen daher nicht sofort heraus, wenn Sie sie aufdrehen. Zudem besitzt das Pro 16 Plus laut Dell als erstes Notebook modulare Typ-C-Ports: Sie sind verschraubt statt verlötet und lassen sich deswegen einfacher ersetzen. Selbst sollten Sie das aber nicht probieren, denn dazu muss die Platine ausgebaut werden, weil sich die Schrauben der USB-C-Module auf deren Unterseite befinden. Thomas Rau Mit einem Gewicht von knapp unter zwei Kilogramm, gehört das Notebook nicht zu den leichtesten 16-Zoll-Modellen. Trotzdem lässt es sich auf kürzeren Strecken bequem transportieren – zum Beispiel zwischen Wohnung und Büro oder innerhalb des Unternehmens. Die Akkulaufzeit geht in Ordnung: Im WLAN-Test erreicht das Dell-Notebook eine Laufzeit von über 14 Stunden, im Office-Einsatz sind es 12 Stunden. Mit einem größeren Akku würde die Ausdauer noch deutlich besser ausfallen, da das Pro 16 mit einer Leistungsaufnahme von unter vier Watt im Akkubetrieb sehr sparsam arbeitet – vor allem, weil es ein LCD-Display statt OLED nutzt. Doch sein Akku fasst nur 55 Wattstunden, mit größerem Akku laufen Lunar-Lake-Laptops zwei bis vier Stunden länger. Das passt aber zum Einsatzzweck des 16-Zöllers: Er ist für den gelegentlichen Akkubetrieb gedacht, nicht als ultramobiler Laptop, mit dem Sie einen ganzen Tag unterwegs arbeiten. Mit Standardeinstellungen lädt das Notebook sehr gemächlich: Nach einer Stunde an der Steckdose ist es nur zu 51 Prozent geladen – das wiederum verlängert die Lebensdauer des Akkus. Thomas Rau Beim Bildschirm können Sie zwischen Displayvarianten mit und ohne Touchscreen wählen und bei der Auflösung zwischen FHD+ und QHD+. Die Auflösung des Testmodells beträgt 1920 x 1200 und ist damit sinnvoll für den Büroalltag. Ebenso alltagstauglich für den Einsatz am Schreibtisch sind die Messergebnisse bei Helligkeit, Kontrast und Ausleuchtung – die Werte sind nicht überragend, aber absolut in Ordnung für Word, Excel und Powerpoint. Das Dell Pro 16 Plus ist aber kein Laptop, den Sie sich wegen der Bildqualität kaufen sollten. Denn die mäßige Farbwiedergabe mit geringer Farbraumabdeckung und Farbtreue disqualifiziert es für ambitionierte Foto- oder Videobearbeitung. Andere Laptops mit LCD bieten eine höhere Maximalhelligkeit und lassen sich daher unter verschiedenen Lichtbedingungen flexibler nutzen. Der Vorteil beim Dell-Notebook ist dafür seine entspiegelte Bildschirmoberfläche. Der Nummernblock rechts in der Tastatur erleichtert die schnelle Eingabe von Zahlen und dürfte daher Excel-Arbeiter begeistern – zumal diese Tasten fast genauso groß sind wie in der Haupt-Tastatur. Beim Layout fällt die zweizeilige, aber schmale Enter-Taste auf, die Pfeiltasten sind nicht abgesetzt. Auf der Tastatur lässt sich angenehm tippen, denn sie ist sehr stabil eingebaut, die Tasten verfügen über einen klaren Druckpunkt und einen guten Hub. Besonders leise ist sie aber nicht. Auch das große Touchpad gibt eine deutlich spürbare Klick-Rückmeldung, auf der rechten Seite fühlt es sich aber etwas schwammig an.",
    "source": "cio",
    "crawled_at": "2025-05-27T08:10:58.825900+00:00"
  },
  {
    "url": "https://www.cio.de/article/3694592/den-lebenslauf-fuer-algorithmen-optimieren.html",
    "title": "Den Lebenslauf für Algorithmen optimieren",
    "published": "2025-05-26T06:10:53+00:00",
    "author": "",
    "text": "Um zu einem Gespräch eingeladen zu werden, sollte in das Zusammenstellen der Bewerbungsunterlagen Zeit investiert werden. Ist bei der Vorsortierung eine künstliche Intelligenz im Spiel, heißt es zudem, einige Standards zu beachten. Foto: Lisa-S – shutterstock.com Eine Umfrage hat ergeben, dass ein Großteil, nämlich etwa zwei Drittel der sich Bewerbenden , sich gar nicht über den Einsatz von Algorithmen im Bewerbungsprozess bewusst sind. Auch wenn sich dies mittlerweile schätzungsweise zu etwa einem Gleichgewicht verschoben haben dürfte, gibt es dennoch viele, denen dies nicht bewusst ist. Merken Sie sich daher zunächst die Faustformel: Je größer das Unternehmen, desto höher die Chance, dass Algorithmen bei der Bewertung Ihrer Bewerbung involviert sind. Dies gilt vor allem für einfache Algorithmen, die z.B. ein Matching vornehmen oder bestimmte Aspekte sortieren, sowie kategorisieren und katalogisieren. Denn sobald ein Algorithmus im Rahmen des Prozesses auch aktiv eine “Entscheidung trifft”, ist nach DSGVO die Zustimmung der betroffenen Person erforderlich und Sie haben das Recht, Informationen über die zugrundeliegende Entscheidungslogik zu erhalten. Lesen Sie daher im Idealfall vor der Bewerbung aufmerksam die Datenschutzbestimmungen des Unternehmens. Wenn Sie nun aber wissen oder davon ausgehen, dass ein Unternehmen Algorithmen für die Bearbeitung von Bewerbungen einsetzt, dann gibt es eine ganze Menge Tipps und Kniffe, wie Sie dies zu Ihrem Vorteil nutzen können. Algorithmen verarbeiten Informationen vor allem dann besonders zuverlässig, wenn Sie klar strukturiert und innerhalb dieser Struktur logisch angeordnet sind. Versehen Sie daher sämtliche Teilbereiche Ihres Lebenslaufs mit entsprechenden Überschriften, wie “Ausbildung”, “Berufserfahrungen” etc. Achten Sie anschließend darauf, dass Sie diese Struktur stringent einhalten und die Sortierung einheitlich ist. Üblich ist mittlerweile eine antichronologische Auflistung. Verzichten Sie aus diesem Grund auch lieber auf allzu ausgefallene und kreative Designs, schräge Anordnungen, sowie Tabellen, Logos oder Piktogramme, da diese die Dokumentenstruktur unterlaufen. Geben Sie Beschäftigungszeiten niemals nur in Jahren an – offen gesagt hassen das bereits die menschlichen Personalerinnen und Personaler –, sondern immer mit den dazugehörigen Monaten. Haben Sie diese vergessen? Dann finden Sie die Information im jeweiligen Arbeitszeugnis. Sie möchten damit Lücken kaschieren? Das ist sowieso die Vermutung des Personalers oder der Personalerin. In aller Regel “achten” Algorithmen in einer Bewerbung auf bestimmte Stichworte, die Sie in der Regel in der Stellenausschreibung finden. Allerdings liegt der Fokus hierauf vor allem auf fachlichen Anforderungen, weniger auf persönlichen. Kaum ein Algorithmus wird Ihre Bewerbung beispielsweise nach “Kommunikationsfähigkeit” oder “Kundenorientierung” durchleuchten. Wenn in der Ausschreibung aber bestimmte, fachliche Anforderungen genannt werden, wie z.B. bestimmte Technologien und Programmiersprachen bei IT-Positionen, dann müssen diese unbedingt in die Bewerbung mit aufgenommen werden, und zwar im exakten Wortlaut der Stellenanzeige. Weitere Informationen zu fachlich relevanten Themen und Stichworten, auf die auch der Algorithmus möglicherweise reagiert, finden Sie auf der Webseite des Unternehmens. Achten Sie dabei darauf, dass für Ihre angestrebte Position sowohl lokale, als auch globale Begrifflichkeiten gebräuchlich sein könnten und versuchen Sie entsprechend, alle Optionen zu berücksichtigen. Wenn Sie eine Skill-Liste erstellen, ergänzen Sie die einzelnen Fähigkeiten bestenfalls um Ihr Kenntnisniveau. Hierzu sollten Sie Begriffe nutzen, bei denen Sie mit an Sicherheit grenzender Wahrscheinlichkeit davon ausgehen können, dass der Algorithmus diese interpretieren kann – wie z.B. “Expert”, “fortgeschritten” usw. Lesetipp: Fieser Code – Wenn Algorithmen Vorurteile ausspucken Reine Skill-Listen ergeben jedoch ohnehin nur dann Sinn, wenn es um Aufgaben mit einer Vielzahl fachlicher Anforderungen geht, wie z.B. in der Softwareentwicklung. Achten Sie dann darauf, dass Sie die Liste auch für menschliche Augen ansprechend und nachvollziehbar ist. Sollten für Sie hingegen nur einige Kernfähigkeiten relevant sein, dann kann es mehr Sinn machen, die Fähigkeiten anhand praktischer Erfahrungen aufzuführen. Da viele Algorithmen Profile mittlerweile semantisch nach Inhalten durchleuchten, sollte dies der Erfassung Ihrer Fähigkeiten in aller Regel nicht schaden. In den letzten Jahren häufen sich in Bewerbungen sogenannte Management Summaries oder “Kurzprofile”. Diese sind mitunter gar nicht so kurz, wie der Name vermuten lässt. Doch ist hierbei Vorsicht geboten. Denn ausschweifende Formulierungen und irrelevante Informationen sorgen für eine möglicherweise ungenauere oder sogar falsche Klassifizierung durch den Algorithmus. Gleichzeitig sollten Sie darauf achten, die “Sprache des Unternehmens” zu sprechen. Auch hier bietet Ihnen bereits die Stellenanzeige wichtige Anhaltspunkte. Wenn es für einen Sachverhalt Ihrer Arbeit mehrere, unterschiedliche Formulierungen gibt, nutzen Sie immer diejenige, die auch in dem Unternehmen verwendet wird, in dem Sie sich bewerben. Nehmen Sie übrigens lieber Abstand davon, Ihre Teamfähigkeit, Flexibilität, Kreativität, Belastbarkeit usw. in Ihrer Bewerbung zu betonen. Zum einen sucht kein HR-Algorithmus dieser Welt nach diesen Begriffen und zum anderen sind diese Worthülsen ohne konkrete Beispiele aus der Praxis für Ihre Bewerbung auch für den menschlichen Betrachter im Unternehmen nutzlos. Der Tipp, Rechtschreibfehler in der Bewerbung zu vermeiden, ist sicherlich nicht erst seit dem Einsatz von Algorithmen gültig und wichtig. Doch während das menschliche Auge über manchen Rechtschreibfehler genauso flüchtig hinwegliest, wie er auch entstanden ist, oder der menschliche Leser diesen sanftmütig toleriert, wird ein Algorithmus in den meisten Fällen unverzeihlich aussortieren. Der Begriff, den Sie ja eigentlich auch meinen, kommt für den Algorithmus im Dokument schlicht nicht vor. Wenn Sie beispielsweise anstatt “Kreditorenbuchhaltung” laut Ihrem Lebenslauf Erfahrungen in “Kreditprenbuchhaltung” haben, dann wird der Algorithmus Ihnen diese Fähigkeit einfach nicht zuerkennen. Achten Sie unbedingt darauf, dass Ihr finales Dokument maschinenlesbar und das Kopieren von Text möglich ist. Verzichten Sie außerdem auf irrelevante Informationen, wie z.B. Namen, Geburtsdatum oder gar Beruf der Eltern, denn solche Informationen “verwirren” den Algorithmus. Nehmen Sie übrigens auch lieber Abstand von dem Gedanken, Ihre Stichwortliste noch um ein paar interessante, aber nicht zutreffende Begriffe mit weißer Schrift auf weißem Grund zu ergänzen. Manch ein Algorithmus erkennt mittlerweile sehr wohl auch die Textfarbe. Zudem werden Sie ja auch in möglicherweise anschließenden Gesprächen gezielt auf diese Kenntnisse hin befragt. Spätestens dann sollte ein solcher “Täuschungsversuch” auffallen und Sie haben bei diesem Unternehmen keine Chancen mehr. Daher empfiehlt sich gegenüber dem Algorithmus schon im eigenen Interesse Ehrlichkeit bei der Bewerbung. Befolgen Sie diese Kniffe bei der Erstellung Ihrer Vita, sollte Ihre Vita so aufbereitet sein, dass sie die erste Hürde im Recruiting-Prozess gut meistert – egal ob der erste Empfänger ein Mensch oder eine Künstliche Intelligenz ist. Um zu einem Gespräch eingeladen zu werden, sollte in das Zusammenstellen der Bewerbungsunterlagen Zeit investiert werden. Ist bei der Vorsortierung eine künstliche Intelligenz im Spiel, heißt es zudem, einige Standards zu beachten. Foto: Lisa-S – shutterstock.com Eine Umfrage hat ergeben, dass ein Großteil, nämlich etwa zwei Drittel der sich Bewerbenden , sich gar nicht über den Einsatz von Algorithmen im Bewerbungsprozess bewusst sind. Auch wenn sich dies mittlerweile schätzungsweise zu etwa einem Gleichgewicht verschoben haben dürfte, gibt es dennoch viele, denen dies nicht bewusst ist. Merken Sie sich daher zunächst die Faustformel: Je größer das Unternehmen, desto höher die Chance, dass Algorithmen bei der Bewertung Ihrer Bewerbung involviert sind. Dies gilt vor allem für einfache Algorithmen, die z.B. ein Matching vornehmen oder bestimmte Aspekte sortieren, sowie kategorisieren und katalogisieren. Denn sobald ein Algorithmus im Rahmen des Prozesses auch aktiv eine “Entscheidung trifft”, ist nach DSGVO die Zustimmung der betroffenen Person erforderlich und Sie haben das Recht, Informationen über die zugrundeliegende Entscheidungslogik zu erhalten. Lesen Sie daher im Idealfall vor der Bewerbung aufmerksam die Datenschutzbestimmungen des Unternehmens. Wenn Sie nun aber wissen oder davon ausgehen, dass ein Unternehmen Algorithmen für die Bearbeitung von Bewerbungen einsetzt, dann gibt es eine ganze Menge Tipps und Kniffe, wie Sie dies zu Ihrem Vorteil nutzen können. Algorithmen verarbeiten Informationen vor allem dann besonders zuverlässig, wenn Sie klar strukturiert und innerhalb dieser Struktur logisch angeordnet sind. Versehen Sie daher sämtliche Teilbereiche Ihres Lebenslaufs mit entsprechenden Überschriften, wie “Ausbildung”, “Berufserfahrungen” etc. Achten Sie anschließend darauf, dass Sie diese Struktur stringent einhalten und die Sortierung einheitlich ist. Üblich ist mittlerweile eine antichronologische Auflistung. Verzichten Sie aus diesem Grund auch lieber auf allzu ausgefallene und kreative Designs, schräge Anordnungen, sowie Tabellen, Logos oder Piktogramme, da diese die Dokumentenstruktur unterlaufen. Geben Sie Beschäftigungszeiten niemals nur in Jahren an – offen gesagt hassen das bereits die menschlichen Personalerinnen und Personaler –, sondern immer mit den dazugehörigen Monaten. Haben Sie diese vergessen? Dann finden Sie die Information im jeweiligen Arbeitszeugnis. Sie möchten damit Lücken kaschieren? Das ist sowieso die Vermutung des Personalers oder der Personalerin. In aller Regel “achten” Algorithmen in einer Bewerbung auf bestimmte Stichworte, die Sie in der Regel in der Stellenausschreibung finden. Allerdings liegt der Fokus hierauf vor allem auf fachlichen Anforderungen, weniger auf persönlichen. Kaum ein Algorithmus wird Ihre Bewerbung beispielsweise nach “Kommunikationsfähigkeit” oder “Kundenorientierung” durchleuchten. Wenn in der Ausschreibung aber bestimmte, fachliche Anforderungen genannt werden, wie z.B. bestimmte Technologien und Programmiersprachen bei IT-Positionen, dann müssen diese unbedingt in die Bewerbung mit aufgenommen werden, und zwar im exakten Wortlaut der Stellenanzeige. Weitere Informationen zu fachlich relevanten Themen und Stichworten, auf die auch der Algorithmus möglicherweise reagiert, finden Sie auf der Webseite des Unternehmens. Achten Sie dabei darauf, dass für Ihre angestrebte Position sowohl lokale, als auch globale Begrifflichkeiten gebräuchlich sein könnten und versuchen Sie entsprechend, alle Optionen zu berücksichtigen. Wenn Sie eine Skill-Liste erstellen, ergänzen Sie die einzelnen Fähigkeiten bestenfalls um Ihr Kenntnisniveau. Hierzu sollten Sie Begriffe nutzen, bei denen Sie mit an Sicherheit grenzender Wahrscheinlichkeit davon ausgehen können, dass der Algorithmus diese interpretieren kann – wie z.B. “Expert”, “fortgeschritten” usw. Lesetipp: Fieser Code – Wenn Algorithmen Vorurteile ausspucken Reine Skill-Listen ergeben jedoch ohnehin nur dann Sinn, wenn es um Aufgaben mit einer Vielzahl fachlicher Anforderungen geht, wie z.B. in der Softwareentwicklung. Achten Sie dann darauf, dass Sie die Liste auch für menschliche Augen ansprechend und nachvollziehbar ist. Sollten für Sie hingegen nur einige Kernfähigkeiten relevant sein, dann kann es mehr Sinn machen, die Fähigkeiten anhand praktischer Erfahrungen aufzuführen. Da viele Algorithmen Profile mittlerweile semantisch nach Inhalten durchleuchten, sollte dies der Erfassung Ihrer Fähigkeiten in aller Regel nicht schaden. In den letzten Jahren häufen sich in Bewerbungen sogenannte Management Summaries oder “Kurzprofile”. Diese sind mitunter gar nicht so kurz, wie der Name vermuten lässt. Doch ist hierbei Vorsicht geboten. Denn ausschweifende Formulierungen und irrelevante Informationen sorgen für eine möglicherweise ungenauere oder sogar falsche Klassifizierung durch den Algorithmus. Gleichzeitig sollten Sie darauf achten, die “Sprache des Unternehmens” zu sprechen. Auch hier bietet Ihnen bereits die Stellenanzeige wichtige Anhaltspunkte. Wenn es für einen Sachverhalt Ihrer Arbeit mehrere, unterschiedliche Formulierungen gibt, nutzen Sie immer diejenige, die auch in dem Unternehmen verwendet wird, in dem Sie sich bewerben. Nehmen Sie übrigens lieber Abstand davon, Ihre Teamfähigkeit, Flexibilität, Kreativität, Belastbarkeit usw. in Ihrer Bewerbung zu betonen. Zum einen sucht kein HR-Algorithmus dieser Welt nach diesen Begriffen und zum anderen sind diese Worthülsen ohne konkrete Beispiele aus der Praxis für Ihre Bewerbung auch für den menschlichen Betrachter im Unternehmen nutzlos. Der Tipp, Rechtschreibfehler in der Bewerbung zu vermeiden, ist sicherlich nicht erst seit dem Einsatz von Algorithmen gültig und wichtig. Doch während das menschliche Auge über manchen Rechtschreibfehler genauso flüchtig hinwegliest, wie er auch entstanden ist, oder der menschliche Leser diesen sanftmütig toleriert, wird ein Algorithmus in den meisten Fällen unverzeihlich aussortieren. Der Begriff, den Sie ja eigentlich auch meinen, kommt für den Algorithmus im Dokument schlicht nicht vor. Wenn Sie beispielsweise anstatt “Kreditorenbuchhaltung” laut Ihrem Lebenslauf Erfahrungen in “Kreditprenbuchhaltung” haben, dann wird der Algorithmus Ihnen diese Fähigkeit einfach nicht zuerkennen. Achten Sie unbedingt darauf, dass Ihr finales Dokument maschinenlesbar und das Kopieren von Text möglich ist. Verzichten Sie außerdem auf irrelevante Informationen, wie z.B. Namen, Geburtsdatum oder gar Beruf der Eltern, denn solche Informationen “verwirren” den Algorithmus. Nehmen Sie übrigens auch lieber Abstand von dem Gedanken, Ihre Stichwortliste noch um ein paar interessante, aber nicht zutreffende Begriffe mit weißer Schrift auf weißem Grund zu ergänzen. Manch ein Algorithmus erkennt mittlerweile sehr wohl auch die Textfarbe. Zudem werden Sie ja auch in möglicherweise anschließenden Gesprächen gezielt auf diese Kenntnisse hin befragt. Spätestens dann sollte ein solcher “Täuschungsversuch” auffallen und Sie haben bei diesem Unternehmen keine Chancen mehr. Daher empfiehlt sich gegenüber dem Algorithmus schon im eigenen Interesse Ehrlichkeit bei der Bewerbung. Befolgen Sie diese Kniffe bei der Erstellung Ihrer Vita, sollte Ihre Vita so aufbereitet sein, dass sie die erste Hürde im Recruiting-Prozess gut meistert – egal ob der erste Empfänger ein Mensch oder eine Künstliche Intelligenz ist.",
    "source": "cio",
    "crawled_at": "2025-05-27T08:10:58.907138+00:00"
  },
  {
    "url": "https://www.cio.de/article/3831704/cio-des-jahres-2025-wettbewerb-startet-2.html",
    "title": "Bewerben Sie sich noch bis 30. Mai für den CIO des Jahres 2025",
    "published": "2025-05-26T07:14:25+00:00",
    "author": "",
    "text": "cio.de / Tobias Tschepe Es ist wieder so weit: Der renommierteste IT-Award Deutschlands ist startklar. Bis zum 30. Mai 2025 laden wir CIOs, IT-Vorstände aber auch CISOs und Digital-Verantwortliche aus Unternehmen sowie Öffentlichen Einrichtungen in Bund, Ländern und Kommunen herzlich ein, sich mit spannenden IT-Projekten für den „CIO des Jahres 2025“ zu bewerben. +++ Machen Sie mit beim CIO des Jahres Award 2025 +++ Wie immer küren wir die Gewinnerinnen und Gewinner in den Kategorien Großunternehmen, Mittelstand und Public Sector. Darüber hinaus vergibt die Jury wieder eine Reihe von Special Awards – unter anderem zu den Themen Artificial Intelligence, Customer Experience, Cloud Excellence und Sustainability. Alle Preisträgerinnen und Preisträger sowie die Finalistinnen und Finalisten, die es unter die jeweiligen Top-5 geschafft haben, zeichnen wir im Rahmen unserer feierlichen Award-Gala am 16. Oktober 2025 in München aus. Machen Sie also mit und bewerben Sie sich für den CIO des Jahres 2025 . Wir freuen uns auf Ihre Teilnahme. Alle weiteren Informationen zum Wettbewerb und alle Unterlagen finden Sie ab sofort hier . cio.de / Tobias Tschepe Es ist wieder so weit: Der renommierteste IT-Award Deutschlands ist startklar. Bis zum 30. Mai 2025 laden wir CIOs, IT-Vorstände aber auch CISOs und Digital-Verantwortliche aus Unternehmen sowie Öffentlichen Einrichtungen in Bund, Ländern und Kommunen herzlich ein, sich mit spannenden IT-Projekten für den „CIO des Jahres 2025“ zu bewerben. +++ Machen Sie mit beim CIO des Jahres Award 2025 +++ Wie immer küren wir die Gewinnerinnen und Gewinner in den Kategorien Großunternehmen, Mittelstand und Public Sector. Darüber hinaus vergibt die Jury wieder eine Reihe von Special Awards – unter anderem zu den Themen Artificial Intelligence, Customer Experience, Cloud Excellence und Sustainability. Alle Preisträgerinnen und Preisträger sowie die Finalistinnen und Finalisten, die es unter die jeweiligen Top-5 geschafft haben, zeichnen wir im Rahmen unserer feierlichen Award-Gala am 16. Oktober 2025 in München aus. Machen Sie also mit und bewerben Sie sich für den CIO des Jahres 2025 . Wir freuen uns auf Ihre Teilnahme. Alle weiteren Informationen zum Wettbewerb und alle Unterlagen finden Sie ab sofort hier .",
    "source": "cio",
    "crawled_at": "2025-05-27T08:10:59.000972+00:00"
  },
  {
    "url": "https://www.cio.de/article/3992261/heute-startet-der-cio-charity-runandbike-2025.html",
    "title": "Der CIO Charity Run&Bike 2025 ist live!",
    "published": "2025-05-26T07:22:35+00:00",
    "author": "",
    "text": "Foundry Es geht los! Vom 23. Mai bis 9. Juni 2025 sporteln Deutschlands IT-Verantwortliche im Rahmen den CIO Charity Run&Bike gemeinsam für den guten Zweck. Über 1.000 IT-Verantwortliche haben sich bereits angemeldet. Kurzentschlossene können sich weiterhin registrieren: https://www.cio-charity.de/ Egal ob Laufschuh, Fahrrad oder Rollstuhl: mit jedem gemeinsam erzielten Kilometer unterstützt die Charity-Aktion der CIO-Community gemeinnützige Organisationen für mehr Bildungsgerechtigkeit, Chancengleichheit sowie die digitale Integration von benachteiligten Jugendlichen und jungen Erwachsenen. Verfolgt die Aktion und teilt euren Beitrag in den sozialen Medien unter dem Hashtag #CIOcharity25. „Unterstützen benachteiligter Kinder ist ganz viele Schweißtropfen wert“, bringt Peter Meyerhans, CIO bei der Drees & Sommer SE, den Grund für das rege Interesse deutscher CIOs an der Spendenaktion auf den Punkt. Markus Bentele, VP Information Technology / Group CIO und Mitglied des Aufsichtsrats bei der Mahle GmbH, freut sich auch in diesem Jahr auf die Veranstaltung und appelliert an die Community: „Wir haben auch als CIOs eine soziale Mitverantwortung und deswegen lasst uns sporteln für den guten Zweck. Mit jedem erzielten Kilometer, egal ob Laufschuh, Fahrrad oder Rollstuhl unterstützten wir die Charity-Aktion der CIO-Community und damit gemeinnützige Organisationen für mehr Bildungsgerechtigkeit, Chancengleichheit und die digitale Integration von benachteiligten Jugendlichen und jungen Erwachsenen – Also nicht nachdenken, sondern laufen, radeln oder rollen.“ 2025 unterstützt der CIO Charity Run&Bike die START-Stiftung und Save the Children. START setzt sich seit 2002 für Chancengerechtigkeit ein, indem die Stiftung deutschlandweit Jugendliche mit Migrationshintergrund in Bildung und Engagement fördert. Das Sozialunternehmen bietet ihnen Ressourcen, Netzwerke und Zugangsmöglichkeiten, um ihre Zukunft aktiv zu gestalten und einen gesellschaftlichen Beitrag zu leisten. Mehr zur START-Stiftung und deren Förderinitiativen lest ihr im ausführlichen Artikel: „CIO Charity Run&Bike 2025 – Lernen Sie die START-Stiftung kennen“ Save the Children ist die weltweit größte unabhängige Kinderrechtsorganisation. Sie unterstützt Kinder und ihre Familien in Deutschland und rund 120 Ländern. Die Organisation agiert unparteiisch und unabhängig von politischen, religiösen oder anderen Bindungen, mit dem Ziel, die Rechte und das Wohlergehen aller Kinder zu fördern. Mehr zum Engagement von Save the Children und welchen Impact jeder gespendete Euro hat, erfahrt ihr im Artikel: „CIO Charity Run&Bike 2025 – Lernen Sie Save the Children kennen“ Der Spendentopf ist bereits jetzt mit 75.000 Euro gefüllt. Dafür danken wir unseren Partnern: Acent, Adesso, Faktor D Consulting, Infosys, p.digital, Randstad digital, Servicenow, Skaylink, Tata Consultancy Services (TCS) und Foundry. Außerdem kann der Spendentopf durch Direktspenden weiter befüllt werden! Der Spender mit der höchsten Direktspende erhält in diesem Jahr ein Bild des Performancekünstlers Michael Raivard! Hier geht es zur Direktspende: https://www.betterplace.org/de/fundraising-events/48834-cio-charity-run-bike25 Wer lieber gemeinsam mit anderen für den guten Zweck laufen möchte, ist herzlich zum Local Run am 27. Mai 2025 in Frankfurt am Main eingeladen. Local-Run-Partner ist Tata Consultancy Services (TCS). Die Strecke ist ein Rundweg und einen Kilometer lang. Jeder kann so viele Runde drehen, wie er möchte. Hier findet Ihr alle Informationen dazu: CIO Charity Run&Bike 25 ist eine Aktion von CIO, CIO Stiftung und WHU. Seit 2011 unterstützen die Charity-Initiativen der CIO-Community Kinder und Jugendliche, die einen erschwerten Zugang zu Bildungsmöglichkeiten haben – aus finanziellen oder sozialen Gründen. Jedes Jahr wählt das Kuratorium der CIO-Stiftung zwei Förderinitiativen als Nutznießer der Aktion, die sich der Förderungen der gesellschaftlichen und digitalen Teilhabe verschrieben haben. Foundry Es geht los! Vom 23. Mai bis 9. Juni 2025 sporteln Deutschlands IT-Verantwortliche im Rahmen den CIO Charity Run&Bike gemeinsam für den guten Zweck. Über 1.000 IT-Verantwortliche haben sich bereits angemeldet. Kurzentschlossene können sich weiterhin registrieren: https://www.cio-charity.de/ Egal ob Laufschuh, Fahrrad oder Rollstuhl: mit jedem gemeinsam erzielten Kilometer unterstützt die Charity-Aktion der CIO-Community gemeinnützige Organisationen für mehr Bildungsgerechtigkeit, Chancengleichheit sowie die digitale Integration von benachteiligten Jugendlichen und jungen Erwachsenen. Verfolgt die Aktion und teilt euren Beitrag in den sozialen Medien unter dem Hashtag #CIOcharity25. „Unterstützen benachteiligter Kinder ist ganz viele Schweißtropfen wert“, bringt Peter Meyerhans, CIO bei der Drees & Sommer SE, den Grund für das rege Interesse deutscher CIOs an der Spendenaktion auf den Punkt. Markus Bentele, VP Information Technology / Group CIO und Mitglied des Aufsichtsrats bei der Mahle GmbH, freut sich auch in diesem Jahr auf die Veranstaltung und appelliert an die Community: „Wir haben auch als CIOs eine soziale Mitverantwortung und deswegen lasst uns sporteln für den guten Zweck. Mit jedem erzielten Kilometer, egal ob Laufschuh, Fahrrad oder Rollstuhl unterstützten wir die Charity-Aktion der CIO-Community und damit gemeinnützige Organisationen für mehr Bildungsgerechtigkeit, Chancengleichheit und die digitale Integration von benachteiligten Jugendlichen und jungen Erwachsenen – Also nicht nachdenken, sondern laufen, radeln oder rollen.“ 2025 unterstützt der CIO Charity Run&Bike die START-Stiftung und Save the Children. START setzt sich seit 2002 für Chancengerechtigkeit ein, indem die Stiftung deutschlandweit Jugendliche mit Migrationshintergrund in Bildung und Engagement fördert. Das Sozialunternehmen bietet ihnen Ressourcen, Netzwerke und Zugangsmöglichkeiten, um ihre Zukunft aktiv zu gestalten und einen gesellschaftlichen Beitrag zu leisten. Mehr zur START-Stiftung und deren Förderinitiativen lest ihr im ausführlichen Artikel: „CIO Charity Run&Bike 2025 – Lernen Sie die START-Stiftung kennen“ Save the Children ist die weltweit größte unabhängige Kinderrechtsorganisation. Sie unterstützt Kinder und ihre Familien in Deutschland und rund 120 Ländern. Die Organisation agiert unparteiisch und unabhängig von politischen, religiösen oder anderen Bindungen, mit dem Ziel, die Rechte und das Wohlergehen aller Kinder zu fördern. Mehr zum Engagement von Save the Children und welchen Impact jeder gespendete Euro hat, erfahrt ihr im Artikel: „CIO Charity Run&Bike 2025 – Lernen Sie Save the Children kennen“ Der Spendentopf ist bereits jetzt mit 75.000 Euro gefüllt. Dafür danken wir unseren Partnern: Acent, Adesso, Faktor D Consulting, Infosys, p.digital, Randstad digital, Servicenow, Skaylink, Tata Consultancy Services (TCS) und Foundry. Außerdem kann der Spendentopf durch Direktspenden weiter befüllt werden! Der Spender mit der höchsten Direktspende erhält in diesem Jahr ein Bild des Performancekünstlers Michael Raivard! Hier geht es zur Direktspende: https://www.betterplace.org/de/fundraising-events/48834-cio-charity-run-bike25 Wer lieber gemeinsam mit anderen für den guten Zweck laufen möchte, ist herzlich zum Local Run am 27. Mai 2025 in Frankfurt am Main eingeladen. Local-Run-Partner ist Tata Consultancy Services (TCS). Die Strecke ist ein Rundweg und einen Kilometer lang. Jeder kann so viele Runde drehen, wie er möchte. Hier findet Ihr alle Informationen dazu: CIO Charity Run&Bike 25 ist eine Aktion von CIO, CIO Stiftung und WHU. Seit 2011 unterstützen die Charity-Initiativen der CIO-Community Kinder und Jugendliche, die einen erschwerten Zugang zu Bildungsmöglichkeiten haben – aus finanziellen oder sozialen Gründen. Jedes Jahr wählt das Kuratorium der CIO-Stiftung zwei Förderinitiativen als Nutznießer der Aktion, die sich der Förderungen der gesellschaftlichen und digitalen Teilhabe verschrieben haben.",
    "source": "cio",
    "crawled_at": "2025-05-27T08:10:59.172056+00:00"
  },
  {
    "url": "https://www.cio.de/article/3994922/fruhere-vw-manager-wegen-dieselskandal-zu-haft-verurteilt.html",
    "title": "Frühere VW-Manager wegen Dieselskandal zu Haft verurteilt",
    "published": "2025-05-26T09:27:22+00:00",
    "author": "",
    "text": "Wellnhofer Designs – shutterstock.com Im Strafprozess zur Dieselaffäre sind vier frühere Führungskräfte von Volkswagen wegen Betrugs schuldig gesprochen worden. Die Wirtschaftsstrafkammer des Landgerichts Braunschweig verurteilte zwei Angeklagte zu mehrjährigen Haftstrafen, zwei Ex-Mitarbeiter erhielten Bewährungsstrafen. Ein ehemaliger Leiter der Dieselmotoren-Entwicklung muss für viereinhalb Jahre ins Gefängnis. Zwei Jahre und sieben Monate Haft bekam der frühere Leiter der Antriebselektronik. Der ranghöchste Angeklagte, ein Ex-Entwicklungsvorstand der Marke Volkswagen, erhielt ein Jahr und drei Monate auf Bewährung. Ein ehemaliger Abteilungsleiter wurde zu einem Jahr und zehn Monaten auf Bewährung verurteilt. Mit dem Urteil geht ein riesiges Verfahren nach fast vier Jahren zu Ende. Während die Angeklagten aus Sicht der Ermittler überführt sind, wehren sich die Männer und sehen sich als Bauernopfer. Die Staatsanwaltschaft hatte zwischen zwei und vier Jahren Gefängnis gefordert und hielt nur in einem Fall Bewährung für angebracht. Die Verteidigung dagegen plädierte auf drei Freisprüche und eine Verwarnung. Das Urteil ist nicht rechtskräftig und die juristische Aufarbeitung ist auch nach diesem Schuldspruch nicht beendet. In Braunschweig sind nach dem ersten Prozess und dem Komplex gegen Winterkorn noch vier weitere Strafverfahren gegen insgesamt 31 Angeklagte offen, wie ein Sprecher des Landgerichts sagte. Der Skandal um Manipulationen bei Abgastests von Dieselautos war im September 2015 aufgeflogen. In den USA hatte der Wolfsburger Autobauer kurz zuvor falsche Testergebnisse eingeräumt. Wenige Tage später trat Konzernchef Winterkorn zurück. VW schlitterte in eine der größten Krisen, die den Konzern nach eigenen Angaben bisher etwa 33 Milliarden Euro kostete. Ursprünglich geplant war, dass der frühere Volkswagen-Konzernchef Martin Winterkorn mit auf der Anklagebank sitzt. Sein Verfahrensteil wurde aber schon vor dem Auftakt im September 2021 aus gesundheitlichen Gründen abgetrennt. Mittlerweile äußerte sich Winterkorn sowohl als Zeuge als auch als Angeklagter vor Gericht und wies dabei die Verantwortung für den Dieselskandal entschieden von sich. Ein Unfall mit einem Klinikaufenthalt unterbrach den Prozess gegen den prominentesten Angeklagten aber. Ob und wann das Verfahren gegen den mittlerweile 78-Jährigen fortgesetzt werden kann, ist völlig offen. (dpa/ad) Wellnhofer Designs – shutterstock.com Im Strafprozess zur Dieselaffäre sind vier frühere Führungskräfte von Volkswagen wegen Betrugs schuldig gesprochen worden. Die Wirtschaftsstrafkammer des Landgerichts Braunschweig verurteilte zwei Angeklagte zu mehrjährigen Haftstrafen, zwei Ex-Mitarbeiter erhielten Bewährungsstrafen. Ein ehemaliger Leiter der Dieselmotoren-Entwicklung muss für viereinhalb Jahre ins Gefängnis. Zwei Jahre und sieben Monate Haft bekam der frühere Leiter der Antriebselektronik. Der ranghöchste Angeklagte, ein Ex-Entwicklungsvorstand der Marke Volkswagen, erhielt ein Jahr und drei Monate auf Bewährung. Ein ehemaliger Abteilungsleiter wurde zu einem Jahr und zehn Monaten auf Bewährung verurteilt. Mit dem Urteil geht ein riesiges Verfahren nach fast vier Jahren zu Ende. Während die Angeklagten aus Sicht der Ermittler überführt sind, wehren sich die Männer und sehen sich als Bauernopfer. Die Staatsanwaltschaft hatte zwischen zwei und vier Jahren Gefängnis gefordert und hielt nur in einem Fall Bewährung für angebracht. Die Verteidigung dagegen plädierte auf drei Freisprüche und eine Verwarnung. Das Urteil ist nicht rechtskräftig und die juristische Aufarbeitung ist auch nach diesem Schuldspruch nicht beendet. In Braunschweig sind nach dem ersten Prozess und dem Komplex gegen Winterkorn noch vier weitere Strafverfahren gegen insgesamt 31 Angeklagte offen, wie ein Sprecher des Landgerichts sagte. Der Skandal um Manipulationen bei Abgastests von Dieselautos war im September 2015 aufgeflogen. In den USA hatte der Wolfsburger Autobauer kurz zuvor falsche Testergebnisse eingeräumt. Wenige Tage später trat Konzernchef Winterkorn zurück. VW schlitterte in eine der größten Krisen, die den Konzern nach eigenen Angaben bisher etwa 33 Milliarden Euro kostete. Ursprünglich geplant war, dass der frühere Volkswagen-Konzernchef Martin Winterkorn mit auf der Anklagebank sitzt. Sein Verfahrensteil wurde aber schon vor dem Auftakt im September 2021 aus gesundheitlichen Gründen abgetrennt. Mittlerweile äußerte sich Winterkorn sowohl als Zeuge als auch als Angeklagter vor Gericht und wies dabei die Verantwortung für den Dieselskandal entschieden von sich. Ein Unfall mit einem Klinikaufenthalt unterbrach den Prozess gegen den prominentesten Angeklagten aber. Ob und wann das Verfahren gegen den mittlerweile 78-Jährigen fortgesetzt werden kann, ist völlig offen. (dpa/ad)",
    "source": "cio",
    "crawled_at": "2025-05-27T08:10:59.386370+00:00"
  },
  {
    "url": "https://www.cio.de/article/3994686/arzteprasident-algorithmen-entscheiden-nicht-uber-behandlung.html",
    "title": "Ärztepräsident: Algorithmen entscheiden nicht über Behandlung",
    "published": "2025-05-26T09:30:25+00:00",
    "author": "",
    "text": "fizkes – shutterstock.com Ärztepräsident Klaus Reinhardt sieht große Chancen für Künstliche Intelligenz in der Medizin, mahnt aber einen verantwortungsvollen Einsatz an. «Die Entscheidung über eine Behandlung müssen immer Ärztinnen und Ärzte treffen und nicht digitale Algorithmen», sagte der Chef der Bundesärztekammer der Deutschen Presse-Agentur. «Bei aller Technologie darf die menschliche Nähe nicht verloren gehen. Sie ist das Fundament guter Medizin.» Künstliche Intelligenz (KI) ist ein Hauptthema des Deutschen Ärztetags, der am Dienstag in Leipzig beginnt. Reinhardt sagte, auch in der Medizin eröffne KI völlig neue Perspektiven – mit besserer Diagnostik, personalisierten Therapien oder effizienteren Abläufen in der Versorgung. «So kann wieder mehr Raum für die direkte Zuwendung zu den Patientinnen und Patienten entstehen.» In der Forschung könne KI durch die Analyse riesiger Datenmengen die Entwicklung neuer Medikamente und Therapien beschleunigen. Der Ärztepräsident betonte zugleich: «Ethische Leitplanken und verlässliche rechtliche Rahmenbedingungen sind unerlässlich.» Sensible Gesundheitsdaten müssten geschützt und wirtschaftliche Einflussnahmen Dritter auf medizinische Entscheidungen ausgeschlossen werden. Trotz aller Herausforderungen sollte man sich den Blick auf die Chancen und Möglichkeiten nicht verstellen lassen. (dpa/ad) fizkes – shutterstock.com Ärztepräsident Klaus Reinhardt sieht große Chancen für Künstliche Intelligenz in der Medizin, mahnt aber einen verantwortungsvollen Einsatz an. «Die Entscheidung über eine Behandlung müssen immer Ärztinnen und Ärzte treffen und nicht digitale Algorithmen», sagte der Chef der Bundesärztekammer der Deutschen Presse-Agentur. «Bei aller Technologie darf die menschliche Nähe nicht verloren gehen. Sie ist das Fundament guter Medizin.» Künstliche Intelligenz (KI) ist ein Hauptthema des Deutschen Ärztetags, der am Dienstag in Leipzig beginnt. Reinhardt sagte, auch in der Medizin eröffne KI völlig neue Perspektiven – mit besserer Diagnostik, personalisierten Therapien oder effizienteren Abläufen in der Versorgung. «So kann wieder mehr Raum für die direkte Zuwendung zu den Patientinnen und Patienten entstehen.» In der Forschung könne KI durch die Analyse riesiger Datenmengen die Entwicklung neuer Medikamente und Therapien beschleunigen. Der Ärztepräsident betonte zugleich: «Ethische Leitplanken und verlässliche rechtliche Rahmenbedingungen sind unerlässlich.» Sensible Gesundheitsdaten müssten geschützt und wirtschaftliche Einflussnahmen Dritter auf medizinische Entscheidungen ausgeschlossen werden. Trotz aller Herausforderungen sollte man sich den Blick auf die Chancen und Möglichkeiten nicht verstellen lassen. (dpa/ad)",
    "source": "cio",
    "crawled_at": "2025-05-27T08:10:59.493256+00:00"
  },
  {
    "url": "https://www.cio.de/article/3994967/ifo-umfrage-weniger-unternehmen-wollen-stellen-abbauen.html",
    "title": "Ifo-Umfrage: Weniger Unternehmen wollen Stellen abbauen",
    "published": "2025-05-26T10:27:39+00:00",
    "author": "",
    "text": "Photo Smoothies – shutterstock.com Im Mai habe das vom Ifo-Institut ermittelte Beschäftigungsbarometer auf 95,2 Punkte zugelegt, von 94 Punkten im Vormonat, teilte das Forschungsinstitut am Montag in München mit. Der Wert ist damit den zweiten Monat in Folge gestiegen und hat den höchsten Stand seit Juli 2024 erreicht. “Der Arbeitsmarkt zeigt erste Anzeichen einer Stabilisierung”, kommentierte Ifo-Experte Klaus Wohlrabe das Ergebnis einer Umfrage unter deutschen Firmen. Allerdings zeige der Anstieg des Beschäftigungsbarometers bisher noch keine “echte Trendwende”, sagte er. Dies werde maßgeblich von der weiteren wirtschaftlichen Entwicklung abhängen. In den verschiedenen Bereichen der deutschen Wirtschaft zeigte die Umfrage deutliche Unterschiede. In der Industrie sei das Beschäftigungsbarometer im Mai zwar zum fünften Mal in Folge gestiegen. “Insgesamt bauen die Unternehmen jedoch weiterhin mehrheitlich Stellen ab”, heißt es weiter in der Mitteilung des Ifo-Instituts. Dagegen haben Dienstleister ihren Personalbestand leicht aufgestockt – insbesondere in der Leiharbeitsbranche keimt nach Einschätzung der Ifo-Experten “vorsichtiger Optimismus” auf. Im Handel überwiege hingegen weiter der Abbau von Stellen. Auch das Baugewerbe plane noch überwiegend mit weniger Beschäftigten, wenngleich sich auch hier der Stellenabbau verringert habe. Laut jüngsten Daten der Bundesagentur für Arbeit ist die Zahl der Arbeitslosen in Deutschland dank einer leichten Frühjahresbelebung im April um 36.000 auf 2,932 Millionen Menschen gesunken. Das sind aber 182.000 mehr als ein Jahr zuvor. Die Arbeitslosenquote ging im Vergleich zum Vormonat um 0,1 Punkte auf 6,3 Prozent zurück. (dpa/ad) Photo Smoothies – shutterstock.com Im Mai habe das vom Ifo-Institut ermittelte Beschäftigungsbarometer auf 95,2 Punkte zugelegt, von 94 Punkten im Vormonat, teilte das Forschungsinstitut am Montag in München mit. Der Wert ist damit den zweiten Monat in Folge gestiegen und hat den höchsten Stand seit Juli 2024 erreicht. “Der Arbeitsmarkt zeigt erste Anzeichen einer Stabilisierung”, kommentierte Ifo-Experte Klaus Wohlrabe das Ergebnis einer Umfrage unter deutschen Firmen. Allerdings zeige der Anstieg des Beschäftigungsbarometers bisher noch keine “echte Trendwende”, sagte er. Dies werde maßgeblich von der weiteren wirtschaftlichen Entwicklung abhängen. In den verschiedenen Bereichen der deutschen Wirtschaft zeigte die Umfrage deutliche Unterschiede. In der Industrie sei das Beschäftigungsbarometer im Mai zwar zum fünften Mal in Folge gestiegen. “Insgesamt bauen die Unternehmen jedoch weiterhin mehrheitlich Stellen ab”, heißt es weiter in der Mitteilung des Ifo-Instituts. Dagegen haben Dienstleister ihren Personalbestand leicht aufgestockt – insbesondere in der Leiharbeitsbranche keimt nach Einschätzung der Ifo-Experten “vorsichtiger Optimismus” auf. Im Handel überwiege hingegen weiter der Abbau von Stellen. Auch das Baugewerbe plane noch überwiegend mit weniger Beschäftigten, wenngleich sich auch hier der Stellenabbau verringert habe. Laut jüngsten Daten der Bundesagentur für Arbeit ist die Zahl der Arbeitslosen in Deutschland dank einer leichten Frühjahresbelebung im April um 36.000 auf 2,932 Millionen Menschen gesunken. Das sind aber 182.000 mehr als ein Jahr zuvor. Die Arbeitslosenquote ging im Vergleich zum Vormonat um 0,1 Punkte auf 6,3 Prozent zurück. (dpa/ad)",
    "source": "cio",
    "crawled_at": "2025-05-27T08:10:59.574719+00:00"
  },
  {
    "url": "https://www.cio.de/article/3661045/10-ratschlaege-fuer-erfolgreiche-besprechungen.html",
    "title": "10 Ratschläge für erfolgreiche Meetings",
    "published": "2025-05-27T03:31:02+00:00",
    "author": "",
    "text": "Sie wollen eine Botschaft kommunizieren? Dann versetzen Sie sich in die Lage ihrer Zuhörer. Foto: Gorodenkoff – shutterstock.com Zunächst scheint sich bei einer Besprechung in erster Linie alles um die die Sache zu drehen. Dennoch kann das Gespräch um ein sachliches Thema intensiv von Gefühlen mitbestimmt sein. So gehen Kommunikationsmodelle davon aus, dass das Verhältnis zwischen Sach- und Beziehungskomponenten mit einem Eisberg vergleichbar ist: Rund 20 Prozent erscheinen unmittelbar auf der sachlichen Ebene, wohingegen sich die anderen 80 Prozent verdeckt im Beziehungsbereich abspielen. Dieser Teil bedarf jedoch großer Aufmerksamkeit, damit die Besprechung erfolgreich verlaufen soll. Dazu zehn Tipps: Unabhängig davon, ob eine Routine-Besprechung oder eine einzelne Konferenz ansteht, ist die Versuchung groß, möglichst viele Themen abzuarbeiten und somit in die Komplexitätsfalle zu tappen. Dadurch sinkt die Aufmerksamkeit der am Gespräch Beteilgten sehr schnell. Spätestens wenn die Ergebnisse zusammengefasst werden, geht der Durchblick verloren. Am besten ist es, die Tagesordnungspunkte nach der KISS-Methode (keep ist simple and stupid) zu gliedern: Haben sich die Teilnehmer gegenseitig begrüßt und vorgestellt, kommen Themenblock, Zusammenfassung und das weitere Vorgehen zur Sprache. Allerdings sollte der Themenblock so wenig einzelne Themen wie möglich umfassen. Ist die Thematik sehr komplex und weitergehende Gliederungen notwendig, sollten Unterpunkte vorab besprochen werden. Bei unproblematischen Einzelfragen sind auch Einzelgespräche denkbar. Vor allem bei komplizierten Situationen mit verschiedenen Interessen bietet es sich an, Schritt für Schritt vorzugehen und zuerst mit ausgewählten Stakeholder zu konferieren. Allerdings besteht die Gefahr, dass sich später Beteiligte übergangen fühlen könnten und wahrscheinlich Ergebnisse der nachfolgenden gemeinsamen Besprechung in Frage gestelt werden. Für Vorgespräche ist daher eine gewisse Phase der Vorbereitung sinnvoll. Im Zusammenhang mit der terminlichen Abstimmung, der Anreise-Empfehlung oder der Hilfe bei der Hotelbuchung bieten sich zahlreiche Gelegenheiten zum Gedankenaustausch an – entweder direkt oder über die Sekretariate. Reisen kosten Zeit und Geld, daher können Besprechungen über moderne Medien wie Konferenztelefone, Videokonferenzen oder Online-Meetings organisiert werden. Für Routine-Meetings zwischen bekannten Akteuren eignen sich diese Medien hervorragend. Für Kick-offs, Krisengespräche oder Entscheidungsfindungen mit großer Tragweite ist der persönliche Kontakt ein Muss. Ist im Routine-Meeting mit ausschweifenden Erläuterungen zu rechnen? Lässt die Strategie-Konferenz eine schmerzhafte Entscheidung erwarten? Dann bietet sich ein Zeit-Management an, das die alltäglichen Lebensgewohnheiten nutzt: zur Mittagszeit geht es zum Essen, der Berufsverkehr läutet den Feierabend ein und sorgt damit für Unruhe im Besprechungsraum. Situationsgerecht eingeplant, können diese Leitplanken die Besprechungsdauer sinnvoll begrenzen oder eine passende Zäsur erlauben. Die Besprechungsvorbereitung beginnt mit den Einladungen. Innerhalb des Unternehmens können Online-Kalender vielleicht zur effizienten Terminfindung dienen, ansonsten ist die Einladung die erste Möglichkeit, mit den geplanten Teilnehmern in Kontakt zu treten. Der erste Eindruck zählt, selbst wenn sich die Akteure schon aus anderem Zusammenhang kennen. Dabei zeigen schon kleine Gesten große Wirkung: kann ein Parkplatz angeboten werden, gibt es gerade örtliche Besonderheiten bei der Anreise zu beachten, ist der Sitzungszeitraum für alle Teilnehmer akzeptabel und mit der Anreise “kompatibel”? Die Begrüßung beginnt nicht im Sitzungsraum, sondern bereits auf dem Weg dorthin. Sprechen sie die Teilnehmer bereits am Empfang mit deren Namen an und weisen Sie Ihnen den Weg zum Besprechungsraum. Es ist unwahrscheinlich, dass alle Teilnehmer gleichzeitig und exakt zum Besprechungsbeginn eintreffen. Hieraus ergeben sich gute Gelegenheiten, weitere Wertschätzung zu signalisieren: der kleine Imbiss aus der Teeküche wird besonders die weiter angereisten Teilnehmer erfreuen; die fünf Minuten Karrenzzeit erspart verspäteten Teilnehmern die Peinlichkeit, mit einer Entschuldigung in die Begrüßungsphase zu platzen; eine ausgedruckte Agenda mit Teilnehmerliste sowie Namensschildern und Schreibzeug auf dem Tisch schafft für alle Beteiligten gleiche Augenhöhe. Idealerweise lässt sich damit eine Aufmerksamkeit verbinden, welche mit dem Unternehmenslogo für den Wiedererkennungswert geschmückt, als “kleines Geschenk dir Freundschaft erhält”. Entscheidend ist dafür nicht der materielle Wert, sondern allein die freundliche Geste. Mit der Begrüßung und Vorstellung des geplanten Besprechungsverlaufs kann eine Vorstellungsrunde unmittelbar mit einem so genannten Blitzlicht verknüpft werden: welche Erwartungen haben die Teilnehmer mitgebracht, ist die Reihenfolge des geplanten Verlaufs akzeptabel, gibt es unberücksichtigte Aspekte? Diese Vorgehensweise erfordert zwar den Mut, unvorhergesehenen Situationen Raum zu eröffnen. Sie schafft aber ein offenes Gesprächsklima, das sich noch auszahlen kann. Visualisierungen können Besprechungsablauf sinnvoll unterstützen. Der Folieneinsatz wird jedoch dann Distanz schaffen, falls er den Eindruck erweckt, vorgefertigte Besprechungsergebnisse zu platzieren. Eine gemeinschaftlich entwickelte Skizze – etwa am Flipchart – fördert dagegen das offene Gesprächsklima und kann zu den besseren Ergebnissen führen, weil sich alle Beteiligten aktiv in das Geschehen einbringen und wiederfinden können. Das ist vor allem bei der Diskussion technologisch komplexer Fragen unter verschiedenen Personengruppen, wie Fachabteilung und IT-Abteilung oder IT-Manager im Führungs-Meeting des Unternehmens – entscheidend. Die Flipchart-Skizzen kann man leicht fotografieren und so dokumentieren sowie bei Bedarf auch später in eine professionelle Grafik umwandeln. Erfahrene Gesprächsmoderatoren fassen das Diskussionsergebnis am Ende jedes Besprechungspunktes in eigenen Worten zusammen und sorgen durch aktives Nachfragen dafür, dass spätestens hier letztmals Widerspruch angemeldet werden kann. Ist dies nicht der Fall, wird das Ergebnis im Protokoll festgehalten. Dabei ist das Herbeiführen einer einvernehmlichen Entscheidung natürlich wünschenswert, steht jedoch nicht alleine im Mittelpunkt. Entscheidend ist die Formulierung des kollektiv getragenen Ergebnisses, welches Mindermeinungen angemessen berücksichtigt. Moderne Medien lassen es gerade in schwierigen Besprechungssituationen zu, dass die Ergebnisse direkt formuliert und mittels Beamer für alle Beteiligten sichtbar dargestellt werden. Im Idealfall liegt so am Ende der Besprechung das Protokoll vor. Die besten Gesprächsergebnisse sind wertlos, wenn sie nach der Besprechung nicht unmittelbar weiter verfolgt werden. Grundlage dafür ist die zügige Bereitstellung Dokumentation der Ergebnisse, möglicherweise mit zeitlichem Versatz zur Durchsicht der Teilnehmer gegenüber Dritten – falls eine formale Genehmigung des Protokolls nötig ist. Dann gilt es, die Ergebnisse beziehungsweise Ziele aktiv zu verfolgen, ob im Einzelgespräch oder in der Folgebesprechung. Hier schließt sich der Kreislauf: je positiver die Teilnehmer das Meeting in Erinnerung haben, desto erfolgreicher wird der Folgekontakt verlaufen. Meetings sind wie Eisberge Foto: adike – shutterstock.com Auch wenn es um ein Sachthema (= Spitze des Eisbergs) geht, entscheidet die emotionale Kommunktion über Erfolg und Misserfolg einer Sitzung. Und letztere ist leider nicht sichtbar, ebenso wie der größte Teil des Eisbergs. 1. Lichten Sie Ihre Agenda … Foto: Ruslan Ivantsov – shutterstock.com … sonst sehen Sie den Wald vor lauter Bäumen nicht. Beschränken Sie sich auf das Wesentliche und halten Sie sich an eine Struktur: Begrüßung und Vorstellung; Themenblock; Zusammenfassung; weiteres Vorgehen. 2. Bringen Sie alle an einen Tisch … Foto: Rawpixels.com – shutterstock.com … sonst fühlen sich einige übergangen. Bei schwierigen Themen bieten sich Vorgespräche an. 3. Videokonferenzen … Foto: Cisco … sparen Zeit und Geld. Sie eignen sich für Routine-Meetings. Bei Kick-offs oder Krisengesprächen ist der persönliche Kontakt dagegen ein Muss. 4. Der Zeitpunkt eines Meetings … Foto: Andrey Popov – shutterstock.com … ist schon die halbe Miete. Wer ausschweifende Sitzungen vermeiden will, setzt sie vor der Mittagspause oder dann an, wenn der Berufsverkehr schon einsetzt. 5. Die Einladung … Foto: Zhukov Oleg – shutterstock.com …ist die erste Möglichkeit mit den Teilnehmern in Kontakt zu treten. Dabei zeigen schon kleine Gesten grosse Wirkung: kann ein Parkplatz angeboten werden, gibt es gerade örtliche Besonderheiten bei der Anreise zu beachten. 6. Begrüßen Sie die Teilnehmer … Foto: tsyhun – shutterstock.com … nicht erst im Sitzungsraum, sondern schon am Empfang. 7. Eine kleine Aufmerksamkeit aus der Teeküche … Foto: Silatip – shutterstock.com … erfreut besonders die weiter angereisten Teilnehmer der Besprechung. 8. Flipchart statt Powerpoint Foto: auremar – shutterstock.com Eine gemeinsam entwickelte Skizze am Flipchart fördert das offene Gesprächsklima und bringt oft mehr als eine vorgefertigte Präsentation, weil sich die Teilnehmer aktiv einbringen können. 9. Erfahrene Moderatoren … Foto: Michail Petrov – shutterstock.com … fassen die Ergebnisse am Ende des Besprechungspunktes zusammen und haken noch einmal nach, ob es Einwände gibt. 10. Nach dem Meeting ist vor dem Meeting Foto: benjaminec – shutterstock.com Zu Ergebnissen kommen, ist die eine Sache. Die andere ist aber, die Ergebnisse auch umzusetzen beziehungsweise die Ziele zu verfolgen, und zwar möglichst zeitnah zur Besprechung. Sie wollen eine Botschaft kommunizieren? Dann versetzen Sie sich in die Lage ihrer Zuhörer. Foto: Gorodenkoff – shutterstock.com Zunächst scheint sich bei einer Besprechung in erster Linie alles um die die Sache zu drehen. Dennoch kann das Gespräch um ein sachliches Thema intensiv von Gefühlen mitbestimmt sein. So gehen Kommunikationsmodelle davon aus, dass das Verhältnis zwischen Sach- und Beziehungskomponenten mit einem Eisberg vergleichbar ist: Rund 20 Prozent erscheinen unmittelbar auf der sachlichen Ebene, wohingegen sich die anderen 80 Prozent verdeckt im Beziehungsbereich abspielen. Dieser Teil bedarf jedoch großer Aufmerksamkeit, damit die Besprechung erfolgreich verlaufen soll. Dazu zehn Tipps: Unabhängig davon, ob eine Routine-Besprechung oder eine einzelne Konferenz ansteht, ist die Versuchung groß, möglichst viele Themen abzuarbeiten und somit in die Komplexitätsfalle zu tappen. Dadurch sinkt die Aufmerksamkeit der am Gespräch Beteilgten sehr schnell. Spätestens wenn die Ergebnisse zusammengefasst werden, geht der Durchblick verloren. Am besten ist es, die Tagesordnungspunkte nach der KISS-Methode (keep ist simple and stupid) zu gliedern: Haben sich die Teilnehmer gegenseitig begrüßt und vorgestellt, kommen Themenblock, Zusammenfassung und das weitere Vorgehen zur Sprache. Allerdings sollte der Themenblock so wenig einzelne Themen wie möglich umfassen. Ist die Thematik sehr komplex und weitergehende Gliederungen notwendig, sollten Unterpunkte vorab besprochen werden. Bei unproblematischen Einzelfragen sind auch Einzelgespräche denkbar. Vor allem bei komplizierten Situationen mit verschiedenen Interessen bietet es sich an, Schritt für Schritt vorzugehen und zuerst mit ausgewählten Stakeholder zu konferieren. Allerdings besteht die Gefahr, dass sich später Beteiligte übergangen fühlen könnten und wahrscheinlich Ergebnisse der nachfolgenden gemeinsamen Besprechung in Frage gestelt werden. Für Vorgespräche ist daher eine gewisse Phase der Vorbereitung sinnvoll. Im Zusammenhang mit der terminlichen Abstimmung, der Anreise-Empfehlung oder der Hilfe bei der Hotelbuchung bieten sich zahlreiche Gelegenheiten zum Gedankenaustausch an – entweder direkt oder über die Sekretariate. Reisen kosten Zeit und Geld, daher können Besprechungen über moderne Medien wie Konferenztelefone, Videokonferenzen oder Online-Meetings organisiert werden. Für Routine-Meetings zwischen bekannten Akteuren eignen sich diese Medien hervorragend. Für Kick-offs, Krisengespräche oder Entscheidungsfindungen mit großer Tragweite ist der persönliche Kontakt ein Muss. Ist im Routine-Meeting mit ausschweifenden Erläuterungen zu rechnen? Lässt die Strategie-Konferenz eine schmerzhafte Entscheidung erwarten? Dann bietet sich ein Zeit-Management an, das die alltäglichen Lebensgewohnheiten nutzt: zur Mittagszeit geht es zum Essen, der Berufsverkehr läutet den Feierabend ein und sorgt damit für Unruhe im Besprechungsraum. Situationsgerecht eingeplant, können diese Leitplanken die Besprechungsdauer sinnvoll begrenzen oder eine passende Zäsur erlauben. Die Besprechungsvorbereitung beginnt mit den Einladungen. Innerhalb des Unternehmens können Online-Kalender vielleicht zur effizienten Terminfindung dienen, ansonsten ist die Einladung die erste Möglichkeit, mit den geplanten Teilnehmern in Kontakt zu treten. Der erste Eindruck zählt, selbst wenn sich die Akteure schon aus anderem Zusammenhang kennen. Dabei zeigen schon kleine Gesten große Wirkung: kann ein Parkplatz angeboten werden, gibt es gerade örtliche Besonderheiten bei der Anreise zu beachten, ist der Sitzungszeitraum für alle Teilnehmer akzeptabel und mit der Anreise “kompatibel”? Die Begrüßung beginnt nicht im Sitzungsraum, sondern bereits auf dem Weg dorthin. Sprechen sie die Teilnehmer bereits am Empfang mit deren Namen an und weisen Sie Ihnen den Weg zum Besprechungsraum. Es ist unwahrscheinlich, dass alle Teilnehmer gleichzeitig und exakt zum Besprechungsbeginn eintreffen. Hieraus ergeben sich gute Gelegenheiten, weitere Wertschätzung zu signalisieren: der kleine Imbiss aus der Teeküche wird besonders die weiter angereisten Teilnehmer erfreuen; die fünf Minuten Karrenzzeit erspart verspäteten Teilnehmern die Peinlichkeit, mit einer Entschuldigung in die Begrüßungsphase zu platzen; eine ausgedruckte Agenda mit Teilnehmerliste sowie Namensschildern und Schreibzeug auf dem Tisch schafft für alle Beteiligten gleiche Augenhöhe. Idealerweise lässt sich damit eine Aufmerksamkeit verbinden, welche mit dem Unternehmenslogo für den Wiedererkennungswert geschmückt, als “kleines Geschenk dir Freundschaft erhält”. Entscheidend ist dafür nicht der materielle Wert, sondern allein die freundliche Geste. Mit der Begrüßung und Vorstellung des geplanten Besprechungsverlaufs kann eine Vorstellungsrunde unmittelbar mit einem so genannten Blitzlicht verknüpft werden: welche Erwartungen haben die Teilnehmer mitgebracht, ist die Reihenfolge des geplanten Verlaufs akzeptabel, gibt es unberücksichtigte Aspekte? Diese Vorgehensweise erfordert zwar den Mut, unvorhergesehenen Situationen Raum zu eröffnen. Sie schafft aber ein offenes Gesprächsklima, das sich noch auszahlen kann. Visualisierungen können Besprechungsablauf sinnvoll unterstützen. Der Folieneinsatz wird jedoch dann Distanz schaffen, falls er den Eindruck erweckt, vorgefertigte Besprechungsergebnisse zu platzieren. Eine gemeinschaftlich entwickelte Skizze – etwa am Flipchart – fördert dagegen das offene Gesprächsklima und kann zu den besseren Ergebnissen führen, weil sich alle Beteiligten aktiv in das Geschehen einbringen und wiederfinden können. Das ist vor allem bei der Diskussion technologisch komplexer Fragen unter verschiedenen Personengruppen, wie Fachabteilung und IT-Abteilung oder IT-Manager im Führungs-Meeting des Unternehmens – entscheidend. Die Flipchart-Skizzen kann man leicht fotografieren und so dokumentieren sowie bei Bedarf auch später in eine professionelle Grafik umwandeln. Erfahrene Gesprächsmoderatoren fassen das Diskussionsergebnis am Ende jedes Besprechungspunktes in eigenen Worten zusammen und sorgen durch aktives Nachfragen dafür, dass spätestens hier letztmals Widerspruch angemeldet werden kann. Ist dies nicht der Fall, wird das Ergebnis im Protokoll festgehalten. Dabei ist das Herbeiführen einer einvernehmlichen Entscheidung natürlich wünschenswert, steht jedoch nicht alleine im Mittelpunkt. Entscheidend ist die Formulierung des kollektiv getragenen Ergebnisses, welches Mindermeinungen angemessen berücksichtigt. Moderne Medien lassen es gerade in schwierigen Besprechungssituationen zu, dass die Ergebnisse direkt formuliert und mittels Beamer für alle Beteiligten sichtbar dargestellt werden. Im Idealfall liegt so am Ende der Besprechung das Protokoll vor. Die besten Gesprächsergebnisse sind wertlos, wenn sie nach der Besprechung nicht unmittelbar weiter verfolgt werden. Grundlage dafür ist die zügige Bereitstellung Dokumentation der Ergebnisse, möglicherweise mit zeitlichem Versatz zur Durchsicht der Teilnehmer gegenüber Dritten – falls eine formale Genehmigung des Protokolls nötig ist. Dann gilt es, die Ergebnisse beziehungsweise Ziele aktiv zu verfolgen, ob im Einzelgespräch oder in der Folgebesprechung. Hier schließt sich der Kreislauf: je positiver die Teilnehmer das Meeting in Erinnerung haben, desto erfolgreicher wird der Folgekontakt verlaufen. Meetings sind wie Eisberge Foto: adike – shutterstock.com Auch wenn es um ein Sachthema (= Spitze des Eisbergs) geht, entscheidet die emotionale Kommunktion über Erfolg und Misserfolg einer Sitzung. Und letztere ist leider nicht sichtbar, ebenso wie der größte Teil des Eisbergs. 1. Lichten Sie Ihre Agenda … Foto: Ruslan Ivantsov – shutterstock.com … sonst sehen Sie den Wald vor lauter Bäumen nicht. Beschränken Sie sich auf das Wesentliche und halten Sie sich an eine Struktur: Begrüßung und Vorstellung; Themenblock; Zusammenfassung; weiteres Vorgehen. 2. Bringen Sie alle an einen Tisch … Foto: Rawpixels.com – shutterstock.com … sonst fühlen sich einige übergangen. Bei schwierigen Themen bieten sich Vorgespräche an. 3. Videokonferenzen … Foto: Cisco … sparen Zeit und Geld. Sie eignen sich für Routine-Meetings. Bei Kick-offs oder Krisengesprächen ist der persönliche Kontakt dagegen ein Muss. 4. Der Zeitpunkt eines Meetings … Foto: Andrey Popov – shutterstock.com … ist schon die halbe Miete. Wer ausschweifende Sitzungen vermeiden will, setzt sie vor der Mittagspause oder dann an, wenn der Berufsverkehr schon einsetzt. 5. Die Einladung … Foto: Zhukov Oleg – shutterstock.com …ist die erste Möglichkeit mit den Teilnehmern in Kontakt zu treten. Dabei zeigen schon kleine Gesten grosse Wirkung: kann ein Parkplatz angeboten werden, gibt es gerade örtliche Besonderheiten bei der Anreise zu beachten. 6. Begrüßen Sie die Teilnehmer … Foto: tsyhun – shutterstock.com … nicht erst im Sitzungsraum, sondern schon am Empfang. 7. Eine kleine Aufmerksamkeit aus der Teeküche … Foto: Silatip – shutterstock.com … erfreut besonders die weiter angereisten Teilnehmer der Besprechung. 8. Flipchart statt Powerpoint Foto: auremar – shutterstock.com Eine gemeinsam entwickelte Skizze am Flipchart fördert das offene Gesprächsklima und bringt oft mehr als eine vorgefertigte Präsentation, weil sich die Teilnehmer aktiv einbringen können. 9. Erfahrene Moderatoren … Foto: Michail Petrov – shutterstock.com … fassen die Ergebnisse am Ende des Besprechungspunktes zusammen und haken noch einmal nach, ob es Einwände gibt. 10. Nach dem Meeting ist vor dem Meeting Foto: benjaminec – shutterstock.com Zu Ergebnissen kommen, ist die eine Sache. Die andere ist aber, die Ergebnisse auch umzusetzen beziehungsweise die Ziele zu verfolgen, und zwar möglichst zeitnah zur Besprechung.",
    "source": "cio",
    "crawled_at": "2025-05-27T08:10:59.664417+00:00"
  },
  {
    "url": "https://www.cio.de/article/3994197/wie-tech-konzerne-das-dei-rad-zuruckdrehen.html",
    "title": "Wie Tech-Konzerne das DEI-Rad zurückdrehen",
    "published": "2025-05-27T04:13:00+00:00",
    "author": "",
    "text": "Jacob Lund / Shutterstock Im Zuge der Kampagne der Trump-Administration gegen DEI-Initiativen (Diversity, Equity und Inclusion – Vielfalt, Gerechtigkeit und Inklusion) sind viele Unternehmen der Tech-Branche auf eine neue Linie eingeschwenkt. Im Gegensatz zu ihren Versprechen aus dem Jahr 2020, sich für Vielfalt einzusetzen, machten bekannte Konzerne wie Google, Amazon und Meta Schlagzeilen, weil sie ihre DEI-Programme beendet oder zurückgefahren haben. Einige eilten den Übergriffen der Trump-Administration sogar voraus, indem sie bereits am 10. Januar 2025, mehr als eine Woche vor dem offiziellen Amtsantritt der Trump-Administration, Änderungen an der DEI-Sprache und den Programmen vorgenommen haben. Abonnieren Sie unsere CIO-Newsletter für mehr Einblicke, Hintergründe und Deep Dives aus der IT-Community. Berichten zufolge sehen sich Unternehmen aus allen Branchen den Forderungen von Aktionären ausgesetzt, die DEI-Sprache zu reduzieren und Diversitätsziele aus den öffentlichen Berichten zu streichen. Unternehmen wie Costco und Apple haben sich gegen diese „Vorschläge“ gewehrt. Viele andere haben jedoch nachgegeben und darüber hinaus DEI-Mitarbeiter entlassen sowie interne DEI-Initiativen zusammengestrichen. Im Zuge dessen ist dieser Abbau auch in Europa angekommen. So hieß es Mitte Mai in Berichten , dass SAP den Frauenanteil im Konzern nicht weiter gezielt fördern will – die angepeilte Quote von 40 Prozent in der Belegschaft werde aufgegeben. Zudem verliere das „Diversity & Inclusion Office seine Eigenständigkeit. Auch T-Mobile, Roche, Novartis und die UBS hätte ihre Ziele angepasst, so die „ Personalwirtschaft “ im April. Die „Süddeutsche Zeitung“ titelte einen Monat später: „ Goodbye, Diversity? “ Wir zeigen Ihnen, wo die wichtigsten Akteure der US-Tech-Branche derzeit in Sachen Vielfalt, Gleichberechtigung und Integration stehen. Zu Beginn des Jahres schien es, als wolle IBM an seinen DEI-Initiativen festhalten. Als die konservative Denkfabrik „The Heritage Foundation“ unter anderem IBM aufforderte, finanzielle Anreize und Boni für DEI aufzugeben, wehrte sich der Konzern zunächst gegen diesen Forderung. In den vergangenen Monaten hat die Führung von Big Blue jedoch eine Kehrtwende vollzogen und erhebliche Änderungen an den DEI-Praktiken angekündigt. Dies ist ein überraschender Schritt für ein Unternehmen, das ein Pionier der Inklusion gewesen ist, indem es 1984 die sexuelle Orientierung in seine globale Nichtdiskriminierungs-Policy aufnahm und diese 2002 um die Geschlechtsidentität erweiterte. Am 10. April 2025 gab der rechte Influencer Robby Starbuck eine Erklärung ab, in der er sich auf ein internes Memo bezog. Demnach hatte IBM das Ende der DEI-Abteilung und des Diversity Councils angekündigt, die ursprünglich in den 1990er Jahren ins Leben gerufen worden waren. IBM soll zudem angekündigt haben, dass es nicht mehr am HRC-Arbeitsplatzindex (Human Rights Campaign) teilnehmen wird. In den vergangenen 15 Jahren hatte der Konzern hier eine Quote von 100 Prozent erreichte und damit zu den besten Arbeitsplätzen für LGBTQ+-Gleichstellung gezählt. In einer Erklärung gegenüber Bloomberg gab IBM an, dass diese Änderungen durch die „inhärenten Spannungen bei der Umsetzung der Inklusion“ sowie durch rechtliche Faktoren angesichts der zunehmenden Kontrolle motiviert seien. Während einer Aktionärsversammlung am 30. April 2025 stellte die Heritage Foundation erneut einen Antrag, in dem die IBM-Aktionäre aufgefordert wurden, für die Abschaffung der DEI zu stimmen. Der Antrag wurde zurückgezogen, nachdem IBM Änderungen vorgenommen hatte, um die DEI im Unternehmen zu verringern. Im Januar dieses Jahres kündigte Meta an, mehrere interne DEI-Programme zu beenden , die sich um Diversität im Recruiting drehen. Außerdem wurde Maxine Williams, Chief Diversity Officer, in eine neue Rolle versetzt, um sich auf „Zugänglichkeit und Engagement“ zu konzentrieren. Meta zufolge zielt ein Teil dieses Rückzugs darauf ab, auf „faire und konsistente“ Praktiken zu fokussieren, die Voreingenommenheit („bias“) für alle, unabhängig von ihrem Hintergrund, abmildern, wie aus einem durchgesickerten Memo von Janelle Gale, VP of HR, hervorgeht. Zu diesen Bemühungen gehörten bisher die Abschaffung von Quoten, die Beendigung diversitätsgetriebener Rekrutierung sowie die Aufgabe von Bemühungen um die Vielfalt bei Lieferanten. Darüber hinaus wurden Programme für Gleichberechtigung und Eingliederung gestrichen und das Meta DEI-Team geschrumpft. Das Unternehmen sagte außerdem eine Spende in Höhe von einer Million Dollar für Trumps Amtseinführung zu und holte den UFC-Präsidenten und CEO Dana White, einen erklärten Trump-Unterstützer, in seinen Vorstand. Meta ersetzte auch seinen Präsidenten für globale Angelegenheiten laut dem Nachrichtenportal Axios durch Joel Kaplan, einen prominenten Republikaner. Nach dem Vorbild von Meta hat Google alle Ziele für die Einstellung von Mitarbeitern nach diversen Kriterien gestrichen. Obwohl das Unternehmen seit 2014 regelmäßig Berichte über Diversität publik gemacht hat, will Google die weitere Veröffentlichung solcher Reports prüfen, berichtet das Wall Street Journal . Darüber hinaus plant Google, alle DEI-Initiativen zu überprüfen, um zu sehen, ob sie mit den Anordnungen der Exekutive, die auf die Reduzierung der DEI abzielen, konform sind. Im jährlichen 10-K-Bericht des Unternehmens an die Börsenaufsicht in den USA wurde „Vielfalt“ nicht erwähnt – nach acht Mal im Vorjahr. Google entfernte außerdem Ende 2024 eine Handvoll kultureller Veranstaltungen aus dem Standard-Google-Kalender und änderte für alle Google Maps-Nutzer in den USA den Golf von Mexiko in den Golf von Amerika (inzwischen sehen mexikanische Nutzer den „Golf von Mexiko“, während alle Nutzer außerhalb der USA und Mexikos sowohl den „Golf von Mexiko“ als auch den „Golf von Amerika“ auf der Karte sehen). Google wurde inzwischen von der mexikanischen Regierung wegen der Umbenennung verklagt. Amazon hat in diesem Jahr seinen Jahresbericht und seine Website in Bezug auf Vielfalt gestrichen und einige DEI-Programme eingestellt. Einem internen Memo zufolge war das Unternehmen dabei, „veraltete Programme und Materialien zurückzuschrauben“. Im Jahr 2020 hatte sich Amazon verpflichtet, den Anteil Schwarzer Führungskräfte auf der Ebene der Vizepräsidenten und Direktoren zu verdoppeln, und dies im Jahr 2021 bekräftigt. Auf der Positionsseite des Unternehmens heißt es heute immerhin noch, dass sich das Unternehmen für ein vielfältiges und integratives Unternehmen einsetzt. Amazon hat auch erklärt, dass die von den Mitarbeitern geleiteten Affinitätsgruppen weiterhin tätig sein werden. Auf einer Aktionärsversammlung von Apple wurde der Antrag einer konservativen Gruppe abgelehnt, die eine Abschaffung der DEI-Richtlinien gefordert hatte. Dabei riet Apple seinen Aktionären, gegen den Antrag zu stimmen. Apple hat keine Änderungen an seiner Website oder seiner Diversity-Sprache vorgenommen und scheint sich verpflichtet zu fühlen, eine gerechtere Wirtschaft zu fördern. Auf seiner Website werden die Diversity-Daten beibehalten, Nutzer können seit 2014 globale demografische Daten zu den Mitarbeitenden einsehen. Auf der jüngsten Jahreshauptversammlung wurde ein Vorschlag zur Abschaffung der DEI-Programme vorgelegt und mit einer überwältigenden Mehrheit von 97 Prozent der Stimmen abgelehnt . Im aktuellen Klima hat Apple Schritte unternommen, die zeigen, dass das Unternehmen seine Unterstützung für Inklusivität und Fortschritt beibehalten will. Salesforce ist ein weiteres Unternehmen, das die Erwähnung von Diversitätszielen aus seinem 10-K-Bericht für 2023 gestrichen hat. Jedoch veröffentlichte das Unternehmen ein „ Gleichstellungs-Update “ für 2024, in dem es sein Engagement für Vielfalt und Repräsentation bekräftigt. CEO Marc Benioff erklärte außerdem in einem Gespräch mit Axios, dass das Unternehmen den Mitarbeitenden angesichts der gegen die DEI gerichteten Anordnungen der Trump-Administration zur Seite stehen wird. „Präsidenten ändern sich, Verwaltungen ändern sich. Wir ändern uns nicht“, sagte Benioff in einem Interview mit MarketWatch. Salesforce hat die demografische Zusammensetzung seiner Belegschaft bereits offengelegt, bevor dies üblich war. Zudem drängte der Konzern schon auf ein Engagement für DEI im Jahr 2019, bevor es 2020 nach der Ermordung von George Floyd in Minneapolis eine größere DEI-Initiative gab. (ajf/jd) Jacob Lund / Shutterstock Im Zuge der Kampagne der Trump-Administration gegen DEI-Initiativen (Diversity, Equity und Inclusion – Vielfalt, Gerechtigkeit und Inklusion) sind viele Unternehmen der Tech-Branche auf eine neue Linie eingeschwenkt. Im Gegensatz zu ihren Versprechen aus dem Jahr 2020, sich für Vielfalt einzusetzen, machten bekannte Konzerne wie Google, Amazon und Meta Schlagzeilen, weil sie ihre DEI-Programme beendet oder zurückgefahren haben. Einige eilten den Übergriffen der Trump-Administration sogar voraus, indem sie bereits am 10. Januar 2025, mehr als eine Woche vor dem offiziellen Amtsantritt der Trump-Administration, Änderungen an der DEI-Sprache und den Programmen vorgenommen haben. Abonnieren Sie unsere CIO-Newsletter für mehr Einblicke, Hintergründe und Deep Dives aus der IT-Community. Berichten zufolge sehen sich Unternehmen aus allen Branchen den Forderungen von Aktionären ausgesetzt, die DEI-Sprache zu reduzieren und Diversitätsziele aus den öffentlichen Berichten zu streichen. Unternehmen wie Costco und Apple haben sich gegen diese „Vorschläge“ gewehrt. Viele andere haben jedoch nachgegeben und darüber hinaus DEI-Mitarbeiter entlassen sowie interne DEI-Initiativen zusammengestrichen. Im Zuge dessen ist dieser Abbau auch in Europa angekommen. So hieß es Mitte Mai in Berichten , dass SAP den Frauenanteil im Konzern nicht weiter gezielt fördern will – die angepeilte Quote von 40 Prozent in der Belegschaft werde aufgegeben. Zudem verliere das „Diversity & Inclusion Office seine Eigenständigkeit. Auch T-Mobile, Roche, Novartis und die UBS hätte ihre Ziele angepasst, so die „ Personalwirtschaft “ im April. Die „Süddeutsche Zeitung“ titelte einen Monat später: „ Goodbye, Diversity? “ Wir zeigen Ihnen, wo die wichtigsten Akteure der US-Tech-Branche derzeit in Sachen Vielfalt, Gleichberechtigung und Integration stehen. Zu Beginn des Jahres schien es, als wolle IBM an seinen DEI-Initiativen festhalten. Als die konservative Denkfabrik „The Heritage Foundation“ unter anderem IBM aufforderte, finanzielle Anreize und Boni für DEI aufzugeben, wehrte sich der Konzern zunächst gegen diesen Forderung. In den vergangenen Monaten hat die Führung von Big Blue jedoch eine Kehrtwende vollzogen und erhebliche Änderungen an den DEI-Praktiken angekündigt. Dies ist ein überraschender Schritt für ein Unternehmen, das ein Pionier der Inklusion gewesen ist, indem es 1984 die sexuelle Orientierung in seine globale Nichtdiskriminierungs-Policy aufnahm und diese 2002 um die Geschlechtsidentität erweiterte. Am 10. April 2025 gab der rechte Influencer Robby Starbuck eine Erklärung ab, in der er sich auf ein internes Memo bezog. Demnach hatte IBM das Ende der DEI-Abteilung und des Diversity Councils angekündigt, die ursprünglich in den 1990er Jahren ins Leben gerufen worden waren. IBM soll zudem angekündigt haben, dass es nicht mehr am HRC-Arbeitsplatzindex (Human Rights Campaign) teilnehmen wird. In den vergangenen 15 Jahren hatte der Konzern hier eine Quote von 100 Prozent erreichte und damit zu den besten Arbeitsplätzen für LGBTQ+-Gleichstellung gezählt. In einer Erklärung gegenüber Bloomberg gab IBM an, dass diese Änderungen durch die „inhärenten Spannungen bei der Umsetzung der Inklusion“ sowie durch rechtliche Faktoren angesichts der zunehmenden Kontrolle motiviert seien. Während einer Aktionärsversammlung am 30. April 2025 stellte die Heritage Foundation erneut einen Antrag, in dem die IBM-Aktionäre aufgefordert wurden, für die Abschaffung der DEI zu stimmen. Der Antrag wurde zurückgezogen, nachdem IBM Änderungen vorgenommen hatte, um die DEI im Unternehmen zu verringern. Im Januar dieses Jahres kündigte Meta an, mehrere interne DEI-Programme zu beenden , die sich um Diversität im Recruiting drehen. Außerdem wurde Maxine Williams, Chief Diversity Officer, in eine neue Rolle versetzt, um sich auf „Zugänglichkeit und Engagement“ zu konzentrieren. Meta zufolge zielt ein Teil dieses Rückzugs darauf ab, auf „faire und konsistente“ Praktiken zu fokussieren, die Voreingenommenheit („bias“) für alle, unabhängig von ihrem Hintergrund, abmildern, wie aus einem durchgesickerten Memo von Janelle Gale, VP of HR, hervorgeht. Zu diesen Bemühungen gehörten bisher die Abschaffung von Quoten, die Beendigung diversitätsgetriebener Rekrutierung sowie die Aufgabe von Bemühungen um die Vielfalt bei Lieferanten. Darüber hinaus wurden Programme für Gleichberechtigung und Eingliederung gestrichen und das Meta DEI-Team geschrumpft. Das Unternehmen sagte außerdem eine Spende in Höhe von einer Million Dollar für Trumps Amtseinführung zu und holte den UFC-Präsidenten und CEO Dana White, einen erklärten Trump-Unterstützer, in seinen Vorstand. Meta ersetzte auch seinen Präsidenten für globale Angelegenheiten laut dem Nachrichtenportal Axios durch Joel Kaplan, einen prominenten Republikaner. Nach dem Vorbild von Meta hat Google alle Ziele für die Einstellung von Mitarbeitern nach diversen Kriterien gestrichen. Obwohl das Unternehmen seit 2014 regelmäßig Berichte über Diversität publik gemacht hat, will Google die weitere Veröffentlichung solcher Reports prüfen, berichtet das Wall Street Journal . Darüber hinaus plant Google, alle DEI-Initiativen zu überprüfen, um zu sehen, ob sie mit den Anordnungen der Exekutive, die auf die Reduzierung der DEI abzielen, konform sind. Im jährlichen 10-K-Bericht des Unternehmens an die Börsenaufsicht in den USA wurde „Vielfalt“ nicht erwähnt – nach acht Mal im Vorjahr. Google entfernte außerdem Ende 2024 eine Handvoll kultureller Veranstaltungen aus dem Standard-Google-Kalender und änderte für alle Google Maps-Nutzer in den USA den Golf von Mexiko in den Golf von Amerika (inzwischen sehen mexikanische Nutzer den „Golf von Mexiko“, während alle Nutzer außerhalb der USA und Mexikos sowohl den „Golf von Mexiko“ als auch den „Golf von Amerika“ auf der Karte sehen). Google wurde inzwischen von der mexikanischen Regierung wegen der Umbenennung verklagt. Amazon hat in diesem Jahr seinen Jahresbericht und seine Website in Bezug auf Vielfalt gestrichen und einige DEI-Programme eingestellt. Einem internen Memo zufolge war das Unternehmen dabei, „veraltete Programme und Materialien zurückzuschrauben“. Im Jahr 2020 hatte sich Amazon verpflichtet, den Anteil Schwarzer Führungskräfte auf der Ebene der Vizepräsidenten und Direktoren zu verdoppeln, und dies im Jahr 2021 bekräftigt. Auf der Positionsseite des Unternehmens heißt es heute immerhin noch, dass sich das Unternehmen für ein vielfältiges und integratives Unternehmen einsetzt. Amazon hat auch erklärt, dass die von den Mitarbeitern geleiteten Affinitätsgruppen weiterhin tätig sein werden. Auf einer Aktionärsversammlung von Apple wurde der Antrag einer konservativen Gruppe abgelehnt, die eine Abschaffung der DEI-Richtlinien gefordert hatte. Dabei riet Apple seinen Aktionären, gegen den Antrag zu stimmen. Apple hat keine Änderungen an seiner Website oder seiner Diversity-Sprache vorgenommen und scheint sich verpflichtet zu fühlen, eine gerechtere Wirtschaft zu fördern. Auf seiner Website werden die Diversity-Daten beibehalten, Nutzer können seit 2014 globale demografische Daten zu den Mitarbeitenden einsehen. Auf der jüngsten Jahreshauptversammlung wurde ein Vorschlag zur Abschaffung der DEI-Programme vorgelegt und mit einer überwältigenden Mehrheit von 97 Prozent der Stimmen abgelehnt . Im aktuellen Klima hat Apple Schritte unternommen, die zeigen, dass das Unternehmen seine Unterstützung für Inklusivität und Fortschritt beibehalten will. Salesforce ist ein weiteres Unternehmen, das die Erwähnung von Diversitätszielen aus seinem 10-K-Bericht für 2023 gestrichen hat. Jedoch veröffentlichte das Unternehmen ein „ Gleichstellungs-Update “ für 2024, in dem es sein Engagement für Vielfalt und Repräsentation bekräftigt. CEO Marc Benioff erklärte außerdem in einem Gespräch mit Axios, dass das Unternehmen den Mitarbeitenden angesichts der gegen die DEI gerichteten Anordnungen der Trump-Administration zur Seite stehen wird. „Präsidenten ändern sich, Verwaltungen ändern sich. Wir ändern uns nicht“, sagte Benioff in einem Interview mit MarketWatch. Salesforce hat die demografische Zusammensetzung seiner Belegschaft bereits offengelegt, bevor dies üblich war. Zudem drängte der Konzern schon auf ein Engagement für DEI im Jahr 2019, bevor es 2020 nach der Ermordung von George Floyd in Minneapolis eine größere DEI-Initiative gab. (ajf/jd)",
    "source": "cio",
    "crawled_at": "2025-05-27T08:10:59.916358+00:00"
  },
  {
    "url": "https://www.cio.de/article/3994401/sap-will-ki-allgegenwaertig-machen.html",
    "title": "SAP will KI allgegenwärtig machen",
    "published": "2025-05-27T05:11:00+00:00",
    "author": "",
    "text": "TenPixels – shutterstock.com „Wir machen wir KI für Unternehmen greifbar und treiben die digitale Transformation voran, damit unsere Kunden in einer zunehmend unberechenbaren Welt erfolgreich sein können“, verspricht SAP-Chef Christian Klein zur Eröffnung der diesjährigen Sapphire in Orlando, Florida. Der deutsche Softwarekonzern stellt dazu Erweiterungen von Joule, Partnerschaften mit anderen KI-Pionieren sowie neue Features für die Business Data Cloud und die Business Suite vor. „SAP kombiniert die weltweit leistungsfähigste Suite von Geschäftsanwendungen mit einer einzigartigen Datenvielfalt und den neuesten KI-Innovationen, um Mehrwerte für die Kunden zu schaffen“, so Klein. Christian Klein (SAP) / Supplied Sein Kollege Thomas Saueressig, als SAP-Vorstand verantwortlich für den Bereich Customer Services & Delivery, spricht zur diesjährigen Sapphire von einem regelrechten Feuerwerk an Innovationen. Der Blick des Managers richtet sich dabei vor allem auf SAPs Copiloten Joule und ein wachsendes Netz von KI-Agenten. Joule werde die Art und Weise verändern, wie Menschen arbeiten und Unternehmen funktionieren, stellt Saueressig seinen Kunden in Aussicht. 34.000 Betriebe würden bereits mit SAPs Business AI arbeiten. 230 AI-Szenarien seien heute schon fest im eigenen Softwarekosmos eingebettet – bis Ende 2025 sollen es über 400 sein. Joule soll als Begleiter der Anwenderinnen und Anwender allgegenwärtig werden, so der Plan der SAP-Verantwortlichen. Der KI-Assistent soll die User während ihres gesamten Tages begleiten können, sowohl innerhalb wie auch außerhalb des SAP-Anwendungsuniversums. Der Business-Copilot sei in der Lage, Daten zu finden, daraus Erkenntnisse in Echtzeit zu gewinnen und Arbeitsabläufe zu optimieren. Rund um Joule baut SAP zusätzliche Tools, um Anwendern die Nutzung des KI-Assistenten so komfortabel wie möglich zu machen. Beispielsweise soll es eine Art Aktionsleiste geben, die von SAP WalkMe angetrieben wird und das Nutzerverhalten über alle Anwendungen hinweg untersucht. Damit entwickle sich Joule zu einer proaktiven KI, die die Bedürfnisse der Nutzer vorhersehe, bevor sie entstehen, hieß es in einer Mitteilung des Softwarekonzerns. Zusätzlich will SAP seinen Kunden im Rahmen einer Partnerschaft mit Perplexity eine Business Answer Engine an die Hand geben. Damit könnten User auch außerhalb von SAP Fragen an Joule stellen. Anwender könnten eine Wirtschaftsmeldung auf einer Nachrichtenseite, beispielsweise zu neuen Zöllen, markieren und Joule direkt fragen, was dies für das eigene Business bedeute, beschreibt Saueressig ein mögliches Szenario. Der Copilot könne diese Meldung dann direkt mit Daten aus dem SAP-System verknüpfen und entsprechend Tipps geben, wie das Unternehmen angesichts der Veränderungen reagieren sollte. Neben Joule arbeitet SAP eigenen Angaben zufolge mit Hochdruck am Bau weiterer KI-Agenten. Diese Agenten, die auf Geschäftsdaten aus der eigenen Business Data Cloud (BCD) basieren und von Joule orchestriert werden, sollen system- und bereichsübergreifend arbeiten können, um zu antizipieren, sich anzupassen und eigenständig zu handeln. Unternehmen könnten damit in einer sich schnell verändernden Welt agil bleiben, verspricht SAP. Zusätzlich kündigt SAP eine Art Betriebssystem für die KI-Entwicklung an. Die SAP AI Foundation biete Entwicklern Zugang zu allen Werkzeugen, die sie für den Aufbau, die Erweiterung und den Betrieb benutzerdefinierter KI-Lösungen benötigten. Damit Anwenderunternehmen angesichts immer zahlreicherer KI-Agenten nicht den Überblick verlieren, hat SAP außerdem eine erweiterte Bibliothek von KI-Agenten vorgestellt. Darüber hinaus arbeitet SAP mit anderen KI-Anbietern zusammen, um ein Ökosystem interoperabler Agenten auf die Beine zu stellen, die End-to-End-Prozesse ausführen können. SAP-Manager Saueressig nennt an dieser Stelle Googles A2A-Initiative. Das Agent-to-Agent-Protocol soll plattformübergreifend Spezifikationen anbieten, damit KI-Agenten verschiedener Anbieter interagieren können. Für die Business Data Cloud (BDC) hat SAP außerdem neue intelligente Anwendungen sogenannte Insight Apps angekündigt. Diese Apps sollen Unternehmen helfen, Routinearbeiten durch eine Kombination aus Standardgeschäftskennzahlen, KI-Modellen und integrierten Planungsfunktionen zu optimieren. Der Softwarekonzern nennt als Beispiel die Anwendung People Intelligence. Diese verknüpft Daten zu Mitarbeitern und Fähigkeiten aus der SAP SuccessFactors HCM Suite für tiefere Einblicke in die Belegschaft. Mit Hilfe KI-gesteuerter Empfehlungen sollen Führungskräfte die Teamleistung optimieren, das Mitarbeiterwachstum fördern und die Einhaltung von Vorschriften gewährleisten können, hieß es. In Sachen Datenanalysen will SAP außerdem enger mit dem Analytics-Spezialisten Palantir zusammenarbeiten. Die Nutzung der entsprechenden Werkzeuge im SAP-Kontext sei jedoch optional, relativiert Saueressig und versucht so Bedenken hinsichtlich der Kooperation mit dem umstrittenen Softwareanbieter zu zerstreuen. Vor allem Kunden in den USA nutzten die Tools von Palantir, begründet der SAP-Manager die engere Zusammenarbeit. Den Schlussakkord in SAPs Dreiklang aus Geschäftsdaten, Business AI und Geschäftsanwendungen setzt die Business Suite. Zur Sapphire stellt der Softwarehersteller zusätzliche Pakete für dedizierte Anwendungsbereiche vor – beispielsweise Finance, Supply Chain Management (SCM), Human Capital Management (HCM), das Strategic Procurement und das Kundenmanagement. Unter dem im Februar dieses Jahres vorgestellten Label Business Suite, mit der der Konzern in alten On-Premises-Zeiten große Erfolge gefeiert hatte, versteht SAP ein modulares Set verschiedener miteinander integrierter Lösungen. Konkret nennt der Anbieter Cloud ERP, Business Applikationen, die Business Data Cloud und Business AI sowie als gemeinsame Basis die Business Technology Platform (BTP). Mit integriert ist außerdem SAP Build, um Kunden dabei zu helfen, ihre Anwendungen an individuelle Anforderungen anzupassen – ohne dabei allerdings in ein zu starkes Customizing abzudriften und immer einen „Clean Core“ zu behalten. Auffallend an dieser Stelle: SAP spricht im Zusammenhang mit Business-Anwendungen nur noch von Cloud ERP und der Business Suite. Der Name S/4HANA, der die Strategie der SAP im zurückliegenden Jahrzehnt maßgeblich bestimmt hat , fällt gar nicht mehr. In einem 26-seitigen Innovation-Guide, den SAP zu Sapphire 2025 veröffentlicht hat, wird S/4HANA kein einziges Mal erwähnt. Inwieweit damit ein regelrechter Strategiewechsel einhergeht oder ob es sich lediglich um ein Umlabeln handelt, ist noch nicht klar ersichtlich. Vielleicht möchte SAP an dieser Stelle auch einen Schlussstrich ziehen unter die ständigen Migrationsdiskussionen der vergangenen Jahre. Viele Unternehmen verbinden mit S/4HANA langwierige und kostenintensive Umstiegsprojekte und haben vielfach noch gar damit nicht angefangen, obwohl das Support-Ende für das Vorgänger-Release immer näher rückt. SAP-Vorstand Saueressig verspricht seinen Kunden zur diesjährigen Sapphire jedenfalls, dass künftig vieles einfacher soll – angefangen von der Migration bis hin zu den Preis- und Lizenzmodellen. Die Transition Guidance soll Anwenderunternehmen dabei helfen, schneller in die Cloud zu wechseln. Mit Joule als Einstiegspunkt und auf der Grundlage von Erkenntnissen aus SAP-Lösungen wie SAP Signavio und SAP LeanIX liefere die App personalisierte Anleitungen und umsetzbare Empfehlungen, die auf die Transformationsziele eines Unternehmens zugeschnitten seien, versprechen die Walldorfer. SAP Für die Business Suite in der Cloud soll es in Zukunft ein vereinfachtes Service- und Supportmodell in drei Stufen geben: „Wir wollen näher am Kunden sein und deren Transformation begleiten“, verspricht Saueressig und verweist noch einmal auf den Dreiklang aus Daten, Applikationen und KI. Der Business Kontext mache den Unterschied. SAP sitze mit seinen Lösungen am richtigen Hebel. Der SAP-Mann gibt sich selbstbewusst: „Wir halten nicht nur Schritt mit den Entwicklungen, sondern wir sind Schrittmacher.“ TenPixels – shutterstock.com „Wir machen wir KI für Unternehmen greifbar und treiben die digitale Transformation voran, damit unsere Kunden in einer zunehmend unberechenbaren Welt erfolgreich sein können“, verspricht SAP-Chef Christian Klein zur Eröffnung der diesjährigen Sapphire in Orlando, Florida. Der deutsche Softwarekonzern stellt dazu Erweiterungen von Joule, Partnerschaften mit anderen KI-Pionieren sowie neue Features für die Business Data Cloud und die Business Suite vor. „SAP kombiniert die weltweit leistungsfähigste Suite von Geschäftsanwendungen mit einer einzigartigen Datenvielfalt und den neuesten KI-Innovationen, um Mehrwerte für die Kunden zu schaffen“, so Klein. Christian Klein (SAP) / Supplied Sein Kollege Thomas Saueressig, als SAP-Vorstand verantwortlich für den Bereich Customer Services & Delivery, spricht zur diesjährigen Sapphire von einem regelrechten Feuerwerk an Innovationen. Der Blick des Managers richtet sich dabei vor allem auf SAPs Copiloten Joule und ein wachsendes Netz von KI-Agenten. Joule werde die Art und Weise verändern, wie Menschen arbeiten und Unternehmen funktionieren, stellt Saueressig seinen Kunden in Aussicht. 34.000 Betriebe würden bereits mit SAPs Business AI arbeiten. 230 AI-Szenarien seien heute schon fest im eigenen Softwarekosmos eingebettet – bis Ende 2025 sollen es über 400 sein. Joule soll als Begleiter der Anwenderinnen und Anwender allgegenwärtig werden, so der Plan der SAP-Verantwortlichen. Der KI-Assistent soll die User während ihres gesamten Tages begleiten können, sowohl innerhalb wie auch außerhalb des SAP-Anwendungsuniversums. Der Business-Copilot sei in der Lage, Daten zu finden, daraus Erkenntnisse in Echtzeit zu gewinnen und Arbeitsabläufe zu optimieren. Rund um Joule baut SAP zusätzliche Tools, um Anwendern die Nutzung des KI-Assistenten so komfortabel wie möglich zu machen. Beispielsweise soll es eine Art Aktionsleiste geben, die von SAP WalkMe angetrieben wird und das Nutzerverhalten über alle Anwendungen hinweg untersucht. Damit entwickle sich Joule zu einer proaktiven KI, die die Bedürfnisse der Nutzer vorhersehe, bevor sie entstehen, hieß es in einer Mitteilung des Softwarekonzerns. Zusätzlich will SAP seinen Kunden im Rahmen einer Partnerschaft mit Perplexity eine Business Answer Engine an die Hand geben. Damit könnten User auch außerhalb von SAP Fragen an Joule stellen. Anwender könnten eine Wirtschaftsmeldung auf einer Nachrichtenseite, beispielsweise zu neuen Zöllen, markieren und Joule direkt fragen, was dies für das eigene Business bedeute, beschreibt Saueressig ein mögliches Szenario. Der Copilot könne diese Meldung dann direkt mit Daten aus dem SAP-System verknüpfen und entsprechend Tipps geben, wie das Unternehmen angesichts der Veränderungen reagieren sollte. Neben Joule arbeitet SAP eigenen Angaben zufolge mit Hochdruck am Bau weiterer KI-Agenten. Diese Agenten, die auf Geschäftsdaten aus der eigenen Business Data Cloud (BCD) basieren und von Joule orchestriert werden, sollen system- und bereichsübergreifend arbeiten können, um zu antizipieren, sich anzupassen und eigenständig zu handeln. Unternehmen könnten damit in einer sich schnell verändernden Welt agil bleiben, verspricht SAP. Zusätzlich kündigt SAP eine Art Betriebssystem für die KI-Entwicklung an. Die SAP AI Foundation biete Entwicklern Zugang zu allen Werkzeugen, die sie für den Aufbau, die Erweiterung und den Betrieb benutzerdefinierter KI-Lösungen benötigten. Damit Anwenderunternehmen angesichts immer zahlreicherer KI-Agenten nicht den Überblick verlieren, hat SAP außerdem eine erweiterte Bibliothek von KI-Agenten vorgestellt. Darüber hinaus arbeitet SAP mit anderen KI-Anbietern zusammen, um ein Ökosystem interoperabler Agenten auf die Beine zu stellen, die End-to-End-Prozesse ausführen können. SAP-Manager Saueressig nennt an dieser Stelle Googles A2A-Initiative. Das Agent-to-Agent-Protocol soll plattformübergreifend Spezifikationen anbieten, damit KI-Agenten verschiedener Anbieter interagieren können. Für die Business Data Cloud (BDC) hat SAP außerdem neue intelligente Anwendungen sogenannte Insight Apps angekündigt. Diese Apps sollen Unternehmen helfen, Routinearbeiten durch eine Kombination aus Standardgeschäftskennzahlen, KI-Modellen und integrierten Planungsfunktionen zu optimieren. Der Softwarekonzern nennt als Beispiel die Anwendung People Intelligence. Diese verknüpft Daten zu Mitarbeitern und Fähigkeiten aus der SAP SuccessFactors HCM Suite für tiefere Einblicke in die Belegschaft. Mit Hilfe KI-gesteuerter Empfehlungen sollen Führungskräfte die Teamleistung optimieren, das Mitarbeiterwachstum fördern und die Einhaltung von Vorschriften gewährleisten können, hieß es. In Sachen Datenanalysen will SAP außerdem enger mit dem Analytics-Spezialisten Palantir zusammenarbeiten. Die Nutzung der entsprechenden Werkzeuge im SAP-Kontext sei jedoch optional, relativiert Saueressig und versucht so Bedenken hinsichtlich der Kooperation mit dem umstrittenen Softwareanbieter zu zerstreuen. Vor allem Kunden in den USA nutzten die Tools von Palantir, begründet der SAP-Manager die engere Zusammenarbeit. Den Schlussakkord in SAPs Dreiklang aus Geschäftsdaten, Business AI und Geschäftsanwendungen setzt die Business Suite. Zur Sapphire stellt der Softwarehersteller zusätzliche Pakete für dedizierte Anwendungsbereiche vor – beispielsweise Finance, Supply Chain Management (SCM), Human Capital Management (HCM), das Strategic Procurement und das Kundenmanagement. Unter dem im Februar dieses Jahres vorgestellten Label Business Suite, mit der der Konzern in alten On-Premises-Zeiten große Erfolge gefeiert hatte, versteht SAP ein modulares Set verschiedener miteinander integrierter Lösungen. Konkret nennt der Anbieter Cloud ERP, Business Applikationen, die Business Data Cloud und Business AI sowie als gemeinsame Basis die Business Technology Platform (BTP). Mit integriert ist außerdem SAP Build, um Kunden dabei zu helfen, ihre Anwendungen an individuelle Anforderungen anzupassen – ohne dabei allerdings in ein zu starkes Customizing abzudriften und immer einen „Clean Core“ zu behalten. Auffallend an dieser Stelle: SAP spricht im Zusammenhang mit Business-Anwendungen nur noch von Cloud ERP und der Business Suite. Der Name S/4HANA, der die Strategie der SAP im zurückliegenden Jahrzehnt maßgeblich bestimmt hat , fällt gar nicht mehr. In einem 26-seitigen Innovation-Guide, den SAP zu Sapphire 2025 veröffentlicht hat, wird S/4HANA kein einziges Mal erwähnt. Inwieweit damit ein regelrechter Strategiewechsel einhergeht oder ob es sich lediglich um ein Umlabeln handelt, ist noch nicht klar ersichtlich. Vielleicht möchte SAP an dieser Stelle auch einen Schlussstrich ziehen unter die ständigen Migrationsdiskussionen der vergangenen Jahre. Viele Unternehmen verbinden mit S/4HANA langwierige und kostenintensive Umstiegsprojekte und haben vielfach noch gar damit nicht angefangen, obwohl das Support-Ende für das Vorgänger-Release immer näher rückt. SAP-Vorstand Saueressig verspricht seinen Kunden zur diesjährigen Sapphire jedenfalls, dass künftig vieles einfacher soll – angefangen von der Migration bis hin zu den Preis- und Lizenzmodellen. Die Transition Guidance soll Anwenderunternehmen dabei helfen, schneller in die Cloud zu wechseln. Mit Joule als Einstiegspunkt und auf der Grundlage von Erkenntnissen aus SAP-Lösungen wie SAP Signavio und SAP LeanIX liefere die App personalisierte Anleitungen und umsetzbare Empfehlungen, die auf die Transformationsziele eines Unternehmens zugeschnitten seien, versprechen die Walldorfer. SAP Für die Business Suite in der Cloud soll es in Zukunft ein vereinfachtes Service- und Supportmodell in drei Stufen geben: „Wir wollen näher am Kunden sein und deren Transformation begleiten“, verspricht Saueressig und verweist noch einmal auf den Dreiklang aus Daten, Applikationen und KI. Der Business Kontext mache den Unterschied. SAP sitze mit seinen Lösungen am richtigen Hebel. Der SAP-Mann gibt sich selbstbewusst: „Wir halten nicht nur Schritt mit den Entwicklungen, sondern wir sind Schrittmacher.“",
    "source": "cio",
    "crawled_at": "2025-05-27T08:11:00.058481+00:00"
  },
  {
    "url": "https://www.cio.de/article/3695844/was-ist-ein-kooperativer-fuehrungsstil.html",
    "title": "Was ist ein kooperativer Führungsstil?",
    "published": "2025-05-27T06:10:42+00:00",
    "author": "",
    "text": "Kooperative Führungskräfte teilen Verantwortung mit ihren Mitarbeitern und beziehen sie in Entscheidungen ein. Foto: NDAB Creativity – shutterstock.com Ein Führungsstil beschreibt die Grundhaltung einer Führungskraft sowie ihr Verhalten gegenüber Mitarbeitern. Es gibt verschiedene Theorien und Modelle mit unterschiedlichen Führungsstilen . Eine bekannte Einteilung hat der Sozialpsychologe Kurt Lewin vorgenommen. Lewin emigrierte 1933 aus Deutschland und forschte in den USA. In dieser Zeit entstand die Unterscheidung und Abstufung zwischen den Führungsstilen autoritär, laissez-faire und kooperativ: Beim autoritären Führungsstil gibt die Führungsperson ihren Mitarbeitern Anweisungen, was zu tun ist. Mitarbeiter haben diese Anweisungen zu akzeptieren und auszuführen. Beim Laissez-faire-Führungsstil überträgt die Führungskraft Aufgaben auf die Mitarbeiter. Vorgesetzte machen klare Zielvorgaben, definieren die erwarteten Arbeitsergebnisse und delegieren die Aufgaben an die Mitarbeiter. Dazwischen liegt der kooperative Führungsstil , bei dem Führungskraft und Mitarbeiter Verantwortung teilen beziehungsweise gemeinsam übernehmen. Eines der Forschungsergebnisse Lewins war, dass ein kooperativer Führungsstil mit einer erhöhten Arbeitszufriedenheit der Mitarbeiter verbunden ist. Kooperative Führungskräfte teilen Verantwortung mit ihren Mitarbeitern und beziehen sie in Entscheidungen ein. Für Prof. Dr. Guido Möllering, Direktor des Reinhard-Mohn-Instituts für Unternehmensführung an der Universität Witten/Herdecke, zählt zu den Merkmalen einer kooperativen Führungskraft auch, dass mehr Autonomie gewährt wird bei zugleich gegenseitiger Transparenz und Koordination: “Die formale Führungskraft kommuniziert auf Augenhöhe, das heißt mit Respekt und Anerkennung der Fähigkeiten und Bedürfnisse der Geführten. Es gibt kaum noch Anweisungen, sondern man einigt sich, was zu tun ist”, so Möllering. Man verständige sich häufiger über die gemeinsamen Werte und Ziele. Führungskräfte sähen sich selbst als Vermittelnde. Für den Transformationsexperten und Berater Martin Michaelis ist es nicht nur eine Frage von Branchen, Unternehmenskultur oder Generationen, ob kooperatives Führen sinnvoll ist. “In der heutigen Zeit ständiger und schneller Veränderung haben Unternehmen gar keine andere Wahl, als Ihren Mitarbeitern in einem bestimmten Maße mehr Verantwortung zu übergeben. Das bedeutet für Führungskräfte, dass sie ihre Mitarbeiter mehr in Entscheidungsprozesse einbinden müssen.” Schwierig werde es dann, wenn unter den Mitarbeitern nur eine niedrige Bereitschaft bestehe, Verantwortung zu übernehmen. “Wichtig ist dann, Schritt für Schritt vorzugehen: je nach individueller Kapazität und nicht zu viel auf einmal an Verantwortungen zu delegieren”, rät Michaelis. “Die stärkere Partizipation und das Empowerment, das kooperative Führung ermöglicht, sind sehr motivierend, können aber auch überfordern”, weiß Experte Möllering. Wenn Verantwortung stärker geteilt werde, werfe das Fragen auf: Wer trägt das Risiko von gemeinsamen Entscheidungen? Und: Wer bekommt welchen Anteil am gemeinsamen Erfolg? “Wenn ein gemeinsames Verständnis hergestellt werden kann, wie die kooperative Führung wirklich gemeint ist, dann überwiegen klar die Vorteile”, ist Möllering überzeugt. Wichtig sei auch, dass eine echte Beteiligung an der Führung möglich ist. Also nicht am Ende doch wieder einer alles alleine entscheide. Doch lässt sich ein solcher kooperativer Führungsstil erlernen? “Es gibt eine Menge Kompetenzen, die erlernt werden können”, sagt Martin Michaelis auf die Frage, ob sich kooperatives Führen erlernen lässt. Dabei unterscheidet er zwischen Methoden und Verhalten, sowie Haltung. Neue Methoden und Verhaltensweisen lassen sich erlernen. Dazu zählt beispielsweise, sich selbst als Führungskraft zurückzunehmen, Mitarbeitern mehr Raum zu geben und ihnen mehr Fragen zu stellen. “Eine kooperative Haltung braucht meist etwas mehr Zeit”, so Michaelis. Je nach Person ständen oft alte Einstellungen und Glaubenssätze im Weg. Eine wichtige Erkenntnis lautet: Wer kooperativ führen möchte, muss Schritt für Schritt lernen, Vertrauen zu haben. “Eine ‘Dann mache ich das jetzt lieber selbst’-Haltung ergibt keinen Sinn”, sagt Michaelis. In einer konkreten Situation ist eine Aufgabe damit vielleicht schneller und auch besser erledigt. Aber damit nehme man seinen Mitarbeitern den Raum, zu lernen und sich weiterzuentwickeln. Und damit auch die Möglichkeit, zumindest mittelfristig mehr Verantwortung zu übernehmen. Die Bertelsmann Stiftung und das Reinhard-Mohn-Institut der Universität Witten/Herdecke haben für ihren Führungskräfte-Radar eine repräsentative Befragung unter Führungskräften in Deutschland vorgenommen. Eine Beobachtung: Wenn Home-Office zur Dauereinrichtung wird, befürchten Führungskräfte, dass der Austausch mit den Mitarbeitern mehr und mehr verloren geht und die Unternehmenskultur leidet. Viele Führungskräfte konnten ihre Mitarbeiter in Home-Office-Corona-Zeiten nicht so unterstützen, wie sie es gerne getan hätten (45,7 Prozent). Guido Möllering vom Reinhard-Mohn-Institut sagt: “Die Ausnahmesituation hat uns verschiedene Aspekte deutlicher sehen lassen als sonst”. Er nennt die folgenden drei Punkte: Führung funktioniert nur, wenn die Geführten mitspielen, also kooperativ die Impulse der Führenden aufnehmen oder konstruktiv der Führungskraft Feedback geben. Das Management kann gerade in einer Krise nicht alle Probleme alleine lösen und alle Entscheidungen alleine treffen. Notgedrungen wird mehr delegiert, pragmatisch gehandelt und sich aufeinander verlassen. Man ist im Team beim gemeinsamen, kooperativen Problemlösen mehr auf Augenhöhe. Gerade beim Führen auf Distanz (insbesondere wegen Homeoffice) merkt man deutlich, dass Führen nicht primär Kontrolle, sondern Unterstützung der Geführten bedeutet. Der Team-Gedanke verstärkt sich und die Verantwortung für das gemeinsame Ergebnis wird stärker geteilt. Übergreifend werde deutlich, wie wichtig eine solide Vertrauensbasis sei, so Möllering: “Diese baut man nicht durch hierarchische Anweisungen, sondern durch kollegiale Zusammenarbeit auf.” Im Gegensatz zu dem oft in Krisen vermuteten autoritären Führungsstil hat sich in der Corona-Pandemie nicht die lenkende Führungskraft früherer Zeiten, sondern die vermittelnde Führungskraft bewährt. Tipps zur virtuellen Mitarbeiterführung Foto: fizkes – shutterstock.com Seit der Pandemie gehört virtuelle Mitarbeiterführung zu den Standartaufgaben für jeden Vorgesetzten. Wir haben die wichtigsten Learnings aus dieser Zeit zusammengefasst. Unterschiedliche Arbeits- und Lebensumstände anerkennen Foto: Jelena Zelen – shutterstock.com Zu den größten Herausforderungen zählen die unterschiedlichen Voraussetzungen, womit Teammitglieder bei der Heimarbeit konfrontiert sind. Nicht jeder hat ausreichenden Raum für ein separates Home-Office. Dazu kommen Ablenkungen wie Kinder, Haustiere oder bei Singles ein Gefühl der Isolation. All das hat Einfluss darauf, wie und zu welchen Zeiten Mitarbeiter ihre Aufgaben am besten erledigen können. Vorgesetzte, die offen Verständnis für individuelle Situationen zeigen, schaffen die Grundlage einer vertrauensvollen Zusammenarbeit. Stress-Level steuern Foto: Rawpixel.com – shutterstock.com Permanenter Stress im Home-Office ist keine gute Voraussetzung, um kontinuierlich gute Arbeit zu leisten. Wer als Führungskraft vermittelt, dass es okay ist, nicht immer perfekt zu funktionieren, nimmt Mitarbeitern etwas den Druck in der Gewöhnung an die neue Normalität. Vielen fällt es mit dieser Gewissheit leichter, Deadlines einzuhalten und den Erwartungen zu entsprechen. Regelmäßigen Kontakt pflegen Foto: fizkes – shutterstock.com Ein tägliches Gespräch mit Chefin oder Chef – ist das nicht zu viel der Kommunikation? Nein, denn insbesondere bei der digitalen Mitarbeiterführung ist die Regelmäßigkeit des Austauschs entscheidend. Nur so lässt sich einschätzen, ob alles wie besprochen läuft und sich alle im Team den Anforderungen gewachsen fühlen. Missverständnisse und Fehler passieren – ähnlich wie im Büro – vor allem, wenn zu wenig kommuniziert wird. Neue Technologien nutzen Foto: Tada Images – shutterstock.com Nur mit Personen, zu denen man regelmäßigen Kontakt pflegt, können Beziehungen entstehen. Das funktioniert im Zeitalter des digitalen Austauschs über zahlreiche Kommunikationskanäle. Moderne Videokonferenz-Tools wie Zoom, Teams, Google Meet etc. ermöglichen eine Kommunikation von Angesicht zu Angesicht und machen sichtbar, wie es allen Teammitgliedern geht. Kommunikationsregeln festlegen Foto: patpitchaya – shutterstock.com Dezentral organisierte Teamarbeit funktioniert am effektivsten, wenn sich alle über die Grundregeln der Kommunikation einig sind. Vorgesetzte können für klare Verhältnisse sorgen, indem sie Häufigkeit, Zweck und Timing des Austauschs und die dafür priorisierten Kanäle festlegen. Videokonferenzen sind in der Regel die erste Wahl für die tägliche Gruppenbesprechung. Gerade größere Gesprächsrunden lassen sich durch simple Tricks so strukturieren, dass auch Meetings mit hoher Teilnehmerzahl geordnet und effektiv ablaufen. Wenn es um dringliche Angelegenheiten oder Nachfragen geht, sind andere Kanäle wie Instant Messaging der bessere Weg. Unified-Communications-Plattformen ermöglichen eine Vielzahl von Anwendungen und Kommunikationskanälen. Erwartungen definieren Foto: ogichobanov – shutterstock.com Oft werden beim Übergang von der klassischen Büroarbeit ins Home-Office Aufgaben innerhalb eines Teams neu verteilt oder kommen neue hinzu. Damit Mitarbeiter diese erfüllen können, muss klar sein, was genau von ihnen erwartet wird. Manchen mag es außerhalb der gewohnten Büroatmosphäre anfangs schwerfallen, Aufträge zu priorisieren. Gemeinsam kann geklärt werden, welche Aufgaben Priorität haben und zu schaffen ist. Einfach davon auszugehen, dass jeder weiß, was zu tun ist, ist kontraproduktiv. Besser ist, von Anfang an eine Feedback-Schleife zu vereinbaren, um Erwartungen anzupassen und in den bekannten Applikationen zu dokumentieren. Ein gemeinsames Ziel verfolgen Foto: Rawpixel.com – shutterstock.com Teams funktionieren vor allem dann, wenn alle Mitglieder eine gemeinsame Mission verfolgen. Das dabei entstehende Gemeinschaftsgefühl hilft auch, Unsicherheiten zu überwinden und mit ungewohnten Arbeitssituationen umzugehen. Wenn jeder weiß, was er zum gemeinsamen Erfolg beiträgt, ist das die beste Motivation, Höchstleistungen zu erbringen. Erfolge sollten außerdem gewürdigt werden. Auf die Ergebnisse konzentrieren Foto: everything possible – shutterstock.com Wie lassen sich Engagement und Selbstverantwortung fördern? Indem Führungskräfte sich auf die gewünschten Ergebnisse konzentrieren und Teammitgliedern den Freiraum lassen, selbst einzuteilen, wie sie zum Ziel kommen wollen. Voraussetzung dafür ist ausreichend Zeit und zuvor aufgebautes Vertrauen. Ist das der Fall, lässt sich auf diesem Weg nicht nur die Kreativität der Mitarbeiter fördern, sondern auch kräftezehrendes Mikromanagement vermeiden. Virtuelle Brainstorms lassen sich beispielsweise in Breakout-Räume aufteilen. Kleinere Teams können dadurch in separaten Sitzungen arbeiten und ihre Ideen sammeln, die anschließend in der größeren Runde präsentiert werden. Strikte Kontrollmechanismen vermeiden Foto: ibreakstock – shutterstock.com Regelmäßige Kommunikation und klare Zielvorgaben sind wichtig. Sie dürfen aber nicht dazu führen, dass Mitarbeiter das Gefühl bekommen, im Home-Office überwacht zu werden. Vorgesetzte, die mehrmals täglich penible Rückmeldungen zu erledigten Arbeitsschritten einfordern, signalisieren damit fehlendes Vertrauen. Sie riskieren zudem, dass Teams den Fokus verlieren. Beratung und Betreuung sind besser als strikte Kontrolle. Neue Team-Mitglieder integrieren Foto: iQoncept – shutterstock.com Als neues Mitglied in ein dezentral arbeitendes Team zu kommen, kann zur Herausforderung werden, weil sich die Dynamik einer Gruppe anfangs schwerer erspüren lässt. Umso wichtiger ist es, Neulingen zu Beginn ihrer Tätigkeit das Gefühl zu geben, Teil der Gruppe zu sein. Unternehmen, die bereits über längere Erfahrung in dezentralem Arbeiten verfügen, haben dies zum festen Bestandteil ihres Onboardings gemacht. Das Wir-Gefühl stärken Foto: Girts Ragelis – shutterstock.com Selbst in gut funktionierenden Arbeitsumfeldern kann es gelegentlich zu Unsicherheiten, Unzufriedenheit oder Ängsten der Mitarbeiter kommen. Die Aufgabe von Führungskräften besteht darin, Teams davor zu schützen. Das gelingt am besten, wenn auch die sozialen Aspekte der gemeinsamen Arbeit berücksichtigt werden. Dafür braucht es keine verpflichtenden gemeinsamen Kaffeepausen, aber von Zeit zu Zeit die Gelegenheit für einen lockeren Austausch, der Mitarbeitern das Gefühl gibt, trotz der Distanz wahrgenommen zu werden. Virtuell lässt sich der Teamgeist auch fördern, wenn zur Abwechslung mal eine Happy Hour, ein virtuelles Quizzen oder ein gemeinsames Essen per Videochat organisiert wird. Kooperative Führungskräfte teilen Verantwortung mit ihren Mitarbeitern und beziehen sie in Entscheidungen ein. Foto: NDAB Creativity – shutterstock.com Ein Führungsstil beschreibt die Grundhaltung einer Führungskraft sowie ihr Verhalten gegenüber Mitarbeitern. Es gibt verschiedene Theorien und Modelle mit unterschiedlichen Führungsstilen . Eine bekannte Einteilung hat der Sozialpsychologe Kurt Lewin vorgenommen. Lewin emigrierte 1933 aus Deutschland und forschte in den USA. In dieser Zeit entstand die Unterscheidung und Abstufung zwischen den Führungsstilen autoritär, laissez-faire und kooperativ: Beim autoritären Führungsstil gibt die Führungsperson ihren Mitarbeitern Anweisungen, was zu tun ist. Mitarbeiter haben diese Anweisungen zu akzeptieren und auszuführen. Beim Laissez-faire-Führungsstil überträgt die Führungskraft Aufgaben auf die Mitarbeiter. Vorgesetzte machen klare Zielvorgaben, definieren die erwarteten Arbeitsergebnisse und delegieren die Aufgaben an die Mitarbeiter. Dazwischen liegt der kooperative Führungsstil , bei dem Führungskraft und Mitarbeiter Verantwortung teilen beziehungsweise gemeinsam übernehmen. Eines der Forschungsergebnisse Lewins war, dass ein kooperativer Führungsstil mit einer erhöhten Arbeitszufriedenheit der Mitarbeiter verbunden ist. Kooperative Führungskräfte teilen Verantwortung mit ihren Mitarbeitern und beziehen sie in Entscheidungen ein. Für Prof. Dr. Guido Möllering, Direktor des Reinhard-Mohn-Instituts für Unternehmensführung an der Universität Witten/Herdecke, zählt zu den Merkmalen einer kooperativen Führungskraft auch, dass mehr Autonomie gewährt wird bei zugleich gegenseitiger Transparenz und Koordination: “Die formale Führungskraft kommuniziert auf Augenhöhe, das heißt mit Respekt und Anerkennung der Fähigkeiten und Bedürfnisse der Geführten. Es gibt kaum noch Anweisungen, sondern man einigt sich, was zu tun ist”, so Möllering. Man verständige sich häufiger über die gemeinsamen Werte und Ziele. Führungskräfte sähen sich selbst als Vermittelnde. Für den Transformationsexperten und Berater Martin Michaelis ist es nicht nur eine Frage von Branchen, Unternehmenskultur oder Generationen, ob kooperatives Führen sinnvoll ist. “In der heutigen Zeit ständiger und schneller Veränderung haben Unternehmen gar keine andere Wahl, als Ihren Mitarbeitern in einem bestimmten Maße mehr Verantwortung zu übergeben. Das bedeutet für Führungskräfte, dass sie ihre Mitarbeiter mehr in Entscheidungsprozesse einbinden müssen.” Schwierig werde es dann, wenn unter den Mitarbeitern nur eine niedrige Bereitschaft bestehe, Verantwortung zu übernehmen. “Wichtig ist dann, Schritt für Schritt vorzugehen: je nach individueller Kapazität und nicht zu viel auf einmal an Verantwortungen zu delegieren”, rät Michaelis. “Die stärkere Partizipation und das Empowerment, das kooperative Führung ermöglicht, sind sehr motivierend, können aber auch überfordern”, weiß Experte Möllering. Wenn Verantwortung stärker geteilt werde, werfe das Fragen auf: Wer trägt das Risiko von gemeinsamen Entscheidungen? Und: Wer bekommt welchen Anteil am gemeinsamen Erfolg? “Wenn ein gemeinsames Verständnis hergestellt werden kann, wie die kooperative Führung wirklich gemeint ist, dann überwiegen klar die Vorteile”, ist Möllering überzeugt. Wichtig sei auch, dass eine echte Beteiligung an der Führung möglich ist. Also nicht am Ende doch wieder einer alles alleine entscheide. Doch lässt sich ein solcher kooperativer Führungsstil erlernen? “Es gibt eine Menge Kompetenzen, die erlernt werden können”, sagt Martin Michaelis auf die Frage, ob sich kooperatives Führen erlernen lässt. Dabei unterscheidet er zwischen Methoden und Verhalten, sowie Haltung. Neue Methoden und Verhaltensweisen lassen sich erlernen. Dazu zählt beispielsweise, sich selbst als Führungskraft zurückzunehmen, Mitarbeitern mehr Raum zu geben und ihnen mehr Fragen zu stellen. “Eine kooperative Haltung braucht meist etwas mehr Zeit”, so Michaelis. Je nach Person ständen oft alte Einstellungen und Glaubenssätze im Weg. Eine wichtige Erkenntnis lautet: Wer kooperativ führen möchte, muss Schritt für Schritt lernen, Vertrauen zu haben. “Eine ‘Dann mache ich das jetzt lieber selbst’-Haltung ergibt keinen Sinn”, sagt Michaelis. In einer konkreten Situation ist eine Aufgabe damit vielleicht schneller und auch besser erledigt. Aber damit nehme man seinen Mitarbeitern den Raum, zu lernen und sich weiterzuentwickeln. Und damit auch die Möglichkeit, zumindest mittelfristig mehr Verantwortung zu übernehmen. Die Bertelsmann Stiftung und das Reinhard-Mohn-Institut der Universität Witten/Herdecke haben für ihren Führungskräfte-Radar eine repräsentative Befragung unter Führungskräften in Deutschland vorgenommen. Eine Beobachtung: Wenn Home-Office zur Dauereinrichtung wird, befürchten Führungskräfte, dass der Austausch mit den Mitarbeitern mehr und mehr verloren geht und die Unternehmenskultur leidet. Viele Führungskräfte konnten ihre Mitarbeiter in Home-Office-Corona-Zeiten nicht so unterstützen, wie sie es gerne getan hätten (45,7 Prozent). Guido Möllering vom Reinhard-Mohn-Institut sagt: “Die Ausnahmesituation hat uns verschiedene Aspekte deutlicher sehen lassen als sonst”. Er nennt die folgenden drei Punkte: Führung funktioniert nur, wenn die Geführten mitspielen, also kooperativ die Impulse der Führenden aufnehmen oder konstruktiv der Führungskraft Feedback geben. Das Management kann gerade in einer Krise nicht alle Probleme alleine lösen und alle Entscheidungen alleine treffen. Notgedrungen wird mehr delegiert, pragmatisch gehandelt und sich aufeinander verlassen. Man ist im Team beim gemeinsamen, kooperativen Problemlösen mehr auf Augenhöhe. Gerade beim Führen auf Distanz (insbesondere wegen Homeoffice) merkt man deutlich, dass Führen nicht primär Kontrolle, sondern Unterstützung der Geführten bedeutet. Der Team-Gedanke verstärkt sich und die Verantwortung für das gemeinsame Ergebnis wird stärker geteilt. Übergreifend werde deutlich, wie wichtig eine solide Vertrauensbasis sei, so Möllering: “Diese baut man nicht durch hierarchische Anweisungen, sondern durch kollegiale Zusammenarbeit auf.” Im Gegensatz zu dem oft in Krisen vermuteten autoritären Führungsstil hat sich in der Corona-Pandemie nicht die lenkende Führungskraft früherer Zeiten, sondern die vermittelnde Führungskraft bewährt. Tipps zur virtuellen Mitarbeiterführung Foto: fizkes – shutterstock.com Seit der Pandemie gehört virtuelle Mitarbeiterführung zu den Standartaufgaben für jeden Vorgesetzten. Wir haben die wichtigsten Learnings aus dieser Zeit zusammengefasst. Unterschiedliche Arbeits- und Lebensumstände anerkennen Foto: Jelena Zelen – shutterstock.com Zu den größten Herausforderungen zählen die unterschiedlichen Voraussetzungen, womit Teammitglieder bei der Heimarbeit konfrontiert sind. Nicht jeder hat ausreichenden Raum für ein separates Home-Office. Dazu kommen Ablenkungen wie Kinder, Haustiere oder bei Singles ein Gefühl der Isolation. All das hat Einfluss darauf, wie und zu welchen Zeiten Mitarbeiter ihre Aufgaben am besten erledigen können. Vorgesetzte, die offen Verständnis für individuelle Situationen zeigen, schaffen die Grundlage einer vertrauensvollen Zusammenarbeit. Stress-Level steuern Foto: Rawpixel.com – shutterstock.com Permanenter Stress im Home-Office ist keine gute Voraussetzung, um kontinuierlich gute Arbeit zu leisten. Wer als Führungskraft vermittelt, dass es okay ist, nicht immer perfekt zu funktionieren, nimmt Mitarbeitern etwas den Druck in der Gewöhnung an die neue Normalität. Vielen fällt es mit dieser Gewissheit leichter, Deadlines einzuhalten und den Erwartungen zu entsprechen. Regelmäßigen Kontakt pflegen Foto: fizkes – shutterstock.com Ein tägliches Gespräch mit Chefin oder Chef – ist das nicht zu viel der Kommunikation? Nein, denn insbesondere bei der digitalen Mitarbeiterführung ist die Regelmäßigkeit des Austauschs entscheidend. Nur so lässt sich einschätzen, ob alles wie besprochen läuft und sich alle im Team den Anforderungen gewachsen fühlen. Missverständnisse und Fehler passieren – ähnlich wie im Büro – vor allem, wenn zu wenig kommuniziert wird. Neue Technologien nutzen Foto: Tada Images – shutterstock.com Nur mit Personen, zu denen man regelmäßigen Kontakt pflegt, können Beziehungen entstehen. Das funktioniert im Zeitalter des digitalen Austauschs über zahlreiche Kommunikationskanäle. Moderne Videokonferenz-Tools wie Zoom, Teams, Google Meet etc. ermöglichen eine Kommunikation von Angesicht zu Angesicht und machen sichtbar, wie es allen Teammitgliedern geht. Kommunikationsregeln festlegen Foto: patpitchaya – shutterstock.com Dezentral organisierte Teamarbeit funktioniert am effektivsten, wenn sich alle über die Grundregeln der Kommunikation einig sind. Vorgesetzte können für klare Verhältnisse sorgen, indem sie Häufigkeit, Zweck und Timing des Austauschs und die dafür priorisierten Kanäle festlegen. Videokonferenzen sind in der Regel die erste Wahl für die tägliche Gruppenbesprechung. Gerade größere Gesprächsrunden lassen sich durch simple Tricks so strukturieren, dass auch Meetings mit hoher Teilnehmerzahl geordnet und effektiv ablaufen. Wenn es um dringliche Angelegenheiten oder Nachfragen geht, sind andere Kanäle wie Instant Messaging der bessere Weg. Unified-Communications-Plattformen ermöglichen eine Vielzahl von Anwendungen und Kommunikationskanälen. Erwartungen definieren Foto: ogichobanov – shutterstock.com Oft werden beim Übergang von der klassischen Büroarbeit ins Home-Office Aufgaben innerhalb eines Teams neu verteilt oder kommen neue hinzu. Damit Mitarbeiter diese erfüllen können, muss klar sein, was genau von ihnen erwartet wird. Manchen mag es außerhalb der gewohnten Büroatmosphäre anfangs schwerfallen, Aufträge zu priorisieren. Gemeinsam kann geklärt werden, welche Aufgaben Priorität haben und zu schaffen ist. Einfach davon auszugehen, dass jeder weiß, was zu tun ist, ist kontraproduktiv. Besser ist, von Anfang an eine Feedback-Schleife zu vereinbaren, um Erwartungen anzupassen und in den bekannten Applikationen zu dokumentieren. Ein gemeinsames Ziel verfolgen Foto: Rawpixel.com – shutterstock.com Teams funktionieren vor allem dann, wenn alle Mitglieder eine gemeinsame Mission verfolgen. Das dabei entstehende Gemeinschaftsgefühl hilft auch, Unsicherheiten zu überwinden und mit ungewohnten Arbeitssituationen umzugehen. Wenn jeder weiß, was er zum gemeinsamen Erfolg beiträgt, ist das die beste Motivation, Höchstleistungen zu erbringen. Erfolge sollten außerdem gewürdigt werden. Auf die Ergebnisse konzentrieren Foto: everything possible – shutterstock.com Wie lassen sich Engagement und Selbstverantwortung fördern? Indem Führungskräfte sich auf die gewünschten Ergebnisse konzentrieren und Teammitgliedern den Freiraum lassen, selbst einzuteilen, wie sie zum Ziel kommen wollen. Voraussetzung dafür ist ausreichend Zeit und zuvor aufgebautes Vertrauen. Ist das der Fall, lässt sich auf diesem Weg nicht nur die Kreativität der Mitarbeiter fördern, sondern auch kräftezehrendes Mikromanagement vermeiden. Virtuelle Brainstorms lassen sich beispielsweise in Breakout-Räume aufteilen. Kleinere Teams können dadurch in separaten Sitzungen arbeiten und ihre Ideen sammeln, die anschließend in der größeren Runde präsentiert werden. Strikte Kontrollmechanismen vermeiden Foto: ibreakstock – shutterstock.com Regelmäßige Kommunikation und klare Zielvorgaben sind wichtig. Sie dürfen aber nicht dazu führen, dass Mitarbeiter das Gefühl bekommen, im Home-Office überwacht zu werden. Vorgesetzte, die mehrmals täglich penible Rückmeldungen zu erledigten Arbeitsschritten einfordern, signalisieren damit fehlendes Vertrauen. Sie riskieren zudem, dass Teams den Fokus verlieren. Beratung und Betreuung sind besser als strikte Kontrolle. Neue Team-Mitglieder integrieren Foto: iQoncept – shutterstock.com Als neues Mitglied in ein dezentral arbeitendes Team zu kommen, kann zur Herausforderung werden, weil sich die Dynamik einer Gruppe anfangs schwerer erspüren lässt. Umso wichtiger ist es, Neulingen zu Beginn ihrer Tätigkeit das Gefühl zu geben, Teil der Gruppe zu sein. Unternehmen, die bereits über längere Erfahrung in dezentralem Arbeiten verfügen, haben dies zum festen Bestandteil ihres Onboardings gemacht. Das Wir-Gefühl stärken Foto: Girts Ragelis – shutterstock.com Selbst in gut funktionierenden Arbeitsumfeldern kann es gelegentlich zu Unsicherheiten, Unzufriedenheit oder Ängsten der Mitarbeiter kommen. Die Aufgabe von Führungskräften besteht darin, Teams davor zu schützen. Das gelingt am besten, wenn auch die sozialen Aspekte der gemeinsamen Arbeit berücksichtigt werden. Dafür braucht es keine verpflichtenden gemeinsamen Kaffeepausen, aber von Zeit zu Zeit die Gelegenheit für einen lockeren Austausch, der Mitarbeitern das Gefühl gibt, trotz der Distanz wahrgenommen zu werden. Virtuell lässt sich der Teamgeist auch fördern, wenn zur Abwechslung mal eine Happy Hour, ein virtuelles Quizzen oder ein gemeinsames Essen per Videochat organisiert wird.",
    "source": "cio",
    "crawled_at": "2025-05-27T08:11:00.176683+00:00"
  },
  {
    "url": "https://www.cio.de/article/3995672/putin-will-westliche-it-firmen-in-russland-ausbremsen.html",
    "title": "Putin will westliche IT-Firmen in Russland ausbremsen",
    "published": "2025-05-27T07:49:13+00:00",
    "author": "",
    "text": "Asatur Yesayants – shutterstock.com Kremlchef Wladimir Putin will die Dienstleistungen aus Russland fortgegangener westlicher IT-Konzerne im Land sperren. «Man muss sie drosseln», sagte Putin bei einer Besprechung mit russischen Unternehmern. Er sage dies ohne jede Verlegenheit. Der Westen wolle Russland strangulieren, also müsse man Gleiches mit Gleichem vergelten, forderte der 72-Jährige. Auch anderen Branchen versprach er Protektionsmaßnahmen. Vorausgegangen war die Klage eines russischen IT-Managers über Milliardenverluste für einheimische Technologieunternehmen. Die Branche leide darunter, dass Russen weiter vielfach auf Zoom oder Microsoft setzten. Putin versprach, die Bürger «von ihren schlechten Angewohnheiten zu befreien». Virtuelle ausländische Handelsplattformen kritisierte Putin zudem als «Loch», über die alles Mögliche nach Russland eingeführt werde. Russland hat bereits jetzt, die Netzgeschwindigkeit vieler ausländischer Online-Dienste gedrosselt. So können Russen YouTube ohne virtuelles privates Netzwerk (VPN) praktisch nicht mehr nutzen, da Videos zu lange laden. Russland baut parallel dazu die Videoplattform RUTube auf. Facebook oder Instagram sind seit Kriegsbeginn ebenfalls als extremistisch eingestuft und daher gesperrt. Die Behörden haben auch viele große VPN-Anbieter bereits blockiert, damit die Russen nicht auf Umwegen unkontrolliert im Netz surfen. (dpa/ad) Asatur Yesayants – shutterstock.com Kremlchef Wladimir Putin will die Dienstleistungen aus Russland fortgegangener westlicher IT-Konzerne im Land sperren. «Man muss sie drosseln», sagte Putin bei einer Besprechung mit russischen Unternehmern. Er sage dies ohne jede Verlegenheit. Der Westen wolle Russland strangulieren, also müsse man Gleiches mit Gleichem vergelten, forderte der 72-Jährige. Auch anderen Branchen versprach er Protektionsmaßnahmen. Vorausgegangen war die Klage eines russischen IT-Managers über Milliardenverluste für einheimische Technologieunternehmen. Die Branche leide darunter, dass Russen weiter vielfach auf Zoom oder Microsoft setzten. Putin versprach, die Bürger «von ihren schlechten Angewohnheiten zu befreien». Virtuelle ausländische Handelsplattformen kritisierte Putin zudem als «Loch», über die alles Mögliche nach Russland eingeführt werde. Russland hat bereits jetzt, die Netzgeschwindigkeit vieler ausländischer Online-Dienste gedrosselt. So können Russen YouTube ohne virtuelles privates Netzwerk (VPN) praktisch nicht mehr nutzen, da Videos zu lange laden. Russland baut parallel dazu die Videoplattform RUTube auf. Facebook oder Instagram sind seit Kriegsbeginn ebenfalls als extremistisch eingestuft und daher gesperrt. Die Behörden haben auch viele große VPN-Anbieter bereits blockiert, damit die Russen nicht auf Umwegen unkontrolliert im Netz surfen. (dpa/ad)",
    "source": "cio",
    "crawled_at": "2025-05-27T08:11:00.933388+00:00"
  },
  {
    "url": "https://www.cio.de/article/3995683/meta-startet-ki-training-in-deutschland.html",
    "title": "Meta startet KI-Training in Deutschland",
    "published": "2025-05-27T07:54:32+00:00",
    "author": "",
    "text": "Algi Febri Sugita – shutterstock.com Der Facebook-Konzern Meta kann ab sofort in großem Stil damit beginnen, seine Systeme mit Künstlicher Intelligenz mit Nutzerdaten aus Deutschland zu trainieren. Das US-Unternehmen will dazu alle Beiträge, die Nutzer jemals auf Facebook oder Instagram gepostet haben, auslesen, um damit seine KI-Modelle zu verbessern. Kunden konnten dieser Nutzung aktiv widersprechen. Die Widerspruchsfrist war allerdings in der Nacht zum Dienstag ausgelaufen. WhatsApp gehört ebenfalls zu Meta, die Chat-Inhalte sind aber verschlüsselt – der Konzern kann sie deshalb nicht verwenden. Allerdings gelten Chats mit dem KI-Assistenten «Meta AI» als öffentlich und können ebenfalls für das Training genutzt werden. Zuvor waren Verbraucherschützer aus Deutschland mit ihrem Versuch gescheitert, die Verwendung der Daten für das KI-Training gerichtlich untersagen zu lassen. Das Oberlandesgericht Köln entschied am vergangenen Freitag in einem Eilverfahren, dass Meta Nutzerbeiträge aus Facebook und Instagram für das Training seiner KI-Software Meta AI verwenden darf (Az. 15 UKl 2/25). Geklagt hatte die Verbraucherzentrale Nordrhein-Westfalen. Sie begründete ihren Antrag auf Erlass einer einstweiligen Anordnung unter anderem mit einem Verstoß gegen europäisches Datenschutzrecht. Meta betonte nach der Urteilsverkündung, dass mit dem Verfahren zum KI-Training keine Datenschutz-Bestimmungen verletzt würden. «Wir sind verpflichtet, Deutsch-trainierte KI in die Hände der deutschen Bevölkerung zu bringen und sicherzustellen, dass jeder in Europa gleichberechtigten Zugang zu den vollen Vorteilen der generativen KI hat», sagte ein Meta-Sprecher. Meta kann bislang im KI-Wettbewerb mit den Marktführern nicht mithalten. Bei einer aktuellen Umfrage des deutschen Digital-Branchenverbandes Bitkom zur Nutzung von KI-Anwendungen durch die Menschen in Deutschland lagen die Konkurrenten OpenAI (ChatGPT) mit 43 Prozent, Microsoft (CoPilot) mit 39 Prozent und Google (Gemini) mit 28 Prozent weit vorn. In der Liste der meistgenutzten KI-Anwendungen tauchte das KI-Sprachmodell Llama von Meta überhaupt nicht auf. Meta hatte Llama 2023 als quell-offenes System (Open Source) vorgestellt und in der Fachwelt für große Aufmerksamkeit gesorgt. Inzwischen sind aber etliche Experten der Meinung, dass Meta mit dem Tempo der drei US-Marktführer nicht mehr mithalten kann. Sie sehen selbst bei chinesischen Herausforderern wie DeepSeek eine größere Dynamik. (dpa/ad) Algi Febri Sugita – shutterstock.com Der Facebook-Konzern Meta kann ab sofort in großem Stil damit beginnen, seine Systeme mit Künstlicher Intelligenz mit Nutzerdaten aus Deutschland zu trainieren. Das US-Unternehmen will dazu alle Beiträge, die Nutzer jemals auf Facebook oder Instagram gepostet haben, auslesen, um damit seine KI-Modelle zu verbessern. Kunden konnten dieser Nutzung aktiv widersprechen. Die Widerspruchsfrist war allerdings in der Nacht zum Dienstag ausgelaufen. WhatsApp gehört ebenfalls zu Meta, die Chat-Inhalte sind aber verschlüsselt – der Konzern kann sie deshalb nicht verwenden. Allerdings gelten Chats mit dem KI-Assistenten «Meta AI» als öffentlich und können ebenfalls für das Training genutzt werden. Zuvor waren Verbraucherschützer aus Deutschland mit ihrem Versuch gescheitert, die Verwendung der Daten für das KI-Training gerichtlich untersagen zu lassen. Das Oberlandesgericht Köln entschied am vergangenen Freitag in einem Eilverfahren, dass Meta Nutzerbeiträge aus Facebook und Instagram für das Training seiner KI-Software Meta AI verwenden darf (Az. 15 UKl 2/25). Geklagt hatte die Verbraucherzentrale Nordrhein-Westfalen. Sie begründete ihren Antrag auf Erlass einer einstweiligen Anordnung unter anderem mit einem Verstoß gegen europäisches Datenschutzrecht. Meta betonte nach der Urteilsverkündung, dass mit dem Verfahren zum KI-Training keine Datenschutz-Bestimmungen verletzt würden. «Wir sind verpflichtet, Deutsch-trainierte KI in die Hände der deutschen Bevölkerung zu bringen und sicherzustellen, dass jeder in Europa gleichberechtigten Zugang zu den vollen Vorteilen der generativen KI hat», sagte ein Meta-Sprecher. Meta kann bislang im KI-Wettbewerb mit den Marktführern nicht mithalten. Bei einer aktuellen Umfrage des deutschen Digital-Branchenverbandes Bitkom zur Nutzung von KI-Anwendungen durch die Menschen in Deutschland lagen die Konkurrenten OpenAI (ChatGPT) mit 43 Prozent, Microsoft (CoPilot) mit 39 Prozent und Google (Gemini) mit 28 Prozent weit vorn. In der Liste der meistgenutzten KI-Anwendungen tauchte das KI-Sprachmodell Llama von Meta überhaupt nicht auf. Meta hatte Llama 2023 als quell-offenes System (Open Source) vorgestellt und in der Fachwelt für große Aufmerksamkeit gesorgt. Inzwischen sind aber etliche Experten der Meinung, dass Meta mit dem Tempo der drei US-Marktführer nicht mehr mithalten kann. Sie sehen selbst bei chinesischen Herausforderern wie DeepSeek eine größere Dynamik. (dpa/ad)",
    "source": "cio",
    "crawled_at": "2025-05-27T08:11:01.062229+00:00"
  }
]