[
  {
    "url": "https://www.cio.de/article/3991929/google-zeigt-prototypen-einer-schlanken-ar-brille.html",
    "title": "Google zeigt Prototypen einer schlanken AR-Brille",
    "published": "2025-05-21T09:40:00+00:00",
    "author": "",
    "text": "Ground Picture | shutterstock.com Google hat neue Prototypen von Computer-Brillen vorgestellt, die Informationen ins Blickfeld der Nutzer einblenden können. In der Demonstration tauchten in der schlanken Brille etwa Routenanweisungen und Fotos auf. Auch konnten sich zwei Personen in verschiedenen Sprachen miteinander unterhalten. Die Brille blendete jeweils die Übersetzung in Englisch ein. “Untertitel für die reale Welt”, nennt das Google. Leichte Computer-Brillen mit sogenannter Erweiterter Realität (AR, Augmented Reality) sind seit Jahren ein Traum der Tech-Industrie. Der Konzern entwickelte für die Technik das Betriebssystem Android XR. Die Brillen sind zum Tragen über den gesamten Tag gedacht, betont Google. Neben Kameras haben sie auch ein Mikrofon sowie Lautsprecher und verbinden sich mit dem Smartphone. Die Google-KI Gemini könne damit “die Welt sehen”. Für ein Verbraucherprodukt arbeitet Google mit den Brillen-Anbietern Gentle Monster und Warby Parker zusammen, hieß es bei der Entwicklerkonferenz Google I/O. Unter anderem auch der Facebook-Konzern Meta arbeitet an einer solchen Brille. Auf dem Markt brachte das Unternehmen bisher Kamera-Brillen ohne Display heraus. Sie werden in Kooperation mit dem weltgrößten Brillenkonzern Luxottica unter der Marke Ray-ban verkauft. Auch Facebook-Gründer Mark Zuckerberg betont, der entscheidende Vorteil sei, dass die KI dadurch sehen und hören könne, was die Nutzer sehen und hören – und dadurch besser die Situation verstehe. Prototypen einer Brille mit Display hat Meta auch – sie wirken aber etwas klobiger als die von Google. Bei beiden Brillen ist unter anderem unklar, wie lange die Batterie bei Alltagsnutzung halten würde. Selbst die sparsamsten modernen Chips brauchen für solche Aufgaben relativ viel Strom – und ein Brillengestell hat verständlicherweise wenig Platz für Akkus. Apple forscht ebenfalls schon seit Jahren an Erweiterter Realität, bei der digitale Inhalte für den Nutzer in die reale Umgebung eingeblendet werden. Angesichts des Standes der Technologie bremste Apple jedoch Medienberichten zufolge die Entwicklung von AR-Brillen mit durchsichtigen Gläsern. Stattdessen brachte der Konzern das Headset Vision Pro heraus, bei dem Kameras die reale Umgebung filmen und für die Nutzer auf Displays vor den Augen wiedergeben. In diesem Bild werden dann auch die digitalen Elemente integriert. Mit einem Preis ab knapp 4.000 Euro ist die Brille deutlich teurer als Headsets der Konkurrenz. (dpa/rs) Ground Picture | shutterstock.com Google hat neue Prototypen von Computer-Brillen vorgestellt, die Informationen ins Blickfeld der Nutzer einblenden können. In der Demonstration tauchten in der schlanken Brille etwa Routenanweisungen und Fotos auf. Auch konnten sich zwei Personen in verschiedenen Sprachen miteinander unterhalten. Die Brille blendete jeweils die Übersetzung in Englisch ein. “Untertitel für die reale Welt”, nennt das Google. Leichte Computer-Brillen mit sogenannter Erweiterter Realität (AR, Augmented Reality) sind seit Jahren ein Traum der Tech-Industrie. Der Konzern entwickelte für die Technik das Betriebssystem Android XR. Die Brillen sind zum Tragen über den gesamten Tag gedacht, betont Google. Neben Kameras haben sie auch ein Mikrofon sowie Lautsprecher und verbinden sich mit dem Smartphone. Die Google-KI Gemini könne damit “die Welt sehen”. Für ein Verbraucherprodukt arbeitet Google mit den Brillen-Anbietern Gentle Monster und Warby Parker zusammen, hieß es bei der Entwicklerkonferenz Google I/O. Unter anderem auch der Facebook-Konzern Meta arbeitet an einer solchen Brille. Auf dem Markt brachte das Unternehmen bisher Kamera-Brillen ohne Display heraus. Sie werden in Kooperation mit dem weltgrößten Brillenkonzern Luxottica unter der Marke Ray-ban verkauft. Auch Facebook-Gründer Mark Zuckerberg betont, der entscheidende Vorteil sei, dass die KI dadurch sehen und hören könne, was die Nutzer sehen und hören – und dadurch besser die Situation verstehe. Prototypen einer Brille mit Display hat Meta auch – sie wirken aber etwas klobiger als die von Google. Bei beiden Brillen ist unter anderem unklar, wie lange die Batterie bei Alltagsnutzung halten würde. Selbst die sparsamsten modernen Chips brauchen für solche Aufgaben relativ viel Strom – und ein Brillengestell hat verständlicherweise wenig Platz für Akkus. Apple forscht ebenfalls schon seit Jahren an Erweiterter Realität, bei der digitale Inhalte für den Nutzer in die reale Umgebung eingeblendet werden. Angesichts des Standes der Technologie bremste Apple jedoch Medienberichten zufolge die Entwicklung von AR-Brillen mit durchsichtigen Gläsern. Stattdessen brachte der Konzern das Headset Vision Pro heraus, bei dem Kameras die reale Umgebung filmen und für die Nutzer auf Displays vor den Augen wiedergeben. In diesem Bild werden dann auch die digitalen Elemente integriert. Mit einem Preis ab knapp 4.000 Euro ist die Brille deutlich teurer als Headsets der Konkurrenz. (dpa/rs)",
    "source": "cio",
    "crawled_at": "2025-05-28T09:16:45.632420+00:00"
  },
  {
    "url": "https://www.cio.de/article/3828970/vorkonfigurierte-komplettsysteme-fur-ki-projekte.html",
    "title": "Vorkonfigurierte Komplettsysteme für KI-Projekte",
    "published": "2025-05-21T13:06:24+00:00",
    "author": "",
    "text": "Unternehmen wollen KI und Chatbots immer stärker in ihre Prozesse einbinden. Lokal trainierte Lösungen bieten hier schnelle Erfolge mit wenigen Klicks. Shutterstock.com – PeopleImages.com – Yuri A Eine Krankenhauskette möchte mittels generativer Künstlicher Intelligenz (KI) einen virtuellen Assistenten für ihre Belegschaft erstellen. Der Chatbot soll den Beschäftigten anhand der hauseigenen Informationsbestände zu unterschiedlichsten Fragen Auskunft geben, um ihnen zeitraubende Suchen in Unterlagen und im Intranet zu ersparen: Welche unserer Kliniken hat die größte Erfahrung mit Katarakt-Operationen? Was waren die fünf wichtigsten Punkte im heutigen Rundschreiben der Geschäftsführung? Wie ändert das neue Medizinforschungsgesetz den Ablauf unserer klinischen Studien? Welche unserer Ärzte haben die Zusatzqualifikation für Tropenmedizin? Und wann gibt es in der Kantine wieder Apfelstrudel? Die Klinikkette unseres fiktiven Beispiels hat eine zwanzigköpfige IT-Abteilung, einige der IT-Fachleute haben sich auch schon mit KI-Themen befasst. Das IT-Team hat kürzlich sogar eine Datenwissenschaftlerin angestellt, die den hauseigenen Datenbestand für KI-Einsatzzwecke aufbereiten soll. Aber dem Team fehlt das Know-how für das Training von KI-Basismodellen. Und es fehlt die Zeit, um herauszufinden, wie man die benötigte Hardware- und Software-Infrastruktur für den KI-Betrieb korrekt zusammenstellt, dimensioniert und konfiguriert. Was tun? Großunternehmen können sich ein dediziertes Team leisten, das ein KI-Basismodell trainiert, um es für die eigenen Belange maßzuschneidern. Die meisten Unternehmen bis hin zum gehobenen Mittelstand hingegen haben weder Fachkräfte noch Know-how oder Budget für einen derart aufwendigen Ansatz, das Potenzial von KI zu erschließen. Doch auch sie wissen: Generative KI wird künftig eine zentrale Rolle spielen, um Prozesse zu beschleunigen, neue Services anzubieten – und generell, um wettbewerbsfähig zu bleiben. Ein beliebtes Vorgehen wird deshalb darin bestehen, vortrainierte Modelle mit hauseigenen Datenbeständen für individuelle Einsatzfälle anzupassen. Das KI-Modell einfach in einer Public Cloud zu trainieren und zu betreiben, ist für viele Organisationen dabei keine Option. In einigen Organisationen verbieten Regularien dies, andere wollen die Hoheit über sensible und personenbezogene Daten nicht infrage stellen. Mit Blick auf die Datensouveränität werden Unternehmen deshalb vortrainierte Modelle in aller Regel lokal anpassen. Dafür benötigen sie eine Reihe von Hardware- und Softwarebausteinen, von Servern und Speichern bis hin zu KI-Analysetools. Deren Zusammenstellung zur in sich stimmigen KI-Trainings- und Betriebsumgebung war bislang ein zeitraubendes Unterfangen, oft erschwert durch einen weiteren Umstand: Auf KI spezialisierte Datenwissenschaftler sind keine IT-Betriebsexperten, das IT-Team wiederum müsste sich aber in die Anforderungen der KI-Lösungen erst einarbeiten. Den Aufbau einer KI-Umgebung erleichtern nun aber integrierte, speziell auf den Einsatz generativer KI ausgelegte Komplettpakete aus Hardware, Software und Services. Diese Angebote sind in verschiedenen Leistungsstufen erhältlich, um alles vom Pilotprojekt bis zum Training eines großen KI-Modells mit umfangreicher Datenbasis abzudecken. JETZT WHITEPAPER LESEN UND HPE PRIVATE CLOUD AI VERSTEHEN. Um möglichst schnell Projekterfolge zu erzielen, sollte ein solches KI-Komplettpaket vor allem Blaupausen umfassen, mit denen sich die häufigsten KI-Einsatzfälle mit wenigen Mausklicks verwirklichen lassen. HPE Private Cloud AI – eine Familie von KI-Komplettsystemen, die HPE gemeinsam mit dem KI-Vorreiter NVIDIA entwickelt hat – umfasst zu diesem Zweck neben von NVIDIA vortrainierten KI-Modellen auch sogenannte „Accelerators“ (Lösungsbeschleuniger). Diese ermöglichen es einem IT-Team, mit geringem Aufwand und nur grundlegendem KI-Know-how zügig folgende beliebte Szenarien umzusetzen: 1. Dokumentation: Ob klinische Studie, industrielle Fertigung oder Softwareentwicklung – im Laufe eines Projekts fällt ein Berg von Unterlagen an. Dieser will dann für die Dokumentation ausgewertet und aggregiert sein. Hier kann ein entsprechend trainierter KI-Assistent seine Stärken ausspielen: Er fasst große Dokumentenbestände zusammen und arrangiert die wichtigen Informationen zu einer stimmigen Projektdokumentation. 2. Code-Erzeugung: Bei der Softwareentwicklung können sich Entwicklungsteams heute viel Arbeit ersparen, indem sie Routineschritte an KI-Assistenten übergeben. Das beschleunigt Abläufe deutlich und vermeidet menschliche Fehler. Die Entwickler müssen nur noch die Qualität des erzeugten Codes kontrollieren. Insbesondere für diesen Einsatzfall ist die Zusammenarbeit von HPE mit NVIDIA von Bedeutung: Der Marktführer bei KI-Prozessoren setzt den Maßstab für performante Unterstützung selbst äußerst rechenintensiver Programmier- und KI-Aufgaben. 3. Wissensmanagement: In den Medien ist immer wieder von Fehlern zu lesen, die Chatbots wie ChatGPT machen, wenn man sie als Suchmaschine nutzt. Die Fehlerquelle liegt hier schlicht darin, dass die Datenbasis aus dem Internet stammt: Oft fehlt der Kontext zur Frage, ebenso die Qualitätskontrolle der Daten. Trainiert ein Unternehmen hingegen eine KI mit dem hauseigenen Informationsbestand (Retrieval-Augmented Generation, kurz RAG genannt), dann erweist sich ein KI-Assistent als verlässlicher Detektiv im unternehmenseigenen Wissensbestand. Dank lokalem Training und Betrieb bleibt die Datenhoheit stets gewahrt. 4. Virtueller Assistent für Beschäftigte: Diesem Anwendungsfall sind wir anfangs beim fiktiven Beispiel der Klinikkette schon begegnet. Ein KI-Assistent ist nicht nur in der Lage, Informationen zu finden oder Fragen zu beantworten. Vielmehr kann er auch Meeting-Protokolle oder Jahresberichte zusammenfassen und bei einer Recherche Informationen aggregieren. Jeder Mitarbeiter erhält so seinen eigenen persönlichen Assistenten und kann sich auf die wichtigen Dinge seines Arbeitsbereichs konzentrieren. 5. Kundenservice: Ähnlich wie beim KI-Assistenten für die Belegschaft, lässt sich generative KI auch nutzen, um einen unternehmensspezifischen virtuellen Kundenberater zu etablieren. Auch hier dient die eigene Wissensdatenbank als exklusive Datenbasis. Ein Chatbot für eine Klinikkette zum Beispiel gibt dann Auskunft zu den Spezialisierungen der einzelnen Kliniken, ihren Sprech- und Besuchszeiten oder führt Besucher im Haus zum gewünschten Behandlungszimmer. Auf Fragen ohne direkten Bezug zum Unternehmen gibt er hingegen an, keine Auskunft erteilen zu können. Dies vermeidet bei professionellen KI-Bots jene Halluzinationen, die man aus dem Consumer-Segment kennt. Neben diesen fünf übergreifenden Lösungsbeschleunigern umfasst HPE Private Cloud AI auch noch eine Reihe branchenspezifischer Varianten: für Industrieunternehmen, die öffentliche Hand, den Einzelhandel und Netzbetreiber. So erhalten zum Beispiel Fertigungsunternehmen Blaupausen für die KI-gestützte Qualitätskontrolle, die vorausschauende Wartung des Maschinenparks, die KI-gestützte Optimierung der Lieferkette und Chatbots für den Verkaufsprozess. Zudem ist die einfache Umsetzung zahlreicher weiterer Anwendungsfälle möglich: HPE Private Cloud AI enthält einen KI-Werkzeugkasten, der es Anwenderunternehmen erleichtert, Blaupausen für individuelle KI-Projekte zu erstellen und dann unternehmensweit auszurollen. JETZT ZUM LÖSUNGSBERICHT. Das KI-Modelltraining ist sehr rechenintensiv. Dies gilt auch für Fälle, in denen es „lediglich“ um Anpassung und Finetuning eines bestehenden Basismodells geht. Deshalb baut HPE bei Private Cloud AI auf die enge Kooperation mit KI-Branchenprimus NVIDIA. Gemeinsam mit NVIDIA hat HPE eine skalierbare Lösungsfamilie entwickelt, die alle üblichen Anwendungsfälle hochperformant unterstützt. Die Systeme der Lösungsfamilie gibt es in den „T-Shirt-Größen“ S, M und L, jeweils mit einer Erweiterungsoption: Mittelständische Unternehmen und Organisationen stehen heute häufig vor dem schwierigen Sprung von „Lass uns mal diesen KI-Piloten ausprobieren!“ zu „Wie können wir die folgenden fünf KI-Anwendungsfälle zielstrebig und effizient umsetzen?“ HPE Private Cloud AI ermöglicht es diesen Unternehmen, einen solchen Sprung mit geringem Aufwand zu bewältigen – und beim Einsatz einer Blaupause sogar mit wenigen Mausklicks. Dadurch profitieren Anwender im Unternehmen schnell von den vielfältigen Möglichkeiten generativer KI – und es bleibt trotzdem noch Zeit für einen Apfelstrudel in der Kantine. Mehr über HPE Private Cloud AI erfahren? ZUm LÖSUNGSBERICHT! ZUM WHITEPAPER! Unternehmen wollen KI und Chatbots immer stärker in ihre Prozesse einbinden. Lokal trainierte Lösungen bieten hier schnelle Erfolge mit wenigen Klicks. Shutterstock.com – PeopleImages.com – Yuri A Eine Krankenhauskette möchte mittels generativer Künstlicher Intelligenz (KI) einen virtuellen Assistenten für ihre Belegschaft erstellen. Der Chatbot soll den Beschäftigten anhand der hauseigenen Informationsbestände zu unterschiedlichsten Fragen Auskunft geben, um ihnen zeitraubende Suchen in Unterlagen und im Intranet zu ersparen: Welche unserer Kliniken hat die größte Erfahrung mit Katarakt-Operationen? Was waren die fünf wichtigsten Punkte im heutigen Rundschreiben der Geschäftsführung? Wie ändert das neue Medizinforschungsgesetz den Ablauf unserer klinischen Studien? Welche unserer Ärzte haben die Zusatzqualifikation für Tropenmedizin? Und wann gibt es in der Kantine wieder Apfelstrudel? Die Klinikkette unseres fiktiven Beispiels hat eine zwanzigköpfige IT-Abteilung, einige der IT-Fachleute haben sich auch schon mit KI-Themen befasst. Das IT-Team hat kürzlich sogar eine Datenwissenschaftlerin angestellt, die den hauseigenen Datenbestand für KI-Einsatzzwecke aufbereiten soll. Aber dem Team fehlt das Know-how für das Training von KI-Basismodellen. Und es fehlt die Zeit, um herauszufinden, wie man die benötigte Hardware- und Software-Infrastruktur für den KI-Betrieb korrekt zusammenstellt, dimensioniert und konfiguriert. Was tun? Großunternehmen können sich ein dediziertes Team leisten, das ein KI-Basismodell trainiert, um es für die eigenen Belange maßzuschneidern. Die meisten Unternehmen bis hin zum gehobenen Mittelstand hingegen haben weder Fachkräfte noch Know-how oder Budget für einen derart aufwendigen Ansatz, das Potenzial von KI zu erschließen. Doch auch sie wissen: Generative KI wird künftig eine zentrale Rolle spielen, um Prozesse zu beschleunigen, neue Services anzubieten – und generell, um wettbewerbsfähig zu bleiben. Ein beliebtes Vorgehen wird deshalb darin bestehen, vortrainierte Modelle mit hauseigenen Datenbeständen für individuelle Einsatzfälle anzupassen. Das KI-Modell einfach in einer Public Cloud zu trainieren und zu betreiben, ist für viele Organisationen dabei keine Option. In einigen Organisationen verbieten Regularien dies, andere wollen die Hoheit über sensible und personenbezogene Daten nicht infrage stellen. Mit Blick auf die Datensouveränität werden Unternehmen deshalb vortrainierte Modelle in aller Regel lokal anpassen. Dafür benötigen sie eine Reihe von Hardware- und Softwarebausteinen, von Servern und Speichern bis hin zu KI-Analysetools. Deren Zusammenstellung zur in sich stimmigen KI-Trainings- und Betriebsumgebung war bislang ein zeitraubendes Unterfangen, oft erschwert durch einen weiteren Umstand: Auf KI spezialisierte Datenwissenschaftler sind keine IT-Betriebsexperten, das IT-Team wiederum müsste sich aber in die Anforderungen der KI-Lösungen erst einarbeiten. Den Aufbau einer KI-Umgebung erleichtern nun aber integrierte, speziell auf den Einsatz generativer KI ausgelegte Komplettpakete aus Hardware, Software und Services. Diese Angebote sind in verschiedenen Leistungsstufen erhältlich, um alles vom Pilotprojekt bis zum Training eines großen KI-Modells mit umfangreicher Datenbasis abzudecken. JETZT WHITEPAPER LESEN UND HPE PRIVATE CLOUD AI VERSTEHEN. Um möglichst schnell Projekterfolge zu erzielen, sollte ein solches KI-Komplettpaket vor allem Blaupausen umfassen, mit denen sich die häufigsten KI-Einsatzfälle mit wenigen Mausklicks verwirklichen lassen. HPE Private Cloud AI – eine Familie von KI-Komplettsystemen, die HPE gemeinsam mit dem KI-Vorreiter NVIDIA entwickelt hat – umfasst zu diesem Zweck neben von NVIDIA vortrainierten KI-Modellen auch sogenannte „Accelerators“ (Lösungsbeschleuniger). Diese ermöglichen es einem IT-Team, mit geringem Aufwand und nur grundlegendem KI-Know-how zügig folgende beliebte Szenarien umzusetzen: 1. Dokumentation: Ob klinische Studie, industrielle Fertigung oder Softwareentwicklung – im Laufe eines Projekts fällt ein Berg von Unterlagen an. Dieser will dann für die Dokumentation ausgewertet und aggregiert sein. Hier kann ein entsprechend trainierter KI-Assistent seine Stärken ausspielen: Er fasst große Dokumentenbestände zusammen und arrangiert die wichtigen Informationen zu einer stimmigen Projektdokumentation. 2. Code-Erzeugung: Bei der Softwareentwicklung können sich Entwicklungsteams heute viel Arbeit ersparen, indem sie Routineschritte an KI-Assistenten übergeben. Das beschleunigt Abläufe deutlich und vermeidet menschliche Fehler. Die Entwickler müssen nur noch die Qualität des erzeugten Codes kontrollieren. Insbesondere für diesen Einsatzfall ist die Zusammenarbeit von HPE mit NVIDIA von Bedeutung: Der Marktführer bei KI-Prozessoren setzt den Maßstab für performante Unterstützung selbst äußerst rechenintensiver Programmier- und KI-Aufgaben. 3. Wissensmanagement: In den Medien ist immer wieder von Fehlern zu lesen, die Chatbots wie ChatGPT machen, wenn man sie als Suchmaschine nutzt. Die Fehlerquelle liegt hier schlicht darin, dass die Datenbasis aus dem Internet stammt: Oft fehlt der Kontext zur Frage, ebenso die Qualitätskontrolle der Daten. Trainiert ein Unternehmen hingegen eine KI mit dem hauseigenen Informationsbestand (Retrieval-Augmented Generation, kurz RAG genannt), dann erweist sich ein KI-Assistent als verlässlicher Detektiv im unternehmenseigenen Wissensbestand. Dank lokalem Training und Betrieb bleibt die Datenhoheit stets gewahrt. 4. Virtueller Assistent für Beschäftigte: Diesem Anwendungsfall sind wir anfangs beim fiktiven Beispiel der Klinikkette schon begegnet. Ein KI-Assistent ist nicht nur in der Lage, Informationen zu finden oder Fragen zu beantworten. Vielmehr kann er auch Meeting-Protokolle oder Jahresberichte zusammenfassen und bei einer Recherche Informationen aggregieren. Jeder Mitarbeiter erhält so seinen eigenen persönlichen Assistenten und kann sich auf die wichtigen Dinge seines Arbeitsbereichs konzentrieren. 5. Kundenservice: Ähnlich wie beim KI-Assistenten für die Belegschaft, lässt sich generative KI auch nutzen, um einen unternehmensspezifischen virtuellen Kundenberater zu etablieren. Auch hier dient die eigene Wissensdatenbank als exklusive Datenbasis. Ein Chatbot für eine Klinikkette zum Beispiel gibt dann Auskunft zu den Spezialisierungen der einzelnen Kliniken, ihren Sprech- und Besuchszeiten oder führt Besucher im Haus zum gewünschten Behandlungszimmer. Auf Fragen ohne direkten Bezug zum Unternehmen gibt er hingegen an, keine Auskunft erteilen zu können. Dies vermeidet bei professionellen KI-Bots jene Halluzinationen, die man aus dem Consumer-Segment kennt. Neben diesen fünf übergreifenden Lösungsbeschleunigern umfasst HPE Private Cloud AI auch noch eine Reihe branchenspezifischer Varianten: für Industrieunternehmen, die öffentliche Hand, den Einzelhandel und Netzbetreiber. So erhalten zum Beispiel Fertigungsunternehmen Blaupausen für die KI-gestützte Qualitätskontrolle, die vorausschauende Wartung des Maschinenparks, die KI-gestützte Optimierung der Lieferkette und Chatbots für den Verkaufsprozess. Zudem ist die einfache Umsetzung zahlreicher weiterer Anwendungsfälle möglich: HPE Private Cloud AI enthält einen KI-Werkzeugkasten, der es Anwenderunternehmen erleichtert, Blaupausen für individuelle KI-Projekte zu erstellen und dann unternehmensweit auszurollen. JETZT ZUM LÖSUNGSBERICHT. Das KI-Modelltraining ist sehr rechenintensiv. Dies gilt auch für Fälle, in denen es „lediglich“ um Anpassung und Finetuning eines bestehenden Basismodells geht. Deshalb baut HPE bei Private Cloud AI auf die enge Kooperation mit KI-Branchenprimus NVIDIA. Gemeinsam mit NVIDIA hat HPE eine skalierbare Lösungsfamilie entwickelt, die alle üblichen Anwendungsfälle hochperformant unterstützt. Die Systeme der Lösungsfamilie gibt es in den „T-Shirt-Größen“ S, M und L, jeweils mit einer Erweiterungsoption: Mittelständische Unternehmen und Organisationen stehen heute häufig vor dem schwierigen Sprung von „Lass uns mal diesen KI-Piloten ausprobieren!“ zu „Wie können wir die folgenden fünf KI-Anwendungsfälle zielstrebig und effizient umsetzen?“ HPE Private Cloud AI ermöglicht es diesen Unternehmen, einen solchen Sprung mit geringem Aufwand zu bewältigen – und beim Einsatz einer Blaupause sogar mit wenigen Mausklicks. Dadurch profitieren Anwender im Unternehmen schnell von den vielfältigen Möglichkeiten generativer KI – und es bleibt trotzdem noch Zeit für einen Apfelstrudel in der Kantine. Mehr über HPE Private Cloud AI erfahren? ZUm LÖSUNGSBERICHT! ZUM WHITEPAPER!",
    "source": "cio",
    "crawled_at": "2025-05-28T09:16:45.679712+00:00"
  },
  {
    "url": "https://www.cio.de/article/3819664/zweifel-an-der-public-cloud-wachsen.html",
    "title": "Zweifel an der Public Cloud wachsen",
    "published": "2025-05-22T04:13:00+00:00",
    "author": "",
    "text": "Evgeniyqw – shutterstock.com In den vergangenen Jahren haben sich Unternehmen bemüht, Workloads und Applikationen so schnell wie möglich in die Public Cloud zu verlagern, um Investitionsausgaben zu minimieren und Geld zu sparen. Zunehmend jedoch prüfen CIOs diese Investitionen, ob sie noch vernünftig sind: Steigern sie wirklich die Produktivität und helfen sie bei der IT-Kostensenkung? „Beim Ansturm auf die öffentliche Cloud haben viele Leute nicht über die Preisgestaltung nachgedacht“, berichtet Tracy Woo, Principal Analyst bei Forrester. Das hat Folgen: „Wenn die Ausgaben steigen und die Budgets knapper werden, fragen sie sich, was los ist und wie sie das Schiff in die richtige Richtung lenken können.“ Abonnieren Sie unsere CIO-Newsletter für mehr Einblicke, Hintergründe und Deep Dives aus der CIO-Community. Ron Hollowell, CTO bei der Reinsurance Group of America (RGA), will sich 2025 darauf konzentrieren, die Public Cloud richtig zu dimensionieren. Dies gelinge mit einem höheren Reifegrad der Prozesse rund um Workloads, Verteilungskriterien und Implementierungspraktiken. „Kostenoptimierung und klar definierte Kriterien für die Auswahl der Workloads werden darüber bestimmen, welche Services in die Public Cloud und welche in die Private Cloud gehen“, so der IT-Chef. Als VP für Cloud-Funktionen beim Softwareunternehmen Endava berät Radu Vunvulea CIOs in großen Unternehmen. „In diesem Jahr werden wir häufiger über Hybrid-Cloud, Multi-Cloud und die Rückführung zu On-Premises sprechen“, lautet auch seine Erwartung. Zu den Gründen gehören höhere Kosten (als erwartet). Hinzu kommen Leistungs- und Latenzprobleme, Sicherheits-, Datenschutz- und Compliance-Bedenken sowie regionale Vorschriften zur digitalen Souveränität, die sich darauf auswirken, wo Daten gespeichert, transportiert und verarbeitet werden können. „Der Hauptgrund, um Private Clouds den Vorzug vor Public Clouds zu geben, sind jedoch die Kosten“, sagt Hollowell. Er sieht Public Clouds generell als kosteneffizienteste Lösung für saisonale oder sporadische, bedarfsabhängige Arbeitslasten. „Für Workloads mit konstanteren Kapazitätsanforderungen kann allerdings die Wirtschaftlichkeit von Private Clouds oder Lösungen mit fester Kapazität attraktiver sein.“ Auch für viele andere CIOs seien die Kosten das wichtigste Entscheidungskriterium, ergänzt Vunvulea. Während bis zu 80 Prozent der Enterprise-Systeme, an denen Endava arbeitet, teilweise oder vollständig die öffentliche Cloud nutzen, migrieren etwa 60 Prozent dieser Unternehmen mindestens ein System zurück. „Wir interpretieren das schon als einen Trend“, sagt er. Wohin gehen diese Arbeitslasten? „Es gibt einen erneuten Fokus auf On-Premises, On-Premises Private Cloud oder gehostete Private Clouds, insbesondere da datenintensive Workloads wie generative KI die Cloud-Ausgaben in die Höhe treiben“, berichtet Forrester-Expertin Woo. Die Analysten prognostizieren, dass vier von fünf so genannten Cloud-Leadern ihre Investitionen in Private Clouds in diesem Jahr um rund ein Fünftel steigern werden. Allerdings dreht sich das Jahr 2025 nicht ausschließlich um die Repatriierung . „Gleichzeitig legen auch die Investitionen in Public Clouds zu durch GenAI, andere Anforderungen sowie den Zugang zu neuer Infrastruktur“, prognostiziert Woo. Für das St. Jude’s Research Hospital ist die Public Cloud eine gute Möglichkeit, Wissen in die Hände von Forschern zu geben. Laut CIO Keith Perry betreibt das Krankenhaus Supercomputer vor Ort, um einen Großteil seiner Forschungsdaten zu generieren. Die Übertragung dieser Daten in und aus der öffentlichen Cloud könne laut dem IT-Chef jedoch teuer werden. „Die akademische Gemeinschaft erwartet, dass sich die Daten in der Nähe ihrer Hochleistungsrechner befinden, daher haben alle mit hohen Gebühren zu kämpfen“, erklärt Perry. Woo fügt hinzu, dass Public Clouds für datenintensive Workloads kostspielig sind, da Unternehmen sowohl für gespeicherte als auch für zwischen Verfügbarkeitszonen (Availability Zones), Regionen und Clouds übertragene Daten Gebühren zahlen müssen. Die Anbieter erheben zudem Ausstiegsgebühren für Daten, die eine bestimmte AZ verlassen, sowie für Daten, die in eine bestimmte AZ gelangen. „Für Übertragungen zwischen AZs werden Sie also im Grunde doppelt belastet und diese Übertragungsgebühren können sich wirklich summieren“, erläutert Woo. Auch Vunvulea warnt, dass die Kosten für die Datenübertragung hoch und dass die Datenübertragung sowie -synchronisation komplex sein kann. „Wir haben KI-Projekte gesehen, bei denen etwa 45 Prozent der Cloud-Kosten durch die Übertragung von Daten aus der Public Cloud an einen anderen Standort entstanden sind“, sagt er. Wenn man die kompletten Systeme mit allem, was man rund um den Service braucht, einrichtet, könne die Lösung drei- oder viermal so viel kosten wie ursprünglich veranschlagt. Unternehmen, die eine KI-Lösung aufbauen, müssen mehr als nur den KI-Service berücksichtigen. Um Geheimnisse zu schützen und Zugriffe zu regeln, müssen Vaults hinzugefügt sowie Sicherheitsanwendungen und -richtlinien definiert und konfiguriert werden. Die sichere Speicherung, Datentransformation, Überwachung, das Auditing und eine Compliance-Ebene erhöhen die Komplexität des Systems. Um den KI-Dienst herum muss eine Lösung mit weiteren zehn bis 12 Cloud-Diensten aufgebaut werden, die die Anforderungen eines Enterprise-Systems erfüllen. Auch das geht ins Geld. Unternehmen haben keine große Wahl bei der Cloud, wenn es darum geht, die größeren Basismodelle wie ChatGPT 3.5 und 4.0 zu nutzen. Die erforderliche Rechenleistung wäre zu kostspielig, um sie im eigenen Haus zu reproduzieren, sagt Sid Nag, Experte für Cloud, Edge und AI Infrastructure bei Gartner. Bis 2027 werden jedoch nach Einschätzung der Analysten mehr als 50 Prozent der von Unternehmen genutzten KI-LLMs branchenspezifisch sein. Ihr Vorteil: Sie sind deutlich kleiner als die Allzweck-Grundmodelle und damit attraktiver. Laut Nag erfordern branchenspezifische KI-Modelle weniger Ressourcen für das Training und könnten daher vor Ort, in einer privaten Cloud oder in einer gehosteten privaten Cloud-Infrastruktur ausgeführt werden. Allerdings gibt sich der Gartner-Experte vorsichtig, wenn es um das private Cloud-Hosting oder On-Premises-Hosting geht: „Entscheider werden sich gegen die Idee sträuben, zu den Tagen der CapEx-Investitionen zurückzukehren – es sei denn, es gibt wirklich zwingende Gründe.“ Der Kostenfokus passt zudem nicht immer zu den Leistungsanforderungen oder übergeordneten Zielen. „Die Latenzzeit zwischen dem Instrument, das die Daten erzeugt, und der Rechenleistung, die sie verarbeitet, ist eine wichtige Variable bei der Bestimmung des Datenortes“, berichtet CIO Perry vom Krankenhaus St. Jude. In einigen Fällen benötigt das Instrument eine umgehende Verbindung zu Hochleistungs-Rechenressourcen. „Aufgrund der Latenz zwischen den Forschungsinstrumenten und der öffentlichen Cloud ist es oft nicht sinnvoll, dort Echtzeit-Checks vorzunehmen“, führt der CIO aus. Angesichts der vielen Optionen – auch rund um die Themen Sicherheit, Datenschutz und Souveränität – sowie unzähligen Use Cases ist klar, dass es keinen Königsweg in die Cloud gibt. Daher kommt es darauf an, die notwendige Flexibilität zu trainieren, um sich anpassen zu können. In Zukunft, so CTO Hollowell, „ist es unsere strategische Absicht, Hosting-Entscheidungen durch die Linse der geschäftlichen Anforderungen zu bewerten, anstatt einfach alles in die Public Cloud zu verlagern. “ Applikationen mit konsistenten Kapazitätsanforderungen, die sich mit einer traditionellen Infrastruktur erfüllen lassen, werden in einer privaten Cloud ausgeführt. Alle anderen sind Kandidaten für eine öffentliche Cloud. Für CIO Perry geht es beim Aufbau seiner IT-Infrastruktur vor allem darum, die richtigen Baustoffe zu verwenden. „Public Cloud ist nur eines der Materialien, die wir für die Umsetzung der Architektur benötigen.“ Hier müsse man die Balance finden, doch leider sei die optimale Mischung aus On-Premises, Private Cloud und Public Cloud ein bewegliches Ziel. „Ich kann nicht behaupten, dass alles für immer an der richtigen Stelle ist, weil sich die Technologie ständig weiterentwickelt“, räumt Perry ein. Weil sich Cloud-Technologien verändern, sollten Unternehmen bereit und in der Lage sein, mit der Zeit zu gehen, empfiehlt der IT-Chef: „Denn die Tools, die Sie heute haben, sind vielleicht nicht die, die Sie morgen brauchen.“ (ajf/jd) Evgeniyqw – shutterstock.com In den vergangenen Jahren haben sich Unternehmen bemüht, Workloads und Applikationen so schnell wie möglich in die Public Cloud zu verlagern, um Investitionsausgaben zu minimieren und Geld zu sparen. Zunehmend jedoch prüfen CIOs diese Investitionen, ob sie noch vernünftig sind: Steigern sie wirklich die Produktivität und helfen sie bei der IT-Kostensenkung? „Beim Ansturm auf die öffentliche Cloud haben viele Leute nicht über die Preisgestaltung nachgedacht“, berichtet Tracy Woo, Principal Analyst bei Forrester. Das hat Folgen: „Wenn die Ausgaben steigen und die Budgets knapper werden, fragen sie sich, was los ist und wie sie das Schiff in die richtige Richtung lenken können.“ Abonnieren Sie unsere CIO-Newsletter für mehr Einblicke, Hintergründe und Deep Dives aus der CIO-Community. Ron Hollowell, CTO bei der Reinsurance Group of America (RGA), will sich 2025 darauf konzentrieren, die Public Cloud richtig zu dimensionieren. Dies gelinge mit einem höheren Reifegrad der Prozesse rund um Workloads, Verteilungskriterien und Implementierungspraktiken. „Kostenoptimierung und klar definierte Kriterien für die Auswahl der Workloads werden darüber bestimmen, welche Services in die Public Cloud und welche in die Private Cloud gehen“, so der IT-Chef. Als VP für Cloud-Funktionen beim Softwareunternehmen Endava berät Radu Vunvulea CIOs in großen Unternehmen. „In diesem Jahr werden wir häufiger über Hybrid-Cloud, Multi-Cloud und die Rückführung zu On-Premises sprechen“, lautet auch seine Erwartung. Zu den Gründen gehören höhere Kosten (als erwartet). Hinzu kommen Leistungs- und Latenzprobleme, Sicherheits-, Datenschutz- und Compliance-Bedenken sowie regionale Vorschriften zur digitalen Souveränität, die sich darauf auswirken, wo Daten gespeichert, transportiert und verarbeitet werden können. „Der Hauptgrund, um Private Clouds den Vorzug vor Public Clouds zu geben, sind jedoch die Kosten“, sagt Hollowell. Er sieht Public Clouds generell als kosteneffizienteste Lösung für saisonale oder sporadische, bedarfsabhängige Arbeitslasten. „Für Workloads mit konstanteren Kapazitätsanforderungen kann allerdings die Wirtschaftlichkeit von Private Clouds oder Lösungen mit fester Kapazität attraktiver sein.“ Auch für viele andere CIOs seien die Kosten das wichtigste Entscheidungskriterium, ergänzt Vunvulea. Während bis zu 80 Prozent der Enterprise-Systeme, an denen Endava arbeitet, teilweise oder vollständig die öffentliche Cloud nutzen, migrieren etwa 60 Prozent dieser Unternehmen mindestens ein System zurück. „Wir interpretieren das schon als einen Trend“, sagt er. Wohin gehen diese Arbeitslasten? „Es gibt einen erneuten Fokus auf On-Premises, On-Premises Private Cloud oder gehostete Private Clouds, insbesondere da datenintensive Workloads wie generative KI die Cloud-Ausgaben in die Höhe treiben“, berichtet Forrester-Expertin Woo. Die Analysten prognostizieren, dass vier von fünf so genannten Cloud-Leadern ihre Investitionen in Private Clouds in diesem Jahr um rund ein Fünftel steigern werden. Allerdings dreht sich das Jahr 2025 nicht ausschließlich um die Repatriierung . „Gleichzeitig legen auch die Investitionen in Public Clouds zu durch GenAI, andere Anforderungen sowie den Zugang zu neuer Infrastruktur“, prognostiziert Woo. Für das St. Jude’s Research Hospital ist die Public Cloud eine gute Möglichkeit, Wissen in die Hände von Forschern zu geben. Laut CIO Keith Perry betreibt das Krankenhaus Supercomputer vor Ort, um einen Großteil seiner Forschungsdaten zu generieren. Die Übertragung dieser Daten in und aus der öffentlichen Cloud könne laut dem IT-Chef jedoch teuer werden. „Die akademische Gemeinschaft erwartet, dass sich die Daten in der Nähe ihrer Hochleistungsrechner befinden, daher haben alle mit hohen Gebühren zu kämpfen“, erklärt Perry. Woo fügt hinzu, dass Public Clouds für datenintensive Workloads kostspielig sind, da Unternehmen sowohl für gespeicherte als auch für zwischen Verfügbarkeitszonen (Availability Zones), Regionen und Clouds übertragene Daten Gebühren zahlen müssen. Die Anbieter erheben zudem Ausstiegsgebühren für Daten, die eine bestimmte AZ verlassen, sowie für Daten, die in eine bestimmte AZ gelangen. „Für Übertragungen zwischen AZs werden Sie also im Grunde doppelt belastet und diese Übertragungsgebühren können sich wirklich summieren“, erläutert Woo. Auch Vunvulea warnt, dass die Kosten für die Datenübertragung hoch und dass die Datenübertragung sowie -synchronisation komplex sein kann. „Wir haben KI-Projekte gesehen, bei denen etwa 45 Prozent der Cloud-Kosten durch die Übertragung von Daten aus der Public Cloud an einen anderen Standort entstanden sind“, sagt er. Wenn man die kompletten Systeme mit allem, was man rund um den Service braucht, einrichtet, könne die Lösung drei- oder viermal so viel kosten wie ursprünglich veranschlagt. Unternehmen, die eine KI-Lösung aufbauen, müssen mehr als nur den KI-Service berücksichtigen. Um Geheimnisse zu schützen und Zugriffe zu regeln, müssen Vaults hinzugefügt sowie Sicherheitsanwendungen und -richtlinien definiert und konfiguriert werden. Die sichere Speicherung, Datentransformation, Überwachung, das Auditing und eine Compliance-Ebene erhöhen die Komplexität des Systems. Um den KI-Dienst herum muss eine Lösung mit weiteren zehn bis 12 Cloud-Diensten aufgebaut werden, die die Anforderungen eines Enterprise-Systems erfüllen. Auch das geht ins Geld. Unternehmen haben keine große Wahl bei der Cloud, wenn es darum geht, die größeren Basismodelle wie ChatGPT 3.5 und 4.0 zu nutzen. Die erforderliche Rechenleistung wäre zu kostspielig, um sie im eigenen Haus zu reproduzieren, sagt Sid Nag, Experte für Cloud, Edge und AI Infrastructure bei Gartner. Bis 2027 werden jedoch nach Einschätzung der Analysten mehr als 50 Prozent der von Unternehmen genutzten KI-LLMs branchenspezifisch sein. Ihr Vorteil: Sie sind deutlich kleiner als die Allzweck-Grundmodelle und damit attraktiver. Laut Nag erfordern branchenspezifische KI-Modelle weniger Ressourcen für das Training und könnten daher vor Ort, in einer privaten Cloud oder in einer gehosteten privaten Cloud-Infrastruktur ausgeführt werden. Allerdings gibt sich der Gartner-Experte vorsichtig, wenn es um das private Cloud-Hosting oder On-Premises-Hosting geht: „Entscheider werden sich gegen die Idee sträuben, zu den Tagen der CapEx-Investitionen zurückzukehren – es sei denn, es gibt wirklich zwingende Gründe.“ Der Kostenfokus passt zudem nicht immer zu den Leistungsanforderungen oder übergeordneten Zielen. „Die Latenzzeit zwischen dem Instrument, das die Daten erzeugt, und der Rechenleistung, die sie verarbeitet, ist eine wichtige Variable bei der Bestimmung des Datenortes“, berichtet CIO Perry vom Krankenhaus St. Jude. In einigen Fällen benötigt das Instrument eine umgehende Verbindung zu Hochleistungs-Rechenressourcen. „Aufgrund der Latenz zwischen den Forschungsinstrumenten und der öffentlichen Cloud ist es oft nicht sinnvoll, dort Echtzeit-Checks vorzunehmen“, führt der CIO aus. Angesichts der vielen Optionen – auch rund um die Themen Sicherheit, Datenschutz und Souveränität – sowie unzähligen Use Cases ist klar, dass es keinen Königsweg in die Cloud gibt. Daher kommt es darauf an, die notwendige Flexibilität zu trainieren, um sich anpassen zu können. In Zukunft, so CTO Hollowell, „ist es unsere strategische Absicht, Hosting-Entscheidungen durch die Linse der geschäftlichen Anforderungen zu bewerten, anstatt einfach alles in die Public Cloud zu verlagern. “ Applikationen mit konsistenten Kapazitätsanforderungen, die sich mit einer traditionellen Infrastruktur erfüllen lassen, werden in einer privaten Cloud ausgeführt. Alle anderen sind Kandidaten für eine öffentliche Cloud. Für CIO Perry geht es beim Aufbau seiner IT-Infrastruktur vor allem darum, die richtigen Baustoffe zu verwenden. „Public Cloud ist nur eines der Materialien, die wir für die Umsetzung der Architektur benötigen.“ Hier müsse man die Balance finden, doch leider sei die optimale Mischung aus On-Premises, Private Cloud und Public Cloud ein bewegliches Ziel. „Ich kann nicht behaupten, dass alles für immer an der richtigen Stelle ist, weil sich die Technologie ständig weiterentwickelt“, räumt Perry ein. Weil sich Cloud-Technologien verändern, sollten Unternehmen bereit und in der Lage sein, mit der Zeit zu gehen, empfiehlt der IT-Chef: „Denn die Tools, die Sie heute haben, sind vielleicht nicht die, die Sie morgen brauchen.“ (ajf/jd)",
    "source": "cio",
    "crawled_at": "2025-05-28T09:16:45.725310+00:00"
  },
  {
    "url": "https://www.cio.de/article/3987853/die-zukunft-der-versicherungsbranche-im-zeitalter-von-ki-2.html",
    "title": "Die Zukunft der Versicherungsbranche im Zeitalter von KI",
    "published": "2025-05-22T05:11:00+00:00",
    "author": "",
    "text": "PeopleImages.com – Yuri A – shutterstock.com Die Versicherungsbranche steht vor einem tiefgreifenden Wandel, angetrieben durch technologische Innovationen und sich verändernde Marktbedingungen. Davon gehen zumindest Munich Re und ERGO aus. Im „ Tech Trend Radar 2025 “ beleuchten sie die wichtigsten Trends, die die Branche in den kommenden Jahren prägen werden. Insgesamt identifiziert der Bericht 36 Trends, welche fünf Bereichen zugeordnet werden können: Künstliche Intelligenz (KI) wird als entscheidender Faktor für die Versicherungsbranche angesehen. Technologien wie Generative KI (GenAI), KI-Agenten und synthetische Daten ermöglichen effizientere Prozesse. Diese reichen von der Schadensbearbeitung bis zur Risikobewertung. Darüber hinaus transformiert GenAI die Datenanalyse und verbessert die Personalisierung von Versicherungsprodukten, so die Studienmacher. KI-Agenten, die autonom Aufgaben ausführen, könnten zudem die Effizienz in der Kundenbetreuung und Schadensbearbeitung revolutionieren. Gleichzeitig erfordert die zunehmende Nutzung von KI eine robuste Governance. Nur so lassen sich laut den Experten Risiken wie Verzerrungen und Datenschutzverletzungen minimieren. Die Integration von KI in die Medizin eröffnet ebenfalls neue Möglichkeiten für Versicherer: Digitale Gesundheitslösungen wie elektronische Gesundheitsakten (EHRs) und KI-gestützte Diagnosen verbessern sowohl die Risikobewertung als auch die Schadensbearbeitung, so die Autoren. Personalisierte Medizin, die auf genetischen Profilen basiert, soll präzisere Behandlungen ermöglichen. Das könnte die Kosten im Gesundheitswesen senken. Trotz der Vorteile bleiben Herausforderungen, wie hohe Kosten und Datenschutzbedenken bestehen. Neue Aufgaben für die Versicherungsbranche entstehen laut der Studie durch Energiewende und Klimawandel. Erneuerbare Energien wie Solar- und Windkraft erfordern innovative Versicherungsprodukte, um Risiken wie Naturkatastrophen und technische Ausfälle abzudecken. Gleichzeitig wird die Bedeutung von Klimarisikobewertungen immer größer, um Unternehmen und Gemeinden auf extreme Wetterereignisse vorzubereiten. Darüber hinaus verändert die zunehmende Verbreitung von Elektrofahrzeugen (EVs) und autonomen Fahrzeugen (AVs) die Versicherungslandschaft. EVs bringen neue Risiken wie höhere Reparaturkosten und Cyberangriffe mit sich, bieten aber auch Chancen für maßgeschneiderte Versicherungsprodukte. Autonome Fahrzeuge könnten zudem die Unfallhäufigkeit reduzieren, aber die Haftung von den Fahrern auf die Hersteller verlagern. Das würde neue Versicherungsmodelle erfordern, so die Experten. Die digitale Transformation bringt laut den Autoren neue Bedrohungen mit sich, da Cyberangriffe und Deepfakes Unternehmen vor große Herausforderungen stellen. Versicherer entwickeln daher Lösungen wie die „Digital-Immune-System“-Technologie, um die Cybersicherheit zu verbessern und Risiken zu minimieren. Gleichzeitig wächst die Nachfrage nach Versicherungen für digitale Vermögenswerte wie Kryptowährungen und tokenisierte Immobilien. Technologien wie humanoide Roboter, IoT-Sensoren und erweiterte Realität (XR) verändern ebenfalls traditionelle Branchen. Zudem schaffen sie neue Märkte für Versicherer. Laut den Studienmachern könnten humanoide Roboter hier die Schadensbewertung und Kundenbetreuung revolutionieren, während XR immersive Kundenerlebnisse ermöglicht. Die Landwirtschaft profitiert von Remote-Sensing-Technologien, die die Risikobewertung und Schadensbearbeitung verbessern. Während all diese Innovationen Effizienz und Wachstum versprechen, bringen sie auch Herausforderungen mit sich, wie Versicherer müssen daher laut den Autoren der Studie ein Gleichgewicht zwischen technologischer Innovation und Risikomanagement finden. Nur auf diese Art und Weise ließen sich Vertrauen und Compliance aufrechterhalten. PeopleImages.com – Yuri A – shutterstock.com Die Versicherungsbranche steht vor einem tiefgreifenden Wandel, angetrieben durch technologische Innovationen und sich verändernde Marktbedingungen. Davon gehen zumindest Munich Re und ERGO aus. Im „ Tech Trend Radar 2025 “ beleuchten sie die wichtigsten Trends, die die Branche in den kommenden Jahren prägen werden. Insgesamt identifiziert der Bericht 36 Trends, welche fünf Bereichen zugeordnet werden können: Künstliche Intelligenz (KI) wird als entscheidender Faktor für die Versicherungsbranche angesehen. Technologien wie Generative KI (GenAI), KI-Agenten und synthetische Daten ermöglichen effizientere Prozesse. Diese reichen von der Schadensbearbeitung bis zur Risikobewertung. Darüber hinaus transformiert GenAI die Datenanalyse und verbessert die Personalisierung von Versicherungsprodukten, so die Studienmacher. KI-Agenten, die autonom Aufgaben ausführen, könnten zudem die Effizienz in der Kundenbetreuung und Schadensbearbeitung revolutionieren. Gleichzeitig erfordert die zunehmende Nutzung von KI eine robuste Governance. Nur so lassen sich laut den Experten Risiken wie Verzerrungen und Datenschutzverletzungen minimieren. Die Integration von KI in die Medizin eröffnet ebenfalls neue Möglichkeiten für Versicherer: Digitale Gesundheitslösungen wie elektronische Gesundheitsakten (EHRs) und KI-gestützte Diagnosen verbessern sowohl die Risikobewertung als auch die Schadensbearbeitung, so die Autoren. Personalisierte Medizin, die auf genetischen Profilen basiert, soll präzisere Behandlungen ermöglichen. Das könnte die Kosten im Gesundheitswesen senken. Trotz der Vorteile bleiben Herausforderungen, wie hohe Kosten und Datenschutzbedenken bestehen. Neue Aufgaben für die Versicherungsbranche entstehen laut der Studie durch Energiewende und Klimawandel. Erneuerbare Energien wie Solar- und Windkraft erfordern innovative Versicherungsprodukte, um Risiken wie Naturkatastrophen und technische Ausfälle abzudecken. Gleichzeitig wird die Bedeutung von Klimarisikobewertungen immer größer, um Unternehmen und Gemeinden auf extreme Wetterereignisse vorzubereiten. Darüber hinaus verändert die zunehmende Verbreitung von Elektrofahrzeugen (EVs) und autonomen Fahrzeugen (AVs) die Versicherungslandschaft. EVs bringen neue Risiken wie höhere Reparaturkosten und Cyberangriffe mit sich, bieten aber auch Chancen für maßgeschneiderte Versicherungsprodukte. Autonome Fahrzeuge könnten zudem die Unfallhäufigkeit reduzieren, aber die Haftung von den Fahrern auf die Hersteller verlagern. Das würde neue Versicherungsmodelle erfordern, so die Experten. Die digitale Transformation bringt laut den Autoren neue Bedrohungen mit sich, da Cyberangriffe und Deepfakes Unternehmen vor große Herausforderungen stellen. Versicherer entwickeln daher Lösungen wie die „Digital-Immune-System“-Technologie, um die Cybersicherheit zu verbessern und Risiken zu minimieren. Gleichzeitig wächst die Nachfrage nach Versicherungen für digitale Vermögenswerte wie Kryptowährungen und tokenisierte Immobilien. Technologien wie humanoide Roboter, IoT-Sensoren und erweiterte Realität (XR) verändern ebenfalls traditionelle Branchen. Zudem schaffen sie neue Märkte für Versicherer. Laut den Studienmachern könnten humanoide Roboter hier die Schadensbewertung und Kundenbetreuung revolutionieren, während XR immersive Kundenerlebnisse ermöglicht. Die Landwirtschaft profitiert von Remote-Sensing-Technologien, die die Risikobewertung und Schadensbearbeitung verbessern. Während all diese Innovationen Effizienz und Wachstum versprechen, bringen sie auch Herausforderungen mit sich, wie Versicherer müssen daher laut den Autoren der Studie ein Gleichgewicht zwischen technologischer Innovation und Risikomanagement finden. Nur auf diese Art und Weise ließen sich Vertrauen und Compliance aufrechterhalten.",
    "source": "cio",
    "crawled_at": "2025-05-28T09:16:46.391956+00:00"
  },
  {
    "url": "https://www.cio.de/article/3673449/narzissten-brennen-schneller-aus-2.html",
    "title": "Narzissten brennen schneller aus",
    "published": "2025-05-22T06:11:17+00:00",
    "author": "",
    "text": "Die Ärztin und Gesundheitsberaterin Mirriam Prieß sagt: “Viele ignorieren die ersten Alarmzeichen und halten tatsächlich erst inne, wenn nichts mehr geht.” Foto: Prieß Gerade unter IT-Spezialisten ist die Diagnose Burnout weit verbreitet: Rund die Hälfte der ITler zeigt Anzeichen einer tiefen Erschöpfung. Dr. Mirriam Prieß, Ärztin, Autorin und Beraterin für Gesundheitsmanagement, verrät, wie es gelingen kann, einen echten Dialog zu führen und damit Burnout zu verhindern. C IO.de: Frau Prieß, In Ihrem Buch schreiben Sie, dass die tiefgehende Erschöpfung, die oft Führungskräfte verspüren, darauf zurückzuführen ist, dass viele Menschen nicht “ihr eigenes Leben” führen. Was meinen Sie damit? Mirriam Prieß: Das eigene Leben zu leben bedeutet, so zu leben, wie es dem eigenen Wesen entspricht. Viele leben jedoch vielmehr nach ihrer Prägung – also ihrer Erziehung – und leben eine Vorstellung von sich selbst oder fügen sich äußeren Bedingungen und Anforderungen. Sie haben keinen Kontakt mehr mit sich selbst und wissen nicht, was sie wirklich wollen. Wer mit sich nicht in Kontakt steht, kennt weder sein Maß noch seine Grenzen und kann nicht an der richtigen Stelle “Ja” und “Nein” sagen. Darüber entstehen meist unlösbare innere und äußere Konflikte, an denen sich die Betroffenen immer mehr erschöpfen . Was wären denn solche Konflikte? Mirriam Prieß: Sie können sowohl beruflich wie privat sein. Viele sagen an der falschen Stelle zu lange “Ja”, um dann irgendwann nur noch “Nein” zu sagen. Oder sie entscheiden sich für Bedingungen, mit denen sie anschließend hadern. Wenn ich mich für ein System und eine Rolle – also einen Job – entscheide, dann tue ich dies aus freien Stücken und erkenne die damit verbundenen Realitäten und Bedingungen an. Das Problem ist, dass viele dies nicht tun, und am Ende mit dem System und den Bedingungen kämpfen, denen sie zugestimmt haben. Viele erschöpfen sich auch daran, dem eigenen Anspruch nicht gerecht zu werden , einem ständigen Optimierungszwang zu unterliegen und über die eigene Grenzenlosigkeit auszubrennen. Was heißt das in der Praxis? Mirriam Prieß: Wer das Gefühl hat, im Innen nichts zu sein, der muss im Außen alles sein. Diese unbewusste Form von tiefer Minderwertigkeit findet man bei so genannten narzisstischen Persönlichkeiten, die sich über grenzenlose Leistung und über Superlative definieren. Sie verfolgen das Prinzip “Grenzen sind dazu da, um überschritten zu werden”. Das führt dazu, dass betroffene Führungskräfte sich selbst und ihre Teams verbrennen , denn ihre hohen Maßstäbe legen sie auch an die Mitarbeiter an. Große Unternehmen können das nur kompensieren, weil sie eine so hohe Fluktuation haben: Die Führungskräfte wechseln alle drei Jahre die Position. Meinen Sie damit, dass viele Führungskräfte Narzissten sind? Mirriam Prieß: Viele glauben, dass Narzissmus nur mit Selbstverliebtheit zu tun hat und verkennen das dahinter liegende Drama. Das Ende des Gleichnis von Narziss verdeutlicht es: Indem Narziss sein Spiegelbild im Teich zu berühren versucht, zerfällt es. Hier zeigt sich das tiefe Leid des Narzissten: In der tiefen Überzeugung “Nichts” zu sein, muss er jede Berührung mit sich selbst vermeiden, kann sich selbst nur im Außen suchen, wo er sich durch den Superlativ aus seiner Minderwertigkeit zu retten versucht. So ist es ein häufiges Merkmal, dass Narzissten schillernde Persönlichkeiten sind, die innerhalb kürzester Zeit die Karriereleitern erklimmen. Und dann kommt die Erschöpfung. Aber m erkt man nicht schon irgendwann vorher, dass man gerade sehr erschöpft ist? Mirriam Prieß: Viele ignorieren die ersten Alarmzeichen und halten tatsächlich erst inne, wenn nichts mehr geht. Erst dann gehen sie zum Arzt oder in eine Klinik zur Behandlung. Ich rate allerdings dazu, nur eine kurze Auszeit zu nehmen, die nicht so lang wie möglich sondern nur so lang wie nötig dauert. Das Leben geht weiter – und je länger Sie nicht daran teilnehmen, umso schwerer ist die Rückkehr. Vor diesem Hintergrund ist es wichtig, schon bei der ersten Störung zu reagieren und sich rechtzeitig professionelle Unterstützung zu suchen. Je länger sie warten, umso schwerer und langwieriger die Heilung. Führungskräfte haben auch eine Verantwortung ihren Mitarbeitern gegenüber. Wie kann ein Entscheider feststellen, dass etwas schief läuft? Mirriam Prieß: Es gibt vier verschiedene Phasen der Erschöpfung: die Alarmphase, die Widerstandsphase, die Erschöpfungsphase und die Rückzugsphase. Die Symptome sind von außen schwer wahrzunehmen, denn die, die ausbrennen, sind oft Leistungsträger und erhalten die Fassade aufrecht. Ein klassisches Symptom ist, dass die Mitarbeiter anfangen, sich immer mehr aufzuhalsen, obwohl sie eigentlich schon nicht mehr können. Die Konzentrationsschwierigkeiten kompensieren sie, indem sie – oft heimlich – länger bleiben. Viele, die auf dem Weg nach unten sind, lassen sich immer mal wieder für einen bis zwei Tage krankschreiben. Die Betroffenen ziehen sich sozial immer mehr zurück. Wenn ein Chef das Gefühl hat, dass der Mitarbeiter ein Problem hat, dann sollte er das ansprechen . Wie kann das konkret aussehen? Mirriam Prieß: Er kann zum Beispiel sagen: “Ich sehe deutlich, dass du aus dem Gleichgewicht geraten bist und dich erschöpfst. Ich möchte dich darum bitten, dass du dir Hilfe suchst.” Wichtig ist, dafür einen Zeitraum zu vereinbaren und sich danach mit dem Mitarbeiter wieder zusammen zu setzen. Hat er sich keine Hilfe gesucht, muss man Konsequenzen ziehen. Dies kann so weit gehen, dass man den Mitarbeiter vom Projekt abzieht. Je länger man die Sache laufen lässt, umso größer der Reibungsverlust für alle Beteiligten. Nicht nur für den Betroffenen selbst, sondern auch für das Team und das Unternehmen. Nicht selten erschöpft sich am Ende ein ganzes Team durch den Versuch die Erschöpfung eines Einzelnen zu kompensieren. Ein Vorgesetzter kann auch mit dem Betriebsarzt zusammen arbeiten, oder an Hilfe von außen verweisen. Doch egal wofür sich die Führungskraft entscheidet, gelingen kann dies nur, wenn sie mit dem Mitarbeiter im Dialog ist. Führungskräfte sollten doch ohnehin mit ihren Mitarbeitern im Dialog sein. Mirriam Prieß: Ja. Sollten sie. Die Realität ist leider eine andere. Echter Dialog findet nur in den wenigsten Unternehmen statt. Ein Dialog ist erst dann ein Dialog, wenn man offen für den anderen ist und ihm auf Augenhöhe begegnet. Das ist auch in einer Hierarchie möglich. Ein Vorstand kann der Putzfrau gegenüber auf Augenhöhe begegnen. Viele verkennen dies und monologisieren in gegenseitiger Positionierung vor sich hin. Solange Sie sich rein über Ihre Position definieren, werden Sie dem Mensch Mitarbeiter nicht im Dialog begegnet können. Wie kann man als Chef feststellen, dass man keinen echten Dialog führt? Mirriam Prieß: Viele Führungskräfte reden zu den Mitarbeitern, aber nicht mit ihnen. Ich rate Führungskräften, einen Selbsttest durchzuführen und sich eine Woche lang zu beobachten: Wie häufig verliert man die Augenhöhe – und damit den Dialog -, indem man Befehle verteilt? Sehr häufig führen unterschiedliche Meinungen sofort zu einem gegenseitigem Monolog: Da haut man sich seine eigene Position um die Ohren gehauen, anstatt dem anderen zu begegnen. Ein Dialog ist dadurch gekennzeichnet, dass man die Situation anders verlässt, als man sie begonnen hat. Sei es einem anderen Gedanken, einem anderen Gefühl. Im Dialog zu sein, heißt nicht immer gleicher Meinung zu sein. Aber man sollte offen für den anderen und dessen Meinung sein Sie schreiben, dass Erschöpfung oft auch daher stammt, dass man “Ja” sagt, obwohl man “Nein” meint. Wie ist das im Arbeitsalltag zu lösen? Mirriam Prieß: “Finde zu dir selbst zurück”, 208 Seiten, ISBN: 978-3-517-09249-2, € 16,99, Südwest Verlag. Foto: Südwest Verlag Mirriam Prieß: Nicht nur Einzelpersonen sondern auch viele Unternehmenskulturen kranken daran, dass die Menschen nicht dazu in der Lage sind, sich auf Augenhöhe im “Ja” wie im “Nein” zu begegnen. Dies führt häufig zu einer Kultur des “hintenrums” – da werden sich dann Verbündete gesucht, es wird übereinander geredet, anstatt miteinander, oder aber irgendwann wird die Krankheit als Ausweg genommen und es wird über die eigene Schwäche unbewusst versucht, das zu erreichen, was sich vorher im Dialog nicht zu äußern getraut wurde. Für private wie berufliche Gesundheit ist es notwendig, für sich und seine wesentlichen Bedürfnisse einzustehen – diese jedoch nicht mit dem eigenen Willen zu verwechseln – und vor diesem Hintergrund dazu in der Lage sein, gesunde Kompromisse einzugehen. Zielsicher in die Katastrophe Foto: Johan Larson – shutterstock.com Viele Menschen steuern – bewusst oder weniger bewußt – über Jahre hinweg zielsicher auf den Burnout zu. Werden konsequent die häufigsten 13 Fehler gemacht, ist früher oder später der Burnout garantiert! Allzeit bereit! Foto: Luiz Rocha – shutterstock.com Bei Ihrem Job werden “flexible” Arbeitszeiten und Überstunden als selbstverständlich erwartet, auch Reisetätigkeiten, wechselnde Arbeitsplätze, internationale Zusammenarbeit über mehrere Zeitzonen hinweg und Erreichbarkeit 24 Stunden an sieben Tagen per Blackberry, Handy & Co. Brennen für den Job Foto: VikaSuh – shutterstock.com Ihre Tätigkeit begeistert Sie, Überstunden stören Sie nicht. Sie stehen für Flexibilität, Schnelligkeit und höchste Qualitätsansprüche. Das Team, der Chef, der Auftraggeber und alle anderen können sich stets auf Sie verlassen. Sie sind ehrgeizig, der nächste Schritt zum Projekt-Manager, Team- oder Abteilungsleiter winkt und fordert vollen Einsatz auf gleichbleibend hohem Niveau. Brennen Sie für Ihre Aufgaben, das Projekt, Ihr Team, Ihr Unternehmen – bis Sie ausgebrannt sind. Entspannen? Was ist das? Foto: Nattika – shutterstock.com Signale wie anhaltende Müdigkeit, Unkonzentriertheit, Leistungsabfall, Schlafstörungen sowie die Unfähigkeit abzuschalten und aufzutanken, ignorieren Sie. Bedienen Sie sich bei auftretenden Zipperlein großzügig an Produkten der Pharmaindustrie. Nur nicht wütend werden Foto: CREATISTA – shutterstock.com Kümmern Sie sich auf keinen Fall um Ihre Gefühle. Wut, Ärger, Ängste, das Gefühl von Überforderung oder ständiger Gehetztheit ignorieren Sie, ebenso wie das Schwinden Ihrer Lebensfreude, zunehmende Teilnahmslosigkeit, Sinn- und Lustlosigkeit und Depressionen. Bei zunehmendem Leeregefühl lösen Sie sich von der Idee, dass Arbeit Sie innerlich erfüllen könnte. Immer schön fleißig sein! Foto: nikkytok – shutterstock.com Ineffektiv verbrachte Arbeitszeit kompensieren Sie mit Mehrarbeit. Das vertreibt auch die Langeweile am Wochenende und im Urlaub. Sind Sie Freiberufler, verzichten Sie ganz auf Urlaub. Sie müssen die Aufträge abarbeiten, oder das Geld reicht nicht. Machen Sie möglichst mehrere Dinge gleichzeitig, um Zeit zu sparen. Sagen Sie “Ja” zu jeder neuen Aufgabe. Verzweifelt? Sie doch nicht! Foto: Petronilo G. Dangoy Jr. – shutterstock.com Machen Sie sich unentbehrlich. Auch wenn es unmöglich ist und Sie der Verzweiflung nah sind, versuchen Sie, möglichst alle Erwartungen von Teamkollegen, Auftraggebern, internen und externen Projektmitarbeitern, Vorgesetzten und Ihrer Familie und Freunde zu erfüllen. Am besten übertreffen Sie noch deren Erwartungen. Warnsignale? Foto: Jim Barber – shutterstock.com Verwerfen Sie sämtliche Warnungen, Vorhaltungen, Vorwürfe, Bitten und Sorgen von Ihrer/m Partner/in, Angehörigen oder Kollegen. Ihre Ausreden sollten wasserdicht sein: “Nach diesem Projekt wird alles besser” oder “nur noch dieser Fall”. Oder: “Die Umstände/der Vorgesetzte/der Auftraggeber zwingen mich dazu, ich habe keine Wahl.” Im Hamsterrad Foto: dwori – shutterstock.com Hämmern Sie sich und anderen ein, es geht nicht anders, in Ihrem Job jedenfalls nicht. Wenden Sie sich dennoch auf Drängen anderer an eine professionelle Beratung, werden Sie es sicher verstehen, die Sinnlosigkeit dieser Maßnahme unter Beweis zu stellen. Nur nicht drüber reden! Foto: Camilo Torres – shutterstock.com Gehen Sie auf Distanz zu Menschen, zu denen erstaunlicherweise noch Kontakt besteht. Als Eigenbrötler können Sie leichter die Fassade wahren. Sagen Sie niemandem, wie es Ihnen geht. Gemeinsame Mittags- und Kaffeepausen mit Kollegen sind zeitlich unmöglich, die Zeit mit der Familie wird immer knapper. Jede Minute zählt – zum Arbeiten. Foto: Phatic-Photography – shutterstock.com Streichen Sie sämtliche Hobbys einschließlich sportlicher Betätigungen. Falls Sie doch noch ein Privatleben haben, gestalten Sie die Terminplanung zwischen ihm und dem Job noch engmaschiger, nutzen Sie jede freie Minute. Gesund leben? Maßlos überschätzt! Foto: Gorilla – shutterstock.com Gesundes Essen wird als Zeitkiller abgeschafft zugunsten von Fast Food und belegten Semmeln. Damit Sie überhaupt entspannen und von Ängsten und anderen unangenehmen Gefühlen abschalten können, gönnen Sie sich regelmäßig abends etwas Alkoholisches. Perfektion, Perfektion, Perfektion Foto: CoraMax – shutterstock.com Seien Sie nie zufrieden mit Ihren Ergebnissen, auch wenn andere begeistert sind. Sie sind Ihr strengster Kritiker. Weniger als perfekt kommt für Sie nicht in Frage. Stecken Sie sich zusätzliche Ziele. Erlernen Sie eine Fremdsprache, machen Sie eine berufsbegleitende Ausbildung und laufen Sie Marathon. Probleme? Ach was! Foto: Nomad_Soul – shutterstock.com Lösen Sie keine Konflikte und Probleme grundlegend. Schieben Sie alles vor sich her, damit der Berg von Unerledigtem immer höher wird. Ein Ausstieg ist möglich! Foto: SVLuma – shutterstock.com Falls Sie sich in unserem Text zu stark wiedererkennen, steiegen Sie aus! Je früher, desto besser. Gehen Sie zum Arzt, ändern Sie Ihre Lebensweise, solange es noch früh genug ist. Das raten Ihnen Ruth Hellmich, Rechtsanwältin und Geschäftsführerin von CoachingTraining. Die Ärztin und Gesundheitsberaterin Mirriam Prieß sagt: “Viele ignorieren die ersten Alarmzeichen und halten tatsächlich erst inne, wenn nichts mehr geht.” Foto: Prieß Gerade unter IT-Spezialisten ist die Diagnose Burnout weit verbreitet: Rund die Hälfte der ITler zeigt Anzeichen einer tiefen Erschöpfung. Dr. Mirriam Prieß, Ärztin, Autorin und Beraterin für Gesundheitsmanagement, verrät, wie es gelingen kann, einen echten Dialog zu führen und damit Burnout zu verhindern. C IO.de: Frau Prieß, In Ihrem Buch schreiben Sie, dass die tiefgehende Erschöpfung, die oft Führungskräfte verspüren, darauf zurückzuführen ist, dass viele Menschen nicht “ihr eigenes Leben” führen. Was meinen Sie damit? Mirriam Prieß: Das eigene Leben zu leben bedeutet, so zu leben, wie es dem eigenen Wesen entspricht. Viele leben jedoch vielmehr nach ihrer Prägung – also ihrer Erziehung – und leben eine Vorstellung von sich selbst oder fügen sich äußeren Bedingungen und Anforderungen. Sie haben keinen Kontakt mehr mit sich selbst und wissen nicht, was sie wirklich wollen. Wer mit sich nicht in Kontakt steht, kennt weder sein Maß noch seine Grenzen und kann nicht an der richtigen Stelle “Ja” und “Nein” sagen. Darüber entstehen meist unlösbare innere und äußere Konflikte, an denen sich die Betroffenen immer mehr erschöpfen . Was wären denn solche Konflikte? Mirriam Prieß: Sie können sowohl beruflich wie privat sein. Viele sagen an der falschen Stelle zu lange “Ja”, um dann irgendwann nur noch “Nein” zu sagen. Oder sie entscheiden sich für Bedingungen, mit denen sie anschließend hadern. Wenn ich mich für ein System und eine Rolle – also einen Job – entscheide, dann tue ich dies aus freien Stücken und erkenne die damit verbundenen Realitäten und Bedingungen an. Das Problem ist, dass viele dies nicht tun, und am Ende mit dem System und den Bedingungen kämpfen, denen sie zugestimmt haben. Viele erschöpfen sich auch daran, dem eigenen Anspruch nicht gerecht zu werden , einem ständigen Optimierungszwang zu unterliegen und über die eigene Grenzenlosigkeit auszubrennen. Was heißt das in der Praxis? Mirriam Prieß: Wer das Gefühl hat, im Innen nichts zu sein, der muss im Außen alles sein. Diese unbewusste Form von tiefer Minderwertigkeit findet man bei so genannten narzisstischen Persönlichkeiten, die sich über grenzenlose Leistung und über Superlative definieren. Sie verfolgen das Prinzip “Grenzen sind dazu da, um überschritten zu werden”. Das führt dazu, dass betroffene Führungskräfte sich selbst und ihre Teams verbrennen , denn ihre hohen Maßstäbe legen sie auch an die Mitarbeiter an. Große Unternehmen können das nur kompensieren, weil sie eine so hohe Fluktuation haben: Die Führungskräfte wechseln alle drei Jahre die Position. Meinen Sie damit, dass viele Führungskräfte Narzissten sind? Mirriam Prieß: Viele glauben, dass Narzissmus nur mit Selbstverliebtheit zu tun hat und verkennen das dahinter liegende Drama. Das Ende des Gleichnis von Narziss verdeutlicht es: Indem Narziss sein Spiegelbild im Teich zu berühren versucht, zerfällt es. Hier zeigt sich das tiefe Leid des Narzissten: In der tiefen Überzeugung “Nichts” zu sein, muss er jede Berührung mit sich selbst vermeiden, kann sich selbst nur im Außen suchen, wo er sich durch den Superlativ aus seiner Minderwertigkeit zu retten versucht. So ist es ein häufiges Merkmal, dass Narzissten schillernde Persönlichkeiten sind, die innerhalb kürzester Zeit die Karriereleitern erklimmen. Und dann kommt die Erschöpfung. Aber m erkt man nicht schon irgendwann vorher, dass man gerade sehr erschöpft ist? Mirriam Prieß: Viele ignorieren die ersten Alarmzeichen und halten tatsächlich erst inne, wenn nichts mehr geht. Erst dann gehen sie zum Arzt oder in eine Klinik zur Behandlung. Ich rate allerdings dazu, nur eine kurze Auszeit zu nehmen, die nicht so lang wie möglich sondern nur so lang wie nötig dauert. Das Leben geht weiter – und je länger Sie nicht daran teilnehmen, umso schwerer ist die Rückkehr. Vor diesem Hintergrund ist es wichtig, schon bei der ersten Störung zu reagieren und sich rechtzeitig professionelle Unterstützung zu suchen. Je länger sie warten, umso schwerer und langwieriger die Heilung. Führungskräfte haben auch eine Verantwortung ihren Mitarbeitern gegenüber. Wie kann ein Entscheider feststellen, dass etwas schief läuft? Mirriam Prieß: Es gibt vier verschiedene Phasen der Erschöpfung: die Alarmphase, die Widerstandsphase, die Erschöpfungsphase und die Rückzugsphase. Die Symptome sind von außen schwer wahrzunehmen, denn die, die ausbrennen, sind oft Leistungsträger und erhalten die Fassade aufrecht. Ein klassisches Symptom ist, dass die Mitarbeiter anfangen, sich immer mehr aufzuhalsen, obwohl sie eigentlich schon nicht mehr können. Die Konzentrationsschwierigkeiten kompensieren sie, indem sie – oft heimlich – länger bleiben. Viele, die auf dem Weg nach unten sind, lassen sich immer mal wieder für einen bis zwei Tage krankschreiben. Die Betroffenen ziehen sich sozial immer mehr zurück. Wenn ein Chef das Gefühl hat, dass der Mitarbeiter ein Problem hat, dann sollte er das ansprechen . Wie kann das konkret aussehen? Mirriam Prieß: Er kann zum Beispiel sagen: “Ich sehe deutlich, dass du aus dem Gleichgewicht geraten bist und dich erschöpfst. Ich möchte dich darum bitten, dass du dir Hilfe suchst.” Wichtig ist, dafür einen Zeitraum zu vereinbaren und sich danach mit dem Mitarbeiter wieder zusammen zu setzen. Hat er sich keine Hilfe gesucht, muss man Konsequenzen ziehen. Dies kann so weit gehen, dass man den Mitarbeiter vom Projekt abzieht. Je länger man die Sache laufen lässt, umso größer der Reibungsverlust für alle Beteiligten. Nicht nur für den Betroffenen selbst, sondern auch für das Team und das Unternehmen. Nicht selten erschöpft sich am Ende ein ganzes Team durch den Versuch die Erschöpfung eines Einzelnen zu kompensieren. Ein Vorgesetzter kann auch mit dem Betriebsarzt zusammen arbeiten, oder an Hilfe von außen verweisen. Doch egal wofür sich die Führungskraft entscheidet, gelingen kann dies nur, wenn sie mit dem Mitarbeiter im Dialog ist. Führungskräfte sollten doch ohnehin mit ihren Mitarbeitern im Dialog sein. Mirriam Prieß: Ja. Sollten sie. Die Realität ist leider eine andere. Echter Dialog findet nur in den wenigsten Unternehmen statt. Ein Dialog ist erst dann ein Dialog, wenn man offen für den anderen ist und ihm auf Augenhöhe begegnet. Das ist auch in einer Hierarchie möglich. Ein Vorstand kann der Putzfrau gegenüber auf Augenhöhe begegnen. Viele verkennen dies und monologisieren in gegenseitiger Positionierung vor sich hin. Solange Sie sich rein über Ihre Position definieren, werden Sie dem Mensch Mitarbeiter nicht im Dialog begegnet können. Wie kann man als Chef feststellen, dass man keinen echten Dialog führt? Mirriam Prieß: Viele Führungskräfte reden zu den Mitarbeitern, aber nicht mit ihnen. Ich rate Führungskräften, einen Selbsttest durchzuführen und sich eine Woche lang zu beobachten: Wie häufig verliert man die Augenhöhe – und damit den Dialog -, indem man Befehle verteilt? Sehr häufig führen unterschiedliche Meinungen sofort zu einem gegenseitigem Monolog: Da haut man sich seine eigene Position um die Ohren gehauen, anstatt dem anderen zu begegnen. Ein Dialog ist dadurch gekennzeichnet, dass man die Situation anders verlässt, als man sie begonnen hat. Sei es einem anderen Gedanken, einem anderen Gefühl. Im Dialog zu sein, heißt nicht immer gleicher Meinung zu sein. Aber man sollte offen für den anderen und dessen Meinung sein Sie schreiben, dass Erschöpfung oft auch daher stammt, dass man “Ja” sagt, obwohl man “Nein” meint. Wie ist das im Arbeitsalltag zu lösen? Mirriam Prieß: “Finde zu dir selbst zurück”, 208 Seiten, ISBN: 978-3-517-09249-2, € 16,99, Südwest Verlag. Foto: Südwest Verlag Mirriam Prieß: Nicht nur Einzelpersonen sondern auch viele Unternehmenskulturen kranken daran, dass die Menschen nicht dazu in der Lage sind, sich auf Augenhöhe im “Ja” wie im “Nein” zu begegnen. Dies führt häufig zu einer Kultur des “hintenrums” – da werden sich dann Verbündete gesucht, es wird übereinander geredet, anstatt miteinander, oder aber irgendwann wird die Krankheit als Ausweg genommen und es wird über die eigene Schwäche unbewusst versucht, das zu erreichen, was sich vorher im Dialog nicht zu äußern getraut wurde. Für private wie berufliche Gesundheit ist es notwendig, für sich und seine wesentlichen Bedürfnisse einzustehen – diese jedoch nicht mit dem eigenen Willen zu verwechseln – und vor diesem Hintergrund dazu in der Lage sein, gesunde Kompromisse einzugehen. Zielsicher in die Katastrophe Foto: Johan Larson – shutterstock.com Viele Menschen steuern – bewusst oder weniger bewußt – über Jahre hinweg zielsicher auf den Burnout zu. Werden konsequent die häufigsten 13 Fehler gemacht, ist früher oder später der Burnout garantiert! Allzeit bereit! Foto: Luiz Rocha – shutterstock.com Bei Ihrem Job werden “flexible” Arbeitszeiten und Überstunden als selbstverständlich erwartet, auch Reisetätigkeiten, wechselnde Arbeitsplätze, internationale Zusammenarbeit über mehrere Zeitzonen hinweg und Erreichbarkeit 24 Stunden an sieben Tagen per Blackberry, Handy & Co. Brennen für den Job Foto: VikaSuh – shutterstock.com Ihre Tätigkeit begeistert Sie, Überstunden stören Sie nicht. Sie stehen für Flexibilität, Schnelligkeit und höchste Qualitätsansprüche. Das Team, der Chef, der Auftraggeber und alle anderen können sich stets auf Sie verlassen. Sie sind ehrgeizig, der nächste Schritt zum Projekt-Manager, Team- oder Abteilungsleiter winkt und fordert vollen Einsatz auf gleichbleibend hohem Niveau. Brennen Sie für Ihre Aufgaben, das Projekt, Ihr Team, Ihr Unternehmen – bis Sie ausgebrannt sind. Entspannen? Was ist das? Foto: Nattika – shutterstock.com Signale wie anhaltende Müdigkeit, Unkonzentriertheit, Leistungsabfall, Schlafstörungen sowie die Unfähigkeit abzuschalten und aufzutanken, ignorieren Sie. Bedienen Sie sich bei auftretenden Zipperlein großzügig an Produkten der Pharmaindustrie. Nur nicht wütend werden Foto: CREATISTA – shutterstock.com Kümmern Sie sich auf keinen Fall um Ihre Gefühle. Wut, Ärger, Ängste, das Gefühl von Überforderung oder ständiger Gehetztheit ignorieren Sie, ebenso wie das Schwinden Ihrer Lebensfreude, zunehmende Teilnahmslosigkeit, Sinn- und Lustlosigkeit und Depressionen. Bei zunehmendem Leeregefühl lösen Sie sich von der Idee, dass Arbeit Sie innerlich erfüllen könnte. Immer schön fleißig sein! Foto: nikkytok – shutterstock.com Ineffektiv verbrachte Arbeitszeit kompensieren Sie mit Mehrarbeit. Das vertreibt auch die Langeweile am Wochenende und im Urlaub. Sind Sie Freiberufler, verzichten Sie ganz auf Urlaub. Sie müssen die Aufträge abarbeiten, oder das Geld reicht nicht. Machen Sie möglichst mehrere Dinge gleichzeitig, um Zeit zu sparen. Sagen Sie “Ja” zu jeder neuen Aufgabe. Verzweifelt? Sie doch nicht! Foto: Petronilo G. Dangoy Jr. – shutterstock.com Machen Sie sich unentbehrlich. Auch wenn es unmöglich ist und Sie der Verzweiflung nah sind, versuchen Sie, möglichst alle Erwartungen von Teamkollegen, Auftraggebern, internen und externen Projektmitarbeitern, Vorgesetzten und Ihrer Familie und Freunde zu erfüllen. Am besten übertreffen Sie noch deren Erwartungen. Warnsignale? Foto: Jim Barber – shutterstock.com Verwerfen Sie sämtliche Warnungen, Vorhaltungen, Vorwürfe, Bitten und Sorgen von Ihrer/m Partner/in, Angehörigen oder Kollegen. Ihre Ausreden sollten wasserdicht sein: “Nach diesem Projekt wird alles besser” oder “nur noch dieser Fall”. Oder: “Die Umstände/der Vorgesetzte/der Auftraggeber zwingen mich dazu, ich habe keine Wahl.” Im Hamsterrad Foto: dwori – shutterstock.com Hämmern Sie sich und anderen ein, es geht nicht anders, in Ihrem Job jedenfalls nicht. Wenden Sie sich dennoch auf Drängen anderer an eine professionelle Beratung, werden Sie es sicher verstehen, die Sinnlosigkeit dieser Maßnahme unter Beweis zu stellen. Nur nicht drüber reden! Foto: Camilo Torres – shutterstock.com Gehen Sie auf Distanz zu Menschen, zu denen erstaunlicherweise noch Kontakt besteht. Als Eigenbrötler können Sie leichter die Fassade wahren. Sagen Sie niemandem, wie es Ihnen geht. Gemeinsame Mittags- und Kaffeepausen mit Kollegen sind zeitlich unmöglich, die Zeit mit der Familie wird immer knapper. Jede Minute zählt – zum Arbeiten. Foto: Phatic-Photography – shutterstock.com Streichen Sie sämtliche Hobbys einschließlich sportlicher Betätigungen. Falls Sie doch noch ein Privatleben haben, gestalten Sie die Terminplanung zwischen ihm und dem Job noch engmaschiger, nutzen Sie jede freie Minute. Gesund leben? Maßlos überschätzt! Foto: Gorilla – shutterstock.com Gesundes Essen wird als Zeitkiller abgeschafft zugunsten von Fast Food und belegten Semmeln. Damit Sie überhaupt entspannen und von Ängsten und anderen unangenehmen Gefühlen abschalten können, gönnen Sie sich regelmäßig abends etwas Alkoholisches. Perfektion, Perfektion, Perfektion Foto: CoraMax – shutterstock.com Seien Sie nie zufrieden mit Ihren Ergebnissen, auch wenn andere begeistert sind. Sie sind Ihr strengster Kritiker. Weniger als perfekt kommt für Sie nicht in Frage. Stecken Sie sich zusätzliche Ziele. Erlernen Sie eine Fremdsprache, machen Sie eine berufsbegleitende Ausbildung und laufen Sie Marathon. Probleme? Ach was! Foto: Nomad_Soul – shutterstock.com Lösen Sie keine Konflikte und Probleme grundlegend. Schieben Sie alles vor sich her, damit der Berg von Unerledigtem immer höher wird. Ein Ausstieg ist möglich! Foto: SVLuma – shutterstock.com Falls Sie sich in unserem Text zu stark wiedererkennen, steiegen Sie aus! Je früher, desto besser. Gehen Sie zum Arzt, ändern Sie Ihre Lebensweise, solange es noch früh genug ist. Das raten Ihnen Ruth Hellmich, Rechtsanwältin und Geschäftsführerin von CoachingTraining.",
    "source": "cio",
    "crawled_at": "2025-05-28T09:16:47.145868+00:00"
  },
  {
    "url": "https://www.cio.de/article/3696762/freies-denken-organisieren.html",
    "title": "Innovationsmanagement: Freies Denken organisieren",
    "published": "2025-05-22T07:14:40+00:00",
    "author": "",
    "text": "Anstatt sich auf zufällige Heureka-Momente zu verlassen, soll Innovationsmanagement eine Umgebung schaffen, in der Ideen systematisch gefördert und umgesetzt werden. Foto: Pressmaster – shutterstock.com Innovation ist der entscheidende Faktor für den langfristigen Erfolg eines Unternehmens. Heute mehr denn je. Was einige Großkonzerne schon seit Jahren praktizieren, kommt bislang jedoch eher zögerlich auch in anderen Unternehmen an: ein Innovationsmanagement, das sich nicht auf zufällige Ideen Einzelner stützt, sondern gezielt innovationsfördernde Rahmenbedingungen schafft. Damit gewinnt das ganze Unternehmen an Kreativität und Innovationskraft. Es ebnet den Weg für neue Lösungen und stärkt so seine Wettbewerbsfähigkeit. Wer ein professionelles Innovationsmanagement etablieren will, sollte zunächst klären, was darunter zu verstehen ist. “Innovation” leitet sich aus dem lateinischen “innovare” (erneuern) ab. In der Praxis sieht das so aus: Am Anfang steht eine Idee. Um daraus eine Innovation zu machen, müssen vor allem folgende Kriterien erfüllt sein: die Idee muss neu für das Unternehmen sein; ein Mehrwert sollte von Anfang an ersichtlich sein; für die Umsetzung sollte eine Investition erforderlich sein. Erfüllt ein Vorschlag diese Kriterien, wird er in das Innovationsmanagement aufgenommen. Umgesetzt wird die Innovation in der Regel zunächst als Prototyp, Labor- oder Beta-Phase. Dann folgt die Wertschöpfung: Die Innovation wird intern umgesetzt oder in ein marktfähiges, skalierbares Produkt beziehungsweise eine Dienstleistung überführt. Innovationen zu entwickeln und zu etablieren umfasst somit zwei wesentliche Bereiche: einen kreativen Teil, innerhalb dessen die Beteiligten im Wesentlichen Ideen generieren und auf ihre Sinnhaftigkeit und Umsetzbarkeit abklopfen; und einen operativen Teil, in dem es darum geht, die Ideen zur Reife zu bringen, sie umzusetzen und die Innovation in den Markt einzuführen. Unternehmen, die ein professionelles Innovationsmanagement etablieren möchten, sollten sich vorab einige grundsätzliche Fragen stellen und beantworten. Dazu gehört zu klären, welchen Stellenwert das Innovationsmanagement im Unternehmen einnehmen soll. Hierzu ist es sinnvoll, eine Stabsstelle einzurichten, denn es geht um eine Querschnittsfunktion, die alle Bereiche betrifft. Sie kann nur dann ihre optimale Wirkung entfalten, wenn sie nah an der Führungsebene angesiedelt ist. Es gilt zu klären, mit welchen konkreten Maßnahmen und Prozessen sich eine innovative Kultur fördern und etablieren lässt. Welches Anreizsystem ist damit verbunden und wie soll der generische Innovationsprozess aussehen? Schließlich müssen die damit zusammenhängenden Prozesse möglichst reibungslos in die anderen unternehmerischen Abläufe integriert werden. Offenheit und Transparenz sind entscheidend, damit ein Innovationsprozess die gewünschten Ergebnisse bringt. Alle Mitarbeiterinnen und Mitarbeiter, gleichgültig auf welcher Ebene und in welcher Funktion, müssen die Möglichkeit haben, eigene Ideen einzubringen. Grundmodell des Innovationsmanagements Foto: doubleSlash Net-Business GmbH Aufgabe eines Innovationsmanagers ist es also, innovationsfördernde Prozesse zu entwickeln, aufzusetzen und zu begleiten. Er muss, wenn man so will, das freie, kreative Denken organisieren. Denn das ist kein Selbstläufer, sondern erfordert zielgerichtetes Vorgehen. Lesetipp: Herausforderungen für CIOs – 10 Hürden für Innovation Manager Zunächst muss der Innovationsmanager Strukturen und Prozesse aufbauen. Dabei ist es hilfreich, diese an die bereits im Unternehmen bestehenden Strukturen und Prozesse anzudocken. Das verringert Reibungsverluste und macht es einfacher, die Neuerungen in die täglichen Routinen einfließen zu lassen. Sogenannte Stage/Gate-Phasen bilden das Rückgrat des Innovationsprozesses. Stage bezeichnet die Ausarbeitungsphasen, an deren Ende jeweils ein Gate steht. Dort bewertet das sogenannte Bid Board, ein Team, das je nach Aufgabe unterschiedlich besetzt ist, die Ergebnisse der vorangegangenen Stage-Phase. Innovationsprozess Foto: doubleSlash Jedes Gate hat drei Ausgänge: Pass – die Idee wird als aussichtsreich und gut genug empfunden, um sie in die nächste Stufe zu überführen. Stop – die Idee wird verworfen. Replay – die Idee wird an die Verantwortlichen zurückverwiesen, um bestimmte Aufgaben zu erledigen, ehe sie erneut dem Bid Board vorgestellt wird. Beispielhaft kann man sich an vier Stage/Gate-Phasen orientieren: Phase 1: Die Idee wird geboren. Die Ideengeber definieren, wer Nutznießer der potenziellen Innovation sein könnte und suchen einen unternehmensinternen Sponsor. Die Sponsorin oder der Sponsor stellt Ressourcen für die Weiterführung der Idee zur Verfügung (am Anfang meist Arbeitszeit, gegebenenfalls auch finanzielle Mittel), beziehungsweise stellt deren Freigabe in Aussicht, falls Phase 1 erfolgreich zum Abschluss kommt. Phase 2: Zeit für eine STQB-Betrachtung, also Scope (worum geht es genau?), Time, Quality und Budget. Die Idee gewinnt an Qualität und Tiefe. Es entsteht eine detailliertere Beschreibung des potenziellen Projekts, wie es sich realisieren lässt, welchen Nutzen es bringen kann und mit welchem Ressourceneinsatz zu rechnen ist. Phase 3: die Implementierungsphase. Aus der ursprünglichen Idee wird ein gesondertes Projekt. Je nach Umfang kann es jetzt auch schon mit relativ großem Zeit- und Finanzbudget ausgestattet werden. Phase 4: Rollout. Die Innovation startet intern oder extern in den Markt. In der Regel sind vier Funktionsträger oder Gremien an den Prozessen beteiligt: die Ideengebende Person oder ein Team. Die Sponsorenrolle fördert deren Entwicklung, treibt sie voran und verantwortet die Erfolgskontrolle in den verschiedenen Phasen des Stage/Gate-Prozesses. Die bearbeitende Person entwickelt die Idee federführend weiter. Und das Bid Board beurteilt die Ergebnisse der jeweiligen Phase. Dem Bid Board gehören grundsätzlich Verantwortliche von Unternehmensbereichen und/oder Geschäftsfeldern und die Teamleitung an. Übersteigt das Projekt ein gewisses Level an Aufwand und Relevanz für das Unternehmen, kommt auch die oberste Führungsebene hinzu. Nach der Bewertung der Idee und deren Entwicklung benennt das Bid Board eine Person als Projektleitung , die für die weitere Entwicklung der Innovation verantwortlich ist. Um das Ganze möglichst reibungsfrei in die gewohnte Arbeitsumgebung einzufügen, kann das Innovationsmanagement in ein internes Ticketsystem integriert werden, zu dem alle Mitarbeitenden Zugang haben. Ein neues Ticket zu eröffnen oder auf ein bestehendes zu reagieren, ist ausgesprochen einfach und fester Bestandteil von Arbeitsabläufen. Das Innovationsmanagement ist damit alle offen und jeder kann jedes darin befindliche Ticket kommentieren und beispielsweise dafür “voten”. Das ist mitunter ein hilfreicher Indikator dafür, wie die Belegschaft eine Idee einordnet und bewertet. Ein entscheidender Motivations- und Erfolgsfaktor ist, dass neue Ideen und deren Entwicklung von Anfang an belohnt werden. Ideal ist ein Mix aus intrinsischen und extrinsischen Motivatoren. Intrinsische können sein: Freude am Entwickeln und Teilen von Ideen; die Möglichkeit, unabhängig von der hierarchischen Stellung im Unternehmen mitzugestalten und sich einzubringen; Kommentare von Kolleginnen und Kollegen und die Anerkennung durch die Belegschaft. Zu den extrinsischen Motivatoren zählen etwa Gutscheine, Boni oder sonstige Geldzuwendungen, die sich nach jedem erfolgreich abgeschlossenen Gate steigern sollten. Große Unternehmen und Konzerne beteiligen zum Beispiel Mitarbeitende, die Innovationen anstoßen, indem sie einen bestimmten Teil des ersten Jahresumsatzes bekommen, den das Unternehmen mit ihrer Innovation erzielt. Die Gretchenfrage: Funktioniert das im Arbeitsalltag? Die klare Antwort: Ja, sehr gut sogar. Oft steuern Mitarbeitende zunächst überwiegend Ideen zur Optimierung ihres eigenen Arbeitsplatzes und ihrer Arbeitsumgebung ein. Der Gewinn für ein Unternehmen ist klar: Wenn viele Ideen umgesetzt werden, fördert das den Zusammenhalt und das Wir-Gefühl. Die Mitarbeitenden merken: Ich kann etwas bewegen. Wesentliche Einflussfelder auf die Innovationskultur Foto: doubleSlash Net-Business GmbH Ein strukturierter Innovationsprozess kann immenses Motivationspotenzial entfalten: Mitarbeitende, die ihre eigenen Ideen während ihrer Arbeitszeit entwickeln und vorantreiben – und dafür auch noch belohnt werden –, arbeiten damit an Dingen, für die sie sich besonders begeistern. Übrigens: Die Parallelen zur digitalen Transformation und der vielzitierten neuen Unternehmenskultur sind offensichtlich. Denn auch für ein Innovationsmanagement gilt: Die Unternehmensleitung muss den Sinn sehen und die Neuerungen aktiv unterstützen. Tipps für ein erfolgreiches Innovationsmanagement: Gestalten Sie Ihren Innovationsprozess absolut frei von Hierarchien, sie behindern Kreativität. Pflegen Sie maximale Transparenz. Jede Entscheidung muss anhand klarer Kriterien nachvollziehbar sein. Etablieren Sie klar strukturierte, offene Prozesse. Integrieren Sie ein Bonussystem, das sehr früh ansetzt. Sorgen Sie für eine niedrige Einstiegshürde. Innovation lebt nicht zuletzt von der Schwarmintelligenz. Mitmachen muss deshalb einfach sein. Wichtig: Innovationskraft ist primär eine Frage von richtiger und guter Unternehmensführung. Heutzutage gibt es bereits zahlreiche Studiengänge mit Schwerpunkt Innovationsmanagement . Das zeigt, wie wichtig ein Innovationsmanagement für Unternehmen heute schon ist und es dürfte an Bedeutung noch gewinnen. Es kann auch sinnvoll sein, die Innovationsmanagement-Funktion intern zu besetzen und etwa über ein entsprechendes berufsbegleitendes Studium abzubilden. Das hat den Vorteil, dass die Prozesse und Abläufe im Unternehmen schon bekannt sind und es damit leichter fallen dürfte, die passenden Prozesse aufzusetzen. So entstehen innovative Ideen Foto: Stauke – Fotolia.com Die besten Ideengeber im Unternehmen sind nicht die Führungskräfte, sondern die Mitarbeiter und die Kunden, sagt Anne M. Schüller. 1. Ist-Analyse: Foto: Sergej Khackimullin – Fotolia.com Beleuchten Sie die zu optimierende Situation beziehungsweise das zu lösende Problem aus verschiedenen Perspektiven, vor allem aber aus der Sicht des Kunden. Machen Sie dazu Kunden- und Konkurrenzbeobachtungen sowie Interviews mit Mitarbeitern und Externen. Auch Branchenfremde können sinnvolle Beiträge liefern. 2. Ziel-Definition: Foto: Radim Strojek – Fotolia.com Wo wollen Sie hin, was soll am Ende des Prozesses erreicht sein? Dies muss deutlich werden, damit die Ideen-Generierung eine Richtung bekommt. Gehen Sie dabei von kundenrelevanten, differenzierenden Merkmalen aus: Was können wir für unsere Kunden besser, schneller, einfacher, billiger machen. Formulieren Sie all das schriftlich. 3. Zusammenstellung des Teams: Foto: Maximilian Haupt – Fotolia.com Dazu gehören insbesondere die Mitarbeiter, die von der späteren Umsetzung betroffen sind. Damit minimieren Sie von vorne herein aufkommende Widerstände. Sorgen Sie für Visionäre, Querdenker, Missionare, Macher, Kundenbotschafter und Bedenkenträger im Team ebenso wie für Experten und Laien. Mischen Sie alt und jung, Männer und Frauen. Briefen Sie das Team sorgfältig. Ein geschulter Moderator kann helfen, die Prozessschritte zielgerichtet zu steuern. 4. Ideen-Generierung: Foto: chrisharvey – Fotolia.com Begeben Sie sich an einen neutralen, störungsfreien, inspirierenden Ort und setzen Sie passende Kreativitätstechniken ein. Sorgen Sie am Anfang für gute Laune und ein Kreativ-Warm-up. Zeiteinheiten von 30 bis 60 Minuten sind optimal. Hören Sie nicht zu schnell auf, in dieser frühen Phase benötigen Sie ein Maximum an Ideen. Speichern Sie alle Ideen. Und beachten Sie die drei goldenen Regeln einer Kreativ-Sitzung: – Quantität vor Qualität, Inspiration ist erwünscht – alle Teilnehmer sind gleichberechtigt, keine Hierarchie – keinerlei Kritik, weder positiver noch negativer Art 5. Ideen-Bewertung und -Selektion: Foto: Arcurs – Fotolia.com Benutzen Sie jeweils passende Bewertungs- und Selektionstechniken, um die gefundenen Ideen zu verdichten, zu kombinieren und die Spreu vom Weizen zu trennen. Dies kann ein separates Bewertungsteam tun, dem auch Kunden angehören. Erstellen Sie eine Prioritäten-Liste, sortieren Sie nach Marktfähigkeit, Machbarkeit, Zeithorizont, Wirtschaftlichkeit und Nichtkopierbarkeit. Dabei kommt es erfahrungsgemäß zu weiteren Ideen. Am Ende dieses Prozesses verbleiben einige wenige aussichtsreiche Favoriten. Geben Sie diesen Namen und definieren Sie das weitere Vorgehen, beispielsweise in Form eines Projekts. 6. Implementierung: Foto: peppi18 – Fotolia.com Sorgen Sie zunächst für interne Akzeptanz, vor allem bei den ‚betroffenen‘ Mitarbeitern. Dies erfolgt am besten durch Involvieren und frühzeitige, regelmäßige, offene Kommunikation. Stellen Sie die notwendigen Ressourcen bereit. Kommunizieren Sie aktiv mit dem Markt, insbesondere mit den anvisierten Zielgruppen und mit der Presse. Bringen Sie Ihre Idee beziehungsweise Innovation zügig in den Markt, und zwar zum richtigen Zeitpunkt. Experimentieren Sie und testen Sie Varianten. Lassen Sie die Kunden schließlich mitentscheiden. 7. Kontrolle und Optimierung: Foto: MR.LIGHTMAN – Fotolia.com Vergleichen Sie die Ergebnisse mit Ihrer Zieldefinition. Holen Sie sich Feedback vom Kunden, hören Sie dabei auch auf die leisen Töne und die kritischen Hinweise. Optimieren Sie kontinuierlich, das heißt: Beginnen Sie diesen Prozess von vorn. Sorgen Sie für einen regelmäßigen Nachschub an unverbrauchten, außergewöhnlichen Ideen. Anstatt sich auf zufällige Heureka-Momente zu verlassen, soll Innovationsmanagement eine Umgebung schaffen, in der Ideen systematisch gefördert und umgesetzt werden. Foto: Pressmaster – shutterstock.com Innovation ist der entscheidende Faktor für den langfristigen Erfolg eines Unternehmens. Heute mehr denn je. Was einige Großkonzerne schon seit Jahren praktizieren, kommt bislang jedoch eher zögerlich auch in anderen Unternehmen an: ein Innovationsmanagement, das sich nicht auf zufällige Ideen Einzelner stützt, sondern gezielt innovationsfördernde Rahmenbedingungen schafft. Damit gewinnt das ganze Unternehmen an Kreativität und Innovationskraft. Es ebnet den Weg für neue Lösungen und stärkt so seine Wettbewerbsfähigkeit. Wer ein professionelles Innovationsmanagement etablieren will, sollte zunächst klären, was darunter zu verstehen ist. “Innovation” leitet sich aus dem lateinischen “innovare” (erneuern) ab. In der Praxis sieht das so aus: Am Anfang steht eine Idee. Um daraus eine Innovation zu machen, müssen vor allem folgende Kriterien erfüllt sein: die Idee muss neu für das Unternehmen sein; ein Mehrwert sollte von Anfang an ersichtlich sein; für die Umsetzung sollte eine Investition erforderlich sein. Erfüllt ein Vorschlag diese Kriterien, wird er in das Innovationsmanagement aufgenommen. Umgesetzt wird die Innovation in der Regel zunächst als Prototyp, Labor- oder Beta-Phase. Dann folgt die Wertschöpfung: Die Innovation wird intern umgesetzt oder in ein marktfähiges, skalierbares Produkt beziehungsweise eine Dienstleistung überführt. Innovationen zu entwickeln und zu etablieren umfasst somit zwei wesentliche Bereiche: einen kreativen Teil, innerhalb dessen die Beteiligten im Wesentlichen Ideen generieren und auf ihre Sinnhaftigkeit und Umsetzbarkeit abklopfen; und einen operativen Teil, in dem es darum geht, die Ideen zur Reife zu bringen, sie umzusetzen und die Innovation in den Markt einzuführen. Unternehmen, die ein professionelles Innovationsmanagement etablieren möchten, sollten sich vorab einige grundsätzliche Fragen stellen und beantworten. Dazu gehört zu klären, welchen Stellenwert das Innovationsmanagement im Unternehmen einnehmen soll. Hierzu ist es sinnvoll, eine Stabsstelle einzurichten, denn es geht um eine Querschnittsfunktion, die alle Bereiche betrifft. Sie kann nur dann ihre optimale Wirkung entfalten, wenn sie nah an der Führungsebene angesiedelt ist. Es gilt zu klären, mit welchen konkreten Maßnahmen und Prozessen sich eine innovative Kultur fördern und etablieren lässt. Welches Anreizsystem ist damit verbunden und wie soll der generische Innovationsprozess aussehen? Schließlich müssen die damit zusammenhängenden Prozesse möglichst reibungslos in die anderen unternehmerischen Abläufe integriert werden. Offenheit und Transparenz sind entscheidend, damit ein Innovationsprozess die gewünschten Ergebnisse bringt. Alle Mitarbeiterinnen und Mitarbeiter, gleichgültig auf welcher Ebene und in welcher Funktion, müssen die Möglichkeit haben, eigene Ideen einzubringen. Grundmodell des Innovationsmanagements Foto: doubleSlash Net-Business GmbH Aufgabe eines Innovationsmanagers ist es also, innovationsfördernde Prozesse zu entwickeln, aufzusetzen und zu begleiten. Er muss, wenn man so will, das freie, kreative Denken organisieren. Denn das ist kein Selbstläufer, sondern erfordert zielgerichtetes Vorgehen. Lesetipp: Herausforderungen für CIOs – 10 Hürden für Innovation Manager Zunächst muss der Innovationsmanager Strukturen und Prozesse aufbauen. Dabei ist es hilfreich, diese an die bereits im Unternehmen bestehenden Strukturen und Prozesse anzudocken. Das verringert Reibungsverluste und macht es einfacher, die Neuerungen in die täglichen Routinen einfließen zu lassen. Sogenannte Stage/Gate-Phasen bilden das Rückgrat des Innovationsprozesses. Stage bezeichnet die Ausarbeitungsphasen, an deren Ende jeweils ein Gate steht. Dort bewertet das sogenannte Bid Board, ein Team, das je nach Aufgabe unterschiedlich besetzt ist, die Ergebnisse der vorangegangenen Stage-Phase. Innovationsprozess Foto: doubleSlash Jedes Gate hat drei Ausgänge: Pass – die Idee wird als aussichtsreich und gut genug empfunden, um sie in die nächste Stufe zu überführen. Stop – die Idee wird verworfen. Replay – die Idee wird an die Verantwortlichen zurückverwiesen, um bestimmte Aufgaben zu erledigen, ehe sie erneut dem Bid Board vorgestellt wird. Beispielhaft kann man sich an vier Stage/Gate-Phasen orientieren: Phase 1: Die Idee wird geboren. Die Ideengeber definieren, wer Nutznießer der potenziellen Innovation sein könnte und suchen einen unternehmensinternen Sponsor. Die Sponsorin oder der Sponsor stellt Ressourcen für die Weiterführung der Idee zur Verfügung (am Anfang meist Arbeitszeit, gegebenenfalls auch finanzielle Mittel), beziehungsweise stellt deren Freigabe in Aussicht, falls Phase 1 erfolgreich zum Abschluss kommt. Phase 2: Zeit für eine STQB-Betrachtung, also Scope (worum geht es genau?), Time, Quality und Budget. Die Idee gewinnt an Qualität und Tiefe. Es entsteht eine detailliertere Beschreibung des potenziellen Projekts, wie es sich realisieren lässt, welchen Nutzen es bringen kann und mit welchem Ressourceneinsatz zu rechnen ist. Phase 3: die Implementierungsphase. Aus der ursprünglichen Idee wird ein gesondertes Projekt. Je nach Umfang kann es jetzt auch schon mit relativ großem Zeit- und Finanzbudget ausgestattet werden. Phase 4: Rollout. Die Innovation startet intern oder extern in den Markt. In der Regel sind vier Funktionsträger oder Gremien an den Prozessen beteiligt: die Ideengebende Person oder ein Team. Die Sponsorenrolle fördert deren Entwicklung, treibt sie voran und verantwortet die Erfolgskontrolle in den verschiedenen Phasen des Stage/Gate-Prozesses. Die bearbeitende Person entwickelt die Idee federführend weiter. Und das Bid Board beurteilt die Ergebnisse der jeweiligen Phase. Dem Bid Board gehören grundsätzlich Verantwortliche von Unternehmensbereichen und/oder Geschäftsfeldern und die Teamleitung an. Übersteigt das Projekt ein gewisses Level an Aufwand und Relevanz für das Unternehmen, kommt auch die oberste Führungsebene hinzu. Nach der Bewertung der Idee und deren Entwicklung benennt das Bid Board eine Person als Projektleitung , die für die weitere Entwicklung der Innovation verantwortlich ist. Um das Ganze möglichst reibungsfrei in die gewohnte Arbeitsumgebung einzufügen, kann das Innovationsmanagement in ein internes Ticketsystem integriert werden, zu dem alle Mitarbeitenden Zugang haben. Ein neues Ticket zu eröffnen oder auf ein bestehendes zu reagieren, ist ausgesprochen einfach und fester Bestandteil von Arbeitsabläufen. Das Innovationsmanagement ist damit alle offen und jeder kann jedes darin befindliche Ticket kommentieren und beispielsweise dafür “voten”. Das ist mitunter ein hilfreicher Indikator dafür, wie die Belegschaft eine Idee einordnet und bewertet. Ein entscheidender Motivations- und Erfolgsfaktor ist, dass neue Ideen und deren Entwicklung von Anfang an belohnt werden. Ideal ist ein Mix aus intrinsischen und extrinsischen Motivatoren. Intrinsische können sein: Freude am Entwickeln und Teilen von Ideen; die Möglichkeit, unabhängig von der hierarchischen Stellung im Unternehmen mitzugestalten und sich einzubringen; Kommentare von Kolleginnen und Kollegen und die Anerkennung durch die Belegschaft. Zu den extrinsischen Motivatoren zählen etwa Gutscheine, Boni oder sonstige Geldzuwendungen, die sich nach jedem erfolgreich abgeschlossenen Gate steigern sollten. Große Unternehmen und Konzerne beteiligen zum Beispiel Mitarbeitende, die Innovationen anstoßen, indem sie einen bestimmten Teil des ersten Jahresumsatzes bekommen, den das Unternehmen mit ihrer Innovation erzielt. Die Gretchenfrage: Funktioniert das im Arbeitsalltag? Die klare Antwort: Ja, sehr gut sogar. Oft steuern Mitarbeitende zunächst überwiegend Ideen zur Optimierung ihres eigenen Arbeitsplatzes und ihrer Arbeitsumgebung ein. Der Gewinn für ein Unternehmen ist klar: Wenn viele Ideen umgesetzt werden, fördert das den Zusammenhalt und das Wir-Gefühl. Die Mitarbeitenden merken: Ich kann etwas bewegen. Wesentliche Einflussfelder auf die Innovationskultur Foto: doubleSlash Net-Business GmbH Ein strukturierter Innovationsprozess kann immenses Motivationspotenzial entfalten: Mitarbeitende, die ihre eigenen Ideen während ihrer Arbeitszeit entwickeln und vorantreiben – und dafür auch noch belohnt werden –, arbeiten damit an Dingen, für die sie sich besonders begeistern. Übrigens: Die Parallelen zur digitalen Transformation und der vielzitierten neuen Unternehmenskultur sind offensichtlich. Denn auch für ein Innovationsmanagement gilt: Die Unternehmensleitung muss den Sinn sehen und die Neuerungen aktiv unterstützen. Tipps für ein erfolgreiches Innovationsmanagement: Gestalten Sie Ihren Innovationsprozess absolut frei von Hierarchien, sie behindern Kreativität. Pflegen Sie maximale Transparenz. Jede Entscheidung muss anhand klarer Kriterien nachvollziehbar sein. Etablieren Sie klar strukturierte, offene Prozesse. Integrieren Sie ein Bonussystem, das sehr früh ansetzt. Sorgen Sie für eine niedrige Einstiegshürde. Innovation lebt nicht zuletzt von der Schwarmintelligenz. Mitmachen muss deshalb einfach sein. Wichtig: Innovationskraft ist primär eine Frage von richtiger und guter Unternehmensführung. Heutzutage gibt es bereits zahlreiche Studiengänge mit Schwerpunkt Innovationsmanagement . Das zeigt, wie wichtig ein Innovationsmanagement für Unternehmen heute schon ist und es dürfte an Bedeutung noch gewinnen. Es kann auch sinnvoll sein, die Innovationsmanagement-Funktion intern zu besetzen und etwa über ein entsprechendes berufsbegleitendes Studium abzubilden. Das hat den Vorteil, dass die Prozesse und Abläufe im Unternehmen schon bekannt sind und es damit leichter fallen dürfte, die passenden Prozesse aufzusetzen. So entstehen innovative Ideen Foto: Stauke – Fotolia.com Die besten Ideengeber im Unternehmen sind nicht die Führungskräfte, sondern die Mitarbeiter und die Kunden, sagt Anne M. Schüller. 1. Ist-Analyse: Foto: Sergej Khackimullin – Fotolia.com Beleuchten Sie die zu optimierende Situation beziehungsweise das zu lösende Problem aus verschiedenen Perspektiven, vor allem aber aus der Sicht des Kunden. Machen Sie dazu Kunden- und Konkurrenzbeobachtungen sowie Interviews mit Mitarbeitern und Externen. Auch Branchenfremde können sinnvolle Beiträge liefern. 2. Ziel-Definition: Foto: Radim Strojek – Fotolia.com Wo wollen Sie hin, was soll am Ende des Prozesses erreicht sein? Dies muss deutlich werden, damit die Ideen-Generierung eine Richtung bekommt. Gehen Sie dabei von kundenrelevanten, differenzierenden Merkmalen aus: Was können wir für unsere Kunden besser, schneller, einfacher, billiger machen. Formulieren Sie all das schriftlich. 3. Zusammenstellung des Teams: Foto: Maximilian Haupt – Fotolia.com Dazu gehören insbesondere die Mitarbeiter, die von der späteren Umsetzung betroffen sind. Damit minimieren Sie von vorne herein aufkommende Widerstände. Sorgen Sie für Visionäre, Querdenker, Missionare, Macher, Kundenbotschafter und Bedenkenträger im Team ebenso wie für Experten und Laien. Mischen Sie alt und jung, Männer und Frauen. Briefen Sie das Team sorgfältig. Ein geschulter Moderator kann helfen, die Prozessschritte zielgerichtet zu steuern. 4. Ideen-Generierung: Foto: chrisharvey – Fotolia.com Begeben Sie sich an einen neutralen, störungsfreien, inspirierenden Ort und setzen Sie passende Kreativitätstechniken ein. Sorgen Sie am Anfang für gute Laune und ein Kreativ-Warm-up. Zeiteinheiten von 30 bis 60 Minuten sind optimal. Hören Sie nicht zu schnell auf, in dieser frühen Phase benötigen Sie ein Maximum an Ideen. Speichern Sie alle Ideen. Und beachten Sie die drei goldenen Regeln einer Kreativ-Sitzung: – Quantität vor Qualität, Inspiration ist erwünscht – alle Teilnehmer sind gleichberechtigt, keine Hierarchie – keinerlei Kritik, weder positiver noch negativer Art 5. Ideen-Bewertung und -Selektion: Foto: Arcurs – Fotolia.com Benutzen Sie jeweils passende Bewertungs- und Selektionstechniken, um die gefundenen Ideen zu verdichten, zu kombinieren und die Spreu vom Weizen zu trennen. Dies kann ein separates Bewertungsteam tun, dem auch Kunden angehören. Erstellen Sie eine Prioritäten-Liste, sortieren Sie nach Marktfähigkeit, Machbarkeit, Zeithorizont, Wirtschaftlichkeit und Nichtkopierbarkeit. Dabei kommt es erfahrungsgemäß zu weiteren Ideen. Am Ende dieses Prozesses verbleiben einige wenige aussichtsreiche Favoriten. Geben Sie diesen Namen und definieren Sie das weitere Vorgehen, beispielsweise in Form eines Projekts. 6. Implementierung: Foto: peppi18 – Fotolia.com Sorgen Sie zunächst für interne Akzeptanz, vor allem bei den ‚betroffenen‘ Mitarbeitern. Dies erfolgt am besten durch Involvieren und frühzeitige, regelmäßige, offene Kommunikation. Stellen Sie die notwendigen Ressourcen bereit. Kommunizieren Sie aktiv mit dem Markt, insbesondere mit den anvisierten Zielgruppen und mit der Presse. Bringen Sie Ihre Idee beziehungsweise Innovation zügig in den Markt, und zwar zum richtigen Zeitpunkt. Experimentieren Sie und testen Sie Varianten. Lassen Sie die Kunden schließlich mitentscheiden. 7. Kontrolle und Optimierung: Foto: MR.LIGHTMAN – Fotolia.com Vergleichen Sie die Ergebnisse mit Ihrer Zieldefinition. Holen Sie sich Feedback vom Kunden, hören Sie dabei auch auf die leisen Töne und die kritischen Hinweise. Optimieren Sie kontinuierlich, das heißt: Beginnen Sie diesen Prozess von vorn. Sorgen Sie für einen regelmäßigen Nachschub an unverbrauchten, außergewöhnlichen Ideen.",
    "source": "cio",
    "crawled_at": "2025-05-28T09:16:47.700671+00:00"
  },
  {
    "url": "https://www.cio.de/article/3993125/wenn-ki-den-journalismus-ersetzt.html",
    "title": "Wenn KI den Journalismus ersetzt",
    "published": "2025-05-22T07:32:00+00:00",
    "author": "",
    "text": "Yeko Photo Studio – shutterstock.com Deutsche Zeitungsverlage warnen vor einem Ausverkauf journalistischer Inhalte durch Künstliche Intelligenz. Wenn KI-Systeme Verlagsinhalte ersetzten und dabei keiner effektiven Regulierung unterlägen, sei nicht nur das Geschäftsmodell des Journalismus in Gefahr, sondern auch die freie, professionelle Berichterstattung als Pfeiler der Demokratie, sagte der Vorsitzende des Verbands Bayerischer Zeitungsverleger (VBZV), Andreas Scherer, in Brüssel. Die großen KI-Plattformen trainierten mit Inhalten der Verlage ihre Systeme und nutzten sie für eigene Geschäftsmodelle, kritisierte Scherer. “Die automatisierte Aufbereitung und Darstellung journalistischer Inhalte ersetzt den Besuch originärer Presseangebote. Ein schleichender Substanzverlust für die Presse. Und für die Pressefreiheit.” Der Europa-Politiker und CSU-Parteivize Manfred Weber betonte zum Jahrestreffen des VZBV einer Mitteilung zufolge die Bedeutung der freien Presse: “Eine lebendige und vielfältige Presselandschaft ist Kernbestandteil des European Way of Life. Ich bin stolz auf unsere bayerischen Zeitungsverlage”, sagte der Fraktionschef der Europäischen Volkspartei (EVP) im EU-Parlament. Bei den turnusmäßigen Wahlen des Verbands wurde Scherer (Mediengruppe Pressedruck, Augsburg) als Erster Vorsitzender für weitere zwei Jahre im Amt bestätigt. Ebenfalls wiedergewählt wurde der Zweite Vorsitzende Laurent Fischer ( Nordbayerischer Kurier , Bayreuth). Zum VBZV als Interessenvertretung der Branche zählen nach Verbandsangaben 33 bayerische Zeitungsverlage sowie zudem digitale Tochterunternehmen und persönliche Mitglieder. (dpa/rs) Yeko Photo Studio – shutterstock.com Deutsche Zeitungsverlage warnen vor einem Ausverkauf journalistischer Inhalte durch Künstliche Intelligenz. Wenn KI-Systeme Verlagsinhalte ersetzten und dabei keiner effektiven Regulierung unterlägen, sei nicht nur das Geschäftsmodell des Journalismus in Gefahr, sondern auch die freie, professionelle Berichterstattung als Pfeiler der Demokratie, sagte der Vorsitzende des Verbands Bayerischer Zeitungsverleger (VBZV), Andreas Scherer, in Brüssel. Die großen KI-Plattformen trainierten mit Inhalten der Verlage ihre Systeme und nutzten sie für eigene Geschäftsmodelle, kritisierte Scherer. “Die automatisierte Aufbereitung und Darstellung journalistischer Inhalte ersetzt den Besuch originärer Presseangebote. Ein schleichender Substanzverlust für die Presse. Und für die Pressefreiheit.” Der Europa-Politiker und CSU-Parteivize Manfred Weber betonte zum Jahrestreffen des VZBV einer Mitteilung zufolge die Bedeutung der freien Presse: “Eine lebendige und vielfältige Presselandschaft ist Kernbestandteil des European Way of Life. Ich bin stolz auf unsere bayerischen Zeitungsverlage”, sagte der Fraktionschef der Europäischen Volkspartei (EVP) im EU-Parlament. Bei den turnusmäßigen Wahlen des Verbands wurde Scherer (Mediengruppe Pressedruck, Augsburg) als Erster Vorsitzender für weitere zwei Jahre im Amt bestätigt. Ebenfalls wiedergewählt wurde der Zweite Vorsitzende Laurent Fischer ( Nordbayerischer Kurier , Bayreuth). Zum VBZV als Interessenvertretung der Branche zählen nach Verbandsangaben 33 bayerische Zeitungsverlage sowie zudem digitale Tochterunternehmen und persönliche Mitglieder. (dpa/rs)",
    "source": "cio",
    "crawled_at": "2025-05-28T09:16:48.228356+00:00"
  },
  {
    "url": "https://www.cio.de/article/3993141/berlin-will-verbraucher-besser-vor-fake-shops-schutzen.html",
    "title": "Berlin will Verbraucher besser vor Fake-Shops schützen",
    "published": "2025-05-22T07:58:56+00:00",
    "author": "",
    "text": "fizkes – shutterstock.com Das Land Berlin will Verbraucher besser vor betrügerischen Online-Shops schützen und setzt sich im Bund für gesetzliche Änderungen ein. Verbraucherschutzsenatorin Felor Badenberg sieht in den Fake-Shops, die zunehmend professionell agieren, ein wachsendes Problem. “Sie bewirken wirtschaftliche Schäden für Verbraucher und beschädigen zudem auch das Vertrauen in den digitalen Handel”, sagte die CDU-Politikerin der Deutschen Presse-Agentur. Bei der Konferenz der Länder-Verbraucherschutzminister, die derzeit in Berlin läuft, gehört das Thema für sie als Vorsitzende zu den Schwerpunkten. Für die Beratungen kündigte Badenberg einen Antrag an. Ziel ist ein besserer Schutz für Verbraucher, indem Regelungslücken beseitigt werden. “Vermittlungsdienste, seien es Online-Suchmaschinen, Vergleichsportale oder Online-Marktplätze haften nur in Ausnahmefällen», erklärte die Senatorin. “Das Ziel unseres Beschlussvorschlags ist es deshalb, diese Vermittlungsdienste stärker in die Pflicht zu nehmen und die behördliche Rechtsdurchsetzung zur Abschaltung von Fake-Shop-Webseiten zu stärken.” Laut Badenberg sind nach Zahlen von Verbraucherschutzzentralen im Jahr 2024 monatlich 1.600 neue Fake-Shops entstanden. Kunden erhalten nach Bestellungen mangelhafte Ware – oder auch gar keine Sendung. Häufig würden Käuferdaten gestohlen oder auch missbraucht, schilderte Badenberg. Nach einer aktuellen Umfrage der Auskunftei Schufa lägen die Schäden bei jedem vierten Betroffenen zwischen 1.000 und 10.000 Euro. (dpa/rs) fizkes – shutterstock.com Das Land Berlin will Verbraucher besser vor betrügerischen Online-Shops schützen und setzt sich im Bund für gesetzliche Änderungen ein. Verbraucherschutzsenatorin Felor Badenberg sieht in den Fake-Shops, die zunehmend professionell agieren, ein wachsendes Problem. “Sie bewirken wirtschaftliche Schäden für Verbraucher und beschädigen zudem auch das Vertrauen in den digitalen Handel”, sagte die CDU-Politikerin der Deutschen Presse-Agentur. Bei der Konferenz der Länder-Verbraucherschutzminister, die derzeit in Berlin läuft, gehört das Thema für sie als Vorsitzende zu den Schwerpunkten. Für die Beratungen kündigte Badenberg einen Antrag an. Ziel ist ein besserer Schutz für Verbraucher, indem Regelungslücken beseitigt werden. “Vermittlungsdienste, seien es Online-Suchmaschinen, Vergleichsportale oder Online-Marktplätze haften nur in Ausnahmefällen», erklärte die Senatorin. “Das Ziel unseres Beschlussvorschlags ist es deshalb, diese Vermittlungsdienste stärker in die Pflicht zu nehmen und die behördliche Rechtsdurchsetzung zur Abschaltung von Fake-Shop-Webseiten zu stärken.” Laut Badenberg sind nach Zahlen von Verbraucherschutzzentralen im Jahr 2024 monatlich 1.600 neue Fake-Shops entstanden. Kunden erhalten nach Bestellungen mangelhafte Ware – oder auch gar keine Sendung. Häufig würden Käuferdaten gestohlen oder auch missbraucht, schilderte Badenberg. Nach einer aktuellen Umfrage der Auskunftei Schufa lägen die Schäden bei jedem vierten Betroffenen zwischen 1.000 und 10.000 Euro. (dpa/rs)",
    "source": "cio",
    "crawled_at": "2025-05-28T09:16:48.890800+00:00"
  },
  {
    "url": "https://www.cio.de/article/3993193/cyberkriminelle-werden-immer-besser.html",
    "title": "Cyberkriminelle werden immer besser",
    "published": "2025-05-22T08:57:10+00:00",
    "author": "",
    "text": "Syda Productions – shutterstock.com Deutschlands Sicherheitsbehörden sehen sich immer versierter arbeitenden Cyberkriminellen gegenüber. Die “Tool-Box”, die zum Einsatz komme, sei sehr breit angelegt, sagte der Vizepräsident des Bundesamtes für Verfassungsschutz (BfV), Sinan Selen, bei einer Konferenz zur Cybersicherheit in Potsdam. Er sehe ein “ganzheitliches Vorgehen”, das “Spionage, Sabotage, Desinformation gleichermaßen bedient”. Was Deutschland dagegenzusetzen hätte, sei vor allem ein pragmatischer Ansatz in der Zusammenarbeit. “Wir müssen ‘hemdsärmeliger’ werden”, führte Selen aus. Es gehe darum, die Fähigkeiten verschiedener stellen gut und partnerschaftlich miteinander zu vernetzen. Diese Partnerschaft beziehe sich nicht nur auf die klassischen Strafverfolgungsbehörden, sondern setze sich fort bei den Unternehmen, der Industrie oder gesellschaftlichen Gruppen, die von Cyberattacken betroffen sind. Nur so könne man dieser langfristigen Bedrohungslage effizient begegnen. Der Präsident des Bundeskriminalamts (BKA), Holger Münch, schob nach, dass dafür aber auch die Rahmenbedingung bei den Behörden geschaffen werden müssten. “Wenn man da aber rumkrebst und 5.000 Euro nicht bekommt für einen bestimmten PC, den man braucht, dann wird es schwierig”, sagte er in Potsdam. Es komme bei der Mitarbeitergewinnung nicht darauf an, mit dem “Gehalt von Microsoft mithalten” zu können. Es kommt darauf an, dass die Menschen zufrieden nach Hause gehen mit dem Gefühl einem sinnerfüllten Job nachzugehen. (dpa/rs) Syda Productions – shutterstock.com Deutschlands Sicherheitsbehörden sehen sich immer versierter arbeitenden Cyberkriminellen gegenüber. Die “Tool-Box”, die zum Einsatz komme, sei sehr breit angelegt, sagte der Vizepräsident des Bundesamtes für Verfassungsschutz (BfV), Sinan Selen, bei einer Konferenz zur Cybersicherheit in Potsdam. Er sehe ein “ganzheitliches Vorgehen”, das “Spionage, Sabotage, Desinformation gleichermaßen bedient”. Was Deutschland dagegenzusetzen hätte, sei vor allem ein pragmatischer Ansatz in der Zusammenarbeit. “Wir müssen ‘hemdsärmeliger’ werden”, führte Selen aus. Es gehe darum, die Fähigkeiten verschiedener stellen gut und partnerschaftlich miteinander zu vernetzen. Diese Partnerschaft beziehe sich nicht nur auf die klassischen Strafverfolgungsbehörden, sondern setze sich fort bei den Unternehmen, der Industrie oder gesellschaftlichen Gruppen, die von Cyberattacken betroffen sind. Nur so könne man dieser langfristigen Bedrohungslage effizient begegnen. Der Präsident des Bundeskriminalamts (BKA), Holger Münch, schob nach, dass dafür aber auch die Rahmenbedingung bei den Behörden geschaffen werden müssten. “Wenn man da aber rumkrebst und 5.000 Euro nicht bekommt für einen bestimmten PC, den man braucht, dann wird es schwierig”, sagte er in Potsdam. Es komme bei der Mitarbeitergewinnung nicht darauf an, mit dem “Gehalt von Microsoft mithalten” zu können. Es kommt darauf an, dass die Menschen zufrieden nach Hause gehen mit dem Gefühl einem sinnerfüllten Job nachzugehen. (dpa/rs)",
    "source": "cio",
    "crawled_at": "2025-05-28T09:16:49.354965+00:00"
  },
  {
    "url": "https://www.cio.de/article/3993217/jony-ive-soll-technik-fur-chatgpt-entwickeln.html",
    "title": "Jony Ive soll Technik für ChatGPT entwickeln",
    "published": "2025-05-22T09:09:00+00:00",
    "author": "",
    "text": "Die ChatGPT-Entwicklerfirma OpenAI holt den einstigen iPhone-Designer Jony Ive an Bord. Man habe bereits vor zwei Jahren angefangen, über neue Geräte für die Ära Künstlicher Intelligenz nachzudenken und daran zu arbeiten, teilten Ive und OpenAI-Chef Sam Altman mit. Jetzt erwirbt OpenAI das von Ive dafür mitgegründete Unternehmen mit dem Namen io. OpenAI lasse sich den Neuzugang insgesamt fast 6,5 Milliarden Dollar kosten, berichteten der Finanzdienst Bloomberg und das Wall Street Journal . Ive war jahrelang Chefdesigner von Apple und arbeitete seit Mitte der 90er Jahre eng mit Gründer Steve Jobs zusammen, bis zu dessen Tod 2011. In dieser Funktion verantwortete Ive das Design mehrerer Generationen von Apple-Geräten, von Mac-Computern über iPods bis hin zu iPhone und iPad. Vor allem das iPhone prägte das Aussehen von Smartphones entscheidend. Ive verließ Apple 2019 und gründete die eigene Firm LoveFrom . Über seine Projekte seitdem wurde nicht viel bekannt. Bei der vor einem Jahr zusätzlich gegründeten Firma io schlossen sich ihm unter anderem die Designerin Evans Hankey, die bis 2023 Ives Nachfolgerin bei Apple war, sowie Tang Tan an, der bis zum vergangenen Jahr das iPhone-Design verantwortete. Da auch Apple neue Geräte für das KI-Zeitalter brauchen dürfte, könnten die drei bei OpenAI mit der Zeit direkt mit ihrem früheren Arbeitgeber konkurrieren. Bei einem Auftritt vor OpenAI-Mitarbeitern sagten Altman und Ive dem Wall Street Journal zufolge, beim ersten Projekt gehe es um ein Gerät, das die Umgebung von Nutzern und deren Leben erfasse. Es sei als eine Ergänzung für Smartphones und Laptops gedacht. Der Kaufpreis für io liege bei fünf Milliarden Dollar in Form von OpenAI-Aktien, berichtete Bloomberg. Zudem habe OpenAI bereits Ende vergangenen Jahres einen Anteil von 23 Prozent an io erworben, wodurch die Gesamtinvestition nahezu 6,5 Milliarden Dollar erreiche. OpenAI ist nicht an der Börse notiert. In diesen Fällen gilt meist die Bewertung des Unternehmens aus Finanzierungsrunden. (dpa/rs) Die ChatGPT-Entwicklerfirma OpenAI holt den einstigen iPhone-Designer Jony Ive an Bord. Man habe bereits vor zwei Jahren angefangen, über neue Geräte für die Ära Künstlicher Intelligenz nachzudenken und daran zu arbeiten, teilten Ive und OpenAI-Chef Sam Altman mit. Jetzt erwirbt OpenAI das von Ive dafür mitgegründete Unternehmen mit dem Namen io. OpenAI lasse sich den Neuzugang insgesamt fast 6,5 Milliarden Dollar kosten, berichteten der Finanzdienst Bloomberg und das Wall Street Journal . Ive war jahrelang Chefdesigner von Apple und arbeitete seit Mitte der 90er Jahre eng mit Gründer Steve Jobs zusammen, bis zu dessen Tod 2011. In dieser Funktion verantwortete Ive das Design mehrerer Generationen von Apple-Geräten, von Mac-Computern über iPods bis hin zu iPhone und iPad. Vor allem das iPhone prägte das Aussehen von Smartphones entscheidend. Ive verließ Apple 2019 und gründete die eigene Firm LoveFrom . Über seine Projekte seitdem wurde nicht viel bekannt. Bei der vor einem Jahr zusätzlich gegründeten Firma io schlossen sich ihm unter anderem die Designerin Evans Hankey, die bis 2023 Ives Nachfolgerin bei Apple war, sowie Tang Tan an, der bis zum vergangenen Jahr das iPhone-Design verantwortete. Da auch Apple neue Geräte für das KI-Zeitalter brauchen dürfte, könnten die drei bei OpenAI mit der Zeit direkt mit ihrem früheren Arbeitgeber konkurrieren. Bei einem Auftritt vor OpenAI-Mitarbeitern sagten Altman und Ive dem Wall Street Journal zufolge, beim ersten Projekt gehe es um ein Gerät, das die Umgebung von Nutzern und deren Leben erfasse. Es sei als eine Ergänzung für Smartphones und Laptops gedacht. Der Kaufpreis für io liege bei fünf Milliarden Dollar in Form von OpenAI-Aktien, berichtete Bloomberg. Zudem habe OpenAI bereits Ende vergangenen Jahres einen Anteil von 23 Prozent an io erworben, wodurch die Gesamtinvestition nahezu 6,5 Milliarden Dollar erreiche. OpenAI ist nicht an der Börse notiert. In diesen Fällen gilt meist die Bewertung des Unternehmens aus Finanzierungsrunden. (dpa/rs)",
    "source": "cio",
    "crawled_at": "2025-05-28T09:16:49.914436+00:00"
  },
  {
    "url": "https://www.cio.de/article/3993223/russische-cyber-kampagne-in-nato-staaten-aufgedeckt-2.html",
    "title": "Russische Cyber-Kampagne in Nato-Staaten aufgedeckt",
    "published": "2025-05-22T09:20:00+00:00",
    "author": "",
    "text": "Andrey_Popov – shutterstock.com Westliche Geheimdienste haben nach britischen Angaben eine Cyber-Kampagne Russlands aufgedeckt, die gegen logistische und technologische Ziele in Nato-Staaten gerichtet ist. Wie das britische National Cyber Security Centre mitteilte, soll die Einheit 26165 des russischen Geheimdienstes GRU seit 2022 eine Kampagne gegen staatliche und private Organisationen durchgeführt haben. Dabei sollen auch solche ins Visier geraten sein, die mit der Koordination und Lieferung von Hilfsgütern für die Ukraine befasst sind. Betroffen waren demnach die Bereiche Verteidigung, IT-Dienstleistungen sowie Systeme zum Verkehrsmanagement im See- und Luftverkehr – einschließlich Häfen und Flughäfen in mehreren Nato-Staaten, darunter auch Deutschland. Zum Einsatz kamen bei der auch als APT 28 bezeichneten Einheit demnach eine Mischung aus Techniken wie das Erraten von Zugangsdaten, Phishing sowie die Ausnutzung von Berechtigungen innerhalb von Microsoft-Exchange-Postfächern. Außerdem seien mit dem Internet verbundene Kameras an ukrainischen Grenzübergängen und in der Nähe militärischer Einrichtungen ins Visier genommen worden, um Hilfslieferungen für die Ukraine zu überwachen und nachzuverfolgen. Verantwortliche bei Technologie- und Logistikunternehmen sollten unverzüglich Maßnahmen ergreifen, um sich zu schützen, hieß es in der Mitteilung. Dazu gehöre eine erhöhte Wachsamkeit, Multifaktorauthentifizierung und das rasche Aufspielen von Security-Updates. Das National Cyber Security Centre in Großbritannien gehört zum Geheimdienst GCHQ. Zu den an der Aufdeckung beteiligten Behörden zählen auch der Bundesnachrichtendienst, das Bundesamt für Verfassungsschutz, das Bundesamt für Sicherheit in der Informationstechnik sowie Dienste aus den USA, Tschechien, Polen, Australien, Kanada, Dänemark, Estland, Frankreich und den Niederlanden. (dpa) Andrey_Popov – shutterstock.com Westliche Geheimdienste haben nach britischen Angaben eine Cyber-Kampagne Russlands aufgedeckt, die gegen logistische und technologische Ziele in Nato-Staaten gerichtet ist. Wie das britische National Cyber Security Centre mitteilte, soll die Einheit 26165 des russischen Geheimdienstes GRU seit 2022 eine Kampagne gegen staatliche und private Organisationen durchgeführt haben. Dabei sollen auch solche ins Visier geraten sein, die mit der Koordination und Lieferung von Hilfsgütern für die Ukraine befasst sind. Betroffen waren demnach die Bereiche Verteidigung, IT-Dienstleistungen sowie Systeme zum Verkehrsmanagement im See- und Luftverkehr – einschließlich Häfen und Flughäfen in mehreren Nato-Staaten, darunter auch Deutschland. Zum Einsatz kamen bei der auch als APT 28 bezeichneten Einheit demnach eine Mischung aus Techniken wie das Erraten von Zugangsdaten, Phishing sowie die Ausnutzung von Berechtigungen innerhalb von Microsoft-Exchange-Postfächern. Außerdem seien mit dem Internet verbundene Kameras an ukrainischen Grenzübergängen und in der Nähe militärischer Einrichtungen ins Visier genommen worden, um Hilfslieferungen für die Ukraine zu überwachen und nachzuverfolgen. Verantwortliche bei Technologie- und Logistikunternehmen sollten unverzüglich Maßnahmen ergreifen, um sich zu schützen, hieß es in der Mitteilung. Dazu gehöre eine erhöhte Wachsamkeit, Multifaktorauthentifizierung und das rasche Aufspielen von Security-Updates. Das National Cyber Security Centre in Großbritannien gehört zum Geheimdienst GCHQ. Zu den an der Aufdeckung beteiligten Behörden zählen auch der Bundesnachrichtendienst, das Bundesamt für Verfassungsschutz, das Bundesamt für Sicherheit in der Informationstechnik sowie Dienste aus den USA, Tschechien, Polen, Australien, Kanada, Dänemark, Estland, Frankreich und den Niederlanden. (dpa)",
    "source": "cio",
    "crawled_at": "2025-05-28T09:16:50.494796+00:00"
  },
  {
    "url": "https://www.cio.de/article/3993232/indischer-partner-ubernimmt-insolventen-motorradbauer-ktm.html",
    "title": "Indischer Partner übernimmt insolventen Motorradbauer KTM",
    "published": "2025-05-22T09:30:00+00:00",
    "author": "",
    "text": "Raimo Bergroth – shutterstock.com Die indische Bajaj Auto International Holdings B.V. übernimmt die Mehrheit an dem insolventen österreichischen Motorradhersteller KTM. Im Gegenzug stellt Bajaj rund 600 Millionen Euro zur Verfügung und verhindert so die Abwicklung von KTM. Das teilte die KTM-Mutter Pierer Mobility mit. Bajaj, ein Hersteller von Motorrädern und Auto-Rikschas, war schon bislang an KTM beteiligt. Durch die Verpfändung weiterer Unternehmensanteile übernimmt Bajaj nun die Mehrheit, wie Pierer Mobility mitteilte. KTM, der ehemals größte europäische Motorradbauer, war im November durch einen starken Rückgang der Nachfrage und hohen Lagerbeständen in die Insolvenz geschlittert. Die Produktion in Mattinghofen nahe der bayerischen Grenze wurde seitdem heruntergefahren. “Heute haben wir die Chance bekommen, die Geschichte von KTM fortzuschreiben”, sagte KTM-Vorstand Gottfried Neumeister. Er kündigte an, dass die aktuellen Produktionsstandorte, inklusive des Stammwerkes in Mattinghofen, auch in Zukunft bestehen sollen. Die Schulden belaufen sich auf rund zwei Milliarden Euro. Die Gläubiger räumten der KTM AG und zwei ebenfalls insolventen Konzerngesellschaften eine Frist bis Freitag ein, um davon 30 Prozent – etwa 600 Millionen Euro – zu bezahlen. Andernfalls drohte der Abverkauf des Firmenvermögens im Rahmen eines Konkursverfahrens. Im Zuge der Übernahme von KTM durch Bajaj werde sich der bislang dominierende Eigentümer Stefan Pierer als Vorstand der Pierer Mobility AG zurückziehen, hieß es in einer Mitteilung der Konzernmutter. (dpa/rs) Raimo Bergroth – shutterstock.com Die indische Bajaj Auto International Holdings B.V. übernimmt die Mehrheit an dem insolventen österreichischen Motorradhersteller KTM. Im Gegenzug stellt Bajaj rund 600 Millionen Euro zur Verfügung und verhindert so die Abwicklung von KTM. Das teilte die KTM-Mutter Pierer Mobility mit. Bajaj, ein Hersteller von Motorrädern und Auto-Rikschas, war schon bislang an KTM beteiligt. Durch die Verpfändung weiterer Unternehmensanteile übernimmt Bajaj nun die Mehrheit, wie Pierer Mobility mitteilte. KTM, der ehemals größte europäische Motorradbauer, war im November durch einen starken Rückgang der Nachfrage und hohen Lagerbeständen in die Insolvenz geschlittert. Die Produktion in Mattinghofen nahe der bayerischen Grenze wurde seitdem heruntergefahren. “Heute haben wir die Chance bekommen, die Geschichte von KTM fortzuschreiben”, sagte KTM-Vorstand Gottfried Neumeister. Er kündigte an, dass die aktuellen Produktionsstandorte, inklusive des Stammwerkes in Mattinghofen, auch in Zukunft bestehen sollen. Die Schulden belaufen sich auf rund zwei Milliarden Euro. Die Gläubiger räumten der KTM AG und zwei ebenfalls insolventen Konzerngesellschaften eine Frist bis Freitag ein, um davon 30 Prozent – etwa 600 Millionen Euro – zu bezahlen. Andernfalls drohte der Abverkauf des Firmenvermögens im Rahmen eines Konkursverfahrens. Im Zuge der Übernahme von KTM durch Bajaj werde sich der bislang dominierende Eigentümer Stefan Pierer als Vorstand der Pierer Mobility AG zurückziehen, hieß es in einer Mitteilung der Konzernmutter. (dpa/rs)",
    "source": "cio",
    "crawled_at": "2025-05-28T09:16:50.543184+00:00"
  },
  {
    "url": "https://www.cio.de/article/3824567/tipps-fur-die-richtige-datenstrategie-2.html",
    "title": "Tipps für die richtige Datenstrategie",
    "published": "2025-05-22T09:34:10+00:00",
    "author": "",
    "text": "alphaspirit.it/Shutterstock Wie funktionieren Datenstrategien und brauchen Unternehmen so etwas überhaupt? Diese Frage beschäftigt heute viele Verantwortliche in den Unternehmen. Gleichzeitig stehen sie zunehmend unter Druck, wettbewerbsfähig und innovativ zu bleiben. Ein Schlüsselfaktor, dieses Ziels zu erreichen, ist die effektive Nutzung von Daten: Sie erlauben es, Effizienzreserven in Prozessen zu erkennen, Kunden besser zu verstehen, um Produkte und Dienstleistungen anzupassen oder gar neue Angebote zu entwickeln. Besteht Konsens darüber, was man mit den Daten erreichen möchte, so lässt sich daraus eine Datenstrategie ableiten – also ein konkreter Handlungsrahmen, um Maßnahmen zu strukturieren und das übergeordnete Ziel, den “Nordstern”, zu verfolgen. Aus vielen verschiedenen Einzelentscheidungen in unterschiedlichen Unternehmensbereichen entsteht mit einer Datenstrategie ein kohärentes Bestreben, ein gemeinsames Ziel zu erreichen. Im Beispiel betrachten wir ein Unternehmen, das das Ziel verfolgt, der führende Online-Optiker zu sein: Um Brillen erfolgreich online verkaufen zu können, muss das Unternehmen Daten aus unterschiedlichen Quellen zusammenführen, angefangen bei den Produktdaten von den Glas- und Rahmenproduzenten über Marketingdaten bis hin zu medizinischen Daten von Kunden oder Informationen über die Auslastung von Lagern und Fertigungskapazitäten. Darüber hinaus muss der Online-Optiker eine erhebliche Menge an Fachwissen von Optikern in seinen Produktdaten kodieren. Dieses Fachwissen bestimmt beispielsweise die optimale Brillengröße, wobei Faktoren wie die Sehkraft des Kunden und die Geometrie der Gläser berücksichtigt werden. Durch die Kodierung dieses Wissens in den Produktdaten kann das Unternehmen sicherstellen, dass die Kunden die richtige Brille erhalten. Auf Basis all dieser Daten können die verschiedenen am Prozess beteiligten Abteilungen – Beschaffung, Produktion und E-Commerce – nahtlos zusammenarbeiten, um ein hochwertiges Ergebnis zu liefern, die Materialeinsatzplanung zu optimieren und Prognosen für zukünftige Entwicklungen zu erstellen. Bei einer Datenstrategie geht es nicht nur darum, Daten zu verwalten, sondern darum, wie Geschäftswissen am besten in Daten gespeichert und durch sie verstanden werden kann. Begleitet wird eine Datenstrategie von einer geeigneten Organisationskultur, die Mechanismen für den Ausgleich der Bedürfnisse verschiedener Interessengruppen bereithält und dabei unter anderem die Zusammenarbeit und den Wissensaustausch fördert. Ohne eine Datenstrategie zur Strukturierung unterschiedlicher Bemühungen bleibt in jeder Organisation ab einer gewissen Größe beziehungsweise Komplexität die Wertschöpfung aus Daten weit hinter den Möglichkeiten zurück. Daten werden dann im Wesentlichen nur lokal genutzt oder entlang relativ starrer Pfade aggregiert. Die Folge: Die Agilität des Unternehmens in Bezug auf notwendige Veränderungen bleibt gehemmt. Fehlt eine solche Strategie, können auch technische Konzepte und Architekturen diesen Wert kaum steigern. Eine gut durchdachte Datenstrategie kann auf unterschiedlichste Weisen formuliert sein. Sie umfasst eine Vielzahl verschiedener Facetten wie zum Beispiel Verfügbarkeit, Auffindbarkeit, Sicherheit, Schutz personenbezogener Daten, Kostenkontrolle, etc. Aus einer Vielzahl datenbezogener Projekte lassen sich jedoch vier Schlüsselaspekte identifizieren, die die Grundlage für eine Datenstrategie bilden: Identität, Bitemporalität, Vernetzung und Föderalismus. Ein sehr konkretes Beispiel, nämlich Markenlogos, verdeutlichen diese vier Elemente einer Datenstrategie: Identifiziert wird die Marke und erst darüber das Logo in einer konkreten Ausprägung (zu Beispiel Dateiformat oder Auflösung). Die Daten für Marke und Logo sind offensichtlich miteinander vernetzt, wie schon aus der Identifikation deutlich wird. Bei einem Wechsel des Logos beispielsweise bei einem Re-Branding kann so sichergestellt werden, dass die Referenz Bestand hat. Die Berücksichtigung der Bitemporalität stellt sicher, dass der Logowechsel in allen beteiligten Systemen zu einem definierten Zeitpunkt umgesetzt wird: Die Bitemporalität berücksichtigt Benachrichtigungen über zu erwartende Änderungen und erlaubt hier die Abfrage zukünftiger Inhalte, um die neuen Logos vorbereitend cachen zu können. Umgekehrt kann auch eine in die Vergangenheit gerichtete Abfrage sinnvoll sein, typischerweise aber eher bei Inhaltsstoffen, Preisen, Lieferbedingungen, etc. als bei einem Markenlogo. Die Festlegung, welche Marken es gibt, wie die Formate identifiziert werden, etc. kann nicht allein der Einkauf oder das Marketing festlegen. Dafür braucht es die notwendige Vernetzung . Diese Entscheidungen müssen durch eine gemeinsame Autorität festgelegt werden, eine Institution im föderalen System der Datenstrategie. Wie essentiell eine Datenstrategie für Unternehmen ist, beweist auch das Phänomen Produktdaten. Sie haben viele Quellen, beispielsweise die eigene Produktentwicklung, aber auch „fremde“ Hersteller und Zwischenhändler. Sie sind wesentlicher Bestandteil wichtiger Geschäftsprozesse, werden in den unterschiedlichsten Abteilungen benötigt und sie werden in einer Vielzahl von Systemen genutzt: Wenn nicht klar ist, was Produktdaten identifizieren, in welchem Zusammenhang sie miteinander stehen und welche Regeln für ihre Domänen übergreifende Bereitstellung gelten, entsteht aus ihnen ein undurchdringlicher Datensumpf, der weder produktiv noch analytisch sinnvoll eingesetzt werden kann. Das gilt umso mehr, je größer und differenzierter ein Unternehmen ist. Viele große Unternehmen betreiben schließlich zahlreiche E-Commerce-Systeme, etliche Produktionsstraßen in unterschiedlichen Ländern und managen verschiedene Marken und Produktkategorien. Eine Datenstrategie legt ferner fest, wie Unternehmen das Wissen um ihre Produkte, Services, Prozesse und Geschäftsmodelle codieren. Damit werden Lösungen möglich, die auch eine automatisierte Entscheidungsunterstützung erlauben. Dazu kurz zurück zu unserem Online-Optiker: Um Brillen online zu verkaufen, muss viel Optikerfachwissen codiert werden, damit der Kunde bei der Konfiguration seiner Brille nicht gravierende Fehler macht. Die optimale Größe der Gleitsicht-Brillengläser hängt nämlich unter anderem von der Sehstärke und der Glasgeometrie ab. Um erfolgreich Brillen online zu verkaufen, muss dieses Erfahrungswissen von Optikern in den Produktdaten codiert werden, und die verschiedenen Zuständigkeiten (Beschaffung, Produktion, eCommerce) müssen diese Daten pflegen, verbinden und nutzen. Ein Wissensgraph (Knowledge Graph) erfasst die Bedeutung der Daten und spielt eine besondere Rolle bei der Identifikation und der Vernetzung der Daten: Das dreischichtige Wissensgraph-Modell nach Dave McComb erweitert einen typischerweise zweischichtigen Blick auf Schemata beziehungsweise Klassen einerseits und Daten beziehungsweise Instanzen andererseits. McComb führt eine mittlere Ebene ein, die eine Zwitter-Rolle einnimmt und bezeichnet diese drei Ebenen als Konzepte, Kategorien und Daten. Ganz praktisch hat Katariina Kari, Lead Ontologist bei Inter Ikea Systems, mit Ihrem Team einen solchen Knowledge Graph eingeführt. An diesem Beispiel orientieren wir uns, übertragen das aber auf das Online-Optiker-Beispiel. Die Integration der Kategorien und insbesondere der Daten in die gesamte Landschaft erfolgt über die Referenz auf die übergeordneten Ebenen, so dass eine Vernetzung darüber möglich ist. Es können also beispielsweise alle Fassungen mit der Steg-Farbe Tortoise verknüpft werden. Über Ähnlichkeiten können beispielsweise ähnliche Produkte im eCommerce-System vorgeschlagen werden. Das zurzeit viel diskutierte Konzept Data Mesh von Zhamak Dehghani, Technologiedirektorin des IT-Beratungsunternehmens ThoughtWorks ist nichts anderes als die konkrete Ausprägung einer Datenstrategie. Dieses soziotechnische Konzept basiert auf den vier Prinzipien Domain Ownership, Daten als Produkt, Self-Service-Datenplattform und föderierte Governance. Wir setzen dieses Konzept in Relation zu den vier Schlüsselaspekten Identität, Bitemporalität, Vernetzung und Föderalismus. Je nach Business-Anforderungen und Komplexität der Datenströme in einem Unternehmen kann ein Data-Mesh die sinnvollste Realisierung einer Datenstrategie darstellen. Allzu oft wird dabei vor allem die technische und weniger die soziologische Seite betont. Wir sehen aber auch, dass die vier Prinzipien Domain Ownership, Data as a Product, Self Service Data Platform und Federated Governance wenig konkrete Orientierung geben: Was enthält ein Data Product? Wie steht es zu anderen Data Products in Verbindung? Was soll eine Self Service Data Platform ermöglichen? Hier kommen wir zurück zu den vier Schlüsselaspekten einer Datenstrategie: Identität, Bitemporalität, Vernetzung und Föderalismus. Diese Schlüsselaspekte fokussieren die Datenstrategie auf konkrete Punkte und können so beispielsweise der Realisierung eines Data Mesh Struktur geben: Welche Identitäten werden in den Datenprodukten exponiert? Welche Datenprodukte müssen gemeinsame Identitäten referenzieren, um Vernetzung zu ermöglichen? Müssen Datenprodukte nur „für den Moment“ realisiert werden oder für einen Blick nach vorne oder zurück – Stichwort Bitemporalität. Und über allem thront die Frage: Wer hat die Kompetenz, Entitäten zu identifizieren? Kompetenz bedeutet dabei sowohl das fachliche, technische und gestalterische Wissen als auch den allgemein anerkannten Auftrag zur Gestaltung der entsprechenden Informationsräume. Der Data Mesh Ansatz bezieht das föderale Prinzip explizit auf Governance, also auf die Verwaltung inklusive der Gestaltung der Verwaltung. Wir gehen mit unserem Verständnis von Föderalismus darüber hinaus und verstehen darunter explizit auch die Gestaltung der Datenräume: Auch die Erstellung und Pflege der Konzepte, Kategorien und Daten in einem Knowledge Graphen wird als föderale Struktur organisiert: Für die oberste Schicht, die Konzepte, ist eine zentrale Gestaltung notwendig. Die Ebene der Kategorien kann aufgebrochen und lokaler realisiert werden. Insbesondere können verschiedene Teilbereiche der zweiten Ebene von unterschiedlichen Teams verwaltet werden. Die Daten-Ebene entsteht dann wirklich lokal in den Domänen und unterliegt dem jeweiligen Owner eines Data Products. In Anerkennung von Peter Druckers “Culture eats strategy for breakfast” ist auch für eine erfolgreiche Datenstrategie eine entsprechende Kultur quasi zwingende Voraussetzung. (Unternehmens-) Kultur umfasst die immateriellen Grundlagen gestaltender Leistungen einer Organisation. In Bezug auf die Daten-Kultur stellt sich also beispielsweise die Frage der Ausgestaltung der föderalen Strukturen: Betont eine Organisation eher zentrale Verantwortung oder lokale Verantwortung? Entsprechen föderale Ebenen auch hierarchischen Ebenen, werden Entscheidungen also über Führungskräfte eskaliert oder werden kompetente, das heißt entscheidungsfähige, Gremien auf andere Weise zusammengesetzt? Wie wird die dezentralisierte Kompetenz der Domänen ausbalanciert im Vergleich mit zentral bereitgestellten Plattformen, die mit möglichst geringer Lernkurve für die Nutzer aus den Domänen zu verwenden sind, dafür aber mit erheblichem Aufwand betrieben werden müssen. Unternehmen, die ihre Datenstrategie überdenken, sollten einen Nordstern entwickeln, dann aber sehr pragmatisch vorgehen. Der Nordstern steht für das Zielbild, das angestrebt wird: Will man Effizienz steigern, auf der Basis von Erkenntnissen aus den vorhandenen Daten Produkte oder Services verbessern und neue Geschäftsfelder erschließen? Wenn das Ziel einer Datenstrategie und entsprechender Initiativen nicht klar ist, dann ist die Realisierung zum Scheitern verurteilt. Erst wenn die Richtung klar ist, können praktisch realisierbare Schritte zum Erfolg führen. Die Organisation kann behutsam verändert werden, um beispielsweise föderale Governance-Strukturen aufzubauen, eine zentrale Steuerung des obersten Ontology-Layers realisiert und im Wechselspiel mit den Domänen angepasst und verbessert werden. Die Domänen müssen in die Lage versetzt werden, eigenständig Datenprodukte realisieren zu können, bei zentraler Definition der Policies, die für alle gelten müssen, beispielsweise in Bezug auf Identitäts- und Zugriffsmanagement. Und hier, beim Schaffen einer Plattform – geplant oder emergent als Ergebnis nur lose koordinierter Initiativen zur Reduktion des Kommunikations-Overheads – nähert sich die Datenstrategie der klassischen IT-Strategie, insbesondere in Bezug auf Cloud-Architekturen. Wettbewerbsfähigkeit durch Innovation braucht eine gut durchdachte Datenstrategie. Durch die Orientierung an den Schlüsselaspekten Identität, Bitemporalität, Vernetzung und Föderalismus können Unternehmen das Potenzial ihrer Daten erschließen und fundierte Entscheidungen treffen. Dabei geht es nicht nur um das Sammeln und Analysieren von Daten, sondern um die Schaffung einer Kultur der datengesteuerten Entscheidungsfindung. Sie erfordert die Fähigkeit, ein Gleichgewicht zwischen Zentralisierung und Dezentralisierung herzustellen. Dabei wird ein Kernelement unserer Gesellschaft, der Föderalismus, zum strukturierenden Element. alphaspirit.it/Shutterstock Wie funktionieren Datenstrategien und brauchen Unternehmen so etwas überhaupt? Diese Frage beschäftigt heute viele Verantwortliche in den Unternehmen. Gleichzeitig stehen sie zunehmend unter Druck, wettbewerbsfähig und innovativ zu bleiben. Ein Schlüsselfaktor, dieses Ziels zu erreichen, ist die effektive Nutzung von Daten: Sie erlauben es, Effizienzreserven in Prozessen zu erkennen, Kunden besser zu verstehen, um Produkte und Dienstleistungen anzupassen oder gar neue Angebote zu entwickeln. Besteht Konsens darüber, was man mit den Daten erreichen möchte, so lässt sich daraus eine Datenstrategie ableiten – also ein konkreter Handlungsrahmen, um Maßnahmen zu strukturieren und das übergeordnete Ziel, den “Nordstern”, zu verfolgen. Aus vielen verschiedenen Einzelentscheidungen in unterschiedlichen Unternehmensbereichen entsteht mit einer Datenstrategie ein kohärentes Bestreben, ein gemeinsames Ziel zu erreichen. Im Beispiel betrachten wir ein Unternehmen, das das Ziel verfolgt, der führende Online-Optiker zu sein: Um Brillen erfolgreich online verkaufen zu können, muss das Unternehmen Daten aus unterschiedlichen Quellen zusammenführen, angefangen bei den Produktdaten von den Glas- und Rahmenproduzenten über Marketingdaten bis hin zu medizinischen Daten von Kunden oder Informationen über die Auslastung von Lagern und Fertigungskapazitäten. Darüber hinaus muss der Online-Optiker eine erhebliche Menge an Fachwissen von Optikern in seinen Produktdaten kodieren. Dieses Fachwissen bestimmt beispielsweise die optimale Brillengröße, wobei Faktoren wie die Sehkraft des Kunden und die Geometrie der Gläser berücksichtigt werden. Durch die Kodierung dieses Wissens in den Produktdaten kann das Unternehmen sicherstellen, dass die Kunden die richtige Brille erhalten. Auf Basis all dieser Daten können die verschiedenen am Prozess beteiligten Abteilungen – Beschaffung, Produktion und E-Commerce – nahtlos zusammenarbeiten, um ein hochwertiges Ergebnis zu liefern, die Materialeinsatzplanung zu optimieren und Prognosen für zukünftige Entwicklungen zu erstellen. Bei einer Datenstrategie geht es nicht nur darum, Daten zu verwalten, sondern darum, wie Geschäftswissen am besten in Daten gespeichert und durch sie verstanden werden kann. Begleitet wird eine Datenstrategie von einer geeigneten Organisationskultur, die Mechanismen für den Ausgleich der Bedürfnisse verschiedener Interessengruppen bereithält und dabei unter anderem die Zusammenarbeit und den Wissensaustausch fördert. Ohne eine Datenstrategie zur Strukturierung unterschiedlicher Bemühungen bleibt in jeder Organisation ab einer gewissen Größe beziehungsweise Komplexität die Wertschöpfung aus Daten weit hinter den Möglichkeiten zurück. Daten werden dann im Wesentlichen nur lokal genutzt oder entlang relativ starrer Pfade aggregiert. Die Folge: Die Agilität des Unternehmens in Bezug auf notwendige Veränderungen bleibt gehemmt. Fehlt eine solche Strategie, können auch technische Konzepte und Architekturen diesen Wert kaum steigern. Eine gut durchdachte Datenstrategie kann auf unterschiedlichste Weisen formuliert sein. Sie umfasst eine Vielzahl verschiedener Facetten wie zum Beispiel Verfügbarkeit, Auffindbarkeit, Sicherheit, Schutz personenbezogener Daten, Kostenkontrolle, etc. Aus einer Vielzahl datenbezogener Projekte lassen sich jedoch vier Schlüsselaspekte identifizieren, die die Grundlage für eine Datenstrategie bilden: Identität, Bitemporalität, Vernetzung und Föderalismus. Ein sehr konkretes Beispiel, nämlich Markenlogos, verdeutlichen diese vier Elemente einer Datenstrategie: Identifiziert wird die Marke und erst darüber das Logo in einer konkreten Ausprägung (zu Beispiel Dateiformat oder Auflösung). Die Daten für Marke und Logo sind offensichtlich miteinander vernetzt, wie schon aus der Identifikation deutlich wird. Bei einem Wechsel des Logos beispielsweise bei einem Re-Branding kann so sichergestellt werden, dass die Referenz Bestand hat. Die Berücksichtigung der Bitemporalität stellt sicher, dass der Logowechsel in allen beteiligten Systemen zu einem definierten Zeitpunkt umgesetzt wird: Die Bitemporalität berücksichtigt Benachrichtigungen über zu erwartende Änderungen und erlaubt hier die Abfrage zukünftiger Inhalte, um die neuen Logos vorbereitend cachen zu können. Umgekehrt kann auch eine in die Vergangenheit gerichtete Abfrage sinnvoll sein, typischerweise aber eher bei Inhaltsstoffen, Preisen, Lieferbedingungen, etc. als bei einem Markenlogo. Die Festlegung, welche Marken es gibt, wie die Formate identifiziert werden, etc. kann nicht allein der Einkauf oder das Marketing festlegen. Dafür braucht es die notwendige Vernetzung . Diese Entscheidungen müssen durch eine gemeinsame Autorität festgelegt werden, eine Institution im föderalen System der Datenstrategie. Wie essentiell eine Datenstrategie für Unternehmen ist, beweist auch das Phänomen Produktdaten. Sie haben viele Quellen, beispielsweise die eigene Produktentwicklung, aber auch „fremde“ Hersteller und Zwischenhändler. Sie sind wesentlicher Bestandteil wichtiger Geschäftsprozesse, werden in den unterschiedlichsten Abteilungen benötigt und sie werden in einer Vielzahl von Systemen genutzt: Wenn nicht klar ist, was Produktdaten identifizieren, in welchem Zusammenhang sie miteinander stehen und welche Regeln für ihre Domänen übergreifende Bereitstellung gelten, entsteht aus ihnen ein undurchdringlicher Datensumpf, der weder produktiv noch analytisch sinnvoll eingesetzt werden kann. Das gilt umso mehr, je größer und differenzierter ein Unternehmen ist. Viele große Unternehmen betreiben schließlich zahlreiche E-Commerce-Systeme, etliche Produktionsstraßen in unterschiedlichen Ländern und managen verschiedene Marken und Produktkategorien. Eine Datenstrategie legt ferner fest, wie Unternehmen das Wissen um ihre Produkte, Services, Prozesse und Geschäftsmodelle codieren. Damit werden Lösungen möglich, die auch eine automatisierte Entscheidungsunterstützung erlauben. Dazu kurz zurück zu unserem Online-Optiker: Um Brillen online zu verkaufen, muss viel Optikerfachwissen codiert werden, damit der Kunde bei der Konfiguration seiner Brille nicht gravierende Fehler macht. Die optimale Größe der Gleitsicht-Brillengläser hängt nämlich unter anderem von der Sehstärke und der Glasgeometrie ab. Um erfolgreich Brillen online zu verkaufen, muss dieses Erfahrungswissen von Optikern in den Produktdaten codiert werden, und die verschiedenen Zuständigkeiten (Beschaffung, Produktion, eCommerce) müssen diese Daten pflegen, verbinden und nutzen. Ein Wissensgraph (Knowledge Graph) erfasst die Bedeutung der Daten und spielt eine besondere Rolle bei der Identifikation und der Vernetzung der Daten: Das dreischichtige Wissensgraph-Modell nach Dave McComb erweitert einen typischerweise zweischichtigen Blick auf Schemata beziehungsweise Klassen einerseits und Daten beziehungsweise Instanzen andererseits. McComb führt eine mittlere Ebene ein, die eine Zwitter-Rolle einnimmt und bezeichnet diese drei Ebenen als Konzepte, Kategorien und Daten. Ganz praktisch hat Katariina Kari, Lead Ontologist bei Inter Ikea Systems, mit Ihrem Team einen solchen Knowledge Graph eingeführt. An diesem Beispiel orientieren wir uns, übertragen das aber auf das Online-Optiker-Beispiel. Die Integration der Kategorien und insbesondere der Daten in die gesamte Landschaft erfolgt über die Referenz auf die übergeordneten Ebenen, so dass eine Vernetzung darüber möglich ist. Es können also beispielsweise alle Fassungen mit der Steg-Farbe Tortoise verknüpft werden. Über Ähnlichkeiten können beispielsweise ähnliche Produkte im eCommerce-System vorgeschlagen werden. Das zurzeit viel diskutierte Konzept Data Mesh von Zhamak Dehghani, Technologiedirektorin des IT-Beratungsunternehmens ThoughtWorks ist nichts anderes als die konkrete Ausprägung einer Datenstrategie. Dieses soziotechnische Konzept basiert auf den vier Prinzipien Domain Ownership, Daten als Produkt, Self-Service-Datenplattform und föderierte Governance. Wir setzen dieses Konzept in Relation zu den vier Schlüsselaspekten Identität, Bitemporalität, Vernetzung und Föderalismus. Je nach Business-Anforderungen und Komplexität der Datenströme in einem Unternehmen kann ein Data-Mesh die sinnvollste Realisierung einer Datenstrategie darstellen. Allzu oft wird dabei vor allem die technische und weniger die soziologische Seite betont. Wir sehen aber auch, dass die vier Prinzipien Domain Ownership, Data as a Product, Self Service Data Platform und Federated Governance wenig konkrete Orientierung geben: Was enthält ein Data Product? Wie steht es zu anderen Data Products in Verbindung? Was soll eine Self Service Data Platform ermöglichen? Hier kommen wir zurück zu den vier Schlüsselaspekten einer Datenstrategie: Identität, Bitemporalität, Vernetzung und Föderalismus. Diese Schlüsselaspekte fokussieren die Datenstrategie auf konkrete Punkte und können so beispielsweise der Realisierung eines Data Mesh Struktur geben: Welche Identitäten werden in den Datenprodukten exponiert? Welche Datenprodukte müssen gemeinsame Identitäten referenzieren, um Vernetzung zu ermöglichen? Müssen Datenprodukte nur „für den Moment“ realisiert werden oder für einen Blick nach vorne oder zurück – Stichwort Bitemporalität. Und über allem thront die Frage: Wer hat die Kompetenz, Entitäten zu identifizieren? Kompetenz bedeutet dabei sowohl das fachliche, technische und gestalterische Wissen als auch den allgemein anerkannten Auftrag zur Gestaltung der entsprechenden Informationsräume. Der Data Mesh Ansatz bezieht das föderale Prinzip explizit auf Governance, also auf die Verwaltung inklusive der Gestaltung der Verwaltung. Wir gehen mit unserem Verständnis von Föderalismus darüber hinaus und verstehen darunter explizit auch die Gestaltung der Datenräume: Auch die Erstellung und Pflege der Konzepte, Kategorien und Daten in einem Knowledge Graphen wird als föderale Struktur organisiert: Für die oberste Schicht, die Konzepte, ist eine zentrale Gestaltung notwendig. Die Ebene der Kategorien kann aufgebrochen und lokaler realisiert werden. Insbesondere können verschiedene Teilbereiche der zweiten Ebene von unterschiedlichen Teams verwaltet werden. Die Daten-Ebene entsteht dann wirklich lokal in den Domänen und unterliegt dem jeweiligen Owner eines Data Products. In Anerkennung von Peter Druckers “Culture eats strategy for breakfast” ist auch für eine erfolgreiche Datenstrategie eine entsprechende Kultur quasi zwingende Voraussetzung. (Unternehmens-) Kultur umfasst die immateriellen Grundlagen gestaltender Leistungen einer Organisation. In Bezug auf die Daten-Kultur stellt sich also beispielsweise die Frage der Ausgestaltung der föderalen Strukturen: Betont eine Organisation eher zentrale Verantwortung oder lokale Verantwortung? Entsprechen föderale Ebenen auch hierarchischen Ebenen, werden Entscheidungen also über Führungskräfte eskaliert oder werden kompetente, das heißt entscheidungsfähige, Gremien auf andere Weise zusammengesetzt? Wie wird die dezentralisierte Kompetenz der Domänen ausbalanciert im Vergleich mit zentral bereitgestellten Plattformen, die mit möglichst geringer Lernkurve für die Nutzer aus den Domänen zu verwenden sind, dafür aber mit erheblichem Aufwand betrieben werden müssen. Unternehmen, die ihre Datenstrategie überdenken, sollten einen Nordstern entwickeln, dann aber sehr pragmatisch vorgehen. Der Nordstern steht für das Zielbild, das angestrebt wird: Will man Effizienz steigern, auf der Basis von Erkenntnissen aus den vorhandenen Daten Produkte oder Services verbessern und neue Geschäftsfelder erschließen? Wenn das Ziel einer Datenstrategie und entsprechender Initiativen nicht klar ist, dann ist die Realisierung zum Scheitern verurteilt. Erst wenn die Richtung klar ist, können praktisch realisierbare Schritte zum Erfolg führen. Die Organisation kann behutsam verändert werden, um beispielsweise föderale Governance-Strukturen aufzubauen, eine zentrale Steuerung des obersten Ontology-Layers realisiert und im Wechselspiel mit den Domänen angepasst und verbessert werden. Die Domänen müssen in die Lage versetzt werden, eigenständig Datenprodukte realisieren zu können, bei zentraler Definition der Policies, die für alle gelten müssen, beispielsweise in Bezug auf Identitäts- und Zugriffsmanagement. Und hier, beim Schaffen einer Plattform – geplant oder emergent als Ergebnis nur lose koordinierter Initiativen zur Reduktion des Kommunikations-Overheads – nähert sich die Datenstrategie der klassischen IT-Strategie, insbesondere in Bezug auf Cloud-Architekturen. Wettbewerbsfähigkeit durch Innovation braucht eine gut durchdachte Datenstrategie. Durch die Orientierung an den Schlüsselaspekten Identität, Bitemporalität, Vernetzung und Föderalismus können Unternehmen das Potenzial ihrer Daten erschließen und fundierte Entscheidungen treffen. Dabei geht es nicht nur um das Sammeln und Analysieren von Daten, sondern um die Schaffung einer Kultur der datengesteuerten Entscheidungsfindung. Sie erfordert die Fähigkeit, ein Gleichgewicht zwischen Zentralisierung und Dezentralisierung herzustellen. Dabei wird ein Kernelement unserer Gesellschaft, der Föderalismus, zum strukturierenden Element.",
    "source": "cio",
    "crawled_at": "2025-05-28T09:16:51.117874+00:00"
  },
  {
    "url": "https://www.cio.de/article/3854433/s-4hana-mit-einer-hybrid-cloud-und-ki-das-potenzial-von-daten-ausschopfen.html",
    "title": "Mit Hybrid Cloud und KI das Potenzial von Daten ausschöpfen",
    "published": "2025-05-22T10:14:12+00:00",
    "author": "",
    "text": "Die Kenntnis aller Optionen hilft, die richtige Entscheidung für den zukünftigen Betrieb von SAP in der Cloud zu treffen. Dragana Gordic – Shutterstock.com Die Frage, auf welcher Plattform und mit welchem Bereitstellungsmodell SAP-ERP-Systeme zukünftig betrieben werden, ist für IT-Entscheider nach wie vor von weitreichender Bedeutung. 2027 läuft der Mainstream Support für SAP ECC aus. 2030 soll auch der kostenpflichtige Extended Support für diese Version enden und Verlängerungsoptionen bis 2033 kursieren bereits. Obwohl die neue ERP-Lösung bereits 2015 vorgestellt wurde, gehen Schätzungen davon aus, dass heute erst 30 Prozent der SAP-Anwender – wenn überhaupt – S4/HANA produktiv nutzen. Was bremst die wichtige Software-Migration? Die S/4HANA-Migration ist für viele Unternehmen ein strategisches Muss, doch die Entscheidungen zur Umsetzung gestaltet sich oft zäh. Nicht fehlendes Know-how oder mangelnder Wille sind die Hauptbremsklötze, sondern vielmehr eine Kombination aus unklarem Business Case und wahrgenommener Komplexität. Viele Entscheider sehen sich außerstande, den direkten geschäftlichen Nutzen der Migration zu quantifizieren, um den Aufwand und die tiefgreifenden Veränderungen in Prozessen und Strukturen rechtfertigen zu können. Das eigentliche Problem ist jedoch der Druck der SAP-Verantwortlichen, im Zuge der Migration die heute bei den Kunden eingesetzten IT-Plattformen in die SAP-Cloud zu überführen. Dieses Momentum verstärkt die Unsicherheit und Komplexität für Projektentscheider erheblich. In der Folge gehen die Marktforscher von Gartner davon aus, dass im Jahr 2030 rund 40 Prozent der SAP-Kunden nach wie vor nicht umgestiegen sein werden ( zum Bericht ). Es ist daher fraglich, ob SAP an den bisherigen Terminen festhalten kann. Die Migration auf S/4HANA konkurriert inzwischen mit der Einführung von KI und hybriden Cloud-Architekturen, wenn es um die wichtigsten IT-Prioritäten in den Unternehmen geht. KI-Lösungen benötigen Zugang zu einer Vielzahl von Datenquellen, deren Integration, Kontrolle, Souveränität, Sicherheit und geringe Latenz gemanagt werden muss. Daher ist eine Hybrid-Cloud-Strategie nicht nur hilfreich, sondern essenzielle Voraussetzung für die erfolgreiche Implementierung von KI. Die Hybrid Cloud hat sich als Standardbetriebsmodell für viele Unternehmen etabliert. HPE SAP S4/HANA kann den betriebswirtschaftlichen Teil der Datenbasis für die KI-Strategie von Unternehmen liefern. Die Annahme, dass die SAP-Cloud mit ihren KI-Tools automatisch die optimale Lösung für die oft erheblich umfangreicheren und vielfältigeren KI-Usecases darstellt, ist jedoch nicht selbstverständlich. Innovative KI-Anwendungen greifen häufig auf ein breiteres Datenspektrum zurück, als nur auf primäre SAP-Daten. Deshalb spielen hybride Konzepte, die Kombinationen beliebiger Datenquellen ermöglichen, die zentrale Rolle. Im Fokus stehen dabei hochsensible Daten, die in der Regel on-premise vorgehalten werden. Diese sollen auch der KI zur Verfügung stehen, jedoch streng kontrolliert. Flexible Datenintegration ist der Schlüssel. Um unterschiedliche Datenquellen flexibel integrieren zu können, sind offene hybride Strukturen notwendig. Der Cloud-only-Ansatz der SAP reicht nicht mehr aus. Die Unterscheidung zwischen on-premise und Cloud ist dann nicht mehr relevant, da sie gemeinsam eine moderne Hybrid-Cloud-Strategie bilden. MEHR ÜBER LÖSUNGEN ERFAHREN! Ein kritischer Punkt beim zukünftigen SAP-Betriebsmodell ist die Kontrolle über Daten und Systeme. Manche Verantwortlichen befürchten, dass Anbieter von Off-Premise-Clouds den Zugriff des Kunden mit einem einzigen Schnitt beenden könnten. Bei On-Premise-Konzepten liegt die Kontrolle beim Kunden: Er behält immer den physischen Zugang und Zugriff auf seine Systeme – das ist in der Public Cloud nicht möglich. Obwohl beide Szenarien theoretischer Natur sind, unterscheiden sie sich in der gefühlten Souveränität erheblich. Gerade in der aktuellen geopolitischen Lage äußern deutsche Unternehmen vermehrt Bedenken, sensible Daten auf Systemen ausländischer Technologiekonzerne zu speichern. Mit dem Fokus auf in alle Richtungen offene hybride Konzepte entscheiden sich SAP-Kunden häufig für Cloud-Optionen ohne SAP RISE. „Die S4/HANA-Migration muss nicht zwangsläufig in einem RISE with SAP-Vertrag oder in der SAP-Cloud enden. Kunden haben die Wahl zu mehr Offenheit und mehr Optionen“, beschreibt Albrecht Munz, verantwortlich für die Geschäftsentwicklung im SAP-Markt bei Hewlett Packard Enterprise (HPE), die Situation. Ein Blick in den Investitionsreport 2024 der Deutschsprachigen SAP-Anwendergruppe e.V. (DSAG) zeigt : 61 Prozent der Unternehmen lehnen RISE with SAP ab, was sogar ein Anstieg gegenüber 2022 bedeutet. Warum ist die Begeisterung für RISE with SAP im ERP-Bereich weiterhin gering? Munz kennt die offenen Fragen aus vielen Diskussionen: HPE ist einer der führenden Anbieter von Informationstechnologie und auf kundenzentrische Cloud- und Service-Strategien fokussiert. Mit HPE GreenLake für SAP profitieren Unternehmen von einer hybriden S/4HANA-Lösung, die Edge-Computing, On-Premise-Flexibilität und Hyperscaler-Skalierbarkeit kombiniert. Verantwortliche behalten so die IT-Kontrolle und Entscheidungsfreiheit. HPE GreenLake bietet vollständig verwaltete Hybrid-Cloud-Services für On-Premise- und Off-Premise-Umgebungen. HPE HPE GreenLake steht für die flexible Integration verschiedener Cloud Services. Mit HPE Private Cloud AI Stack und der HPE GreenLake Cloud Platform lassen sich erste produktive KI-Anwendungsfälle einfach und schnell umsetzen. Damit können Unternehmen ihre KI-Strategien unabhängig von anbieterspezifischen Restriktionen realisieren und die umfassenden Vorteile einer hybriden Cloud-Umgebung nutzen. Die global agierende Würth-Gruppe (40 Mrd. Euro Umsatz) bevorzugt on-premise für ihre großen SAP-Kernsysteme. Um flexibel zu bleiben, nutzt sie Off-Premise-Services. Mit HPE GreenLake hat Würth eine Lösung gefunden, die diese Anforderungen vereinen kann ( Video-Interview , Laufzeit 2:32 Min). Ausschlaggebend für Würth war die enorme Skalierbarkeit der Intel x86-basierten Plattform, also technisch-wirtschaftliche Argumente. Schließlich betreibt ein Konzern dieser Größenordnung ein SAP-BW-System mit rund 32 TB Speicher, das man nicht gerne aus der Hand gibt. EPL Ltd., ein globaler Verpackungsspezialist, entschied sich für HPE GreenLake für SAP, um Cloud-Agilität mit IT-Souveränität zu kombinieren ( Case Study ). ZUR CASE STUDY! HPE GreenLake für SAP überzeugt auch HPE-Partner für deren Kunden. Die Davidoff Öttinger Gruppe, unterstützt von Bechtle AG, integriert ihre globale Wertschöpfungskette – von Tabakfeldern bis zu Flagship-Stores – mit dieser Lösung. HPE GreenLake ermöglicht die Verwaltung des gesamten Systems als Cloud Experience im eigenen Rechenzentrum ( Case Study ). Unabhängig vom Betriebsmodell ist die Verfügbarkeit einer hochskalierbaren und standardisierten IT-Plattform Voraussetzung für einen wirtschaftlichen SAP-Betrieb. Alle Unternehmensgrößen sollten mit einer einheitlichen Technologiebasis abdeckbar sein. Mehrere Betriebssysteme wegen unterschiedlicher Skalierungs- und Sicherheitsanforderungen betreiben zu müssen, ist teuer und unflexibel. Diese x86-basierte Plattform wurde in den letzten Jahren im Rahmen von Co-Engineering-Projekten zwischen SAP, Intel und HPE entwickelt bzw. weiterentwickelt. Von der kleinsten SAP-Instanz bis hin zu den größten heute gebauten und SAP-zertifizierten Serversystemen sind somit alle Leistungsanforderungen ohne Systembrüche abdeckbar. Mit den SAP-Entscheidungen sollten Unternehmen ihre KI-Strategie und Hybrid-Cloud-Konzepte sowie deren Konsequenzen geklärt haben. Dies betrifft sowohl Plattformen als auch Bereitstellungsmodelle. Darüber hinaus sollte die Migration zu SAP S/4HANA auch in Zukunft Plattform- und Anbieterflexibilität gewährleisten. Treffen Sie fundierte SAP-Entscheidungen. HPE GreenLake zeigt Ihnen neue Möglichkeiten auf. Erkunden Sie unsere Lösungen online oder kontaktieren Sie Ihren persönlichen Ansprechpartner bei HPE. JETZT ENTDECKEN! Die Kenntnis aller Optionen hilft, die richtige Entscheidung für den zukünftigen Betrieb von SAP in der Cloud zu treffen. Dragana Gordic – Shutterstock.com Die Frage, auf welcher Plattform und mit welchem Bereitstellungsmodell SAP-ERP-Systeme zukünftig betrieben werden, ist für IT-Entscheider nach wie vor von weitreichender Bedeutung. 2027 läuft der Mainstream Support für SAP ECC aus. 2030 soll auch der kostenpflichtige Extended Support für diese Version enden und Verlängerungsoptionen bis 2033 kursieren bereits. Obwohl die neue ERP-Lösung bereits 2015 vorgestellt wurde, gehen Schätzungen davon aus, dass heute erst 30 Prozent der SAP-Anwender – wenn überhaupt – S4/HANA produktiv nutzen. Was bremst die wichtige Software-Migration? Die S/4HANA-Migration ist für viele Unternehmen ein strategisches Muss, doch die Entscheidungen zur Umsetzung gestaltet sich oft zäh. Nicht fehlendes Know-how oder mangelnder Wille sind die Hauptbremsklötze, sondern vielmehr eine Kombination aus unklarem Business Case und wahrgenommener Komplexität. Viele Entscheider sehen sich außerstande, den direkten geschäftlichen Nutzen der Migration zu quantifizieren, um den Aufwand und die tiefgreifenden Veränderungen in Prozessen und Strukturen rechtfertigen zu können. Das eigentliche Problem ist jedoch der Druck der SAP-Verantwortlichen, im Zuge der Migration die heute bei den Kunden eingesetzten IT-Plattformen in die SAP-Cloud zu überführen. Dieses Momentum verstärkt die Unsicherheit und Komplexität für Projektentscheider erheblich. In der Folge gehen die Marktforscher von Gartner davon aus, dass im Jahr 2030 rund 40 Prozent der SAP-Kunden nach wie vor nicht umgestiegen sein werden ( zum Bericht ). Es ist daher fraglich, ob SAP an den bisherigen Terminen festhalten kann. Die Migration auf S/4HANA konkurriert inzwischen mit der Einführung von KI und hybriden Cloud-Architekturen, wenn es um die wichtigsten IT-Prioritäten in den Unternehmen geht. KI-Lösungen benötigen Zugang zu einer Vielzahl von Datenquellen, deren Integration, Kontrolle, Souveränität, Sicherheit und geringe Latenz gemanagt werden muss. Daher ist eine Hybrid-Cloud-Strategie nicht nur hilfreich, sondern essenzielle Voraussetzung für die erfolgreiche Implementierung von KI. Die Hybrid Cloud hat sich als Standardbetriebsmodell für viele Unternehmen etabliert. HPE SAP S4/HANA kann den betriebswirtschaftlichen Teil der Datenbasis für die KI-Strategie von Unternehmen liefern. Die Annahme, dass die SAP-Cloud mit ihren KI-Tools automatisch die optimale Lösung für die oft erheblich umfangreicheren und vielfältigeren KI-Usecases darstellt, ist jedoch nicht selbstverständlich. Innovative KI-Anwendungen greifen häufig auf ein breiteres Datenspektrum zurück, als nur auf primäre SAP-Daten. Deshalb spielen hybride Konzepte, die Kombinationen beliebiger Datenquellen ermöglichen, die zentrale Rolle. Im Fokus stehen dabei hochsensible Daten, die in der Regel on-premise vorgehalten werden. Diese sollen auch der KI zur Verfügung stehen, jedoch streng kontrolliert. Flexible Datenintegration ist der Schlüssel. Um unterschiedliche Datenquellen flexibel integrieren zu können, sind offene hybride Strukturen notwendig. Der Cloud-only-Ansatz der SAP reicht nicht mehr aus. Die Unterscheidung zwischen on-premise und Cloud ist dann nicht mehr relevant, da sie gemeinsam eine moderne Hybrid-Cloud-Strategie bilden. MEHR ÜBER LÖSUNGEN ERFAHREN! Ein kritischer Punkt beim zukünftigen SAP-Betriebsmodell ist die Kontrolle über Daten und Systeme. Manche Verantwortlichen befürchten, dass Anbieter von Off-Premise-Clouds den Zugriff des Kunden mit einem einzigen Schnitt beenden könnten. Bei On-Premise-Konzepten liegt die Kontrolle beim Kunden: Er behält immer den physischen Zugang und Zugriff auf seine Systeme – das ist in der Public Cloud nicht möglich. Obwohl beide Szenarien theoretischer Natur sind, unterscheiden sie sich in der gefühlten Souveränität erheblich. Gerade in der aktuellen geopolitischen Lage äußern deutsche Unternehmen vermehrt Bedenken, sensible Daten auf Systemen ausländischer Technologiekonzerne zu speichern. Mit dem Fokus auf in alle Richtungen offene hybride Konzepte entscheiden sich SAP-Kunden häufig für Cloud-Optionen ohne SAP RISE. „Die S4/HANA-Migration muss nicht zwangsläufig in einem RISE with SAP-Vertrag oder in der SAP-Cloud enden. Kunden haben die Wahl zu mehr Offenheit und mehr Optionen“, beschreibt Albrecht Munz, verantwortlich für die Geschäftsentwicklung im SAP-Markt bei Hewlett Packard Enterprise (HPE), die Situation. Ein Blick in den Investitionsreport 2024 der Deutschsprachigen SAP-Anwendergruppe e.V. (DSAG) zeigt : 61 Prozent der Unternehmen lehnen RISE with SAP ab, was sogar ein Anstieg gegenüber 2022 bedeutet. Warum ist die Begeisterung für RISE with SAP im ERP-Bereich weiterhin gering? Munz kennt die offenen Fragen aus vielen Diskussionen: HPE ist einer der führenden Anbieter von Informationstechnologie und auf kundenzentrische Cloud- und Service-Strategien fokussiert. Mit HPE GreenLake für SAP profitieren Unternehmen von einer hybriden S/4HANA-Lösung, die Edge-Computing, On-Premise-Flexibilität und Hyperscaler-Skalierbarkeit kombiniert. Verantwortliche behalten so die IT-Kontrolle und Entscheidungsfreiheit. HPE GreenLake bietet vollständig verwaltete Hybrid-Cloud-Services für On-Premise- und Off-Premise-Umgebungen. HPE HPE GreenLake steht für die flexible Integration verschiedener Cloud Services. Mit HPE Private Cloud AI Stack und der HPE GreenLake Cloud Platform lassen sich erste produktive KI-Anwendungsfälle einfach und schnell umsetzen. Damit können Unternehmen ihre KI-Strategien unabhängig von anbieterspezifischen Restriktionen realisieren und die umfassenden Vorteile einer hybriden Cloud-Umgebung nutzen. Die global agierende Würth-Gruppe (40 Mrd. Euro Umsatz) bevorzugt on-premise für ihre großen SAP-Kernsysteme. Um flexibel zu bleiben, nutzt sie Off-Premise-Services. Mit HPE GreenLake hat Würth eine Lösung gefunden, die diese Anforderungen vereinen kann ( Video-Interview , Laufzeit 2:32 Min). Ausschlaggebend für Würth war die enorme Skalierbarkeit der Intel x86-basierten Plattform, also technisch-wirtschaftliche Argumente. Schließlich betreibt ein Konzern dieser Größenordnung ein SAP-BW-System mit rund 32 TB Speicher, das man nicht gerne aus der Hand gibt. EPL Ltd., ein globaler Verpackungsspezialist, entschied sich für HPE GreenLake für SAP, um Cloud-Agilität mit IT-Souveränität zu kombinieren ( Case Study ). ZUR CASE STUDY! HPE GreenLake für SAP überzeugt auch HPE-Partner für deren Kunden. Die Davidoff Öttinger Gruppe, unterstützt von Bechtle AG, integriert ihre globale Wertschöpfungskette – von Tabakfeldern bis zu Flagship-Stores – mit dieser Lösung. HPE GreenLake ermöglicht die Verwaltung des gesamten Systems als Cloud Experience im eigenen Rechenzentrum ( Case Study ). Unabhängig vom Betriebsmodell ist die Verfügbarkeit einer hochskalierbaren und standardisierten IT-Plattform Voraussetzung für einen wirtschaftlichen SAP-Betrieb. Alle Unternehmensgrößen sollten mit einer einheitlichen Technologiebasis abdeckbar sein. Mehrere Betriebssysteme wegen unterschiedlicher Skalierungs- und Sicherheitsanforderungen betreiben zu müssen, ist teuer und unflexibel. Diese x86-basierte Plattform wurde in den letzten Jahren im Rahmen von Co-Engineering-Projekten zwischen SAP, Intel und HPE entwickelt bzw. weiterentwickelt. Von der kleinsten SAP-Instanz bis hin zu den größten heute gebauten und SAP-zertifizierten Serversystemen sind somit alle Leistungsanforderungen ohne Systembrüche abdeckbar. Mit den SAP-Entscheidungen sollten Unternehmen ihre KI-Strategie und Hybrid-Cloud-Konzepte sowie deren Konsequenzen geklärt haben. Dies betrifft sowohl Plattformen als auch Bereitstellungsmodelle. Darüber hinaus sollte die Migration zu SAP S/4HANA auch in Zukunft Plattform- und Anbieterflexibilität gewährleisten. Treffen Sie fundierte SAP-Entscheidungen. HPE GreenLake zeigt Ihnen neue Möglichkeiten auf. Erkunden Sie unsere Lösungen online oder kontaktieren Sie Ihren persönlichen Ansprechpartner bei HPE. JETZT ENTDECKEN!",
    "source": "cio",
    "crawled_at": "2025-05-28T09:16:51.164094+00:00"
  },
  {
    "url": "https://www.cio.de/article/3990582/karriere-ohne-umweg-warum-vielfalt-neue-wege-braucht.html",
    "title": "Karriere ohne Umweg? Warum Vielfalt neue Wege braucht",
    "published": "2025-05-23T04:37:00+00:00",
    "author": "",
    "text": "Quereinsteiger mit unkonventionellen Lebensläufen können eine bereicherung für Teams und Unternehmen sein. Wenn es um die Repräsentation von Frauen in der Tech-Branche geht, ist noch einiges zu tun. Zu diesem Schluss kommt der Nash Squared Leadership Report. Demnach sind lediglich 14 Prozent der IT-Führungskräfte weiblich. In Deutschland lag 2023 der Anteil aller Frauen in leitenden Stellungen bei 28 Prozent. Im europäischen Vergleich liegen wir damit im unteren Drittel der EU-Mitgliedstaaten . Diese Zahlen stehen dabei nicht nur für soziale Ungerechtigkeit, sie bezeugen auch eine Verkennung von wirtschaftlichem Potential. Denn Unternehmen mit diversen Führungsteams erzielen nachweislich höhere Gewinne, wie die McKinsey-Studie „Diversity Matters even more “ belegt. Abonnieren Sie unserer CIO-Newsetter für mehr spannende Einschätzungen, Hintergründe und Analysen aus der CIO-Community. Die Untersuchung kam zu dem Ergebnis, dass europäische Unternehmen mit Frauen in Führungsteams eine bis zu 62 Prozent höhere Chance auf überdurchschnittlichen wirtschaftlichen Erfolg haben. Die Gründe dafür liegen in einer breiteren Perspektivenvielfalt und stärkeren Innovationskraft. Was können Unternehmen im Tech-Bereich also tun, um ihre Teams diverser aufzustellen? Die Standardvorstellung von beruflichem Erfolg ist oftmals, dass dieser einfach das Resultat eines klaren, aufeinander aufbauenden Karrierewegs ist – inklusive eines erkennbaren Plans. Doch das ist heute längst nicht mehr der Fall und war es vielleicht nie. Karrierewege sind nicht immer strikt geplant und verlaufen ganz sicherlich nicht linear. In einer sich schnell wandelnden Branche ist jedoch genau diese starre Sichtweise zunehmend ein Hindernis. Gerade Brüche im Lebenslauf eröffnen neue Chancen, fördern kreative Lösungen und stärken die Anpassungsfähigkeit. Dennoch besteht in vielen Unternehmen, gerade im Hinblick auf Führungspositionen, weiterhin der Druck, Karriere entlang eines vorhersehbaren Musters zu planen. In Bewerbungsgesprächen wird oft gefragt: „Wo sehen Sie sich in fünf Jahren?“ Ein solcher Erwartungsdruck kann jedoch dazu führen, dass Menschen Chancen nicht wahrnehmen, die außerhalb des ursprünglichen Plans liegen. Statt starrer Aufstiegsmodelle wäre es sinnvoller, Entwicklungskriterien neu zu definieren – etwa in den Bereichen Teamkultur, Flexibilität und Weiterbildungsangebote. Gerade im Tech-Bereich, in dem der Markt groß istund die Erwartungen an Innovation entsprechend hoch sind, lohnt es sich, auf unkonventionellen Wegen zu gehen. Wer beispielsweise eine Zeit lang Care-Arbeit übernommen hat – sei es die Betreuung von Kindern oder die Pflege von Angehörigen – entwickelt Fähigkeiten wie Multitasking, Projekt- und Zeitmanagement, Krisenbewältigung und emotionale Intelligenz, die in Führungspositionen essenziell sind. Ebenso erweitern Menschen mit einer fachfremden Ausbildung den Blickwinkel um wertvolle Perspektiven: Wer etwa aus der Geisteswissenschaft in den Tech-Bereich wechselt, bringt oft analytisches Denken, ausgeprägte Kommunikationsfähigkeiten und interdisziplinäre Problemlösungskompetenz mit. Diese Vielfalt an Erfahrungen stärkt Unternehmen nicht nur in ihrer Innovationskraft, sondern fördert auch eine Kultur, die Flexibilität und Lernbereitschaft als essenzielle Erfolgsfaktoren begreift. Gleichzeitig reicht es nicht, bei der Auswahl an Talenten nur auf den arbeitsbezogenen Lebenslauf zu achten. Unternehmen müssen Raum schaffen für nicht-geradlinigen Erfolg, damit Talente bleiben. Das heißt zum Beispiel, traditionelle Karrierestrukturen aufzuweichen für Menschen, die außerhalb des Berufs zusätzlich Verantwortung übernehmen – sei es für Familie, Angehörige oder ehrenamtliches Engagement. Die Tech-Branche verliert wertvolle Talente, wenn sie ausschließlich jene fördert, die einem durchgängigen, ununterbrochenen Karrierepfad folgen können und ihre Leben ausschließlich der Arbeit widmen. Entscheidend können auch Mentoring-Programme sein: Aus eigener Erfahrung zeigt sich, dass gerade junge Frauen in der männerdominierten Tech-Welt dazu neigen, Chancen weniger als solche zu erkennen. Mentoren und Mentorinnen können hier Vorbild sein oder ermutigen, aus der Komfortzone herauszutreten und alternative Karrierewege einzuschlagen. Zu diesem Zweck ist es aber auch wichtig, ehrlich zu kommunizieren. Empowerment gelingt nur durch realistische Vorbilder: Die Idee, dass alles gleichzeitig und perfekt machbar ist – Karriere, Familie, Selbstverwirklichung – ist eine Illusion, die junge Menschen unter Druck setzt. Deshalb sollten etwaige Coachs auch die Herausforderungen und Abstriche offen zur Sprache bringen. Dies schafft realistische Erwartungen und verhindert das Gefühl, ständig hinter den Erwartungen zurückzubleiben. Tech-Unternehmen können stark von diversen Teams profitieren. Doch um dies zu erreichen, müssen die richtigen Weichen gestellt werden: Unternehmen sollten nicht nur das Potential nicht-linearer Karrierewege erkennen, sie sollten auch Raum für nicht-linearen Erfolg schaffen. Karriere sollte weniger als Leiter und mehr als persönlicher Entwicklungsweg betrachtet werden, bei dem Umwege oder unerwartete Chancen eine große Rolle spielen. Erfolg lässt sich nicht immer mit klar definierten Schritten in Form von Titeln und Positionen verbinden. Offenheit für verschiedene Wege, transparente Unterstützung durch Mentoren und Mentorinnen und flexible Arbeitsmodelle sind entscheidend, um die Innovationskraft der Tech-Branche weiter zu stärken. (jd) Quereinsteiger mit unkonventionellen Lebensläufen können eine bereicherung für Teams und Unternehmen sein. Wenn es um die Repräsentation von Frauen in der Tech-Branche geht, ist noch einiges zu tun. Zu diesem Schluss kommt der Nash Squared Leadership Report. Demnach sind lediglich 14 Prozent der IT-Führungskräfte weiblich. In Deutschland lag 2023 der Anteil aller Frauen in leitenden Stellungen bei 28 Prozent. Im europäischen Vergleich liegen wir damit im unteren Drittel der EU-Mitgliedstaaten . Diese Zahlen stehen dabei nicht nur für soziale Ungerechtigkeit, sie bezeugen auch eine Verkennung von wirtschaftlichem Potential. Denn Unternehmen mit diversen Führungsteams erzielen nachweislich höhere Gewinne, wie die McKinsey-Studie „Diversity Matters even more “ belegt. Abonnieren Sie unserer CIO-Newsetter für mehr spannende Einschätzungen, Hintergründe und Analysen aus der CIO-Community. Die Untersuchung kam zu dem Ergebnis, dass europäische Unternehmen mit Frauen in Führungsteams eine bis zu 62 Prozent höhere Chance auf überdurchschnittlichen wirtschaftlichen Erfolg haben. Die Gründe dafür liegen in einer breiteren Perspektivenvielfalt und stärkeren Innovationskraft. Was können Unternehmen im Tech-Bereich also tun, um ihre Teams diverser aufzustellen? Die Standardvorstellung von beruflichem Erfolg ist oftmals, dass dieser einfach das Resultat eines klaren, aufeinander aufbauenden Karrierewegs ist – inklusive eines erkennbaren Plans. Doch das ist heute längst nicht mehr der Fall und war es vielleicht nie. Karrierewege sind nicht immer strikt geplant und verlaufen ganz sicherlich nicht linear. In einer sich schnell wandelnden Branche ist jedoch genau diese starre Sichtweise zunehmend ein Hindernis. Gerade Brüche im Lebenslauf eröffnen neue Chancen, fördern kreative Lösungen und stärken die Anpassungsfähigkeit. Dennoch besteht in vielen Unternehmen, gerade im Hinblick auf Führungspositionen, weiterhin der Druck, Karriere entlang eines vorhersehbaren Musters zu planen. In Bewerbungsgesprächen wird oft gefragt: „Wo sehen Sie sich in fünf Jahren?“ Ein solcher Erwartungsdruck kann jedoch dazu führen, dass Menschen Chancen nicht wahrnehmen, die außerhalb des ursprünglichen Plans liegen. Statt starrer Aufstiegsmodelle wäre es sinnvoller, Entwicklungskriterien neu zu definieren – etwa in den Bereichen Teamkultur, Flexibilität und Weiterbildungsangebote. Gerade im Tech-Bereich, in dem der Markt groß istund die Erwartungen an Innovation entsprechend hoch sind, lohnt es sich, auf unkonventionellen Wegen zu gehen. Wer beispielsweise eine Zeit lang Care-Arbeit übernommen hat – sei es die Betreuung von Kindern oder die Pflege von Angehörigen – entwickelt Fähigkeiten wie Multitasking, Projekt- und Zeitmanagement, Krisenbewältigung und emotionale Intelligenz, die in Führungspositionen essenziell sind. Ebenso erweitern Menschen mit einer fachfremden Ausbildung den Blickwinkel um wertvolle Perspektiven: Wer etwa aus der Geisteswissenschaft in den Tech-Bereich wechselt, bringt oft analytisches Denken, ausgeprägte Kommunikationsfähigkeiten und interdisziplinäre Problemlösungskompetenz mit. Diese Vielfalt an Erfahrungen stärkt Unternehmen nicht nur in ihrer Innovationskraft, sondern fördert auch eine Kultur, die Flexibilität und Lernbereitschaft als essenzielle Erfolgsfaktoren begreift. Gleichzeitig reicht es nicht, bei der Auswahl an Talenten nur auf den arbeitsbezogenen Lebenslauf zu achten. Unternehmen müssen Raum schaffen für nicht-geradlinigen Erfolg, damit Talente bleiben. Das heißt zum Beispiel, traditionelle Karrierestrukturen aufzuweichen für Menschen, die außerhalb des Berufs zusätzlich Verantwortung übernehmen – sei es für Familie, Angehörige oder ehrenamtliches Engagement. Die Tech-Branche verliert wertvolle Talente, wenn sie ausschließlich jene fördert, die einem durchgängigen, ununterbrochenen Karrierepfad folgen können und ihre Leben ausschließlich der Arbeit widmen. Entscheidend können auch Mentoring-Programme sein: Aus eigener Erfahrung zeigt sich, dass gerade junge Frauen in der männerdominierten Tech-Welt dazu neigen, Chancen weniger als solche zu erkennen. Mentoren und Mentorinnen können hier Vorbild sein oder ermutigen, aus der Komfortzone herauszutreten und alternative Karrierewege einzuschlagen. Zu diesem Zweck ist es aber auch wichtig, ehrlich zu kommunizieren. Empowerment gelingt nur durch realistische Vorbilder: Die Idee, dass alles gleichzeitig und perfekt machbar ist – Karriere, Familie, Selbstverwirklichung – ist eine Illusion, die junge Menschen unter Druck setzt. Deshalb sollten etwaige Coachs auch die Herausforderungen und Abstriche offen zur Sprache bringen. Dies schafft realistische Erwartungen und verhindert das Gefühl, ständig hinter den Erwartungen zurückzubleiben. Tech-Unternehmen können stark von diversen Teams profitieren. Doch um dies zu erreichen, müssen die richtigen Weichen gestellt werden: Unternehmen sollten nicht nur das Potential nicht-linearer Karrierewege erkennen, sie sollten auch Raum für nicht-linearen Erfolg schaffen. Karriere sollte weniger als Leiter und mehr als persönlicher Entwicklungsweg betrachtet werden, bei dem Umwege oder unerwartete Chancen eine große Rolle spielen. Erfolg lässt sich nicht immer mit klar definierten Schritten in Form von Titeln und Positionen verbinden. Offenheit für verschiedene Wege, transparente Unterstützung durch Mentoren und Mentorinnen und flexible Arbeitsmodelle sind entscheidend, um die Innovationskraft der Tech-Branche weiter zu stärken. (jd)",
    "source": "cio",
    "crawled_at": "2025-05-28T09:16:51.767174+00:00"
  },
  {
    "url": "https://www.cio.de/article/3689539/der-schluessel-zum-ki-erfolg.html",
    "title": "Was ist organisationales Lernen?",
    "published": "2025-05-23T06:10:01+00:00",
    "author": "",
    "text": "Zu den Prinzipien organisationalen Lernens gehört es, dass KI und Mensch zusammenarbeiten und sich gegenseitig ergänzen. So entsteht für das Unternehmen ein Mehrwert. Foto: Lightspring – shutterstock.com Die Erfolge in Projekten zu maschinellem Lernen oder künstlicher Intelligenz (KI) zeigen sich in vielen Unternehmen nur eingeschränkt, wenn überhaupt. Experten glauben den Grund zu kennen: Die Betriebe versäumen es, ihre Erfahrungen über die gesamte Organisation hinweg zu teilen und für weitere Vorhaben zu nutzen. So gelingt es vielleicht, mithilfe von KI eine manuelle Aufgabe zu automatisieren oder bessere Vorhersagen für einzelne Abläufe zu treffen. Doch die wenigsten schaffen es, Erfahrungen aus ihren KI-Projekten in der Breite zu nutzen, um sich nach und nach zu transformieren. So führen Unternehmen nur in Ausnahmefällen formale Strukturen ein, um ihre KI-Learnings systematisch zu erfassen und für andere bereitzustellen. Einer aktuellen Studie von MIT Sloan Management Review und Boston Consulting Group zufolge zogen im vergangenen Jahr nur elf Prozent der befragten Betriebe einen signifikanten Nutzen aus ihren KI-Initiativen. Ein gern genommenes Beispiel für ungenutzte Chancen ist die Bewertung von Kreditanträgen in der Finanzwirtschaft, die durch maschinelles Lernen deutlich optimiert werden könnte. Die Kriterien sind festlegbar und lassen sich algorithmisch abbilden, die Zahl der Kreditsachbearbeiter könnte gesenkt werden. Dort die Kosten zu reduzieren, ist natürlich ein sensibles Thema. Die Mitarbeiter werden zögern, daran mitzuarbeiten und sich so potenziell um den eigenen Job zu bringen. Untätig zu bleiben ist aber für Banken mittelfristig keine Option, denn dort geht es um viel mehr als die Verbesserung eines Detailprozesses. Aus den Daten rund um Kreditanträge lassen sich viele Informationen gewinnen, die für das Geschäft insgesamt relevant sind. Eine Bank kann zum Beispiel Kundengruppen besser segmentieren und unterversorgte Bereiche aufspüren. Dort ließen sich Kunden dann mit besonderen Angeboten ködern, was zu einer Ausweitung des Geschäfts insgesamt führen würde. Oder die Bank könnte die Daten nutzen, um mehr über die Beweggründe zu erfahren, warum bestimmte Menschen keinen Kredit aufnehmen wollen. “Möglichweise fürchten ja einige, dass allein schon das Bemühen darum auf Kosten ihrer Kreditwürdigkeit gehen könnte”, sagt Sam Ransbotham, Professor für Informationssysteme an der Carroll School of Management des Boston College und einer der Autoren der MIT-Sloan-Studie. Das ließe sich ändern, indem den Interessenten eine risikofreie Prüfung zugesichert würde, die sich garantiert nicht auf ihre Kreditwürdigkeit auswirkt. “Es geht also nicht um eine platte Automatisierung des gewohnten Kreditprozesses, sondern um dessen grundlegende Erneuerung”, sagt Ransbotham. KI würde also den Einstieg in eine neue, vielversprechende Ära der Kreditwürdigkeitsprüfung weisen, Erfolge könnten dem Unternehmen signifikantes Wachstumspotenzial bescheren. Mit hoher Wahrscheinlichkeit würde sich dann zeigen, dass die Mitarbeiter – Veränderungsfähigkeit und -bereitschaft vorausgesetzt – die neue Technologie nutzen und sich damit viel interessantere berufliche Perspektiven eröffnen könnten. Ransbotham sieht daher CIOs nicht so sehr in der Pflicht, bereits bestehende Abläufe effizienter zu gestalten. KI und ML böten ihnen vielmehr die Chance, Dinge anders und besser zu erledigen, der Hebel für zusätzliche Wertschöpfung sei groß. In der Studie von MIT Sloan und Boston Consulting, für die 3.000 Manager in aller Welt befragt wurden, wird deutlich, unter welchen Umständen die erfolgreichen elf Prozent “signifikante finanzielle Vorteile” durch KI erzielt haben. Dort wurde die Technik nicht für simple Automatisierung herangezogen, sondern in die übergeordnete Geschäftsstrategie eingebettet. Diese Unternehmen haben Wege gefunden, um Mensch und KI zusammenzuführen, so dass sich Mitarbeiter und Technik optimal ergänzen. “Wir haben herausgefunden: Wenn sich Unternehmen mit organisationalem Lernen beschäftigen und entsprechend ausrichten, steigt die Wahrscheinlichkeit um ein Vielfaches, dass sie zu diesen elf Prozent der Erfolgreichen gehören”, sagt Ransbotham. Ein imposantes Beispiel für den Nutzen von KI liefert derzeit der Pharmazie- und Konsumgüterkonzern Johnson & Johnson, der Ende Januar seinen Impfstoff für COVID-19 ankündigte. Das Vakzin kann mit nur einer Impfung verabreicht werden und muss anders als die Alternative von Pfizer und Biontech nicht extrem heruntergekühlt werden. Laut Johnson & Johnson unterbindet der Impfstoff zwar nur in 66 Prozent der Fälle Infektionen, aber er verhindert zu 85 Prozent schwere und zu nahezu 100 Prozent tödliche Verläufe. CIO Jim Swanson sagt, den Impfstoff hätte es ohne KI nicht gegeben. Vor acht oder neun Monaten habe Johnson & Johnson noch zwei Wochen dafür gebraucht, eine Charge irgendeines Impfstoffs herzustellen, sagt er. Jetzt würden zwei Chargen pro Woche fertig, eine vierfache Verbesserung also. “Wir haben KI für jedes Detail eingesetzt, das reichte vom Fermentationsprozess bis hin zu den betriebswirtschaftlichen Kalkulationen”, sagt er. “All die analytischen Details summieren sich am Ende zu unserem Ergebnis.” Vor allem die verbesserte Zusammenarbeit über mehrere Fachbereiche hinweg habe den Prozess beschleunigt, berichtet Swanson. Die Data Scientists bei Johnson & Johnson beherrschten nicht nur Tools und Technik, sondern immer auch fachliche Aspekte im Forschungsbereich oder der Supply Chain . Doch die schlagzeilenträchtige Impfstoffentwicklung ist längst nicht alles. Johnson & Johnson nutzt KI inzwischen generell dazu, neue Geschäftsmöglichkeiten zu erschließen. Lösungen auf der Basis von maschinellem Lernen helfen beispielsweise Augenärzten, anhand von Netzhaut-Scans Glaukome zu finden. Zudem nutzt der Pharmariese KI für Operationsroboter in der Chirurgie: “Man hat eine viel höhere Präzision und bessere Verfahren”, lautet das Fazit des CIO. Auch die Abläufe vor und nach einem Eingriff ließen sich verbessern: “Man kann KI so einsetzen, dass Patienten die exakt richtige Behandlung bekommen, so dass ihre Genesung bestmöglich unterstützt wird.” Auch für Hautpflegemittel der Produktreihe “Avena” setzt der Konzern auf KI. Kunden fotografieren ihre Haut und erhalten anhand dessen eine personalisierte Produktempfehlung. Johnson & Johnson nutzt diese Bilder im Sinne des organisationalen Lernens auch, um generell herauszufinden, welche Hautprobleme bestimmte Menschengruppen haben. “Dieses Daten-Feedback von Seiten der Kunden hilft uns, die besseren Produkte zu kreieren”, sagt der CIO. Natürlich ist das nur möglich, wenn die vorhandene Daten-Infrastruktur Privacy und Sicherheit garantiert – die Basisvoraussetzung dafür, dass bei Johnson & Johnson überhaupt viele verschiedene Menschen mit diesen Daten arbeiten können. “Wenn man Daten nicht sicher teilen kann, kann man sie gar nicht teilen”, postuliert Swanson. Oft müsse man sie anonymisieren, um sich auf bestimmte Phänotypen zu konzentrieren – zum Beispiel auf Altersgruppen mit bestimmten Erkrankungen. Der letzte und wichtigste Teil der organisationalen Lernstrategie von Johnson & Johnson betrifft den Aufbau von kollektivem Know-how. “Wenn man sich mit der Nutzung von Daten nicht auskennt, kommt man nicht weiter”, sagt Swanson. Wissenschaftler aus Forschung und Entwicklung, kaufmännisches Personal und Supply-Chain-Professionals würden sich daher gleichermaßen damit beschäftigen. “Wir haben einen Data-Science-Beirat gegründet, den ich gemeinsam mit unserem Forschungschef leite. Wir beide haben entschieden, KI dezentral in unseren Geschäftsbereichen auszurollen.” Noch wichtiger sei, dass die KI-Strategie von der Konzernspitze gestützt werde. “Wir sind uns einig darin, dass wir Technologie im Allgemeinen und KI im Besonderen zum Kern unseres Unternehmens machen wollen. Das ist nichts, was Sie nebenbei machen können”, sagt Swanson. Anand Rao, Partner und Global AI Leader bei PricewaterhouseCoopers, hält das Vorgehen für vorbildlich. Johnson & Johnson gehöre zu den Konzernen, die KI im gesamten Unternehmen so verankern würden, dass sie von möglichst vielen Mitarbeitern genutzt werde – auch von solchen, die keinen technischen oder analytischen Hintergrund hätten. “Unternehmen werden mit KI keinen RoI erzielen, wenn ihre Leute nicht gut geschult, gecoacht und gemanagt werden”, sagt Rao. “Ziel muss es sein, dass nicht nur Einzelpersonen oder Kleingruppen, sondern die gesamte Organisation lernt.” Wichtig sei es Mitarbeiter zu haben, die “mehrsprachig” in dem Sinne sind, dass sie die geschäftliche Seite genauso wie die Software und die KI-Algorithmen verstehen. Alternativ dazu gebe es Sinn, ein Team so zusammenzustellen, dass beide Perspektiven eingebracht würden. Das sei eine große Herausforderung, so Rao. “Es ist schwierig, Menschen mit unterschiedlichen Denkweisen dazu zu bringen zusammenzuarbeiten.” Ein anderes Unternehmen, das sich das Prinzip des organisationalen Lernens zu Herzen nimmt, ist Genpact, ein globales Professional-Services-Unternehmen. Seine Wurzeln liegen im General-Electrics-(GE-)Konzern, der Genpact 2005 mit etwa 100.000 Mitarbeitern und einem Jahresumsatz von 3,5 Milliarden US-Dollar ausgegründet hatte. Als die Pandemie zuschlug, brachen Genpacts Einnahmen weg und das Unternehmen hätte eigentlich Tausende Mitarbeiter entlassen müssen, da viele Kunden von der Krise stark in Mitleidenschaft gezogen worden waren, berichtet Gianni Giacomelli, Chief Innovation Officer des Unternehmens. “Stattdessen waren wir in der Lage, sehr schnell auf neue Marktanforderungen zu reagieren und unser Personal in kürzester Zeit umzuschulen”, sagt Giacomelli, der im Unternehmen auch für Mitarbeitertraining und -entwicklung zuständig ist. “Manchmal dauerte es nur ein paar Wochen, um sie in neue Jobs zu bringen. Dadurch haben wir es tatsächlich geschafft, im Vergleich zu unseren Mitbewerbern zu wachsen, sogar während COVID-19.” Die Umschulung wurde durch gezielten Technologie-Einsatz möglich. Genpact nutzte Process Mining, Natural Language Processing (NLP) und Netzwerkanalysen, um herauszufinden wie Dinge im Unternehmen tatsächlich erledigt werden und, wer über welche Fähigkeiten und welches Fachwissen verfügt und wo es Ungereimtheiten in den Abläufen gibt. Die so gewonnenen Informationen halfen dabei, das Personal besser einzusetzen. Sobald ein Mitarbeiter eine andere neue Rolle übernommen hatte, ermöglichten KI-Systeme ihm eine schnelle Einarbeitung, indem sie den Prozess für die jeweiligen Aufgaben beschrieben oder die jeweilige Person mit relevanten Experten verbanden. “Dadurch konnten wir viel schneller auf die neuen Bedingungen reagieren, mit denen wir aufgrund der Pandemie konfrontiert waren”, sagt Giacomelli. Mit den neuen Technologien bekommt Genpact in den Griff, was viele Jahre lang nicht nur hier, sondern auch in vielen anderen Unternehmen schiefging: das Wissensmanagement. Vor fünf Jahren lag die Misserfolgsrate entsprechender Programme laut dem Knowledge Management Institute bei etwa 50 Prozent. Aber aufgrund erheblicher Verbesserungen bei KI-Technologien im allgemeinen und NLP im Besonderen hat sich die Situation dramatisch verändert. “In den letzten zwei, drei Jahren ist die Qualität der von Maschinen selbst erstellten Ontologien viel besser geworden”, sagt Giacomelli. “Was man zurückbekommt, ist viel präziser.” KI ist eine große Hilfe, um organisationales Wissen in Dokumenten, Geschäftsprozessen und auch in den Köpfen aufzustöbern. Bei Genpact ist das nicht allein die Domäne der IT-Abteilung. Laut Kathleen Featheringham, Direktorin für KI-Strategie und Training bei Booz Allen Hamilton, entscheidet sich in der Qualität des Rollouts, ob es einen relevanten RoI gibt oder nicht. “KI ist die vierte industrielle Revolution”, sagt sie. “Sie verändert das Spiel grundlegend. Es geht hier nicht um ein IT-Problem, alle Rollen entwickeln sich weiter.” Die KI-gestützte Unternehmenstransformation erfordere eine Neubewertung der Leistungsziele, des Mitarbeitertrainingszielen und auch der gesamten Vision. Sei das nicht der Fall und es gebe keinen Konsens über das Vorgehen, könnten das die Mitarbeiter sehr übelnehmen, warnt Featheringham. Zu den Prinzipien organisationalen Lernens gehört es, dass KI und Mensch zusammenarbeiten und sich gegenseitig ergänzen. “Gelingt eine Kooperation, in der Maschinen tun, was sie gut können, und Menschen ihre Intuition und ihr Wissen einbringen, wird man einen großen geschäftlichen Nutzen sehen”, ist Judith Hurwitz überzeugt, Präsidentin und Gründerin von Hurwitz and Associates sowie Autorin von inzwischen zehn Büchern zu Themen wie Führung, Technologie und Analytics. Was ist Value Stream Mapping? Foto: 3rdtimeluckystudio – shutterstock.com Value Stream Mapping ist eine Lean-Management-Technik. Das sollten Sie über die Wertstromanalyse wissen. Was ist IT Business Alignment? Foto: fotogestoeber – shutterstock.com IT-Investitionen müssen zur Unternehmensentwicklung beitragen. IT Alignment bezeichnet dazu die gegenseitige Ausrichtung von Geschäfts- und IT-Stategien. Was sind Serious Games? Foto: TU Köln Screenshot: Welten der Werkstoffe Serious Games sollen Lernen durch Videospiele attraktiver machen. erfahren Sie, wie es funktioniert und welche Ansätze dahinterstecken. Was ist Intelligent Wargaming? Foto: Gorodenkoff – shutterstock.com Intelligent Wargaming nutzt Echtzeitanalysen und Techniken wie Machine Learning zur Unternehmenssteuerung. Auch der CIO ist dabei gefordert. Was ist Agilität? Foto: Andrey_Popov – shutterstock.com Der Begriff Agilität beschreibt sowohl ein methodisches Vorgehen als auch die Gestaltung der Firmenkultur. Ein Überblick. Was sind technische Schulden? Foto: hatoriz – shutterstock.com Technical Debt – zu Deutsch technische Schulden – kann die Innovationskraft und den monetären Erfolg Ihres Unternehmens gefährden. Was ist Outstaffing? Foto: Viesinsh – shutterstock.com Die Outsourcing-Variante Outstaffing stellt einen neuen Weg für die strategische Entwicklung von Unternehmenssoftware dar. Das müssen Sie wissen. Was ist Environmental Social Governance? Foto: Mameraman – shutterstock.com Ab 2023 müssen sich viele Unternehmen in der EU an ESG-Kriterien halten. Wir erklären die Hintergründe und Richtlinien. Was ist Transformational Leadership? Foto: nullplus – shutterstock.com Transformational Leadership fördert Eigenverantwortung und inspiriert Mitarbeiter, Veränderungen und Innovationen im Unternehmen voranzutreiben. Was ist Change Management? Foto: Alex from the Rock – shutterstock.com Was versteht man unter Change Management und wie unterscheidet es sich zur Organisationsentwicklung? Welche Methoden es im Veränderungsmanagement gibt, lesen Sie hier. Was ist ein Citizen Developer? Foto: NDAB Creativity – shutterstock.com Citizen Developer nehmen bei der digitalen Transformation von Unternehmen eine wichtige Rolle ein. Was man darunter versteht, lesen Sie hier. Was ist Operations Management? Foto: Pixparts – shutterstock.com In Zeiten der Digitalisierung kann es für ein Unternehmen entscheidend sein, wie gut es Business- und IT-Prozesse in Einklang bringt. Zwei Wege führen zum Ziel. Was ist Design Thinking? Foto: REDPIXEL.PL – shutterstock.com Design Thinking hilft Unternehmen, kundenorientierte Ideen und Ansätze zu kreieren. Die Methode eignet sich auch für sehr komplexe Probleme. Was ist Servant Leadership? Foto: Jacob Lund – shutterstock.com Servant Leader dienen ihrem Umfeld und helfen anderen dabei, zu wachsen. Dieses Führungsverständnis ist nicht nur im agilen Umfeld beliebt. Projektmanagement-Methoden im Vergleich Foto: NicoElNino – shutterstock.com Damit ein IT-Projekt nicht scheitert, sollte die richtige Methode bereits in Vorfeld gewählt werden. Eine Erklärung verschiedener Methoden mit Anwendungsfällen sowie eine Tabelle, die durch den Auswahlprozess leitet. Was ist Business Intelligence? Foto: SFIO CRACHO – shutterstock.com Business Intelligence (BI) verwandelt Daten in Insights und hilft bei der Entscheidungsfindung im Unternehmen. Wir sagen Ihnen, was Sie zum Thema wissen müssen. Was ist Contract Lifecycle Management? Foto: fizkes – shutterstock.com Erfahren Sie, was Contract Lifecycle Management (CLM) ist und welche Unternehmensbereiche davon profitieren können. Was ist Arbeitnehmerüberlassung? Foto: Alexander Supertramp – shutterstock.com 27.10.2022 Von Matthias RuffMatthias Ruff (Autor) Auf Arbeitnehmerüberlassung greifen Unternehmen zurück, damit Scheinselbständigkeit kein Thema wird. Das sollten Sie beachten. Was ist ein Statement of Work? Foto: wutzkohphoto – shutterstock.com Das Statement of Work (SoW) sorgt in der Projektarbeit für Klarheit. Warum das Dokument wichtig ist und was man beim Verfassen beachten sollte. Was ist Compliance? Foto: Arcady – shutterstock.com Was versteht man unter Compliance? Welche Verfahren und Anforderungen gibt es an Unternehmen? Wie die Einhaltung der Compliance verbessert werden kann, lesen Sie hier. Was ist Controlling? Foto: Roman Samborskyi – shutterstock.com Lesen Sie, was sich hinter dem Begriff Controlling verbirgt, welche Aufgaben ein Controller wahrnimmt, worauf Unternehmen achten sollten und wie die Zukunft des Controllings aussieht. Was ist ein kooperativer Führungsstil? Foto: NDAB Creativity – shutterstock.com Wer kooperativ führt, kommuniziert mit seinen Mitarbeitern auf Augenhöhe und teilt Verantwortung. Dieser Führungsstil hat in Corona-Zeiten Auftrieb erhalten. Was ist Total Quality Management? Foto: greenbutterfly – shutterstock.com Total Quality Management – TQM – unterstützt Unternehmen dabei, sich auf die kontinuierliche Verbesserung von Prozessen und Produkten zu fokussieren. Was ist New Work? Foto: Jacob Lund – shutterstock.com Die Corona-Pandemie hat das Thema New Work befeuert. Doch das Konzept umfasst viel mehr als flexibles Arbeiten und neue Büroräume mit Kickertisch. Was macht ein Solution Architect? Foto: Kutlayev Dmitry – shutterstock.com Der Solution Architect nimmt eine entscheidende Rolle im Unternehmen ein. Lesen Sie, warum. Was ist Gamification? Foto: Pixel-Shot – shutterstock.com Was hat das “Moorhuhn” mit einer Whisky-Marke zu tun? Schon Ende des vergangenen Jahrtausends nutzten Unternehmen spielerische Elemente für ihre Zwecke. Inzwischen hat Gamification Einzug in den Alltag gehalten. Was ist ein Business-Analyst? Foto: SFIO CRACHO – shutterstock.com Mit Datenanalysen unterstützen Business-Analysten Unternehmen dabei, Prozesse, Produkte, Services und Software zu verbessern. Was ist GitOps? Foto: iunewind – shutterstock.com GitOps wendet die Methoden von DevOps und CI/CD für die Bereitstellung von IT-Infrastruktur an. Das müssen Sie zum Thema wissen. Was ist Data Literacy? Foto: Khosro – shutterstock.com Mit Daten umzugehen, sie auszuwerten, zu interpretieren und als Entscheidungsgrundlage zu nutzen, bedarf einer entscheidenden Kernkompetenz: Data Literacy. Was ist Laterale Führung? Foto: Altrendo Images – shutterstock.com Laterale Führung bezeichnet einen unkonventionellen Führungsstil. Klassische, hierarchisch geprägte Führungsinstrumente stehen dabei nicht zur Verfügung. Was ist ITIL? Foto: RoseRodionova – shutterstock.com Das Regelwerk ITIL beschreibt Best Practices für die Bereitstellung von IT-Services. Es soll zu einer stabilen IT-Umgebung beitragen, die Wachstum, Skalierbarkeit und Change ermöglicht. Was ist Workforce Management? Foto: Blue Planet Studio – shutterstock.com Workforce Management ist über die Jahre zu einem komplexen Framework für Personalverwaltung und Budgetierung avanciert. Das sollten Sie zum Thema wissen. Was ist eine Prozessorganisation? Foto: NicoElNino – shutterstock.com So bauen Sie eine Prozessorganisation in fünf Schritten auf. Von der Definition der Rollen bis zur Verknüpfung mit der IT-Organisation. Eine Tabelle zeigt den Ablauf an einem Beispiel. Was ist organisationales Lernen? Foto: Lightspring – shutterstock.com Viele Unternehmen setzen im Kleinen auf KI, versäumen es aber, formale Prozesse einzuführen, damit die gesamte Organisation lernen und sich schneller transformieren kann. Zu den Prinzipien organisationalen Lernens gehört es, dass KI und Mensch zusammenarbeiten und sich gegenseitig ergänzen. So entsteht für das Unternehmen ein Mehrwert. Foto: Lightspring – shutterstock.com Die Erfolge in Projekten zu maschinellem Lernen oder künstlicher Intelligenz (KI) zeigen sich in vielen Unternehmen nur eingeschränkt, wenn überhaupt. Experten glauben den Grund zu kennen: Die Betriebe versäumen es, ihre Erfahrungen über die gesamte Organisation hinweg zu teilen und für weitere Vorhaben zu nutzen. So gelingt es vielleicht, mithilfe von KI eine manuelle Aufgabe zu automatisieren oder bessere Vorhersagen für einzelne Abläufe zu treffen. Doch die wenigsten schaffen es, Erfahrungen aus ihren KI-Projekten in der Breite zu nutzen, um sich nach und nach zu transformieren. So führen Unternehmen nur in Ausnahmefällen formale Strukturen ein, um ihre KI-Learnings systematisch zu erfassen und für andere bereitzustellen. Einer aktuellen Studie von MIT Sloan Management Review und Boston Consulting Group zufolge zogen im vergangenen Jahr nur elf Prozent der befragten Betriebe einen signifikanten Nutzen aus ihren KI-Initiativen. Ein gern genommenes Beispiel für ungenutzte Chancen ist die Bewertung von Kreditanträgen in der Finanzwirtschaft, die durch maschinelles Lernen deutlich optimiert werden könnte. Die Kriterien sind festlegbar und lassen sich algorithmisch abbilden, die Zahl der Kreditsachbearbeiter könnte gesenkt werden. Dort die Kosten zu reduzieren, ist natürlich ein sensibles Thema. Die Mitarbeiter werden zögern, daran mitzuarbeiten und sich so potenziell um den eigenen Job zu bringen. Untätig zu bleiben ist aber für Banken mittelfristig keine Option, denn dort geht es um viel mehr als die Verbesserung eines Detailprozesses. Aus den Daten rund um Kreditanträge lassen sich viele Informationen gewinnen, die für das Geschäft insgesamt relevant sind. Eine Bank kann zum Beispiel Kundengruppen besser segmentieren und unterversorgte Bereiche aufspüren. Dort ließen sich Kunden dann mit besonderen Angeboten ködern, was zu einer Ausweitung des Geschäfts insgesamt führen würde. Oder die Bank könnte die Daten nutzen, um mehr über die Beweggründe zu erfahren, warum bestimmte Menschen keinen Kredit aufnehmen wollen. “Möglichweise fürchten ja einige, dass allein schon das Bemühen darum auf Kosten ihrer Kreditwürdigkeit gehen könnte”, sagt Sam Ransbotham, Professor für Informationssysteme an der Carroll School of Management des Boston College und einer der Autoren der MIT-Sloan-Studie. Das ließe sich ändern, indem den Interessenten eine risikofreie Prüfung zugesichert würde, die sich garantiert nicht auf ihre Kreditwürdigkeit auswirkt. “Es geht also nicht um eine platte Automatisierung des gewohnten Kreditprozesses, sondern um dessen grundlegende Erneuerung”, sagt Ransbotham. KI würde also den Einstieg in eine neue, vielversprechende Ära der Kreditwürdigkeitsprüfung weisen, Erfolge könnten dem Unternehmen signifikantes Wachstumspotenzial bescheren. Mit hoher Wahrscheinlichkeit würde sich dann zeigen, dass die Mitarbeiter – Veränderungsfähigkeit und -bereitschaft vorausgesetzt – die neue Technologie nutzen und sich damit viel interessantere berufliche Perspektiven eröffnen könnten. Ransbotham sieht daher CIOs nicht so sehr in der Pflicht, bereits bestehende Abläufe effizienter zu gestalten. KI und ML böten ihnen vielmehr die Chance, Dinge anders und besser zu erledigen, der Hebel für zusätzliche Wertschöpfung sei groß. In der Studie von MIT Sloan und Boston Consulting, für die 3.000 Manager in aller Welt befragt wurden, wird deutlich, unter welchen Umständen die erfolgreichen elf Prozent “signifikante finanzielle Vorteile” durch KI erzielt haben. Dort wurde die Technik nicht für simple Automatisierung herangezogen, sondern in die übergeordnete Geschäftsstrategie eingebettet. Diese Unternehmen haben Wege gefunden, um Mensch und KI zusammenzuführen, so dass sich Mitarbeiter und Technik optimal ergänzen. “Wir haben herausgefunden: Wenn sich Unternehmen mit organisationalem Lernen beschäftigen und entsprechend ausrichten, steigt die Wahrscheinlichkeit um ein Vielfaches, dass sie zu diesen elf Prozent der Erfolgreichen gehören”, sagt Ransbotham. Ein imposantes Beispiel für den Nutzen von KI liefert derzeit der Pharmazie- und Konsumgüterkonzern Johnson & Johnson, der Ende Januar seinen Impfstoff für COVID-19 ankündigte. Das Vakzin kann mit nur einer Impfung verabreicht werden und muss anders als die Alternative von Pfizer und Biontech nicht extrem heruntergekühlt werden. Laut Johnson & Johnson unterbindet der Impfstoff zwar nur in 66 Prozent der Fälle Infektionen, aber er verhindert zu 85 Prozent schwere und zu nahezu 100 Prozent tödliche Verläufe. CIO Jim Swanson sagt, den Impfstoff hätte es ohne KI nicht gegeben. Vor acht oder neun Monaten habe Johnson & Johnson noch zwei Wochen dafür gebraucht, eine Charge irgendeines Impfstoffs herzustellen, sagt er. Jetzt würden zwei Chargen pro Woche fertig, eine vierfache Verbesserung also. “Wir haben KI für jedes Detail eingesetzt, das reichte vom Fermentationsprozess bis hin zu den betriebswirtschaftlichen Kalkulationen”, sagt er. “All die analytischen Details summieren sich am Ende zu unserem Ergebnis.” Vor allem die verbesserte Zusammenarbeit über mehrere Fachbereiche hinweg habe den Prozess beschleunigt, berichtet Swanson. Die Data Scientists bei Johnson & Johnson beherrschten nicht nur Tools und Technik, sondern immer auch fachliche Aspekte im Forschungsbereich oder der Supply Chain . Doch die schlagzeilenträchtige Impfstoffentwicklung ist längst nicht alles. Johnson & Johnson nutzt KI inzwischen generell dazu, neue Geschäftsmöglichkeiten zu erschließen. Lösungen auf der Basis von maschinellem Lernen helfen beispielsweise Augenärzten, anhand von Netzhaut-Scans Glaukome zu finden. Zudem nutzt der Pharmariese KI für Operationsroboter in der Chirurgie: “Man hat eine viel höhere Präzision und bessere Verfahren”, lautet das Fazit des CIO. Auch die Abläufe vor und nach einem Eingriff ließen sich verbessern: “Man kann KI so einsetzen, dass Patienten die exakt richtige Behandlung bekommen, so dass ihre Genesung bestmöglich unterstützt wird.” Auch für Hautpflegemittel der Produktreihe “Avena” setzt der Konzern auf KI. Kunden fotografieren ihre Haut und erhalten anhand dessen eine personalisierte Produktempfehlung. Johnson & Johnson nutzt diese Bilder im Sinne des organisationalen Lernens auch, um generell herauszufinden, welche Hautprobleme bestimmte Menschengruppen haben. “Dieses Daten-Feedback von Seiten der Kunden hilft uns, die besseren Produkte zu kreieren”, sagt der CIO. Natürlich ist das nur möglich, wenn die vorhandene Daten-Infrastruktur Privacy und Sicherheit garantiert – die Basisvoraussetzung dafür, dass bei Johnson & Johnson überhaupt viele verschiedene Menschen mit diesen Daten arbeiten können. “Wenn man Daten nicht sicher teilen kann, kann man sie gar nicht teilen”, postuliert Swanson. Oft müsse man sie anonymisieren, um sich auf bestimmte Phänotypen zu konzentrieren – zum Beispiel auf Altersgruppen mit bestimmten Erkrankungen. Der letzte und wichtigste Teil der organisationalen Lernstrategie von Johnson & Johnson betrifft den Aufbau von kollektivem Know-how. “Wenn man sich mit der Nutzung von Daten nicht auskennt, kommt man nicht weiter”, sagt Swanson. Wissenschaftler aus Forschung und Entwicklung, kaufmännisches Personal und Supply-Chain-Professionals würden sich daher gleichermaßen damit beschäftigen. “Wir haben einen Data-Science-Beirat gegründet, den ich gemeinsam mit unserem Forschungschef leite. Wir beide haben entschieden, KI dezentral in unseren Geschäftsbereichen auszurollen.” Noch wichtiger sei, dass die KI-Strategie von der Konzernspitze gestützt werde. “Wir sind uns einig darin, dass wir Technologie im Allgemeinen und KI im Besonderen zum Kern unseres Unternehmens machen wollen. Das ist nichts, was Sie nebenbei machen können”, sagt Swanson. Anand Rao, Partner und Global AI Leader bei PricewaterhouseCoopers, hält das Vorgehen für vorbildlich. Johnson & Johnson gehöre zu den Konzernen, die KI im gesamten Unternehmen so verankern würden, dass sie von möglichst vielen Mitarbeitern genutzt werde – auch von solchen, die keinen technischen oder analytischen Hintergrund hätten. “Unternehmen werden mit KI keinen RoI erzielen, wenn ihre Leute nicht gut geschult, gecoacht und gemanagt werden”, sagt Rao. “Ziel muss es sein, dass nicht nur Einzelpersonen oder Kleingruppen, sondern die gesamte Organisation lernt.” Wichtig sei es Mitarbeiter zu haben, die “mehrsprachig” in dem Sinne sind, dass sie die geschäftliche Seite genauso wie die Software und die KI-Algorithmen verstehen. Alternativ dazu gebe es Sinn, ein Team so zusammenzustellen, dass beide Perspektiven eingebracht würden. Das sei eine große Herausforderung, so Rao. “Es ist schwierig, Menschen mit unterschiedlichen Denkweisen dazu zu bringen zusammenzuarbeiten.” Ein anderes Unternehmen, das sich das Prinzip des organisationalen Lernens zu Herzen nimmt, ist Genpact, ein globales Professional-Services-Unternehmen. Seine Wurzeln liegen im General-Electrics-(GE-)Konzern, der Genpact 2005 mit etwa 100.000 Mitarbeitern und einem Jahresumsatz von 3,5 Milliarden US-Dollar ausgegründet hatte. Als die Pandemie zuschlug, brachen Genpacts Einnahmen weg und das Unternehmen hätte eigentlich Tausende Mitarbeiter entlassen müssen, da viele Kunden von der Krise stark in Mitleidenschaft gezogen worden waren, berichtet Gianni Giacomelli, Chief Innovation Officer des Unternehmens. “Stattdessen waren wir in der Lage, sehr schnell auf neue Marktanforderungen zu reagieren und unser Personal in kürzester Zeit umzuschulen”, sagt Giacomelli, der im Unternehmen auch für Mitarbeitertraining und -entwicklung zuständig ist. “Manchmal dauerte es nur ein paar Wochen, um sie in neue Jobs zu bringen. Dadurch haben wir es tatsächlich geschafft, im Vergleich zu unseren Mitbewerbern zu wachsen, sogar während COVID-19.” Die Umschulung wurde durch gezielten Technologie-Einsatz möglich. Genpact nutzte Process Mining, Natural Language Processing (NLP) und Netzwerkanalysen, um herauszufinden wie Dinge im Unternehmen tatsächlich erledigt werden und, wer über welche Fähigkeiten und welches Fachwissen verfügt und wo es Ungereimtheiten in den Abläufen gibt. Die so gewonnenen Informationen halfen dabei, das Personal besser einzusetzen. Sobald ein Mitarbeiter eine andere neue Rolle übernommen hatte, ermöglichten KI-Systeme ihm eine schnelle Einarbeitung, indem sie den Prozess für die jeweiligen Aufgaben beschrieben oder die jeweilige Person mit relevanten Experten verbanden. “Dadurch konnten wir viel schneller auf die neuen Bedingungen reagieren, mit denen wir aufgrund der Pandemie konfrontiert waren”, sagt Giacomelli. Mit den neuen Technologien bekommt Genpact in den Griff, was viele Jahre lang nicht nur hier, sondern auch in vielen anderen Unternehmen schiefging: das Wissensmanagement. Vor fünf Jahren lag die Misserfolgsrate entsprechender Programme laut dem Knowledge Management Institute bei etwa 50 Prozent. Aber aufgrund erheblicher Verbesserungen bei KI-Technologien im allgemeinen und NLP im Besonderen hat sich die Situation dramatisch verändert. “In den letzten zwei, drei Jahren ist die Qualität der von Maschinen selbst erstellten Ontologien viel besser geworden”, sagt Giacomelli. “Was man zurückbekommt, ist viel präziser.” KI ist eine große Hilfe, um organisationales Wissen in Dokumenten, Geschäftsprozessen und auch in den Köpfen aufzustöbern. Bei Genpact ist das nicht allein die Domäne der IT-Abteilung. Laut Kathleen Featheringham, Direktorin für KI-Strategie und Training bei Booz Allen Hamilton, entscheidet sich in der Qualität des Rollouts, ob es einen relevanten RoI gibt oder nicht. “KI ist die vierte industrielle Revolution”, sagt sie. “Sie verändert das Spiel grundlegend. Es geht hier nicht um ein IT-Problem, alle Rollen entwickeln sich weiter.” Die KI-gestützte Unternehmenstransformation erfordere eine Neubewertung der Leistungsziele, des Mitarbeitertrainingszielen und auch der gesamten Vision. Sei das nicht der Fall und es gebe keinen Konsens über das Vorgehen, könnten das die Mitarbeiter sehr übelnehmen, warnt Featheringham. Zu den Prinzipien organisationalen Lernens gehört es, dass KI und Mensch zusammenarbeiten und sich gegenseitig ergänzen. “Gelingt eine Kooperation, in der Maschinen tun, was sie gut können, und Menschen ihre Intuition und ihr Wissen einbringen, wird man einen großen geschäftlichen Nutzen sehen”, ist Judith Hurwitz überzeugt, Präsidentin und Gründerin von Hurwitz and Associates sowie Autorin von inzwischen zehn Büchern zu Themen wie Führung, Technologie und Analytics. Was ist Value Stream Mapping? Foto: 3rdtimeluckystudio – shutterstock.com Value Stream Mapping ist eine Lean-Management-Technik. Das sollten Sie über die Wertstromanalyse wissen. Was ist IT Business Alignment? Foto: fotogestoeber – shutterstock.com IT-Investitionen müssen zur Unternehmensentwicklung beitragen. IT Alignment bezeichnet dazu die gegenseitige Ausrichtung von Geschäfts- und IT-Stategien. Was sind Serious Games? Foto: TU Köln Screenshot: Welten der Werkstoffe Serious Games sollen Lernen durch Videospiele attraktiver machen. erfahren Sie, wie es funktioniert und welche Ansätze dahinterstecken. Was ist Intelligent Wargaming? Foto: Gorodenkoff – shutterstock.com Intelligent Wargaming nutzt Echtzeitanalysen und Techniken wie Machine Learning zur Unternehmenssteuerung. Auch der CIO ist dabei gefordert. Was ist Agilität? Foto: Andrey_Popov – shutterstock.com Der Begriff Agilität beschreibt sowohl ein methodisches Vorgehen als auch die Gestaltung der Firmenkultur. Ein Überblick. Was sind technische Schulden? Foto: hatoriz – shutterstock.com Technical Debt – zu Deutsch technische Schulden – kann die Innovationskraft und den monetären Erfolg Ihres Unternehmens gefährden. Was ist Outstaffing? Foto: Viesinsh – shutterstock.com Die Outsourcing-Variante Outstaffing stellt einen neuen Weg für die strategische Entwicklung von Unternehmenssoftware dar. Das müssen Sie wissen. Was ist Environmental Social Governance? Foto: Mameraman – shutterstock.com Ab 2023 müssen sich viele Unternehmen in der EU an ESG-Kriterien halten. Wir erklären die Hintergründe und Richtlinien. Was ist Transformational Leadership? Foto: nullplus – shutterstock.com Transformational Leadership fördert Eigenverantwortung und inspiriert Mitarbeiter, Veränderungen und Innovationen im Unternehmen voranzutreiben. Was ist Change Management? Foto: Alex from the Rock – shutterstock.com Was versteht man unter Change Management und wie unterscheidet es sich zur Organisationsentwicklung? Welche Methoden es im Veränderungsmanagement gibt, lesen Sie hier. Was ist ein Citizen Developer? Foto: NDAB Creativity – shutterstock.com Citizen Developer nehmen bei der digitalen Transformation von Unternehmen eine wichtige Rolle ein. Was man darunter versteht, lesen Sie hier. Was ist Operations Management? Foto: Pixparts – shutterstock.com In Zeiten der Digitalisierung kann es für ein Unternehmen entscheidend sein, wie gut es Business- und IT-Prozesse in Einklang bringt. Zwei Wege führen zum Ziel. Was ist Design Thinking? Foto: REDPIXEL.PL – shutterstock.com Design Thinking hilft Unternehmen, kundenorientierte Ideen und Ansätze zu kreieren. Die Methode eignet sich auch für sehr komplexe Probleme. Was ist Servant Leadership? Foto: Jacob Lund – shutterstock.com Servant Leader dienen ihrem Umfeld und helfen anderen dabei, zu wachsen. Dieses Führungsverständnis ist nicht nur im agilen Umfeld beliebt. Projektmanagement-Methoden im Vergleich Foto: NicoElNino – shutterstock.com Damit ein IT-Projekt nicht scheitert, sollte die richtige Methode bereits in Vorfeld gewählt werden. Eine Erklärung verschiedener Methoden mit Anwendungsfällen sowie eine Tabelle, die durch den Auswahlprozess leitet. Was ist Business Intelligence? Foto: SFIO CRACHO – shutterstock.com Business Intelligence (BI) verwandelt Daten in Insights und hilft bei der Entscheidungsfindung im Unternehmen. Wir sagen Ihnen, was Sie zum Thema wissen müssen. Was ist Contract Lifecycle Management? Foto: fizkes – shutterstock.com Erfahren Sie, was Contract Lifecycle Management (CLM) ist und welche Unternehmensbereiche davon profitieren können. Was ist Arbeitnehmerüberlassung? Foto: Alexander Supertramp – shutterstock.com 27.10.2022 Von Matthias RuffMatthias Ruff (Autor) Auf Arbeitnehmerüberlassung greifen Unternehmen zurück, damit Scheinselbständigkeit kein Thema wird. Das sollten Sie beachten. Was ist ein Statement of Work? Foto: wutzkohphoto – shutterstock.com Das Statement of Work (SoW) sorgt in der Projektarbeit für Klarheit. Warum das Dokument wichtig ist und was man beim Verfassen beachten sollte. Was ist Compliance? Foto: Arcady – shutterstock.com Was versteht man unter Compliance? Welche Verfahren und Anforderungen gibt es an Unternehmen? Wie die Einhaltung der Compliance verbessert werden kann, lesen Sie hier. Was ist Controlling? Foto: Roman Samborskyi – shutterstock.com Lesen Sie, was sich hinter dem Begriff Controlling verbirgt, welche Aufgaben ein Controller wahrnimmt, worauf Unternehmen achten sollten und wie die Zukunft des Controllings aussieht. Was ist ein kooperativer Führungsstil? Foto: NDAB Creativity – shutterstock.com Wer kooperativ führt, kommuniziert mit seinen Mitarbeitern auf Augenhöhe und teilt Verantwortung. Dieser Führungsstil hat in Corona-Zeiten Auftrieb erhalten. Was ist Total Quality Management? Foto: greenbutterfly – shutterstock.com Total Quality Management – TQM – unterstützt Unternehmen dabei, sich auf die kontinuierliche Verbesserung von Prozessen und Produkten zu fokussieren. Was ist New Work? Foto: Jacob Lund – shutterstock.com Die Corona-Pandemie hat das Thema New Work befeuert. Doch das Konzept umfasst viel mehr als flexibles Arbeiten und neue Büroräume mit Kickertisch. Was macht ein Solution Architect? Foto: Kutlayev Dmitry – shutterstock.com Der Solution Architect nimmt eine entscheidende Rolle im Unternehmen ein. Lesen Sie, warum. Was ist Gamification? Foto: Pixel-Shot – shutterstock.com Was hat das “Moorhuhn” mit einer Whisky-Marke zu tun? Schon Ende des vergangenen Jahrtausends nutzten Unternehmen spielerische Elemente für ihre Zwecke. Inzwischen hat Gamification Einzug in den Alltag gehalten. Was ist ein Business-Analyst? Foto: SFIO CRACHO – shutterstock.com Mit Datenanalysen unterstützen Business-Analysten Unternehmen dabei, Prozesse, Produkte, Services und Software zu verbessern. Was ist GitOps? Foto: iunewind – shutterstock.com GitOps wendet die Methoden von DevOps und CI/CD für die Bereitstellung von IT-Infrastruktur an. Das müssen Sie zum Thema wissen. Was ist Data Literacy? Foto: Khosro – shutterstock.com Mit Daten umzugehen, sie auszuwerten, zu interpretieren und als Entscheidungsgrundlage zu nutzen, bedarf einer entscheidenden Kernkompetenz: Data Literacy. Was ist Laterale Führung? Foto: Altrendo Images – shutterstock.com Laterale Führung bezeichnet einen unkonventionellen Führungsstil. Klassische, hierarchisch geprägte Führungsinstrumente stehen dabei nicht zur Verfügung. Was ist ITIL? Foto: RoseRodionova – shutterstock.com Das Regelwerk ITIL beschreibt Best Practices für die Bereitstellung von IT-Services. Es soll zu einer stabilen IT-Umgebung beitragen, die Wachstum, Skalierbarkeit und Change ermöglicht. Was ist Workforce Management? Foto: Blue Planet Studio – shutterstock.com Workforce Management ist über die Jahre zu einem komplexen Framework für Personalverwaltung und Budgetierung avanciert. Das sollten Sie zum Thema wissen. Was ist eine Prozessorganisation? Foto: NicoElNino – shutterstock.com So bauen Sie eine Prozessorganisation in fünf Schritten auf. Von der Definition der Rollen bis zur Verknüpfung mit der IT-Organisation. Eine Tabelle zeigt den Ablauf an einem Beispiel. Was ist organisationales Lernen? Foto: Lightspring – shutterstock.com Viele Unternehmen setzen im Kleinen auf KI, versäumen es aber, formale Prozesse einzuführen, damit die gesamte Organisation lernen und sich schneller transformieren kann.",
    "source": "cio",
    "crawled_at": "2025-05-28T09:16:51.905406+00:00"
  },
  {
    "url": "https://www.cio.de/article/3991986/gewerbetreibender-versus-freiberufler-was-bin-ich-und-was-darf-ich-sein-2.html",
    "title": "Gewerbetreibender versus Freiberufler – Was bin ich und was darf ich sein?",
    "published": "2025-05-23T06:23:40+00:00",
    "author": "",
    "text": "Tupungato – shutterstock.com Grundsätzlich unterliegen Selbständige, die mit ihrer Unternehmung Gewinne erzielen möchten, der Gewerbeordnung . Es gibt aber Ausnahmen für bestimmte Berufsgruppen und Tätigkeiten. Freiberufler wie Künstler, Journalisten, Ärzte, Rechtsanwälte oder Steuerberater sind von der Pflicht ausgenommen, ein Gewerbe anzumelden. Ebenso Selbständige, die in der Urproduktion arbeiten, also in der Land- und Forstwirtschaft, der Fischerei oder dem Bergbau. Kapitalgesellschaften hingegen werden vom Finanzamt per se immer als Gewerbe eingestuft, ganz unabhängig von der konkreten Tätigkeit. Was zunächst eindeutig klingt, ist bei näherer Betrachtung gar nicht so klar. Die Abgrenzungen verschwimmen häufig, denn nicht nur Künstler und Journalisten können als freiberuflich gelten. Eine freiberufliche Tätigkeit definiert sich nämlich auch durch ihr Tätigkeitsprofil. Sie ist demnach eine selbständig ausgeübte wissenschaftliche, künstlerische, schriftstellerische, unterrichtende oder erzieherische Tätigkeit, die sich durch Professionalität, Gemeinwohlpflicht, Selbstkontrolle und Eigenverantwortlichkeit auszeichnet. In der IT herrscht generell große Unsicherheit. Der Grund: Die Rechtslage ist nicht eindeutig und es gibt viele Einzelfallentscheidungen, die sich von Finanzamt zu Finanzamt unterscheiden. Gemäß der Rechtsprechung des Bundesfinanzhofs (BFH) muss ein IT-Berater das Diplom einer der Katalogberufe besitzen, um als Freiberufler im Tätigkeitsfeld der Informatik anerkannt zu werden: Dies sind Ingenieure oder beratende Betriebswirte. Ohne einen solchen Abschluss muss der IT-Spezialist plausibel nachweisen, dass er die Kenntnisse anderweitig erworben hat. Beim Nachweis ist zu beachten, dass die Tätigkeit möglichst “ingenieurmäßig” sein muss. Das Bundeswirtschaftsministerium schreibt dazu: „Eine freiberufliche Tätigkeit im Sinne von Paragraf 18 Absatz 1 Nr. 1 Satz 2 EstG übt auch aus, wer einem dem Ingenieurberuf ähnlichen Beruf nachgeht. Der ähnliche Beruf muss dem Beruf des Ingenieurs sowohl hinsichtlich der erforderlichen Berufsausbildung als auch hinsichtlich der tatsächlich entfalteten Tätigkeit im Wesentlichen gleichen (ständige Rechtsprechung, vgl. nur BFH-Urteil vom 9. Februar 2006 IV R 27/05, BFH/NV 2006, 1270, m.w.N.).“ Bundesfinanzhof: Urteil vom 22.09.2009 – VIII R 79/06. Ein weiteres Kriterium für eine Freiberuflichkeit im Bereich der IT ist der Arbeitsbereich. Die IHK formuliert dazu: “Von der freiberuflichen Tätigkeit umfasst sind jedoch nur die Beratung und die Anfertigung von Entwürfen oder Gutachten. Die Herstellung, Bearbeitung und der Vertrieb von Sachgütern sind hingegen gewerbliche Tätigkeiten und müssen beim Gewerbeamt angemeldet werden.” Betriebsprüfer nehmen diese Abgrenzungsschwierigkeiten immer häufiger als Anlass für Prüfungen. Ein Beraterwechsel, ein Umzug oder eine Steuererklärung sind Auslöser für Prüfverfahren. Am Ende entscheidet das Finanzamt, sollte es zu einer Betriebsprüfung kommen. Und das kann böse enden, wenn die Finanzbeamten in der Tätigkeit keine Anhaltspunkte für eine Freiberuflichkeit sehen. Dann muss die Gewerbesteuer nachgezahlt werden. Wer also glaubt, eine freiberufliche Tätigkeit auszuüben, muss dies dem Finanzamt belegen, zum Beispiel durch Arbeitsproben. Ein Austausch mit dem Steuerberater oder einem Rechtsanwalt kann hier auch helfen und Sicherheit bringen. Tätigkeitsbeschreibungen sollten Hand und Fuß haben, sich an Formulierungen orientieren und nicht selbst geschrieben werden. Wichtig ist es, sich bereits im Vorfeld zu informieren, wie die Chancen stehen, freiberuflich eingestuft zu werden. Hierbei ist es wichtig zu prüfen, wie die Ausbildungssituation aussieht und welche Tätigkeit auch konkret nachgewiesen werden kann. Tupungato – shutterstock.com Grundsätzlich unterliegen Selbständige, die mit ihrer Unternehmung Gewinne erzielen möchten, der Gewerbeordnung . Es gibt aber Ausnahmen für bestimmte Berufsgruppen und Tätigkeiten. Freiberufler wie Künstler, Journalisten, Ärzte, Rechtsanwälte oder Steuerberater sind von der Pflicht ausgenommen, ein Gewerbe anzumelden. Ebenso Selbständige, die in der Urproduktion arbeiten, also in der Land- und Forstwirtschaft, der Fischerei oder dem Bergbau. Kapitalgesellschaften hingegen werden vom Finanzamt per se immer als Gewerbe eingestuft, ganz unabhängig von der konkreten Tätigkeit. Was zunächst eindeutig klingt, ist bei näherer Betrachtung gar nicht so klar. Die Abgrenzungen verschwimmen häufig, denn nicht nur Künstler und Journalisten können als freiberuflich gelten. Eine freiberufliche Tätigkeit definiert sich nämlich auch durch ihr Tätigkeitsprofil. Sie ist demnach eine selbständig ausgeübte wissenschaftliche, künstlerische, schriftstellerische, unterrichtende oder erzieherische Tätigkeit, die sich durch Professionalität, Gemeinwohlpflicht, Selbstkontrolle und Eigenverantwortlichkeit auszeichnet. In der IT herrscht generell große Unsicherheit. Der Grund: Die Rechtslage ist nicht eindeutig und es gibt viele Einzelfallentscheidungen, die sich von Finanzamt zu Finanzamt unterscheiden. Gemäß der Rechtsprechung des Bundesfinanzhofs (BFH) muss ein IT-Berater das Diplom einer der Katalogberufe besitzen, um als Freiberufler im Tätigkeitsfeld der Informatik anerkannt zu werden: Dies sind Ingenieure oder beratende Betriebswirte. Ohne einen solchen Abschluss muss der IT-Spezialist plausibel nachweisen, dass er die Kenntnisse anderweitig erworben hat. Beim Nachweis ist zu beachten, dass die Tätigkeit möglichst “ingenieurmäßig” sein muss. Das Bundeswirtschaftsministerium schreibt dazu: „Eine freiberufliche Tätigkeit im Sinne von Paragraf 18 Absatz 1 Nr. 1 Satz 2 EstG übt auch aus, wer einem dem Ingenieurberuf ähnlichen Beruf nachgeht. Der ähnliche Beruf muss dem Beruf des Ingenieurs sowohl hinsichtlich der erforderlichen Berufsausbildung als auch hinsichtlich der tatsächlich entfalteten Tätigkeit im Wesentlichen gleichen (ständige Rechtsprechung, vgl. nur BFH-Urteil vom 9. Februar 2006 IV R 27/05, BFH/NV 2006, 1270, m.w.N.).“ Bundesfinanzhof: Urteil vom 22.09.2009 – VIII R 79/06. Ein weiteres Kriterium für eine Freiberuflichkeit im Bereich der IT ist der Arbeitsbereich. Die IHK formuliert dazu: “Von der freiberuflichen Tätigkeit umfasst sind jedoch nur die Beratung und die Anfertigung von Entwürfen oder Gutachten. Die Herstellung, Bearbeitung und der Vertrieb von Sachgütern sind hingegen gewerbliche Tätigkeiten und müssen beim Gewerbeamt angemeldet werden.” Betriebsprüfer nehmen diese Abgrenzungsschwierigkeiten immer häufiger als Anlass für Prüfungen. Ein Beraterwechsel, ein Umzug oder eine Steuererklärung sind Auslöser für Prüfverfahren. Am Ende entscheidet das Finanzamt, sollte es zu einer Betriebsprüfung kommen. Und das kann böse enden, wenn die Finanzbeamten in der Tätigkeit keine Anhaltspunkte für eine Freiberuflichkeit sehen. Dann muss die Gewerbesteuer nachgezahlt werden. Wer also glaubt, eine freiberufliche Tätigkeit auszuüben, muss dies dem Finanzamt belegen, zum Beispiel durch Arbeitsproben. Ein Austausch mit dem Steuerberater oder einem Rechtsanwalt kann hier auch helfen und Sicherheit bringen. Tätigkeitsbeschreibungen sollten Hand und Fuß haben, sich an Formulierungen orientieren und nicht selbst geschrieben werden. Wichtig ist es, sich bereits im Vorfeld zu informieren, wie die Chancen stehen, freiberuflich eingestuft zu werden. Hierbei ist es wichtig zu prüfen, wie die Ausbildungssituation aussieht und welche Tätigkeit auch konkret nachgewiesen werden kann.",
    "source": "cio",
    "crawled_at": "2025-05-28T09:16:52.465196+00:00"
  },
  {
    "url": "https://www.cio.de/article/3683138/agiles-projektmanagement-faq.html",
    "title": "Was Sie über agiles Projektmanagement wissen müssen",
    "published": "2025-05-23T06:56:43+00:00",
    "author": "",
    "text": "Agil durchstarten? Unsere FAQ vermittelt agiles Grundlagenwissen. Foto: Pixel-Shot – shutterstock.com Egal ob Sie Agile -Greenhorn oder -Veteran sind: Die folgenden zehn Fragen und ihre jeweiligen Antworten geben einen Überblick über das grundlegende Wissen zum Thema. So können Sie ja nach Bedarf agil durchstarten oder ihr Wissen auffrischen. Das Wörtchen ‘agile’ entstammt dem relativ weiten Feld des Projektmanagements und bezeichnet eine Methode desselbigen. Hierbei sollen kurze Entwicklungszyklen – auch ‘Sprints’ genannt – die kontinuierliche Verbesserung bei der Entwicklung eines Produkts oder Services gewährleisten. Methoden des stufenweisen Projektmanagements existieren bereits seit 1957. Die erste tiefgehende Diskussion zum Thema Agile wurde in den 1970er Jahren von Winston Royce angestoßen, der damals ein Thesenpapier zur Entwicklung umfassender Software-Systeme veröffentlicht hat. Im Jahr 2001 wurde schließlich das sogenannte ‘ agile manifesto’ veröffentlicht, eine “formelle Proklamation von zwölf Grundprinzipien für einen iterativen Ansatz zur Softwareentwicklung, der den Menschen in den Mittelpunkt stellt”. Veröffentlicht wurde dieser von 17 Developern, die sich zusammengefunden hatten, um auf Grundlage ihrer gemeinsamen Erfahrungen leichtgewichtige Entwicklungsmethoden zu diskutieren. Die ebenfalls hieraus entstandenen zwölf Grundprinzipien bilden bis heute die Basis für agiles Projektmanagement : 1. Kundenzufriedenheit hat stets oberste Priorität. Diese wird durch eine schnelle und fortwährende Auslieferung erreicht. 2. Sich verändernde Rahmenbedingungen werden in jeder Stufe des Entwicklungsprozesses mit einbezogen, um den Kunden mit einem Wettbewerbsvorteil auszustatten. 3. Ein Produkt oder Service wird mit höherer Frequenz ausgeliefert. 4. Stakeholder und Entwickler arbeiten auf täglicher Basis eng zusammen. 5. Alle Stakeholder und Teammitglieder bleiben stets motiviert, um optimale Projektergebnisse zu gewährleisten. Die Teams werden mit allen notwendigen Tools unterstützt. Darüber hinaus genießen sie das Vertrauen, dass die Projektziele erreicht werden. 6. Face-to-Face-Meetings sind die effizienteste und effektivste Form, um den Projekterfolg sicher zu stellen. 7. Ein fertiges, funktionierendes Produkt ist das ultimative Messinstrument für Erfolg. 8. Eine nachhaltige Entwicklung wird durch agile Prozesse gewährleistet, wodurch die Entwicklungsteams und Stakeholder dazu befähigt werden, ein konstantes Tempo zu halten. 9. Die Agilität wird durch einen fortlaufenden Fokus auf technische Exzellenz und angemessenes Design gesteigert. 10. Simplizität ist ein wesentliches Element. 11. Sich selbst organisierende Teams entwickeln mit hoher Wahrscheinlichkeit die besten Architekturen und Designs und werden den Anforderungen am ehesten gerecht. 12. Die Teams überprüfen ihre Arbeit in regelmäßigen Intervallen und verbessern die Effizienz durch Feintuning. Obwohl das Agile-Prinzip originär der Software -Industrie entstammt, haben inzwischen viele Branchen das Agile-Prinzip für die Entwicklung ihrer Produkte und Services übernommen. Warum? In erster Linie wegen der höchst kollaborativen und effizienzsteigernden Wirkung dieser Methode. Auch in den Bereichen Marketing , Bauwesen, Bildung und Finanzwesen wird längst agil gearbeitet. Ursprünglich sollte der Ansatz den Prozess der Softwareentwicklung vereinheitlichen und verbessern, um schneller auf Probleme und/oder Fehler reagieren zu können. Im Gegensatz zum traditionellen “ Wasserfallmodell ” befähigt der agile Ansatz Entwickler und Teams durch iterative und interaktive Sprints ein besseres Produkt abzuliefern. Mit den steigenden Erwartungen der Kunden wird es immer wichtiger Projektmanager zu verpflichten, die die beste Methodik zur Ausführung eines Projekts kennen und auch umsetzen. Nur so kann ein Wettbewerbsvorteil erlangt werden. Die traditionellen – eher schwerfälligen – Methoden des Projektmanagements erfordern in der Regel, dass das komplette Team in jeder Phase des Projekts zu einem Meeting zusammenkommen muss und jedes einzelne Projektziel diskutiert wird. Beim agilen Ansatz setzt man hingegen auf kleinere, fokussiertere Teams, die sich in regelmäßigen Abständen zusammenfinden, um ganz spezifische Ziele in Angriff zu nehmen. Das Resultat: kurzfristige Änderungen lassen sich schneller realisieren. Die Teams sind also agiler, flexibler und effizienter, wodurch sich die Wahrscheinlichkeit erhöht, dass sie die vom Kunden gesteckten Ziele auch erreichen – insbesondere dann, wenn sich dessen Bedürfnisse ändern. Das Agile -Prinzip stattet die Teams mit einem Mechanismus aus, der die schnelle Wiederholung in sich geschlossener Prozesse, die Isolation von Problemen und die Erreichung spezifischer Ziele ermöglicht. Und zwar vor allem schnell. Das ist in der Regel fruchtbarer, als auf das Ende einer unter Umständen langwierigen Projektphase warten zu müssen, nur um dann herauszufinden, welche Ziele verpasst wurden. Agile ist inzwischen extrem populär geworden und hat sich rasant verbreitet. Die Methodik bietet für Projektteams, Projektleiter, Kunden und Stakeholder viele Vorteile . Hier die wichtigsten im Überblick: Schnellere Auslieferung von Lösungen Weniger Ausschuss durch Minimierung von Ressourcen Erhöhte Flexibilität und Anpassungsfähigkeit Erhöhte Erfolgsaussichten durch stärkere Fokussierung Schnellere Reaktionszeiten Schnelleres Identifizieren von Problemen und Fehlern Optimierter Entwicklungsprozess Leichteres, übersichtlicheres Framework Optimale Projektkontrolle Erhöhte Fokussierung auf spezifische Kundenbedürfnisse Mehr Kollaboration und Feedback Natürlich eignet sich der Agile-Ansatz nicht für jedes Projekt gleichermaßen. Warum? Darum: Während des Entwicklungsprozesses fokussiert der Agile-Ansatz Entwickler, Projektteams und Kundenziele – aber nicht notwendigerweise die (End) User Experience. Wegen seiner weniger formellen und flexibleren Prozesse hat es agile unter Umständen in großen, traditionell geprägten Konzernen schwer. Es besteht die Möglichkeit, Hybrid-Lösungen zu erzeugen. Das kann dafür sorgen, dass die Flexibilität weiter erhöht wird und ist im Einzelfall eventuell empfehlenswert. Um herauszufinden, welche Methode(n) am besten geeignet sind, empfiehlt sich Due Diligence . Innerhalb des “Agile-Universums” gibt es etliche populäre Ansätze und Methoden. Hier eine Übersicht – geordnet nach Beliebtheit: Scrum Kanban Lean Dynamic System Development Model Extreme Programming Crystal Adaptive software development Agile Unified Process Crystal Clear methods Disciplined agile delivery Feature-driven development Scrumban Rapid Application Development In einem von zunehmenden Wettbewerb und Geschwindigkeit geprägten Business-Umfeld bietet Agile zahlreiche Vorteile – bei gleichzeitig überschaubaren Nachteilen. Dass die Methodik mittlerweile in zahlreichen Branchen zum Einsatz kommt, spricht für ihre Attraktivität. Agile ist also alles andere als ein vorübergehender Trend – Zukunftssicherheit gewährleistet. Accenture über das agile Unternehmen Foto: Accenture Die Unternehmensberatung Accenture hat eine schematische Darstellung eines agilen Unternehmens erstellt und beschreibt die Auswirkungen auf das IT Operating Model. Neun Charakteristika Foto: Accenture Für Accenture zeichnet sich ein agiles Unternehmen durch neun Charakteristika aus. Die Rolle von Technology Labs Foto: Accenture Accenture rät zum Einführen von Technology Labs. Die IT soll aktiv in die Produktentwicklung einbezogen werden. Sicherheitsmaßnahmen Foto: Accenture Sicherheit will Accenture sowohl Technologie-seitig (Endgeräte) als auch Non-IT-seitig verstanden wissen. Multi-Speed IT Foto: Accenture Multi-Speed IT bezieht sich nicht nur auf agile IT, sondern auch auf Legacys. Unternehmen müssen ihre IT transformieren. Agil durchstarten? Unsere FAQ vermittelt agiles Grundlagenwissen. Foto: Pixel-Shot – shutterstock.com Egal ob Sie Agile -Greenhorn oder -Veteran sind: Die folgenden zehn Fragen und ihre jeweiligen Antworten geben einen Überblick über das grundlegende Wissen zum Thema. So können Sie ja nach Bedarf agil durchstarten oder ihr Wissen auffrischen. Das Wörtchen ‘agile’ entstammt dem relativ weiten Feld des Projektmanagements und bezeichnet eine Methode desselbigen. Hierbei sollen kurze Entwicklungszyklen – auch ‘Sprints’ genannt – die kontinuierliche Verbesserung bei der Entwicklung eines Produkts oder Services gewährleisten. Methoden des stufenweisen Projektmanagements existieren bereits seit 1957. Die erste tiefgehende Diskussion zum Thema Agile wurde in den 1970er Jahren von Winston Royce angestoßen, der damals ein Thesenpapier zur Entwicklung umfassender Software-Systeme veröffentlicht hat. Im Jahr 2001 wurde schließlich das sogenannte ‘ agile manifesto’ veröffentlicht, eine “formelle Proklamation von zwölf Grundprinzipien für einen iterativen Ansatz zur Softwareentwicklung, der den Menschen in den Mittelpunkt stellt”. Veröffentlicht wurde dieser von 17 Developern, die sich zusammengefunden hatten, um auf Grundlage ihrer gemeinsamen Erfahrungen leichtgewichtige Entwicklungsmethoden zu diskutieren. Die ebenfalls hieraus entstandenen zwölf Grundprinzipien bilden bis heute die Basis für agiles Projektmanagement : 1. Kundenzufriedenheit hat stets oberste Priorität. Diese wird durch eine schnelle und fortwährende Auslieferung erreicht. 2. Sich verändernde Rahmenbedingungen werden in jeder Stufe des Entwicklungsprozesses mit einbezogen, um den Kunden mit einem Wettbewerbsvorteil auszustatten. 3. Ein Produkt oder Service wird mit höherer Frequenz ausgeliefert. 4. Stakeholder und Entwickler arbeiten auf täglicher Basis eng zusammen. 5. Alle Stakeholder und Teammitglieder bleiben stets motiviert, um optimale Projektergebnisse zu gewährleisten. Die Teams werden mit allen notwendigen Tools unterstützt. Darüber hinaus genießen sie das Vertrauen, dass die Projektziele erreicht werden. 6. Face-to-Face-Meetings sind die effizienteste und effektivste Form, um den Projekterfolg sicher zu stellen. 7. Ein fertiges, funktionierendes Produkt ist das ultimative Messinstrument für Erfolg. 8. Eine nachhaltige Entwicklung wird durch agile Prozesse gewährleistet, wodurch die Entwicklungsteams und Stakeholder dazu befähigt werden, ein konstantes Tempo zu halten. 9. Die Agilität wird durch einen fortlaufenden Fokus auf technische Exzellenz und angemessenes Design gesteigert. 10. Simplizität ist ein wesentliches Element. 11. Sich selbst organisierende Teams entwickeln mit hoher Wahrscheinlichkeit die besten Architekturen und Designs und werden den Anforderungen am ehesten gerecht. 12. Die Teams überprüfen ihre Arbeit in regelmäßigen Intervallen und verbessern die Effizienz durch Feintuning. Obwohl das Agile-Prinzip originär der Software -Industrie entstammt, haben inzwischen viele Branchen das Agile-Prinzip für die Entwicklung ihrer Produkte und Services übernommen. Warum? In erster Linie wegen der höchst kollaborativen und effizienzsteigernden Wirkung dieser Methode. Auch in den Bereichen Marketing , Bauwesen, Bildung und Finanzwesen wird längst agil gearbeitet. Ursprünglich sollte der Ansatz den Prozess der Softwareentwicklung vereinheitlichen und verbessern, um schneller auf Probleme und/oder Fehler reagieren zu können. Im Gegensatz zum traditionellen “ Wasserfallmodell ” befähigt der agile Ansatz Entwickler und Teams durch iterative und interaktive Sprints ein besseres Produkt abzuliefern. Mit den steigenden Erwartungen der Kunden wird es immer wichtiger Projektmanager zu verpflichten, die die beste Methodik zur Ausführung eines Projekts kennen und auch umsetzen. Nur so kann ein Wettbewerbsvorteil erlangt werden. Die traditionellen – eher schwerfälligen – Methoden des Projektmanagements erfordern in der Regel, dass das komplette Team in jeder Phase des Projekts zu einem Meeting zusammenkommen muss und jedes einzelne Projektziel diskutiert wird. Beim agilen Ansatz setzt man hingegen auf kleinere, fokussiertere Teams, die sich in regelmäßigen Abständen zusammenfinden, um ganz spezifische Ziele in Angriff zu nehmen. Das Resultat: kurzfristige Änderungen lassen sich schneller realisieren. Die Teams sind also agiler, flexibler und effizienter, wodurch sich die Wahrscheinlichkeit erhöht, dass sie die vom Kunden gesteckten Ziele auch erreichen – insbesondere dann, wenn sich dessen Bedürfnisse ändern. Das Agile -Prinzip stattet die Teams mit einem Mechanismus aus, der die schnelle Wiederholung in sich geschlossener Prozesse, die Isolation von Problemen und die Erreichung spezifischer Ziele ermöglicht. Und zwar vor allem schnell. Das ist in der Regel fruchtbarer, als auf das Ende einer unter Umständen langwierigen Projektphase warten zu müssen, nur um dann herauszufinden, welche Ziele verpasst wurden. Agile ist inzwischen extrem populär geworden und hat sich rasant verbreitet. Die Methodik bietet für Projektteams, Projektleiter, Kunden und Stakeholder viele Vorteile . Hier die wichtigsten im Überblick: Schnellere Auslieferung von Lösungen Weniger Ausschuss durch Minimierung von Ressourcen Erhöhte Flexibilität und Anpassungsfähigkeit Erhöhte Erfolgsaussichten durch stärkere Fokussierung Schnellere Reaktionszeiten Schnelleres Identifizieren von Problemen und Fehlern Optimierter Entwicklungsprozess Leichteres, übersichtlicheres Framework Optimale Projektkontrolle Erhöhte Fokussierung auf spezifische Kundenbedürfnisse Mehr Kollaboration und Feedback Natürlich eignet sich der Agile-Ansatz nicht für jedes Projekt gleichermaßen. Warum? Darum: Während des Entwicklungsprozesses fokussiert der Agile-Ansatz Entwickler, Projektteams und Kundenziele – aber nicht notwendigerweise die (End) User Experience. Wegen seiner weniger formellen und flexibleren Prozesse hat es agile unter Umständen in großen, traditionell geprägten Konzernen schwer. Es besteht die Möglichkeit, Hybrid-Lösungen zu erzeugen. Das kann dafür sorgen, dass die Flexibilität weiter erhöht wird und ist im Einzelfall eventuell empfehlenswert. Um herauszufinden, welche Methode(n) am besten geeignet sind, empfiehlt sich Due Diligence . Innerhalb des “Agile-Universums” gibt es etliche populäre Ansätze und Methoden. Hier eine Übersicht – geordnet nach Beliebtheit: Scrum Kanban Lean Dynamic System Development Model Extreme Programming Crystal Adaptive software development Agile Unified Process Crystal Clear methods Disciplined agile delivery Feature-driven development Scrumban Rapid Application Development In einem von zunehmenden Wettbewerb und Geschwindigkeit geprägten Business-Umfeld bietet Agile zahlreiche Vorteile – bei gleichzeitig überschaubaren Nachteilen. Dass die Methodik mittlerweile in zahlreichen Branchen zum Einsatz kommt, spricht für ihre Attraktivität. Agile ist also alles andere als ein vorübergehender Trend – Zukunftssicherheit gewährleistet. Accenture über das agile Unternehmen Foto: Accenture Die Unternehmensberatung Accenture hat eine schematische Darstellung eines agilen Unternehmens erstellt und beschreibt die Auswirkungen auf das IT Operating Model. Neun Charakteristika Foto: Accenture Für Accenture zeichnet sich ein agiles Unternehmen durch neun Charakteristika aus. Die Rolle von Technology Labs Foto: Accenture Accenture rät zum Einführen von Technology Labs. Die IT soll aktiv in die Produktentwicklung einbezogen werden. Sicherheitsmaßnahmen Foto: Accenture Sicherheit will Accenture sowohl Technologie-seitig (Endgeräte) als auch Non-IT-seitig verstanden wissen. Multi-Speed IT Foto: Accenture Multi-Speed IT bezieht sich nicht nur auf agile IT, sondern auch auf Legacys. Unternehmen müssen ihre IT transformieren.",
    "source": "cio",
    "crawled_at": "2025-05-28T09:16:52.514405+00:00"
  },
  {
    "url": "https://www.cio.de/article/3684673/die-cios-der-dax-40-konzerne.html",
    "title": "Die CIOs der DAX-40-Konzerne",
    "published": "2025-05-25T10:51:53+00:00",
    "author": "",
    "text": "Andreas Hubert Foto: Adidas Andreas Hubert ist seit Februar 2021 Group CIO von Adidas. Catherine Jestin ist CIO und Executive VP Digital und Information Management bei Airbus. Foto: Airbus Seit März 2020 hat Catherine Jestin den CIO-Posten bei Airbus SE inne. Im Juli 2021 wurde sie zudem zum Executive Vice President Digital and Information Management berufen. Olav Spiegel ist CIO der Allianz SE. Foto: Allianz Seit 1. November 2023 hat der Versicherungskonzern Allianz mit Olav Spiegel einen neuen Group Chief Information Officer an Bord. Er folgt auf Ralf Schneider. mehr erfahren BASF hat keinen CIO mehr. Foto: 360b – shutterstock.com Nachdem Stefan Beck zum SVP Digitalization of Workspace and Collaboration aufgestiegen ist wird BASF die Rolle des Chief Information Officer (CIO) nicht weiter beibehalten. Bijoy Sagar ist CIO der Bayer AG. Foto: Bayer AG Bijoy Sagar ist seit 1. Juni 2020 Leiter IT und Digitale Transformation bei Bayer . Er soll die Digitalisierung des Pharmakonzerns vorantreiben und die begonnene Neuaufstellung der IT ans Ziel führen. Sagar wird an den Finanzvorstand Wolfgang Nickl berichten. Annette Hamann ist CIO von Baiersdorf. Foto: Beiersdorf Annette Hamann ist CIO und Managing Director BSS IT bei der Hamburger Beiersdorf AG . Alexander Buresch ist CIO der BMW Group. Foto: BMW AG Der Nachfolger von Klaus Straub im Amt des CIO der BMW Group heißt Alexander Buresch. Der Wirtschaftswissenschaftler ist seit mehr als 20 Jahren für tätig und war zuletzt Vice President Corporate Strategy and Planning. Intern wird erwartet, dass Buresch die von Klaus Straub verfolgte IT-Strategie fortführt. Stefan Haverkock ist CIO bei Brenntag. Foto: Brenntag Stefan Haverkock ist seit Januar 2019 VP IT Corporate & EMEA beim Chemiedistributor Brenntag. Er wechselte 2016 in das Unternehmen, nachdem er sieben Jahre bei Baustoffhersteller Knauf in verschiedenen leitenden IT-Positionen gearbeitet hatte. Haverkock berichtet an den CEO des Unternehmens. Heiko Burdack ist CTO der Commerzbank. Foto: Heiko Burdack Der CIO der Signal Iduna Gruppe, Heiko Burdack, wechselte zum 1. Februar 2023 als Chief Technology Officer zur Commerzbank. mehr erfahren Walter Grüner ist CIO bei Covestro. Foto: Covestro Walter Grüner ist seit Mai 2019 Head of Information Technology beim Chemieunternehmen Covestro in Leverkusen. Er berichtet direkt an den CFO Thomas Toepfer. Zuvor war Grüner seit 2013 als Group CIO bei der Kion Group AG tätig. Beim Frankfurter Anbieter von Gabelstapler und Lagertechnik hat er die Globalisierung der IT und die Digitalisierung vorangetrieben. Daimler Truck AG Mit Wirkung zum 1. Juni 2025 übernimmt Raghavendra Vaidya die Position des Chief Information Officer bei Daimler Truck. Er tritt die Nachfolge von Marcus Claesson an, der das Unternehmen auf eigenen Wunsch verlässt. mehr erfahren Bernd Leukert ist seit 2020 im Vorstand der Deutschen Bank. Foto: Mario Andreya Bernd Leukert wurde am 1. Januar 2020 Vorstand für Technologie, Daten und Innovation der Deutschen Bank . Von 2014 bis 2019 war Leukert Technikvorstand bei SAP , wo er 1994 seine Karriere begann. Christoph Böhm ist CIO der Deutschen Börse. Foto: COMPUTERWOCHE/Foto Vogt CIO und COO der Deutsche Börse AG ist seit November 2018 Christoph Böhm . Er wechselt von der SAP AG, wo er als Senior Vice President, Global Cloud Services, arbeitet. Der promovierte Elektroingenieur Böhm war von April 2011 bis Oktober 2014 CIO bei Vodafone. Er kam damals als CEO von der Active Billing GmbH & Co. KG, einer Tochtergesellschaft der Deutschen Telekom. Davor arbeitete er in führenden Positionen bei der Signal Iduna-Gruppe, der Deutschen Post AG und AT&T. Vorgänger Andreas Preuß geht voraussichtlich im Mai 2019 in den Ruhestand. Bernd Gemein ist CIO im Bereich PeP der Deutschen Post. Foto: Deutsche Post Seit September 2018 ist Bernd Gemein CIO für den Unternehmensbereich Post, E-Commerce, Parcel (PeP) bei der Deutschen Post DHL. Gemein berichtet an PeP-COO Tobias Meyer. Zu seinen wichtigsten anstehenden Aufgaben sagte Gemein, derzeit sei vor allem wichtig, eine positive Ergebnisentwicklung in den Jahren 2019 und 2020 sicherzustellen. Dazu gehöre die weitere Verbesserung der Produktivität und der indirekten Kosten sowie des Ertragsmanagements im Post- und Paketgeschäft. Peter Leukert ist CIO der Deutschen Telekom. Foto: Deutsche Telekom Sprecher der Geschäftsführung der Deutsche Telekom IT GmbH und damit CIO ist seit Januar 2017 Peter Leukert. Er wechselt von Motive Partners – einem Fintech Start-up, das er selbst mit gegründet hat. Zuvor war Leukert CIO der Commerzbank und von NYSE Euronext. 2011 wurde er zum “CIO des Jahres” gewählt. Zum 1. September 2025 wechselt Leukert als Chief Digital Officer zu BT. Sebastian Weber ist CTO von Eon. Foto: Eon Seit 1. Juli 2021 verantwortet Sebastian Weber als CTO bei Eon den IT-Betrieb. Er soll auch die digitalen Plattformen des Konzerns ausbauen. Zudem hat er gemeinsam mit Christopher d’Arcy in einer Doppelspitze die Geschäftsführung der IT-Tochter Eon Digital Technology GmbH übernommen. Beide berichten direkt an Digitalvorständin Victoria Ossadnik. Ingo Elfering ist CIO der Fresenius Gruppe. Foto: Fresenius Seit Juli 2020 besetzt Ingo Elfering den neu geschaffenen CIO-Posten bei der Fresenius Gruppe . Der gelernte Wirtschaftsinformatiker soll die globalen IT-Aktivitäten des Konzerns koordinieren und weiterentwickeln. Zudem übernimmt er die Leitung der IT-Dienstleistungstochter Fresenius Digital Technology. Elfering berichtet an Finanzvorstand Rachel Empey. Jürgen Stoffel ist CIO der Hannover Rück. Foto: Hannover Rück SE Hannover Rück: Jürgen Stoffel ist CIO beim weltweit drittgrößten Rückversicherer. Der bisherige CIO Fuchs ging 2014 in den Ruhestand. mehr erfahren Dennis Lentz ist CIO bei HeidelbergCement. Foto: HeidelbergCement Bereits seit Januar 2017 ist Dennis Lentz neuer Director Group IT/CIO beim Baustoffkonzern HeidelbergCement AG. Zuvor war er unter anderem Project Leader bei der Unternehmensberatung Boston Consulting und Project Leader und Leiter Supply Chain Management in Deutschland bei der HeidelbergCement AG. Michael Nilles ist CDIO von Henkel. Foto: Henkel Henkel hat Michael Nilles am 1. Oktober 2019 zum Chief Digital and Information Officer (CDIO) ernannt. Er berichtet direkt an Carsten Knobel, CEO von Henkel. In seiner Position ist Nilles für die Bereiche Digital, IT, Geschäftsprozessmanagement und Corporate Venture Capital verantwortlich. Harsha Deshmukh ist CIO bei Infineon. Foto: Infineon Technologies AG Seit dem Dezember 2021 ist Harsha Deshmukh CIO bei Infineon . Der IT-Chef kommt aus den eigenen Reihen. Er soll unter anderem die IT-Landschaft weiterentwickeln und die Kundenansprache verbessern. mehr erfahren Katrin Lehmann ist Group CIO bei Mercedes-Benz. Foto: Mercedes-Benz Als CIO der Mercedes-Benz Group AG und der Mercedes-Benz AG verantwortet Katrin Lehmann die globale IT für alle Geschäftsbereiche, Marken und Märkte und berichtet direkt an den CEO. mehr erfahren Merck Healthcare-CIO Alessandro de Luca. Foto: Hasan Baran Özkan Merck besetzt Anfang Dezember 2021 im Senior Leadership Team vier Positionen neu. Dazu zählt auch die Beförderung von Alessandro de Luca. Der bisherige CIO Healthcare hatte interimsmäßig als Group CIO gearbeitet und wird diese Funktion dauerhaft übernehmen. Gleichzeitig ist de Luca Leiter Information Technology. Er berichtet an Marcus Kuhnert, der als Chief Financial Officer (CFO) in der Geschäftsleitung sitzt. Lutz Seidenfaden ist CIO bei MTU Aero Engines Foto: Lutz Seidenfaden Lutz Seidenfaden ist seit Juni 2020 CIO (SVP Information Technology) beim Münchner Treibwerk-Hersteller MTU Aero Engines. Seidenfaden kommt von Industrieunternehmen Festo, wo er zuletzt die Stelle des Head of IT Services besetzte. Seine Vorgängerin Pamela Herget-Wehlitz wechselte zur Personalberatung JBH-Herget als Managing Partner. Robin Johnson ist CIO bei Munich Re. Foto: Maersk Robin Johnson ist seit April 2017 CIO beim Münchener Rückversicherer Munich Re . Er übernahm damit als Nachfolger von Rainer Janßen die Leitung des Zentralbereichs Information Technology. Zuvor arbeitete Johnson als CIO bei Maersk Line und Head of Maersk Group Infrastructure Services in Kopenhagen. Vor seinem Wechsel zu Maersk arbeitete Johnson von 2008 bis 2012 als Global CIO beim US-Computerhersteller Dell in Austin, Texas. Mattias Ulbrich ist CIO von Porsche. Foto: Porsche Mattias Ulbrich hat seit 1. September 2018 den CIO-Posten beim Automobilbauer Porsche inne. Seit 2019 ist er zudem Geschäftsführer der IT-Tochter Porsche Digital. Davor hatte der Manager verschiedene leitende IT-Positionen bei Audi, Volkswagen und Seat inne. Johannes Lattwein ist im Vorstand der Porsche Automobil Holding SE für IT zuständig. Foto: Porsche Automobil Holding SE Johannes Lattwein ist seit Februar 2022 Mitglied des Vorstands der Porsche Automobil Holding SE und zuständig für Finanzen und IT. Stephan Hützen ist CIO von Qiagen. Foto: Qiagen Stephan Hützen ist Vice President Global IT bei Qiagen. Das Unternehmen bietet Probenvorbereitungs- und Testtechnologien für die molekulare Diagnostik, akademische Forschung, pharmazeutische Industrie und angewandte Testverfahren an. Christian Niederhagemann ist CIO bei Rheinmetall. Foto: Gea Group Die Geschäfte der Rheinmetall IT Solutions GmbH werden seit September 2024 durch Christian Niederhagemann (CIO) geführt. Florian Roth ist Chief Digital und Information Officer bei SAP. Foto: SAP Florian Roth ist seit Januar 2019 Chief Digital und Information Officer der SAP SE in Walldorf und berichtet direkt an Sabine Bendiek, Chief People & Operating Officer und Mitglied des SAP Vorstandes. In seiner Funktion als Chief Digital und Information Officer (CDIO) vertritt er die Intelligent Enterprise Solutions (IES) Organisation als Trusted Advisor und ist verantwortlich für die IT-Strategie und deren Umsetzung. Roth ist seit 2005 bei SAP tätig und hatte vor seiner jetzigen Funktion verschiedene Führungspositionen in den Bereichen Finanzen, Service und Support sowie Global Business Operations inne. Torsten Müller ist CIO von Sartorius. Foto: Torsten Müller Seit November 2018 ist Torsten Müller Head of Information Technology (CIO) beim Pharma- und Laborzulieferer Sartorius AG mit Sitz in Göttingen. Zuvor war er Chief Digital Officer und Chief Information Officer sowie Mitglied der Geschäftsleitung der Versicherung Helvetia Deutschland in Frankfurt. Hanna Hennig ist CIO von Siemens. Foto: Siemens AG Hanna Hennig ist seit Januar 2020 CIO der Siemens AG . Sie kommt von Osram. Beim Lichtkonzern war Sie seit Juli 2018 CIO. Davor arbeitete Sie bei E.ON. Dort war sie seit Dezember 2013 als Geschäftsführerin der E.ON Business Services GmbH in München für die weltweite Versorgung von IT-Dienstleistungen der E.ON und Uniper Gruppe verantwortlich. Kian Mossanen ist CIO von Siemens Energy. Foto: Frank Erpinar Siemens Energy : Kian Mossanen hat 2020 die IT-Leitung der neuen Energie-Tochter des Siemens-Konzerns übernommen. mehr erfahren Siemens-Healthineers-CIO Stefan Henkel Foto: Foto Vogt Stefan Henkel ist seit 2016 Head of IT von Siemens Healthineers. Der Manager ist bereits seit 1996 im Siemens-Konzern tätig und hatte zuvor diverse IT-Führungspositionen bei Siemens und Siemens Healthcare inne. Stefan Tittel ist CIO von Symrise. Foto: Symrise Stefan Tittel ist seit 2018 CIO und Corporate Vice President Group IT von Kosmetikhersteller Symrise. Davor hatte er die CIO-Posten beim dänischen Elektronikhersteller NKT und dem Logistikunternehmen CWS inne. Hauke Stars ist CIO im Volkswagen-Konzern. Foto: Volkswagen AG Im Konzernvorstand von Volkswagen hat Hauke Stars im Februar 2022 das Ressort IT und Organisation übernommen. mehr erfahren Karsten Rech ist CIO von Vonovia. Foto: Vonovia Karsten Rech ist seit 2015 CIO und Process Office des Wohnungskonzerns Vonovia SE . Seit 2005 war er CIO der Deutsche Annington. Rech sammelte Erfahrung als Geschäftsführer und Aufsichtsrat diverser Tochtergesellschaften. Seine Schwerpunkte liegen im IT-Management, der Geschäftsprozessoptimierung und der Post Merger Integration. Meg Greenhouse verantwortet die IT-Infrastruktur bei Zalando. Foto: Zalando SE Meg Greenhouse ist SVP Zalando Technology Foundation und verantwortet die IT-Infrastruktur des Unternehmens. Dazu gehören unter anderem die Digital Workplace-Lösungen zur Verbesserung des Arbeitsalltages, Finanzlösungen, zentrale Datenplattformen und die Informationssicherheit aller virtuellen Vermögenswerte von Zalando. Meg Greenhouse startete im September 2017 als VP Corporate Technology bei Zalando. Andreas Hubert Foto: Adidas Andreas Hubert ist seit Februar 2021 Group CIO von Adidas. Catherine Jestin ist CIO und Executive VP Digital und Information Management bei Airbus. Foto: Airbus Seit März 2020 hat Catherine Jestin den CIO-Posten bei Airbus SE inne. Im Juli 2021 wurde sie zudem zum Executive Vice President Digital and Information Management berufen. Olav Spiegel ist CIO der Allianz SE. Foto: Allianz Seit 1. November 2023 hat der Versicherungskonzern Allianz mit Olav Spiegel einen neuen Group Chief Information Officer an Bord. Er folgt auf Ralf Schneider. mehr erfahren BASF hat keinen CIO mehr. Foto: 360b – shutterstock.com Nachdem Stefan Beck zum SVP Digitalization of Workspace and Collaboration aufgestiegen ist wird BASF die Rolle des Chief Information Officer (CIO) nicht weiter beibehalten. Bijoy Sagar ist CIO der Bayer AG. Foto: Bayer AG Bijoy Sagar ist seit 1. Juni 2020 Leiter IT und Digitale Transformation bei Bayer . Er soll die Digitalisierung des Pharmakonzerns vorantreiben und die begonnene Neuaufstellung der IT ans Ziel führen. Sagar wird an den Finanzvorstand Wolfgang Nickl berichten. Annette Hamann ist CIO von Baiersdorf. Foto: Beiersdorf Annette Hamann ist CIO und Managing Director BSS IT bei der Hamburger Beiersdorf AG . Alexander Buresch ist CIO der BMW Group. Foto: BMW AG Der Nachfolger von Klaus Straub im Amt des CIO der BMW Group heißt Alexander Buresch. Der Wirtschaftswissenschaftler ist seit mehr als 20 Jahren für tätig und war zuletzt Vice President Corporate Strategy and Planning. Intern wird erwartet, dass Buresch die von Klaus Straub verfolgte IT-Strategie fortführt. Stefan Haverkock ist CIO bei Brenntag. Foto: Brenntag Stefan Haverkock ist seit Januar 2019 VP IT Corporate & EMEA beim Chemiedistributor Brenntag. Er wechselte 2016 in das Unternehmen, nachdem er sieben Jahre bei Baustoffhersteller Knauf in verschiedenen leitenden IT-Positionen gearbeitet hatte. Haverkock berichtet an den CEO des Unternehmens. Heiko Burdack ist CTO der Commerzbank. Foto: Heiko Burdack Der CIO der Signal Iduna Gruppe, Heiko Burdack, wechselte zum 1. Februar 2023 als Chief Technology Officer zur Commerzbank. mehr erfahren Walter Grüner ist CIO bei Covestro. Foto: Covestro Walter Grüner ist seit Mai 2019 Head of Information Technology beim Chemieunternehmen Covestro in Leverkusen. Er berichtet direkt an den CFO Thomas Toepfer. Zuvor war Grüner seit 2013 als Group CIO bei der Kion Group AG tätig. Beim Frankfurter Anbieter von Gabelstapler und Lagertechnik hat er die Globalisierung der IT und die Digitalisierung vorangetrieben. Daimler Truck AG Mit Wirkung zum 1. Juni 2025 übernimmt Raghavendra Vaidya die Position des Chief Information Officer bei Daimler Truck. Er tritt die Nachfolge von Marcus Claesson an, der das Unternehmen auf eigenen Wunsch verlässt. mehr erfahren Bernd Leukert ist seit 2020 im Vorstand der Deutschen Bank. Foto: Mario Andreya Bernd Leukert wurde am 1. Januar 2020 Vorstand für Technologie, Daten und Innovation der Deutschen Bank . Von 2014 bis 2019 war Leukert Technikvorstand bei SAP , wo er 1994 seine Karriere begann. Christoph Böhm ist CIO der Deutschen Börse. Foto: COMPUTERWOCHE/Foto Vogt CIO und COO der Deutsche Börse AG ist seit November 2018 Christoph Böhm . Er wechselt von der SAP AG, wo er als Senior Vice President, Global Cloud Services, arbeitet. Der promovierte Elektroingenieur Böhm war von April 2011 bis Oktober 2014 CIO bei Vodafone. Er kam damals als CEO von der Active Billing GmbH & Co. KG, einer Tochtergesellschaft der Deutschen Telekom. Davor arbeitete er in führenden Positionen bei der Signal Iduna-Gruppe, der Deutschen Post AG und AT&T. Vorgänger Andreas Preuß geht voraussichtlich im Mai 2019 in den Ruhestand. Bernd Gemein ist CIO im Bereich PeP der Deutschen Post. Foto: Deutsche Post Seit September 2018 ist Bernd Gemein CIO für den Unternehmensbereich Post, E-Commerce, Parcel (PeP) bei der Deutschen Post DHL. Gemein berichtet an PeP-COO Tobias Meyer. Zu seinen wichtigsten anstehenden Aufgaben sagte Gemein, derzeit sei vor allem wichtig, eine positive Ergebnisentwicklung in den Jahren 2019 und 2020 sicherzustellen. Dazu gehöre die weitere Verbesserung der Produktivität und der indirekten Kosten sowie des Ertragsmanagements im Post- und Paketgeschäft. Peter Leukert ist CIO der Deutschen Telekom. Foto: Deutsche Telekom Sprecher der Geschäftsführung der Deutsche Telekom IT GmbH und damit CIO ist seit Januar 2017 Peter Leukert. Er wechselt von Motive Partners – einem Fintech Start-up, das er selbst mit gegründet hat. Zuvor war Leukert CIO der Commerzbank und von NYSE Euronext. 2011 wurde er zum “CIO des Jahres” gewählt. Zum 1. September 2025 wechselt Leukert als Chief Digital Officer zu BT. Sebastian Weber ist CTO von Eon. Foto: Eon Seit 1. Juli 2021 verantwortet Sebastian Weber als CTO bei Eon den IT-Betrieb. Er soll auch die digitalen Plattformen des Konzerns ausbauen. Zudem hat er gemeinsam mit Christopher d’Arcy in einer Doppelspitze die Geschäftsführung der IT-Tochter Eon Digital Technology GmbH übernommen. Beide berichten direkt an Digitalvorständin Victoria Ossadnik. Ingo Elfering ist CIO der Fresenius Gruppe. Foto: Fresenius Seit Juli 2020 besetzt Ingo Elfering den neu geschaffenen CIO-Posten bei der Fresenius Gruppe . Der gelernte Wirtschaftsinformatiker soll die globalen IT-Aktivitäten des Konzerns koordinieren und weiterentwickeln. Zudem übernimmt er die Leitung der IT-Dienstleistungstochter Fresenius Digital Technology. Elfering berichtet an Finanzvorstand Rachel Empey. Jürgen Stoffel ist CIO der Hannover Rück. Foto: Hannover Rück SE Hannover Rück: Jürgen Stoffel ist CIO beim weltweit drittgrößten Rückversicherer. Der bisherige CIO Fuchs ging 2014 in den Ruhestand. mehr erfahren Dennis Lentz ist CIO bei HeidelbergCement. Foto: HeidelbergCement Bereits seit Januar 2017 ist Dennis Lentz neuer Director Group IT/CIO beim Baustoffkonzern HeidelbergCement AG. Zuvor war er unter anderem Project Leader bei der Unternehmensberatung Boston Consulting und Project Leader und Leiter Supply Chain Management in Deutschland bei der HeidelbergCement AG. Michael Nilles ist CDIO von Henkel. Foto: Henkel Henkel hat Michael Nilles am 1. Oktober 2019 zum Chief Digital and Information Officer (CDIO) ernannt. Er berichtet direkt an Carsten Knobel, CEO von Henkel. In seiner Position ist Nilles für die Bereiche Digital, IT, Geschäftsprozessmanagement und Corporate Venture Capital verantwortlich. Harsha Deshmukh ist CIO bei Infineon. Foto: Infineon Technologies AG Seit dem Dezember 2021 ist Harsha Deshmukh CIO bei Infineon . Der IT-Chef kommt aus den eigenen Reihen. Er soll unter anderem die IT-Landschaft weiterentwickeln und die Kundenansprache verbessern. mehr erfahren Katrin Lehmann ist Group CIO bei Mercedes-Benz. Foto: Mercedes-Benz Als CIO der Mercedes-Benz Group AG und der Mercedes-Benz AG verantwortet Katrin Lehmann die globale IT für alle Geschäftsbereiche, Marken und Märkte und berichtet direkt an den CEO. mehr erfahren Merck Healthcare-CIO Alessandro de Luca. Foto: Hasan Baran Özkan Merck besetzt Anfang Dezember 2021 im Senior Leadership Team vier Positionen neu. Dazu zählt auch die Beförderung von Alessandro de Luca. Der bisherige CIO Healthcare hatte interimsmäßig als Group CIO gearbeitet und wird diese Funktion dauerhaft übernehmen. Gleichzeitig ist de Luca Leiter Information Technology. Er berichtet an Marcus Kuhnert, der als Chief Financial Officer (CFO) in der Geschäftsleitung sitzt. Lutz Seidenfaden ist CIO bei MTU Aero Engines Foto: Lutz Seidenfaden Lutz Seidenfaden ist seit Juni 2020 CIO (SVP Information Technology) beim Münchner Treibwerk-Hersteller MTU Aero Engines. Seidenfaden kommt von Industrieunternehmen Festo, wo er zuletzt die Stelle des Head of IT Services besetzte. Seine Vorgängerin Pamela Herget-Wehlitz wechselte zur Personalberatung JBH-Herget als Managing Partner. Robin Johnson ist CIO bei Munich Re. Foto: Maersk Robin Johnson ist seit April 2017 CIO beim Münchener Rückversicherer Munich Re . Er übernahm damit als Nachfolger von Rainer Janßen die Leitung des Zentralbereichs Information Technology. Zuvor arbeitete Johnson als CIO bei Maersk Line und Head of Maersk Group Infrastructure Services in Kopenhagen. Vor seinem Wechsel zu Maersk arbeitete Johnson von 2008 bis 2012 als Global CIO beim US-Computerhersteller Dell in Austin, Texas. Mattias Ulbrich ist CIO von Porsche. Foto: Porsche Mattias Ulbrich hat seit 1. September 2018 den CIO-Posten beim Automobilbauer Porsche inne. Seit 2019 ist er zudem Geschäftsführer der IT-Tochter Porsche Digital. Davor hatte der Manager verschiedene leitende IT-Positionen bei Audi, Volkswagen und Seat inne. Johannes Lattwein ist im Vorstand der Porsche Automobil Holding SE für IT zuständig. Foto: Porsche Automobil Holding SE Johannes Lattwein ist seit Februar 2022 Mitglied des Vorstands der Porsche Automobil Holding SE und zuständig für Finanzen und IT. Stephan Hützen ist CIO von Qiagen. Foto: Qiagen Stephan Hützen ist Vice President Global IT bei Qiagen. Das Unternehmen bietet Probenvorbereitungs- und Testtechnologien für die molekulare Diagnostik, akademische Forschung, pharmazeutische Industrie und angewandte Testverfahren an. Christian Niederhagemann ist CIO bei Rheinmetall. Foto: Gea Group Die Geschäfte der Rheinmetall IT Solutions GmbH werden seit September 2024 durch Christian Niederhagemann (CIO) geführt. Florian Roth ist Chief Digital und Information Officer bei SAP. Foto: SAP Florian Roth ist seit Januar 2019 Chief Digital und Information Officer der SAP SE in Walldorf und berichtet direkt an Sabine Bendiek, Chief People & Operating Officer und Mitglied des SAP Vorstandes. In seiner Funktion als Chief Digital und Information Officer (CDIO) vertritt er die Intelligent Enterprise Solutions (IES) Organisation als Trusted Advisor und ist verantwortlich für die IT-Strategie und deren Umsetzung. Roth ist seit 2005 bei SAP tätig und hatte vor seiner jetzigen Funktion verschiedene Führungspositionen in den Bereichen Finanzen, Service und Support sowie Global Business Operations inne. Torsten Müller ist CIO von Sartorius. Foto: Torsten Müller Seit November 2018 ist Torsten Müller Head of Information Technology (CIO) beim Pharma- und Laborzulieferer Sartorius AG mit Sitz in Göttingen. Zuvor war er Chief Digital Officer und Chief Information Officer sowie Mitglied der Geschäftsleitung der Versicherung Helvetia Deutschland in Frankfurt. Hanna Hennig ist CIO von Siemens. Foto: Siemens AG Hanna Hennig ist seit Januar 2020 CIO der Siemens AG . Sie kommt von Osram. Beim Lichtkonzern war Sie seit Juli 2018 CIO. Davor arbeitete Sie bei E.ON. Dort war sie seit Dezember 2013 als Geschäftsführerin der E.ON Business Services GmbH in München für die weltweite Versorgung von IT-Dienstleistungen der E.ON und Uniper Gruppe verantwortlich. Kian Mossanen ist CIO von Siemens Energy. Foto: Frank Erpinar Siemens Energy : Kian Mossanen hat 2020 die IT-Leitung der neuen Energie-Tochter des Siemens-Konzerns übernommen. mehr erfahren Siemens-Healthineers-CIO Stefan Henkel Foto: Foto Vogt Stefan Henkel ist seit 2016 Head of IT von Siemens Healthineers. Der Manager ist bereits seit 1996 im Siemens-Konzern tätig und hatte zuvor diverse IT-Führungspositionen bei Siemens und Siemens Healthcare inne. Stefan Tittel ist CIO von Symrise. Foto: Symrise Stefan Tittel ist seit 2018 CIO und Corporate Vice President Group IT von Kosmetikhersteller Symrise. Davor hatte er die CIO-Posten beim dänischen Elektronikhersteller NKT und dem Logistikunternehmen CWS inne. Hauke Stars ist CIO im Volkswagen-Konzern. Foto: Volkswagen AG Im Konzernvorstand von Volkswagen hat Hauke Stars im Februar 2022 das Ressort IT und Organisation übernommen. mehr erfahren Karsten Rech ist CIO von Vonovia. Foto: Vonovia Karsten Rech ist seit 2015 CIO und Process Office des Wohnungskonzerns Vonovia SE . Seit 2005 war er CIO der Deutsche Annington. Rech sammelte Erfahrung als Geschäftsführer und Aufsichtsrat diverser Tochtergesellschaften. Seine Schwerpunkte liegen im IT-Management, der Geschäftsprozessoptimierung und der Post Merger Integration. Meg Greenhouse verantwortet die IT-Infrastruktur bei Zalando. Foto: Zalando SE Meg Greenhouse ist SVP Zalando Technology Foundation und verantwortet die IT-Infrastruktur des Unternehmens. Dazu gehören unter anderem die Digital Workplace-Lösungen zur Verbesserung des Arbeitsalltages, Finanzlösungen, zentrale Datenplattformen und die Informationssicherheit aller virtuellen Vermögenswerte von Zalando. Meg Greenhouse startete im September 2017 als VP Corporate Technology bei Zalando.",
    "source": "cio",
    "crawled_at": "2025-05-28T09:16:53.101398+00:00"
  },
  {
    "url": "https://www.cio.de/article/3661554/die-top-cios-der-automobil-industrie.html",
    "title": "Die Top-CIOs der Automobil-Industrie",
    "published": "2025-05-25T10:53:32+00:00",
    "author": "",
    "text": "Daimler Truck AG Mit Wirkung zum 1. Juni 2025 übernimmt Raghavendra Vaidya die Position des CIO bei Daimler Truck. Er tritt die Nachfolge von Marcus Claesson an, der das Unternehmen auf eigenen Wunsch verlässt. mehr erfahren Mercedes-Benz Seit März 2025 verantwortet Rouven Rüdenauer die IT von Mercedes-Benz Vans. Er stieg innerhalb des Konzerns auf. mehr erfahren Michael Stening Skoda Nach zwei Jahren im Amt kehrt Skoda-CIO Alexander Eisl zum MAN-Konzern zurück und übergibt die IT-Leitung an Michael Stening. mehr erfahren Frank Erpinar Seit Januar 2025 ist Thomas Buck Group CIO bei der ZF Group. Er war zuvor Group CIO bei Vitesco Technologies und bei Continental als Automotive CIO tätig. Petra Clemens Foto: Cariad Seit Oktober 2024 leitet Petra Clemens die IT von Cariad, der Software-Tochter von Volkswagen. Sie kommt vom Eisenbahnlogistiker VTG. mehr erfahren Katrin Lehmann Foto: Mercedes-Benz Als CIO der Mercedes-Benz Group AG und der Mercedes-Benz AG verantwortet Katrin Lehmann die globale IT für alle Geschäftsbereiche, Marken und Märkte und berichtet direkt an den CEO. mehr erfahren Volker Schwarz Foto: GKN Automotive Limited Der langjährige Rheinmetall-CIO Volker Schwarz ist seit Januar 2024 CIO beim Automobilzulieferer GKN Automotive. mehr erfahren Falko Morlock Foto: Dürr AG Seit 1. September ist Falko Morlock CIO des schwäbischen Maschinen- und Anlagenbauers Dürr AG. mehr erfahren Martin Hofmann ist CTO und CIO bei Volta Trucks. Foto: Raimar von Wienskowski Martin Hofmann, vormals CIO von VW, geht nach dreijähriger Zwischenstation bei Salesforce als CTO und CIO zum schwedischen Automobil-Startup Volta Trucks. mehr erfahren Simon Blankenstein ist CIO der Huf Group. Foto: Johnson Controls Seit Oktober 2022 verantwortet Blankenstein als CIO die IT der Huf Group. Er berichtet an den CFO. Zu seinen wichtigsten Aufgaben gehört der weltweite Rollout von SAP S/4 HANA. mehr erfahren Saskia Kohlhaas ist CO bei IAV. Foto: Saskia Kohlhaas IAV Saskia Kohlhaas ist seit November 2021 Senior Vice President Information Technology beim Engineering-Dienstleister der Automobilindustrie IAV. Ihr Vorgänger beim Engineering-Dienstleister für die Automobilindustrie, Christian Müller-Bagehl, hat sich als Senior Consultant in Berlin selbstständig gemacht. mehr erfahren Sebastian Stoll ist CIO der FEV Group. Foto: Sebastian Stoll Seit 1. Juni 2021 ist Sebastian Stoll CIO und Group Vice President IT der FEV Gruppe. Er hat den Posten von Andreas Engels übernommen , der beim Kölner Compliance-Startup Kerberos eingestiegen ist. Stoll berichtet an CFO Jürgen Koopsingraven. Der neue CIO will zum einen die von Engels begonnene Implementierung von SAP S/4 Hana weiterführen. Zum anderen soll die IT-Sicherheit von FEV gestärkt werden. Im Zuge dessen forciert Stoll auch die Cloud-Migration und das Sourcing optimieren. In einem weiteren großen Projekt soll Stoll die IT auf digitale Geschäftsmodelle ausrichten. mehr erfahren Alexander Buresch ist CIO der BMW Group. Foto: BMW Group Der Nachfolger von Klaus Straub im Amt des CIO der BMW Group heißt Alexander Buresch. Er trat das Amt zum 1. Januar 2020 an. Der Wirtschaftswissenschaftler ist seit über 20 Jahren für BMW tätig und war zuletzt Vice President Corporate Strategy and Planning. Intern wird erwartet, dass Buresch die von Klaus Straub verfolgte IT-Strategie fortführt. mehr erfahren André Wehner ist CIO von MAN Truck & Bus. Foto: MAN Truck & Bus Am 1. Juni 2021 hat André Wehner den CIO-Posten bei MAN Truck & Bus übernommen. Als IT-Chef verantwortet Wehner die weltweite IT des Nutzfahrzeugherstellers. Dazu zählen auch Produktionswerke, Logistikzentren und die eigenen Landesvertriebsgesellschaften. Sein Vorgänger Stephan Fingerling geht als Geschäftsführer zur Group IT Services GmbH, der IT-Tochter der Volkswagen Gruppe. Vor seinem Wechsel zum Münchner Nutzfahrzeughersteller war Wehner CDO bei Skoda Auto. In der neu geschaffenen Stelle kümmerte er sich dort seit 2016 um Unternehmensentwicklung. mehr erfahren Maik Krüger wechselt von BMW zu Dräxlmaier. Foto: BMW Am 1. April trat Maik Krüger die Position des CIO bei Dräxlmaier an. Der studierte Wirtschaftsinformatiker war jahrelang in führenden IT-Positionen bei BMW tätig, zuletzt zeichnete er für die IT des Shop-Floors verantwortlich. Der designierte CIO hat sich für den neuen Arbeitgeber entschieden, weil es ihm imponiert habe, “wie exzellent das Familienunternehmen mit seiner Internationalität und seinem Produktportfolio aufgestellt ist”. Michael Simon ist CIO der VW Group Retail Deutschland GmbH. Foto: Simon Seit 1. Juli 2019 ist Michael Simon Leiter Zentral IT und CIO der Volkswagen Retail Group. Er berichtet an die Geschäftsführung. Zuvor war der studierte Informatiker seit 2015 Leiter IT bei der Weiss Umwelttechnik GmbH. Insgesamt bringt er Erfahrung aus drei Jahrzehnten als Fach- und Führungskraft in der IT mit, unter anderem bei der Salzgitter AG Group. Michael Hilzinger wechselt von Klöckner zu Knorr-Bremse. Foto: Foto Vogt Michael Hilzinger, bisher Group CIO beim Stahlhändler Klöckner in Duisburg, ist seit Juli 2019 CIO beim Bremsen-Spezialisten Knorr-Bremse in München und damit Nachfolger von Helmut Draxler . Bernd Süßmann ist Head of Corporate IT bei der SAS Automotive. Foto: SAS Automotive Bernd Süßmann ist seit September 2018 Head of Corporate IT bei der SAS Automotive in Karlsruhe, einem Joint Venture zwischen Continental and Faurecia. Er trägt dort die Gesamtverantwortung für die IT, führt dabei 80 Mitarbeiter und berichtet an den CFO des Unternehmens, Ekkehard Klautke. Bernhard Pluhatsch ist Head of IT bei Magna Powertrain Transmission Systems. Foto: Magna Bernhard Pluhatsch ist seit Oktober 2018 Head of IT, Transmission Systems bei Magna Powertrain Transmission Systems (MPT TS) in Untergruppenbach bei Heilbronn. Er kommt von der Leoni AG, wo er von 2002 bis 2018 Vice President IT Infrastruktur war. Leoni ist Hersteller von Drähten, Kabeln und Bordnetz-Systemen in Nürnberg. Ex-Porsche-CIO Sven Lorenz ist CPO im Volkswagen-Konzern. Foto: Porsche Sven Lorenz, fast 17 Jahre lang CIO beim Sportwagenhersteller Porsche in Stuttgart-Zuffenhausen, hat eine neue Aufgabe im VW-Konzern übernommen: Mit Wirkung zum Oktober 2018 wurde er Chief Process Officer. Die Stelle ist neu. Als CPO verantwortet Lorenz die konzernweite, also marken- und bereichsübergreifende Prozessharmonisierung, zwischen IT und Fachbereichen. Hintergrund: Mattias Ulbrich, Ex-CIO der Audi AG, wurde im September 2018 neuer CIO bei Porsche. Felix Willing ist CIO bei Hella. Foto: Hella Felix Willing hat Anfang Januar 2018 die Leitung des Bereichs Information Management beim Automobilzulieferer Hella GmbH & Co. KGaA im nordrhein-westfälischen Lippstadt übernommen. In dieser Position fungiert er zugleich als CIO für den globalen Hella Konzern. Zuletzt war er CIO beim Windturbinenbauer Nordex Acciona Windpower AG in Hamburg. Frank Loydl ist CIO der Audi AG. Foto: Audi AG CIO der Audi AG und damit Nachfolger von Mattias Ulbrich ist seit Februar 2018 Frank Loydl. Seit 2016 verantwortete er im Konzern die Software-Entwicklung. Ab 2009 war er bei T-Systems das Delivery Management für den Kunden Volkswagen AG zuständig. Diese Aufgabe übernahm Loydl 2013 schließlich direkt für den Automobilkonzern. Thomas Külpp arbeitet seit 27 Jahren bei Opel – nun als CIO der Opel Automobile GmbH. Foto: Opel Seit Anfang August 2017 ist Thomas Külpp CIO beim Autobauer Opel Automobile GmbH in Rüsselsheim. Zuvor war er bei Opel Director Sales & Marketing. Külpp hat Maschinenbau an der University of Applied Sciences in Wiesbaden studiert und als Diplom-Ingenieur abgeschlossen. Er arbeitet bereits seit 27 Jahren in verschiedenen Positionen bei Opel. Daimler Truck AG Mit Wirkung zum 1. Juni 2025 übernimmt Raghavendra Vaidya die Position des CIO bei Daimler Truck. Er tritt die Nachfolge von Marcus Claesson an, der das Unternehmen auf eigenen Wunsch verlässt. mehr erfahren Mercedes-Benz Seit März 2025 verantwortet Rouven Rüdenauer die IT von Mercedes-Benz Vans. Er stieg innerhalb des Konzerns auf. mehr erfahren Michael Stening Skoda Nach zwei Jahren im Amt kehrt Skoda-CIO Alexander Eisl zum MAN-Konzern zurück und übergibt die IT-Leitung an Michael Stening. mehr erfahren Frank Erpinar Seit Januar 2025 ist Thomas Buck Group CIO bei der ZF Group. Er war zuvor Group CIO bei Vitesco Technologies und bei Continental als Automotive CIO tätig. Petra Clemens Foto: Cariad Seit Oktober 2024 leitet Petra Clemens die IT von Cariad, der Software-Tochter von Volkswagen. Sie kommt vom Eisenbahnlogistiker VTG. mehr erfahren Katrin Lehmann Foto: Mercedes-Benz Als CIO der Mercedes-Benz Group AG und der Mercedes-Benz AG verantwortet Katrin Lehmann die globale IT für alle Geschäftsbereiche, Marken und Märkte und berichtet direkt an den CEO. mehr erfahren Volker Schwarz Foto: GKN Automotive Limited Der langjährige Rheinmetall-CIO Volker Schwarz ist seit Januar 2024 CIO beim Automobilzulieferer GKN Automotive. mehr erfahren Falko Morlock Foto: Dürr AG Seit 1. September ist Falko Morlock CIO des schwäbischen Maschinen- und Anlagenbauers Dürr AG. mehr erfahren Martin Hofmann ist CTO und CIO bei Volta Trucks. Foto: Raimar von Wienskowski Martin Hofmann, vormals CIO von VW, geht nach dreijähriger Zwischenstation bei Salesforce als CTO und CIO zum schwedischen Automobil-Startup Volta Trucks. mehr erfahren Simon Blankenstein ist CIO der Huf Group. Foto: Johnson Controls Seit Oktober 2022 verantwortet Blankenstein als CIO die IT der Huf Group. Er berichtet an den CFO. Zu seinen wichtigsten Aufgaben gehört der weltweite Rollout von SAP S/4 HANA. mehr erfahren Saskia Kohlhaas ist CO bei IAV. Foto: Saskia Kohlhaas IAV Saskia Kohlhaas ist seit November 2021 Senior Vice President Information Technology beim Engineering-Dienstleister der Automobilindustrie IAV. Ihr Vorgänger beim Engineering-Dienstleister für die Automobilindustrie, Christian Müller-Bagehl, hat sich als Senior Consultant in Berlin selbstständig gemacht. mehr erfahren Sebastian Stoll ist CIO der FEV Group. Foto: Sebastian Stoll Seit 1. Juni 2021 ist Sebastian Stoll CIO und Group Vice President IT der FEV Gruppe. Er hat den Posten von Andreas Engels übernommen , der beim Kölner Compliance-Startup Kerberos eingestiegen ist. Stoll berichtet an CFO Jürgen Koopsingraven. Der neue CIO will zum einen die von Engels begonnene Implementierung von SAP S/4 Hana weiterführen. Zum anderen soll die IT-Sicherheit von FEV gestärkt werden. Im Zuge dessen forciert Stoll auch die Cloud-Migration und das Sourcing optimieren. In einem weiteren großen Projekt soll Stoll die IT auf digitale Geschäftsmodelle ausrichten. mehr erfahren Alexander Buresch ist CIO der BMW Group. Foto: BMW Group Der Nachfolger von Klaus Straub im Amt des CIO der BMW Group heißt Alexander Buresch. Er trat das Amt zum 1. Januar 2020 an. Der Wirtschaftswissenschaftler ist seit über 20 Jahren für BMW tätig und war zuletzt Vice President Corporate Strategy and Planning. Intern wird erwartet, dass Buresch die von Klaus Straub verfolgte IT-Strategie fortführt. mehr erfahren André Wehner ist CIO von MAN Truck & Bus. Foto: MAN Truck & Bus Am 1. Juni 2021 hat André Wehner den CIO-Posten bei MAN Truck & Bus übernommen. Als IT-Chef verantwortet Wehner die weltweite IT des Nutzfahrzeugherstellers. Dazu zählen auch Produktionswerke, Logistikzentren und die eigenen Landesvertriebsgesellschaften. Sein Vorgänger Stephan Fingerling geht als Geschäftsführer zur Group IT Services GmbH, der IT-Tochter der Volkswagen Gruppe. Vor seinem Wechsel zum Münchner Nutzfahrzeughersteller war Wehner CDO bei Skoda Auto. In der neu geschaffenen Stelle kümmerte er sich dort seit 2016 um Unternehmensentwicklung. mehr erfahren Maik Krüger wechselt von BMW zu Dräxlmaier. Foto: BMW Am 1. April trat Maik Krüger die Position des CIO bei Dräxlmaier an. Der studierte Wirtschaftsinformatiker war jahrelang in führenden IT-Positionen bei BMW tätig, zuletzt zeichnete er für die IT des Shop-Floors verantwortlich. Der designierte CIO hat sich für den neuen Arbeitgeber entschieden, weil es ihm imponiert habe, “wie exzellent das Familienunternehmen mit seiner Internationalität und seinem Produktportfolio aufgestellt ist”. Michael Simon ist CIO der VW Group Retail Deutschland GmbH. Foto: Simon Seit 1. Juli 2019 ist Michael Simon Leiter Zentral IT und CIO der Volkswagen Retail Group. Er berichtet an die Geschäftsführung. Zuvor war der studierte Informatiker seit 2015 Leiter IT bei der Weiss Umwelttechnik GmbH. Insgesamt bringt er Erfahrung aus drei Jahrzehnten als Fach- und Führungskraft in der IT mit, unter anderem bei der Salzgitter AG Group. Michael Hilzinger wechselt von Klöckner zu Knorr-Bremse. Foto: Foto Vogt Michael Hilzinger, bisher Group CIO beim Stahlhändler Klöckner in Duisburg, ist seit Juli 2019 CIO beim Bremsen-Spezialisten Knorr-Bremse in München und damit Nachfolger von Helmut Draxler . Bernd Süßmann ist Head of Corporate IT bei der SAS Automotive. Foto: SAS Automotive Bernd Süßmann ist seit September 2018 Head of Corporate IT bei der SAS Automotive in Karlsruhe, einem Joint Venture zwischen Continental and Faurecia. Er trägt dort die Gesamtverantwortung für die IT, führt dabei 80 Mitarbeiter und berichtet an den CFO des Unternehmens, Ekkehard Klautke. Bernhard Pluhatsch ist Head of IT bei Magna Powertrain Transmission Systems. Foto: Magna Bernhard Pluhatsch ist seit Oktober 2018 Head of IT, Transmission Systems bei Magna Powertrain Transmission Systems (MPT TS) in Untergruppenbach bei Heilbronn. Er kommt von der Leoni AG, wo er von 2002 bis 2018 Vice President IT Infrastruktur war. Leoni ist Hersteller von Drähten, Kabeln und Bordnetz-Systemen in Nürnberg. Ex-Porsche-CIO Sven Lorenz ist CPO im Volkswagen-Konzern. Foto: Porsche Sven Lorenz, fast 17 Jahre lang CIO beim Sportwagenhersteller Porsche in Stuttgart-Zuffenhausen, hat eine neue Aufgabe im VW-Konzern übernommen: Mit Wirkung zum Oktober 2018 wurde er Chief Process Officer. Die Stelle ist neu. Als CPO verantwortet Lorenz die konzernweite, also marken- und bereichsübergreifende Prozessharmonisierung, zwischen IT und Fachbereichen. Hintergrund: Mattias Ulbrich, Ex-CIO der Audi AG, wurde im September 2018 neuer CIO bei Porsche. Felix Willing ist CIO bei Hella. Foto: Hella Felix Willing hat Anfang Januar 2018 die Leitung des Bereichs Information Management beim Automobilzulieferer Hella GmbH & Co. KGaA im nordrhein-westfälischen Lippstadt übernommen. In dieser Position fungiert er zugleich als CIO für den globalen Hella Konzern. Zuletzt war er CIO beim Windturbinenbauer Nordex Acciona Windpower AG in Hamburg. Frank Loydl ist CIO der Audi AG. Foto: Audi AG CIO der Audi AG und damit Nachfolger von Mattias Ulbrich ist seit Februar 2018 Frank Loydl. Seit 2016 verantwortete er im Konzern die Software-Entwicklung. Ab 2009 war er bei T-Systems das Delivery Management für den Kunden Volkswagen AG zuständig. Diese Aufgabe übernahm Loydl 2013 schließlich direkt für den Automobilkonzern. Thomas Külpp arbeitet seit 27 Jahren bei Opel – nun als CIO der Opel Automobile GmbH. Foto: Opel Seit Anfang August 2017 ist Thomas Külpp CIO beim Autobauer Opel Automobile GmbH in Rüsselsheim. Zuvor war er bei Opel Director Sales & Marketing. Külpp hat Maschinenbau an der University of Applied Sciences in Wiesbaden studiert und als Diplom-Ingenieur abgeschlossen. Er arbeitet bereits seit 27 Jahren in verschiedenen Positionen bei Opel.",
    "source": "cio",
    "crawled_at": "2025-05-28T09:16:53.744005+00:00"
  },
  {
    "url": "https://www.cio.de/article/3993385/bei-der-dkb-ubernimmt-der-ki-agent.html",
    "title": "Bei der DKB übernimmt der KI-Agent",
    "published": "2025-05-26T03:30:00+00:00",
    "author": "",
    "text": "DKB „Mit der IT-Strategie, die wir seit mehreren Jahren verfolgen, schaffen wir uns zunehmend mehr Freiheitsgrade, um uns in den Frontend-Systemen zu differenzieren“, berichtet Arnulf Keese, IT-Vorstand der Deutschen Kreditbank (DKB). Das bewerkstelligt das Finanzinstitut über einen API-Layer, der die Kernbank-Systeme im Backend und dem Frontendbereich verbindet. (Lesen Sie mehr dazu: „ IT-Vorstand Arnulf Keese: DKB teilt die IT in Schichten auf “) Diese Zwischenebene hat die DKB-IT laut Keese seither weiter ausgebaut, skaliert und für weitere Anwendungsfälle in der Bank genutzt. Einer dieser Use Cases ist die DKB-App sowie die 2024 gelaunchte neue Website samt Banking für die Endkunden. Keese: „Im Herbst 2024 haben wir die Legacy-Anwendungen im Frontend, die bis dahin noch parallel betrieben wurden, abgeschaltet und laufen seitdem komplett auf dem neuen Cloud-nativen technischen Stack, der von den Fortschritten der Hyperscaler-Architekturen profitiert.“ Die DKB verfolgt eine Multi-Cloud-Strategie – auch um frei entscheiden zu können, was auf welcher Plattform läuft. Ein Team aus Data Scientists arbeitet bereits seit Jahren an KI-Use-Cases innerhalb der DKB, so der IT-Vorstand: „So haben wir etwa vor einigen Jahren eine automatische Rechnungserkennung für die Buchhaltung entwickelt – da waren wir noch weit weg vom Kunden, haben aber viel gelernt, was das Training von Modellen angeht“, so Keese. Damals sei der Aufwand für das Training noch hoch gewesen. Heute böten die verfügbaren Foundational Models wesentlich mehr Möglichkeiten, schnell gute Ergebnisse zu erzielen. Abonnieren Sie unsere CIO-Newsletter für mehr spannende Interviews, Deep Dives und Best Practices aus der CIO-Community. In einem nächsten Schritt hat das Team aus E-Mails von Kunden mit Hilfe selbsttrainierter Modelle Emotionen herauslesen können. „Ziel war es, früh zu erkennen, ob ein Kunde im Customer-Service-Kontakt einen Notfall, ein allgemeines Problem, oder nur eine Frage hat, um die Anfrage anschließend in die richtigen Kanäle im Callcenter weiterleiten zu können.“ Für die DKB reduzierte das laut Keese den Aufwand, möglichst schnell die möglichst beste Antwort zu liefern – und die Kunden erhielten rascher Auskunft. Diese Lehrjahre haben der DKB geholfen, das Fundament für den „Digital Agent“ zu schaffen. Keese: „Wir müssen auf die Daten zugreifen können und brauchen dafür die richtigen Prozesse und Skills bei den Mitarbeitenden.“ Diese Grundlagenarbeit mündet in immer mehr Use Cases, die ohne das Fundament nicht funktionieren würden. Der KI-basierte Agent ist in der Microsoft-Azure-Welt entstanden. „Als wir vor eineinhalb Jahren angefangen haben, den KI-Agenten aufzubauen, waren die LLMs von ChatGPT dort am weitesten fortgeschritten“, so Keese. Heute hat die Bank zusätzlich mit Amazon Bedrock den Grundstein dafür gelegt, über mehrere Systeme hinweg operieren und entscheiden zu können, welches Sprachmodell wofür eingesetzt wird, um den Digital Agent betreiben zu können. Dabei spielen zum einen Anforderungen hinsichtlich der Resilienz eine Rolle. Zum anderen will die DKB in der Lage sein, im Hinblick auf die rasant fortschreitenden Innovationen im LLM-Markt immer auf dem besten Modell arbeiten zu können. „Daher haben wir intern auch eine hohe Wertschöpfungstiefe um das GPT herumgebaut, um etwa die Logik zu definieren, wie die Kundenanfragen bewertet werden oder welche Rohdatenquellen in die Antwort miteinfließen“, berichtet der Manager. Die DKB-IT wollte so sicherstellen, dass die von der KI ausgegebenen Antworten den Ansprüchen der Bank genügen. Keese sagt ganz klar an: „Die Antworten müssen korrekt sein, die Position des Hauses vertreten und sich auf den Sachverhalt beschränken. Wenn jemand beispielsweise den Agenten fragt, welche Aktien er kaufen soll, dann darf eine Bank dazu nichts sagen.“ Ein Beispiel: Fragt ein Kunde etwas zu den AGBs, könnte das Modell den Originaltext der AGBs zurückgeben. Da es sich dabei aber um juristische Texte handelt, sind sie nicht immer einfach verständlich. Dagegen sind einfache Antworten aus den FAQs des Finanzinstituts womöglich juristisch nicht korrekt. Die richtige Mischung aus den Fakten der AGBs und der Verständlichkeit der FAQs stellt die DKB-IT laut Keese mit der in den Agenten eingebauten Logik sicher. „Wenn ein Kunde eine Frage hat, wollen wir eine möglichst hohe Quote an fallabschließenden Antworten im allerersten Kundenkontakt.“ Wenn der Kunde das Gefühl habe, nur drei Textbausteine zusammengewürfelt zu bekommen, sei das frustrierend für ihn und ineffizient für die Bank. Keese: „Der Vorteil bei LLMs ist, dass, selbst wenn man dem Bot drei Textbausteine gibt, macht er daraus eine zusammenhängende Antwort in guter Sprache – und auf Wunsch auch in mehreren Sprachen.“ Der Agent kennt laut Keese auf Basis datenschutzrechtlicher Anforderungen die persönlichen Finanzprodukte der Kunden. Zudem greift er überwiegend auf bestehende Wissensbausteine zurück und ist mit diesen gezielt verbunden. Die Voraussetzung dafür ist eine interne Wissensplattform mit allen Informationen, die auch die realen Kundenbetreuer aktuell in ihrem Arbeitsalltag nutzen. Angereichert ist das Wissen des KI-Supports durch FAQs, Website-Daten und bestehende Textbausteine. Ende 2023 hatte sich die DKB-IT vorgenommen, den digitalen Agenten für die E-Mail-basierte Kundenkommunikation zu entwickeln. „Ziel war, bei Lastspitzen von Kundenanfragen gewohnt schnell und zielführend Auskunft geben zu können“, präzisiert der IT-Vorstand. Gerade bei Standardthemen, die keine ausführliche Beratung erfordern, wollte man die Kundschaft möglichst schnell zu gewünschten Ergebnis führen und den Kundendienst entlasten – dafür brauchte es Automatisierung. Nach einem Vergleich verschiedener LLMs und über 50 Chatbots am Markt fiel die Wahl auf ChatGPT als Sprachmodell. Der Chatbot wurde größtenteils inhouse selbst entwickelt, um den Datenfluss für die oben beschriebene Detailtiefe und Verständlichkeit in den Antworten zu gewährleisten. Im ersten Halbjahr 2024 begannen erste Pilotversuche. Nachdem anfängliche Schwierigkeiten überwunden sowie Governance und Regulatorik implementiert waren, begannen im Sommer 2024 die ersten Tests im Feld samt Verbesserungs-Iterationen auf Basis von Nutzerfeedback. Anschließend wurde die Lösung scharf geschaltet. „Da haben wir uns Use Case für Use Case vorgearbeitet und sind kurz vor Weihnachten 2024 in den vollständigen Rollout reingekommen“, beschreibt der IT-Chef sein Vorgehen. Im Laufe des Jahres 2025 werde er komplett ausgerollt. Mit dem Rollout des Tools startete die DKB in den öffentlich zugänglichen FAQs. Anschließend hatten eingeloggte Kunden darauf Zugriff und in einem dritten Schritt wurde es auf der Webseite und in die App implementiert. Zudem können Kunden innerhalb des Kontos Fragen etwa zu ihrem Account stellen. Für den Datenschutz sorgt das Finanzhaus, indem der Agent in einer geschützten Umgebung in einer EU-Souveränitätszone von Microsoft agiert. „Wichtiges Grundprinzip dabei ist, dass alles, was die Kunden uns fragen und was wir über den Agenten antworten, in keiner Weise in das Training der Modelle einfließt. Das ist garantiert und vertraglich mit dem Partner abgesichert“, führt Keese aus. Das LLM so nutzen zu können, ohne dabei das Modell zu trainieren, sei sehr wichtig, gerade im Umfeld von Bankgeheimnissen. Der „Lackmustest“ für die Güte des Chatbots ist für den IT-Chef die Zeit, bis der Kunde einen menschlichen Ansprechpartner will. Bei dem Digital Agent merke die DKB-IT in der anonymisierten Auswertung und stichprobenartigen Umfragen, dass die Interaktionsrate mit den Kunden hoch und die Aufforderung nach einem menschlichen Kontakt niedrig ist, was darauf schließen lasse, dass er einen zufriedenstellenden Job macht. „Das Besondere an dem Chatbot ist, dass sich die Kunden in einem echten Dialog befinden, der unendlich weitergeführt werden kann und sich aus allen relevanten, aktuell in der Bank verfügbaren Informationen speist“, führt der IT-Vorstand aus. Die meisten anderen Bot-Dialoge seien sehr regelbasiert in Wenn-Dann-Schleifen konzipiert und nach drei Fragen durchlaufen, danach müsse ein Mensch kontaktiert werden. „Wo wir gerade noch dran sind, ist die Dokumentenprüfung, wenn der Kunde bestimmte Produkte haben will. Hier experimentieren wir mit Teilautomatisierung – etwa bei der Überprüfung von Gehaltsnachweisen“, berichtet Keese. Dabei gehe es vor allem um Schnelligkeit, damit die Kunden möglichst früh eine Zusage für das angefragte Produkt erhielten. Solche Dinge seien insofern wichtig, weil die DKB laut Keese eine Tech-Bank ist und sein will. „Darum begleiten wir technologische Trends, investieren seit Jahren in Data Science und KI – und dadurch rollen wir jetzt immer mehr große und kleine Use Cases aus.“ Das forciere auch insgesamt den Fortschritt im Unternehmen. In vielen Abteilungen probierten Kolleginnen und Kollegen, Prozesse mit KI zu vereinfachen. „Das ist der Prozess der Demokratisierung”, zieht der IT-Chef Bilanz. “Da passiert viel an Stellen, die von außen vielleicht weniger einsehbar sind – etwa im Bereich ESG. Dort gibt es Bergeweise standardisierte Dokumente, wie etwa Energieausweise, bei denen es sträflich wäre, die Erkennung und Einsortierung nicht durch Automatisierung zu vereinfachen.“ Bei allen Effizienzgewinnen durch Automatisierung sei es jedoch wichtig, auch wegen regulatorischer Anforderungen, dass die Entscheidung am Ende immer noch ein Mensch trifft. Seit Mai 2025 hat die DKB zudem eine direkte Innovationskooperation mit OpenAI gestartet. Ein konkretes Projekt dieser Partnerschaft ist die Einführung einer KI-Sprachsteuerung im Banking, die den 5,8 Millionen Kundinnen und Kunden der Direktbank einen smarten Zugang zu Banking-Services ermöglichen soll. Zudem stellt OpenAI die Technologie zur Verfügung, um Agentic AI Workflows zu implementieren. Damit soll die komplexe Dokumentenverarbeitung und damit verbundene Prozesse für die Mitarbeitenden vereinfacht werden. DKB „Mit der IT-Strategie, die wir seit mehreren Jahren verfolgen, schaffen wir uns zunehmend mehr Freiheitsgrade, um uns in den Frontend-Systemen zu differenzieren“, berichtet Arnulf Keese, IT-Vorstand der Deutschen Kreditbank (DKB). Das bewerkstelligt das Finanzinstitut über einen API-Layer, der die Kernbank-Systeme im Backend und dem Frontendbereich verbindet. (Lesen Sie mehr dazu: „ IT-Vorstand Arnulf Keese: DKB teilt die IT in Schichten auf “) Diese Zwischenebene hat die DKB-IT laut Keese seither weiter ausgebaut, skaliert und für weitere Anwendungsfälle in der Bank genutzt. Einer dieser Use Cases ist die DKB-App sowie die 2024 gelaunchte neue Website samt Banking für die Endkunden. Keese: „Im Herbst 2024 haben wir die Legacy-Anwendungen im Frontend, die bis dahin noch parallel betrieben wurden, abgeschaltet und laufen seitdem komplett auf dem neuen Cloud-nativen technischen Stack, der von den Fortschritten der Hyperscaler-Architekturen profitiert.“ Die DKB verfolgt eine Multi-Cloud-Strategie – auch um frei entscheiden zu können, was auf welcher Plattform läuft. Ein Team aus Data Scientists arbeitet bereits seit Jahren an KI-Use-Cases innerhalb der DKB, so der IT-Vorstand: „So haben wir etwa vor einigen Jahren eine automatische Rechnungserkennung für die Buchhaltung entwickelt – da waren wir noch weit weg vom Kunden, haben aber viel gelernt, was das Training von Modellen angeht“, so Keese. Damals sei der Aufwand für das Training noch hoch gewesen. Heute böten die verfügbaren Foundational Models wesentlich mehr Möglichkeiten, schnell gute Ergebnisse zu erzielen. Abonnieren Sie unsere CIO-Newsletter für mehr spannende Interviews, Deep Dives und Best Practices aus der CIO-Community. In einem nächsten Schritt hat das Team aus E-Mails von Kunden mit Hilfe selbsttrainierter Modelle Emotionen herauslesen können. „Ziel war es, früh zu erkennen, ob ein Kunde im Customer-Service-Kontakt einen Notfall, ein allgemeines Problem, oder nur eine Frage hat, um die Anfrage anschließend in die richtigen Kanäle im Callcenter weiterleiten zu können.“ Für die DKB reduzierte das laut Keese den Aufwand, möglichst schnell die möglichst beste Antwort zu liefern – und die Kunden erhielten rascher Auskunft. Diese Lehrjahre haben der DKB geholfen, das Fundament für den „Digital Agent“ zu schaffen. Keese: „Wir müssen auf die Daten zugreifen können und brauchen dafür die richtigen Prozesse und Skills bei den Mitarbeitenden.“ Diese Grundlagenarbeit mündet in immer mehr Use Cases, die ohne das Fundament nicht funktionieren würden. Der KI-basierte Agent ist in der Microsoft-Azure-Welt entstanden. „Als wir vor eineinhalb Jahren angefangen haben, den KI-Agenten aufzubauen, waren die LLMs von ChatGPT dort am weitesten fortgeschritten“, so Keese. Heute hat die Bank zusätzlich mit Amazon Bedrock den Grundstein dafür gelegt, über mehrere Systeme hinweg operieren und entscheiden zu können, welches Sprachmodell wofür eingesetzt wird, um den Digital Agent betreiben zu können. Dabei spielen zum einen Anforderungen hinsichtlich der Resilienz eine Rolle. Zum anderen will die DKB in der Lage sein, im Hinblick auf die rasant fortschreitenden Innovationen im LLM-Markt immer auf dem besten Modell arbeiten zu können. „Daher haben wir intern auch eine hohe Wertschöpfungstiefe um das GPT herumgebaut, um etwa die Logik zu definieren, wie die Kundenanfragen bewertet werden oder welche Rohdatenquellen in die Antwort miteinfließen“, berichtet der Manager. Die DKB-IT wollte so sicherstellen, dass die von der KI ausgegebenen Antworten den Ansprüchen der Bank genügen. Keese sagt ganz klar an: „Die Antworten müssen korrekt sein, die Position des Hauses vertreten und sich auf den Sachverhalt beschränken. Wenn jemand beispielsweise den Agenten fragt, welche Aktien er kaufen soll, dann darf eine Bank dazu nichts sagen.“ Ein Beispiel: Fragt ein Kunde etwas zu den AGBs, könnte das Modell den Originaltext der AGBs zurückgeben. Da es sich dabei aber um juristische Texte handelt, sind sie nicht immer einfach verständlich. Dagegen sind einfache Antworten aus den FAQs des Finanzinstituts womöglich juristisch nicht korrekt. Die richtige Mischung aus den Fakten der AGBs und der Verständlichkeit der FAQs stellt die DKB-IT laut Keese mit der in den Agenten eingebauten Logik sicher. „Wenn ein Kunde eine Frage hat, wollen wir eine möglichst hohe Quote an fallabschließenden Antworten im allerersten Kundenkontakt.“ Wenn der Kunde das Gefühl habe, nur drei Textbausteine zusammengewürfelt zu bekommen, sei das frustrierend für ihn und ineffizient für die Bank. Keese: „Der Vorteil bei LLMs ist, dass, selbst wenn man dem Bot drei Textbausteine gibt, macht er daraus eine zusammenhängende Antwort in guter Sprache – und auf Wunsch auch in mehreren Sprachen.“ Der Agent kennt laut Keese auf Basis datenschutzrechtlicher Anforderungen die persönlichen Finanzprodukte der Kunden. Zudem greift er überwiegend auf bestehende Wissensbausteine zurück und ist mit diesen gezielt verbunden. Die Voraussetzung dafür ist eine interne Wissensplattform mit allen Informationen, die auch die realen Kundenbetreuer aktuell in ihrem Arbeitsalltag nutzen. Angereichert ist das Wissen des KI-Supports durch FAQs, Website-Daten und bestehende Textbausteine. Ende 2023 hatte sich die DKB-IT vorgenommen, den digitalen Agenten für die E-Mail-basierte Kundenkommunikation zu entwickeln. „Ziel war, bei Lastspitzen von Kundenanfragen gewohnt schnell und zielführend Auskunft geben zu können“, präzisiert der IT-Vorstand. Gerade bei Standardthemen, die keine ausführliche Beratung erfordern, wollte man die Kundschaft möglichst schnell zu gewünschten Ergebnis führen und den Kundendienst entlasten – dafür brauchte es Automatisierung. Nach einem Vergleich verschiedener LLMs und über 50 Chatbots am Markt fiel die Wahl auf ChatGPT als Sprachmodell. Der Chatbot wurde größtenteils inhouse selbst entwickelt, um den Datenfluss für die oben beschriebene Detailtiefe und Verständlichkeit in den Antworten zu gewährleisten. Im ersten Halbjahr 2024 begannen erste Pilotversuche. Nachdem anfängliche Schwierigkeiten überwunden sowie Governance und Regulatorik implementiert waren, begannen im Sommer 2024 die ersten Tests im Feld samt Verbesserungs-Iterationen auf Basis von Nutzerfeedback. Anschließend wurde die Lösung scharf geschaltet. „Da haben wir uns Use Case für Use Case vorgearbeitet und sind kurz vor Weihnachten 2024 in den vollständigen Rollout reingekommen“, beschreibt der IT-Chef sein Vorgehen. Im Laufe des Jahres 2025 werde er komplett ausgerollt. Mit dem Rollout des Tools startete die DKB in den öffentlich zugänglichen FAQs. Anschließend hatten eingeloggte Kunden darauf Zugriff und in einem dritten Schritt wurde es auf der Webseite und in die App implementiert. Zudem können Kunden innerhalb des Kontos Fragen etwa zu ihrem Account stellen. Für den Datenschutz sorgt das Finanzhaus, indem der Agent in einer geschützten Umgebung in einer EU-Souveränitätszone von Microsoft agiert. „Wichtiges Grundprinzip dabei ist, dass alles, was die Kunden uns fragen und was wir über den Agenten antworten, in keiner Weise in das Training der Modelle einfließt. Das ist garantiert und vertraglich mit dem Partner abgesichert“, führt Keese aus. Das LLM so nutzen zu können, ohne dabei das Modell zu trainieren, sei sehr wichtig, gerade im Umfeld von Bankgeheimnissen. Der „Lackmustest“ für die Güte des Chatbots ist für den IT-Chef die Zeit, bis der Kunde einen menschlichen Ansprechpartner will. Bei dem Digital Agent merke die DKB-IT in der anonymisierten Auswertung und stichprobenartigen Umfragen, dass die Interaktionsrate mit den Kunden hoch und die Aufforderung nach einem menschlichen Kontakt niedrig ist, was darauf schließen lasse, dass er einen zufriedenstellenden Job macht. „Das Besondere an dem Chatbot ist, dass sich die Kunden in einem echten Dialog befinden, der unendlich weitergeführt werden kann und sich aus allen relevanten, aktuell in der Bank verfügbaren Informationen speist“, führt der IT-Vorstand aus. Die meisten anderen Bot-Dialoge seien sehr regelbasiert in Wenn-Dann-Schleifen konzipiert und nach drei Fragen durchlaufen, danach müsse ein Mensch kontaktiert werden. „Wo wir gerade noch dran sind, ist die Dokumentenprüfung, wenn der Kunde bestimmte Produkte haben will. Hier experimentieren wir mit Teilautomatisierung – etwa bei der Überprüfung von Gehaltsnachweisen“, berichtet Keese. Dabei gehe es vor allem um Schnelligkeit, damit die Kunden möglichst früh eine Zusage für das angefragte Produkt erhielten. Solche Dinge seien insofern wichtig, weil die DKB laut Keese eine Tech-Bank ist und sein will. „Darum begleiten wir technologische Trends, investieren seit Jahren in Data Science und KI – und dadurch rollen wir jetzt immer mehr große und kleine Use Cases aus.“ Das forciere auch insgesamt den Fortschritt im Unternehmen. In vielen Abteilungen probierten Kolleginnen und Kollegen, Prozesse mit KI zu vereinfachen. „Das ist der Prozess der Demokratisierung”, zieht der IT-Chef Bilanz. “Da passiert viel an Stellen, die von außen vielleicht weniger einsehbar sind – etwa im Bereich ESG. Dort gibt es Bergeweise standardisierte Dokumente, wie etwa Energieausweise, bei denen es sträflich wäre, die Erkennung und Einsortierung nicht durch Automatisierung zu vereinfachen.“ Bei allen Effizienzgewinnen durch Automatisierung sei es jedoch wichtig, auch wegen regulatorischer Anforderungen, dass die Entscheidung am Ende immer noch ein Mensch trifft. Seit Mai 2025 hat die DKB zudem eine direkte Innovationskooperation mit OpenAI gestartet. Ein konkretes Projekt dieser Partnerschaft ist die Einführung einer KI-Sprachsteuerung im Banking, die den 5,8 Millionen Kundinnen und Kunden der Direktbank einen smarten Zugang zu Banking-Services ermöglichen soll. Zudem stellt OpenAI die Technologie zur Verfügung, um Agentic AI Workflows zu implementieren. Damit soll die komplexe Dokumentenverarbeitung und damit verbundene Prozesse für die Mitarbeitenden vereinfacht werden.",
    "source": "cio",
    "crawled_at": "2025-05-28T09:16:53.794987+00:00"
  },
  {
    "url": "https://www.cio.de/article/3994135/raghavendra-vaidya-wird-cio-von-daimler-truck.html",
    "title": "Raghavendra Vaidya wird CIO von Daimler Truck",
    "published": "2025-05-26T04:13:00+00:00",
    "author": "",
    "text": "Daimler Truck Ab Juni 2025 ist Raghavendra Vaidya Chief Information Officer (CIO) von Daimler Truck. Er ist bereits seit 2016 im Daimler-Konzern tätig. Vaidya folgt auf Marcus Claesson, der das Unternehmen auf eigenen Wunsch verlässt. „Wir freuen uns, Raghavendra Vaidya in unserem Executive Team zu begrüßen“, kommentiert Andreas Gorbach, Mitglied des Vorstands der Daimler Truck AG undverantwortlich für Truck Technology, Vaidyas Ernennung. Mit einer über 25-jährigen Karriere in verschiedenen IT-Positionen bringe er Erfahrung und Know-how, strategische Vision sowie Führungskompetenz mit, um das Unternehmen in eine datenbasierte Zukunft zu führen. Abonnieren Sie unsere CIO-Newsletter für mehr spannende Personalien, Einblicke und Hintergründe aus der CIO-Community. Derzeit ist Vaidya als Managing Director und CEO des Daimler Truck Innovation Center India (DTICI) tätig, ein Posten, den er 2021 antrat. Zuvor war der Manager fünf Jahre SVP IT bei Mercedes-Benz Research and Development India. Bis zu seinem Eintritt in den Daimler-Konzern hatte Vaidya verschiedene Führungspositionen in mehreren Geschäftsbereichen von General Electric inne. Marcus Claesson verlässt das Unternehmen nach rund fünfeinhalb Jahren als IT-Chef auf eigenen Wunsch. Daimler Truck Vaidyas Vorgänger Marcus Claesson war seit 2019 CIO des Nutzfahrzeugherstellers. Auch er kam aus dem Daimler-Konzern. Vor dem Einstieg bei Daimler Trucks war der Manager zwei Jahre CIO von Daimler Commercial Vehicles. „Ich danke Marcus für seinen Beitrag zu unserem neuen IT-Setup nach dem Spin-Off von der ehemaligen Daimler AG“, verabschiedet Gorbach den scheidenden IT-Chef und ergänzt: „Marcus hat eine Herkules-Aufgabe gemeistert, indem er eine eigenständige IT aufgebaut hat, was große Transformationsschritte beinhaltet hat. Zudem hat er die Fahrzeugkonnektivität über alle Marken hinweg maßgeblich vorangetrieben und dabei unter anderem den Meilenstein von mehr als einer Million vernetzten Fahrzeugen erreicht.“ Sie haben Informationen zu Jobwechseln in der CIO-Community? Dann schreiben Sie uns via: info@cio.de Daimler Truck ist seit Ende 2021 ein eigenständiges Unternehmen, das durch die Abspaltung der Daimler Truck AG von der Daimler AG entstand. Der Nutzfahrzeughersteller hat seinen Hauptsitz in Leinfelden-Echterdingen in Baden-Württemberg und unterhält rund 40 Standorte weltweit. 2024 erwirtschaftete das Unternehmen 54,1 Milliarden Euro Umsatz und beschäftigte etwa 103.000 Menschen. Daimler Truck Ab Juni 2025 ist Raghavendra Vaidya Chief Information Officer (CIO) von Daimler Truck. Er ist bereits seit 2016 im Daimler-Konzern tätig. Vaidya folgt auf Marcus Claesson, der das Unternehmen auf eigenen Wunsch verlässt. „Wir freuen uns, Raghavendra Vaidya in unserem Executive Team zu begrüßen“, kommentiert Andreas Gorbach, Mitglied des Vorstands der Daimler Truck AG undverantwortlich für Truck Technology, Vaidyas Ernennung. Mit einer über 25-jährigen Karriere in verschiedenen IT-Positionen bringe er Erfahrung und Know-how, strategische Vision sowie Führungskompetenz mit, um das Unternehmen in eine datenbasierte Zukunft zu führen. Abonnieren Sie unsere CIO-Newsletter für mehr spannende Personalien, Einblicke und Hintergründe aus der CIO-Community. Derzeit ist Vaidya als Managing Director und CEO des Daimler Truck Innovation Center India (DTICI) tätig, ein Posten, den er 2021 antrat. Zuvor war der Manager fünf Jahre SVP IT bei Mercedes-Benz Research and Development India. Bis zu seinem Eintritt in den Daimler-Konzern hatte Vaidya verschiedene Führungspositionen in mehreren Geschäftsbereichen von General Electric inne. Marcus Claesson verlässt das Unternehmen nach rund fünfeinhalb Jahren als IT-Chef auf eigenen Wunsch. Daimler Truck Vaidyas Vorgänger Marcus Claesson war seit 2019 CIO des Nutzfahrzeugherstellers. Auch er kam aus dem Daimler-Konzern. Vor dem Einstieg bei Daimler Trucks war der Manager zwei Jahre CIO von Daimler Commercial Vehicles. „Ich danke Marcus für seinen Beitrag zu unserem neuen IT-Setup nach dem Spin-Off von der ehemaligen Daimler AG“, verabschiedet Gorbach den scheidenden IT-Chef und ergänzt: „Marcus hat eine Herkules-Aufgabe gemeistert, indem er eine eigenständige IT aufgebaut hat, was große Transformationsschritte beinhaltet hat. Zudem hat er die Fahrzeugkonnektivität über alle Marken hinweg maßgeblich vorangetrieben und dabei unter anderem den Meilenstein von mehr als einer Million vernetzten Fahrzeugen erreicht.“ Sie haben Informationen zu Jobwechseln in der CIO-Community? Dann schreiben Sie uns via: info@cio.de Daimler Truck ist seit Ende 2021 ein eigenständiges Unternehmen, das durch die Abspaltung der Daimler Truck AG von der Daimler AG entstand. Der Nutzfahrzeughersteller hat seinen Hauptsitz in Leinfelden-Echterdingen in Baden-Württemberg und unterhält rund 40 Standorte weltweit. 2024 erwirtschaftete das Unternehmen 54,1 Milliarden Euro Umsatz und beschäftigte etwa 103.000 Menschen.",
    "source": "cio",
    "crawled_at": "2025-05-28T09:16:53.923747+00:00"
  },
  {
    "url": "https://www.cio.de/article/3991917/dell-pro-16-plus-im-test-ki-laptop-mit-grosem-display-2.html",
    "title": "Dell Pro 16 Plus im Test: KI-Laptop mit großem Display",
    "published": "2025-05-26T05:11:00+00:00",
    "author": "",
    "text": "Thomas Rau Auch unter neuem Namen zeigt das Business-Notebook von Dell im Test die bekannten Kernkompetenzen: Das Pro 16 Plus ist ein rundum solide verarbeiteter, zuverlässiger Business-Laptop. Der neue Lunar-Lake-Prozessor macht den Copilot+PC KI- und damit zukunftstauglich. Bei Rechenleistung, Akkulaufzeit und Bildqualität schneidet das Notebook ordentlich ab, ragt aber in keiner Disziplin heraus. Das macht ihn zum Allrounder für den Business-Einsatz besonders in größeren Unternehmen, auf die das Pro 16 Plus bei Ausstattung und Reparaturfähigkeit zugeschnitten ist. Vor allem, wer bei der Büroarbeit eine große Bildschirmfläche für Excel-Tabellen und Powerpoint-Präsentationen benötigt, darf beim 16-Zoll-Notebooks zugreifen. Weitere Profi-Notebooks für unterwegs, das Home-Office oder Büro finden Sie in unserem großen Vergleichs-Test der besten Business-Laptops . Mit dem Pro 16 Plus läutet Dell eine neue Ära bei seinen Notebooks ein: Verschwunden sind die bekannten Markennamen XPS, Inspiron, Latitude und Precision. Ab jetzt heißen die Laptops für Privatanwender Dell, die Business-Geräte Dell Pro und die High-End- und Workstation-Varianten Dell Pro Max. Innerhalb der jeweiligen Serien gibt es die Ausstattungsstufen Base, Plus und Premium. Das Dell Pro 16 Plus lässt sich somit als Business-Notebook der oberen Mittelklasse und als Nachfolger der Latitude-7000er-Serie einordnen. Beim Gehäusedesign hat sich wenig getan: Gegenüber dem Vorgänger 7650 bekommt das Pro 16 Plus eine breitere Tastatur inklusive Nummernblock. Das hellgraue Aluminiumgehäuse versprüht statt Chefetagen-Chic die businesskonforme Eleganz eines Großraumbüros. Aber genau dort soll das Pro 16 Plus seinen Platz finden als produktive Arbeitsmaschine mit großem Display und einem Prozessor aus Intels Lunar-Lake-Generation: Diese Kombination ist bei Copilot+PCs noch recht einzigartig. Denn die sparsamen und recheneffizienten Intel-Prozessoren werden bislang vor allem in ultramobilen 13- und 14-Zoll-Laptops eingesetzt – in 16-Zoll-Modellen sind sie noch selten. Thomas Rau Wie bei Dell üblich, gibt es das Pro 16 Plus in zahlreichen Ausstattungsvarianten, deren Preise bei rund 1600 Euro beginnen. Das Testgerät mit Intel Core Ultra 7 268V, 32B RAM, 1-TB-SSD und 16-Zoll-Bildschirm mit FHD+ kostet rund 2350 Euro. Der Prozessor bietet gegenüber dem vor allem in Consumer-Notebooks häufig zu findenden Core Ultra 7 258V einen etwas höheren Turbo-Takt sowie eine minimal schnellere NPU und CPU-Grafik. Wichtiger fürs Dell Pro ist, dass er Intels vPro-Technik unterstützt, womit sich das Notebook im Unternehmen leichter administrieren und besser schützen lässt. Leistungstests zeigen keinen Unterschied zwischen dem 268V und einem 258V mit der gleichen mittleren Leistungsaufnahme von 25 Watt. Minimal schneller ist das Dell-Notebook lediglich im Vergleich zu Lunar-Lake-Laptops, in denen ein 258V nur rund 20 Watt verbrauchen darf – aber auch dann nur bei CPU-lastigen Aufgaben wie Rendering oder Fotobearbeitung. Insgesamt bietet das Dell Pro ein ausgewogenes Rechentempo bei allen business-relevanten Anwendungen: Im PC Mark 10 ist es ähnlich leistungsstark wie Notebooks mit dem deutlich leistungshungrigerem Core Ultra 7 155H aus der Meteor-Lake-Generation, hat aber aufgrund der verbesserten internen GPU Arc 140V Vorteile bei grafiklastigen Rendering- und Videoschnitt-Programmen. Im System-Benchmark Crossmark hängt es Notebooks mit einem Prozessor aus der Vorgängergeneration um rund 15 Prozent ab. Beim Vergleich mit ARM-Notebooks, die einen Snapdragon X Elite einsetzen, zeigt das Dell Pro das gleiche Verhalten wie alle Lunar-Lake-Laptops: Bei hoher CPU-Last ist es dem Qualcomm-Prozessor klar unterlegen, benötigt ein Programm nur wenige Kerne, liegt es vorne. Am deutlichsten erweist sich das im beliebten, aber wenig praxisnahem Prozessor-Benchmark Cinebench R24: Beim Multi-Core-Test fehlen dem Dell Pro 16 Plus rund 20 Prozent auf Notebooks mit dem Snapdragon X Elite E78, beim Single-Core-Test ist es genau andersherum. In der Praxis fällt dieser Unterschied vor allem bei Office-Tests auf, wo das Dell Pro stärker bei Word, aber schwächer bei Excel ist: Insgesamt liegen Snapdragon und Lunar Lake beim Büroeinsatz aber gleichauf. Gleiches gilt für die Recheneffizienz, wo beide Konkurrenten rund 23 Cinebench-Punkte pro Watt erreichen: Die Snapdragon-Notebooks mit X Elite sind schneller, verbrauchen aber minimal mehr, bei Lunar-Lake-Laptops ist es umgekehrt. Als Copilot+PC erfüllt das Dell Pro 16 Plus dank der NPU des Intel-Prozessors die KI-Vorgaben von Microsoft. Im KI-Benchmark Procyon AI Computer Vision schneidet es aber etwas schlechter ab als die meisten anderen KI-Notebooks mit Lunar Lake oder Snapdragon-Prozessor. Thomas Rau Im Arbeitsalltag mit dem Dell Pro fällt störend auf, dass der Lüfter oft aktiv ist – selbst, wenn nur geringe Rechenleistung gefordert ist. Zwar bleibt das Betriebsgeräusch unter Last gemessen etwas niedriger als bei anderen Notebooks mit Lunar Lake. Die sind aber häufig ganz still, während das Dell fast immer hörbar arbeitet und damit in einer sehr ruhigen Arbeitsumgebung auffällt. Das große Dell Pro 16 Plus bietet viele Anschlüsse wie Thunderbolt 4, USB Typ-A, Micro-SD-Kartenleser und HDMI-Ausgang – optimal für ein Schreibtisch-Gerät, da sich so viele Peripheriegeräte ohne Adapter oder Docking-Station nutzen lassen. Ein Ethernet-Port fehlt, dafür gibt es WLAN mit dem aktuellen Standard Wi-Fi 7. Optional lässt sich das Dell-Notebook mit einem Smartcard-Leser und einem 5G-Modem inklusive Nano-SIM-Einschub ausstatten. Die Kamera löst mit 1440p auf und eignet sich daher sehr gut für Video-Meetings. Die Linse können Sie mit einer mechanischen Abdeckung im Displaydeckel verschließen. Zudem arbeitet die Kamera mit einem Näherungssensor, um den Sperrbildschirm zu aktivieren, wenn Sie sich vom Notebook entfernen und die Displayhelligkeit zu reduzieren, wenn Sie nicht auf den Bildschirm schauen. Servicetechniker erleichtert Dell das Reparieren: Die acht Gehäuseschrauben sind verliersicher und fallen daher nicht sofort heraus, wenn Sie sie aufdrehen. Zudem besitzt das Pro 16 Plus laut Dell als erstes Notebook modulare Typ-C-Ports: Sie sind verschraubt statt verlötet und lassen sich deswegen einfacher ersetzen. Selbst sollten Sie das aber nicht probieren, denn dazu muss die Platine ausgebaut werden, weil sich die Schrauben der USB-C-Module auf deren Unterseite befinden. Thomas Rau Mit einem Gewicht von knapp unter zwei Kilogramm, gehört das Notebook nicht zu den leichtesten 16-Zoll-Modellen. Trotzdem lässt es sich auf kürzeren Strecken bequem transportieren – zum Beispiel zwischen Wohnung und Büro oder innerhalb des Unternehmens. Die Akkulaufzeit geht in Ordnung: Im WLAN-Test erreicht das Dell-Notebook eine Laufzeit von über 14 Stunden, im Office-Einsatz sind es 12 Stunden. Mit einem größeren Akku würde die Ausdauer noch deutlich besser ausfallen, da das Pro 16 mit einer Leistungsaufnahme von unter vier Watt im Akkubetrieb sehr sparsam arbeitet – vor allem, weil es ein LCD-Display statt OLED nutzt. Doch sein Akku fasst nur 55 Wattstunden, mit größerem Akku laufen Lunar-Lake-Laptops zwei bis vier Stunden länger. Das passt aber zum Einsatzzweck des 16-Zöllers: Er ist für den gelegentlichen Akkubetrieb gedacht, nicht als ultramobiler Laptop, mit dem Sie einen ganzen Tag unterwegs arbeiten. Mit Standardeinstellungen lädt das Notebook sehr gemächlich: Nach einer Stunde an der Steckdose ist es nur zu 51 Prozent geladen – das wiederum verlängert die Lebensdauer des Akkus. Thomas Rau Beim Bildschirm können Sie zwischen Displayvarianten mit und ohne Touchscreen wählen und bei der Auflösung zwischen FHD+ und QHD+. Die Auflösung des Testmodells beträgt 1920 x 1200 und ist damit sinnvoll für den Büroalltag. Ebenso alltagstauglich für den Einsatz am Schreibtisch sind die Messergebnisse bei Helligkeit, Kontrast und Ausleuchtung – die Werte sind nicht überragend, aber absolut in Ordnung für Word, Excel und Powerpoint. Das Dell Pro 16 Plus ist aber kein Laptop, den Sie sich wegen der Bildqualität kaufen sollten. Denn die mäßige Farbwiedergabe mit geringer Farbraumabdeckung und Farbtreue disqualifiziert es für ambitionierte Foto- oder Videobearbeitung. Andere Laptops mit LCD bieten eine höhere Maximalhelligkeit und lassen sich daher unter verschiedenen Lichtbedingungen flexibler nutzen. Der Vorteil beim Dell-Notebook ist dafür seine entspiegelte Bildschirmoberfläche. Der Nummernblock rechts in der Tastatur erleichtert die schnelle Eingabe von Zahlen und dürfte daher Excel-Arbeiter begeistern – zumal diese Tasten fast genauso groß sind wie in der Haupt-Tastatur. Beim Layout fällt die zweizeilige, aber schmale Enter-Taste auf, die Pfeiltasten sind nicht abgesetzt. Auf der Tastatur lässt sich angenehm tippen, denn sie ist sehr stabil eingebaut, die Tasten verfügen über einen klaren Druckpunkt und einen guten Hub. Besonders leise ist sie aber nicht. Auch das große Touchpad gibt eine deutlich spürbare Klick-Rückmeldung, auf der rechten Seite fühlt es sich aber etwas schwammig an. Thomas Rau Auch unter neuem Namen zeigt das Business-Notebook von Dell im Test die bekannten Kernkompetenzen: Das Pro 16 Plus ist ein rundum solide verarbeiteter, zuverlässiger Business-Laptop. Der neue Lunar-Lake-Prozessor macht den Copilot+PC KI- und damit zukunftstauglich. Bei Rechenleistung, Akkulaufzeit und Bildqualität schneidet das Notebook ordentlich ab, ragt aber in keiner Disziplin heraus. Das macht ihn zum Allrounder für den Business-Einsatz besonders in größeren Unternehmen, auf die das Pro 16 Plus bei Ausstattung und Reparaturfähigkeit zugeschnitten ist. Vor allem, wer bei der Büroarbeit eine große Bildschirmfläche für Excel-Tabellen und Powerpoint-Präsentationen benötigt, darf beim 16-Zoll-Notebooks zugreifen. Weitere Profi-Notebooks für unterwegs, das Home-Office oder Büro finden Sie in unserem großen Vergleichs-Test der besten Business-Laptops . Mit dem Pro 16 Plus läutet Dell eine neue Ära bei seinen Notebooks ein: Verschwunden sind die bekannten Markennamen XPS, Inspiron, Latitude und Precision. Ab jetzt heißen die Laptops für Privatanwender Dell, die Business-Geräte Dell Pro und die High-End- und Workstation-Varianten Dell Pro Max. Innerhalb der jeweiligen Serien gibt es die Ausstattungsstufen Base, Plus und Premium. Das Dell Pro 16 Plus lässt sich somit als Business-Notebook der oberen Mittelklasse und als Nachfolger der Latitude-7000er-Serie einordnen. Beim Gehäusedesign hat sich wenig getan: Gegenüber dem Vorgänger 7650 bekommt das Pro 16 Plus eine breitere Tastatur inklusive Nummernblock. Das hellgraue Aluminiumgehäuse versprüht statt Chefetagen-Chic die businesskonforme Eleganz eines Großraumbüros. Aber genau dort soll das Pro 16 Plus seinen Platz finden als produktive Arbeitsmaschine mit großem Display und einem Prozessor aus Intels Lunar-Lake-Generation: Diese Kombination ist bei Copilot+PCs noch recht einzigartig. Denn die sparsamen und recheneffizienten Intel-Prozessoren werden bislang vor allem in ultramobilen 13- und 14-Zoll-Laptops eingesetzt – in 16-Zoll-Modellen sind sie noch selten. Thomas Rau Wie bei Dell üblich, gibt es das Pro 16 Plus in zahlreichen Ausstattungsvarianten, deren Preise bei rund 1600 Euro beginnen. Das Testgerät mit Intel Core Ultra 7 268V, 32B RAM, 1-TB-SSD und 16-Zoll-Bildschirm mit FHD+ kostet rund 2350 Euro. Der Prozessor bietet gegenüber dem vor allem in Consumer-Notebooks häufig zu findenden Core Ultra 7 258V einen etwas höheren Turbo-Takt sowie eine minimal schnellere NPU und CPU-Grafik. Wichtiger fürs Dell Pro ist, dass er Intels vPro-Technik unterstützt, womit sich das Notebook im Unternehmen leichter administrieren und besser schützen lässt. Leistungstests zeigen keinen Unterschied zwischen dem 268V und einem 258V mit der gleichen mittleren Leistungsaufnahme von 25 Watt. Minimal schneller ist das Dell-Notebook lediglich im Vergleich zu Lunar-Lake-Laptops, in denen ein 258V nur rund 20 Watt verbrauchen darf – aber auch dann nur bei CPU-lastigen Aufgaben wie Rendering oder Fotobearbeitung. Insgesamt bietet das Dell Pro ein ausgewogenes Rechentempo bei allen business-relevanten Anwendungen: Im PC Mark 10 ist es ähnlich leistungsstark wie Notebooks mit dem deutlich leistungshungrigerem Core Ultra 7 155H aus der Meteor-Lake-Generation, hat aber aufgrund der verbesserten internen GPU Arc 140V Vorteile bei grafiklastigen Rendering- und Videoschnitt-Programmen. Im System-Benchmark Crossmark hängt es Notebooks mit einem Prozessor aus der Vorgängergeneration um rund 15 Prozent ab. Beim Vergleich mit ARM-Notebooks, die einen Snapdragon X Elite einsetzen, zeigt das Dell Pro das gleiche Verhalten wie alle Lunar-Lake-Laptops: Bei hoher CPU-Last ist es dem Qualcomm-Prozessor klar unterlegen, benötigt ein Programm nur wenige Kerne, liegt es vorne. Am deutlichsten erweist sich das im beliebten, aber wenig praxisnahem Prozessor-Benchmark Cinebench R24: Beim Multi-Core-Test fehlen dem Dell Pro 16 Plus rund 20 Prozent auf Notebooks mit dem Snapdragon X Elite E78, beim Single-Core-Test ist es genau andersherum. In der Praxis fällt dieser Unterschied vor allem bei Office-Tests auf, wo das Dell Pro stärker bei Word, aber schwächer bei Excel ist: Insgesamt liegen Snapdragon und Lunar Lake beim Büroeinsatz aber gleichauf. Gleiches gilt für die Recheneffizienz, wo beide Konkurrenten rund 23 Cinebench-Punkte pro Watt erreichen: Die Snapdragon-Notebooks mit X Elite sind schneller, verbrauchen aber minimal mehr, bei Lunar-Lake-Laptops ist es umgekehrt. Als Copilot+PC erfüllt das Dell Pro 16 Plus dank der NPU des Intel-Prozessors die KI-Vorgaben von Microsoft. Im KI-Benchmark Procyon AI Computer Vision schneidet es aber etwas schlechter ab als die meisten anderen KI-Notebooks mit Lunar Lake oder Snapdragon-Prozessor. Thomas Rau Im Arbeitsalltag mit dem Dell Pro fällt störend auf, dass der Lüfter oft aktiv ist – selbst, wenn nur geringe Rechenleistung gefordert ist. Zwar bleibt das Betriebsgeräusch unter Last gemessen etwas niedriger als bei anderen Notebooks mit Lunar Lake. Die sind aber häufig ganz still, während das Dell fast immer hörbar arbeitet und damit in einer sehr ruhigen Arbeitsumgebung auffällt. Das große Dell Pro 16 Plus bietet viele Anschlüsse wie Thunderbolt 4, USB Typ-A, Micro-SD-Kartenleser und HDMI-Ausgang – optimal für ein Schreibtisch-Gerät, da sich so viele Peripheriegeräte ohne Adapter oder Docking-Station nutzen lassen. Ein Ethernet-Port fehlt, dafür gibt es WLAN mit dem aktuellen Standard Wi-Fi 7. Optional lässt sich das Dell-Notebook mit einem Smartcard-Leser und einem 5G-Modem inklusive Nano-SIM-Einschub ausstatten. Die Kamera löst mit 1440p auf und eignet sich daher sehr gut für Video-Meetings. Die Linse können Sie mit einer mechanischen Abdeckung im Displaydeckel verschließen. Zudem arbeitet die Kamera mit einem Näherungssensor, um den Sperrbildschirm zu aktivieren, wenn Sie sich vom Notebook entfernen und die Displayhelligkeit zu reduzieren, wenn Sie nicht auf den Bildschirm schauen. Servicetechniker erleichtert Dell das Reparieren: Die acht Gehäuseschrauben sind verliersicher und fallen daher nicht sofort heraus, wenn Sie sie aufdrehen. Zudem besitzt das Pro 16 Plus laut Dell als erstes Notebook modulare Typ-C-Ports: Sie sind verschraubt statt verlötet und lassen sich deswegen einfacher ersetzen. Selbst sollten Sie das aber nicht probieren, denn dazu muss die Platine ausgebaut werden, weil sich die Schrauben der USB-C-Module auf deren Unterseite befinden. Thomas Rau Mit einem Gewicht von knapp unter zwei Kilogramm, gehört das Notebook nicht zu den leichtesten 16-Zoll-Modellen. Trotzdem lässt es sich auf kürzeren Strecken bequem transportieren – zum Beispiel zwischen Wohnung und Büro oder innerhalb des Unternehmens. Die Akkulaufzeit geht in Ordnung: Im WLAN-Test erreicht das Dell-Notebook eine Laufzeit von über 14 Stunden, im Office-Einsatz sind es 12 Stunden. Mit einem größeren Akku würde die Ausdauer noch deutlich besser ausfallen, da das Pro 16 mit einer Leistungsaufnahme von unter vier Watt im Akkubetrieb sehr sparsam arbeitet – vor allem, weil es ein LCD-Display statt OLED nutzt. Doch sein Akku fasst nur 55 Wattstunden, mit größerem Akku laufen Lunar-Lake-Laptops zwei bis vier Stunden länger. Das passt aber zum Einsatzzweck des 16-Zöllers: Er ist für den gelegentlichen Akkubetrieb gedacht, nicht als ultramobiler Laptop, mit dem Sie einen ganzen Tag unterwegs arbeiten. Mit Standardeinstellungen lädt das Notebook sehr gemächlich: Nach einer Stunde an der Steckdose ist es nur zu 51 Prozent geladen – das wiederum verlängert die Lebensdauer des Akkus. Thomas Rau Beim Bildschirm können Sie zwischen Displayvarianten mit und ohne Touchscreen wählen und bei der Auflösung zwischen FHD+ und QHD+. Die Auflösung des Testmodells beträgt 1920 x 1200 und ist damit sinnvoll für den Büroalltag. Ebenso alltagstauglich für den Einsatz am Schreibtisch sind die Messergebnisse bei Helligkeit, Kontrast und Ausleuchtung – die Werte sind nicht überragend, aber absolut in Ordnung für Word, Excel und Powerpoint. Das Dell Pro 16 Plus ist aber kein Laptop, den Sie sich wegen der Bildqualität kaufen sollten. Denn die mäßige Farbwiedergabe mit geringer Farbraumabdeckung und Farbtreue disqualifiziert es für ambitionierte Foto- oder Videobearbeitung. Andere Laptops mit LCD bieten eine höhere Maximalhelligkeit und lassen sich daher unter verschiedenen Lichtbedingungen flexibler nutzen. Der Vorteil beim Dell-Notebook ist dafür seine entspiegelte Bildschirmoberfläche. Der Nummernblock rechts in der Tastatur erleichtert die schnelle Eingabe von Zahlen und dürfte daher Excel-Arbeiter begeistern – zumal diese Tasten fast genauso groß sind wie in der Haupt-Tastatur. Beim Layout fällt die zweizeilige, aber schmale Enter-Taste auf, die Pfeiltasten sind nicht abgesetzt. Auf der Tastatur lässt sich angenehm tippen, denn sie ist sehr stabil eingebaut, die Tasten verfügen über einen klaren Druckpunkt und einen guten Hub. Besonders leise ist sie aber nicht. Auch das große Touchpad gibt eine deutlich spürbare Klick-Rückmeldung, auf der rechten Seite fühlt es sich aber etwas schwammig an.",
    "source": "cio",
    "crawled_at": "2025-05-28T09:16:53.968462+00:00"
  },
  {
    "url": "https://www.cio.de/article/3694592/den-lebenslauf-fuer-algorithmen-optimieren.html",
    "title": "Den Lebenslauf für Algorithmen optimieren",
    "published": "2025-05-26T06:10:53+00:00",
    "author": "",
    "text": "Um zu einem Gespräch eingeladen zu werden, sollte in das Zusammenstellen der Bewerbungsunterlagen Zeit investiert werden. Ist bei der Vorsortierung eine künstliche Intelligenz im Spiel, heißt es zudem, einige Standards zu beachten. Foto: Lisa-S – shutterstock.com Eine Umfrage hat ergeben, dass ein Großteil, nämlich etwa zwei Drittel der sich Bewerbenden , sich gar nicht über den Einsatz von Algorithmen im Bewerbungsprozess bewusst sind. Auch wenn sich dies mittlerweile schätzungsweise zu etwa einem Gleichgewicht verschoben haben dürfte, gibt es dennoch viele, denen dies nicht bewusst ist. Merken Sie sich daher zunächst die Faustformel: Je größer das Unternehmen, desto höher die Chance, dass Algorithmen bei der Bewertung Ihrer Bewerbung involviert sind. Dies gilt vor allem für einfache Algorithmen, die z.B. ein Matching vornehmen oder bestimmte Aspekte sortieren, sowie kategorisieren und katalogisieren. Denn sobald ein Algorithmus im Rahmen des Prozesses auch aktiv eine “Entscheidung trifft”, ist nach DSGVO die Zustimmung der betroffenen Person erforderlich und Sie haben das Recht, Informationen über die zugrundeliegende Entscheidungslogik zu erhalten. Lesen Sie daher im Idealfall vor der Bewerbung aufmerksam die Datenschutzbestimmungen des Unternehmens. Wenn Sie nun aber wissen oder davon ausgehen, dass ein Unternehmen Algorithmen für die Bearbeitung von Bewerbungen einsetzt, dann gibt es eine ganze Menge Tipps und Kniffe, wie Sie dies zu Ihrem Vorteil nutzen können. Algorithmen verarbeiten Informationen vor allem dann besonders zuverlässig, wenn Sie klar strukturiert und innerhalb dieser Struktur logisch angeordnet sind. Versehen Sie daher sämtliche Teilbereiche Ihres Lebenslaufs mit entsprechenden Überschriften, wie “Ausbildung”, “Berufserfahrungen” etc. Achten Sie anschließend darauf, dass Sie diese Struktur stringent einhalten und die Sortierung einheitlich ist. Üblich ist mittlerweile eine antichronologische Auflistung. Verzichten Sie aus diesem Grund auch lieber auf allzu ausgefallene und kreative Designs, schräge Anordnungen, sowie Tabellen, Logos oder Piktogramme, da diese die Dokumentenstruktur unterlaufen. Geben Sie Beschäftigungszeiten niemals nur in Jahren an – offen gesagt hassen das bereits die menschlichen Personalerinnen und Personaler –, sondern immer mit den dazugehörigen Monaten. Haben Sie diese vergessen? Dann finden Sie die Information im jeweiligen Arbeitszeugnis. Sie möchten damit Lücken kaschieren? Das ist sowieso die Vermutung des Personalers oder der Personalerin. In aller Regel “achten” Algorithmen in einer Bewerbung auf bestimmte Stichworte, die Sie in der Regel in der Stellenausschreibung finden. Allerdings liegt der Fokus hierauf vor allem auf fachlichen Anforderungen, weniger auf persönlichen. Kaum ein Algorithmus wird Ihre Bewerbung beispielsweise nach “Kommunikationsfähigkeit” oder “Kundenorientierung” durchleuchten. Wenn in der Ausschreibung aber bestimmte, fachliche Anforderungen genannt werden, wie z.B. bestimmte Technologien und Programmiersprachen bei IT-Positionen, dann müssen diese unbedingt in die Bewerbung mit aufgenommen werden, und zwar im exakten Wortlaut der Stellenanzeige. Weitere Informationen zu fachlich relevanten Themen und Stichworten, auf die auch der Algorithmus möglicherweise reagiert, finden Sie auf der Webseite des Unternehmens. Achten Sie dabei darauf, dass für Ihre angestrebte Position sowohl lokale, als auch globale Begrifflichkeiten gebräuchlich sein könnten und versuchen Sie entsprechend, alle Optionen zu berücksichtigen. Wenn Sie eine Skill-Liste erstellen, ergänzen Sie die einzelnen Fähigkeiten bestenfalls um Ihr Kenntnisniveau. Hierzu sollten Sie Begriffe nutzen, bei denen Sie mit an Sicherheit grenzender Wahrscheinlichkeit davon ausgehen können, dass der Algorithmus diese interpretieren kann – wie z.B. “Expert”, “fortgeschritten” usw. Lesetipp: Fieser Code – Wenn Algorithmen Vorurteile ausspucken Reine Skill-Listen ergeben jedoch ohnehin nur dann Sinn, wenn es um Aufgaben mit einer Vielzahl fachlicher Anforderungen geht, wie z.B. in der Softwareentwicklung. Achten Sie dann darauf, dass Sie die Liste auch für menschliche Augen ansprechend und nachvollziehbar ist. Sollten für Sie hingegen nur einige Kernfähigkeiten relevant sein, dann kann es mehr Sinn machen, die Fähigkeiten anhand praktischer Erfahrungen aufzuführen. Da viele Algorithmen Profile mittlerweile semantisch nach Inhalten durchleuchten, sollte dies der Erfassung Ihrer Fähigkeiten in aller Regel nicht schaden. In den letzten Jahren häufen sich in Bewerbungen sogenannte Management Summaries oder “Kurzprofile”. Diese sind mitunter gar nicht so kurz, wie der Name vermuten lässt. Doch ist hierbei Vorsicht geboten. Denn ausschweifende Formulierungen und irrelevante Informationen sorgen für eine möglicherweise ungenauere oder sogar falsche Klassifizierung durch den Algorithmus. Gleichzeitig sollten Sie darauf achten, die “Sprache des Unternehmens” zu sprechen. Auch hier bietet Ihnen bereits die Stellenanzeige wichtige Anhaltspunkte. Wenn es für einen Sachverhalt Ihrer Arbeit mehrere, unterschiedliche Formulierungen gibt, nutzen Sie immer diejenige, die auch in dem Unternehmen verwendet wird, in dem Sie sich bewerben. Nehmen Sie übrigens lieber Abstand davon, Ihre Teamfähigkeit, Flexibilität, Kreativität, Belastbarkeit usw. in Ihrer Bewerbung zu betonen. Zum einen sucht kein HR-Algorithmus dieser Welt nach diesen Begriffen und zum anderen sind diese Worthülsen ohne konkrete Beispiele aus der Praxis für Ihre Bewerbung auch für den menschlichen Betrachter im Unternehmen nutzlos. Der Tipp, Rechtschreibfehler in der Bewerbung zu vermeiden, ist sicherlich nicht erst seit dem Einsatz von Algorithmen gültig und wichtig. Doch während das menschliche Auge über manchen Rechtschreibfehler genauso flüchtig hinwegliest, wie er auch entstanden ist, oder der menschliche Leser diesen sanftmütig toleriert, wird ein Algorithmus in den meisten Fällen unverzeihlich aussortieren. Der Begriff, den Sie ja eigentlich auch meinen, kommt für den Algorithmus im Dokument schlicht nicht vor. Wenn Sie beispielsweise anstatt “Kreditorenbuchhaltung” laut Ihrem Lebenslauf Erfahrungen in “Kreditprenbuchhaltung” haben, dann wird der Algorithmus Ihnen diese Fähigkeit einfach nicht zuerkennen. Achten Sie unbedingt darauf, dass Ihr finales Dokument maschinenlesbar und das Kopieren von Text möglich ist. Verzichten Sie außerdem auf irrelevante Informationen, wie z.B. Namen, Geburtsdatum oder gar Beruf der Eltern, denn solche Informationen “verwirren” den Algorithmus. Nehmen Sie übrigens auch lieber Abstand von dem Gedanken, Ihre Stichwortliste noch um ein paar interessante, aber nicht zutreffende Begriffe mit weißer Schrift auf weißem Grund zu ergänzen. Manch ein Algorithmus erkennt mittlerweile sehr wohl auch die Textfarbe. Zudem werden Sie ja auch in möglicherweise anschließenden Gesprächen gezielt auf diese Kenntnisse hin befragt. Spätestens dann sollte ein solcher “Täuschungsversuch” auffallen und Sie haben bei diesem Unternehmen keine Chancen mehr. Daher empfiehlt sich gegenüber dem Algorithmus schon im eigenen Interesse Ehrlichkeit bei der Bewerbung. Befolgen Sie diese Kniffe bei der Erstellung Ihrer Vita, sollte Ihre Vita so aufbereitet sein, dass sie die erste Hürde im Recruiting-Prozess gut meistert – egal ob der erste Empfänger ein Mensch oder eine Künstliche Intelligenz ist. Um zu einem Gespräch eingeladen zu werden, sollte in das Zusammenstellen der Bewerbungsunterlagen Zeit investiert werden. Ist bei der Vorsortierung eine künstliche Intelligenz im Spiel, heißt es zudem, einige Standards zu beachten. Foto: Lisa-S – shutterstock.com Eine Umfrage hat ergeben, dass ein Großteil, nämlich etwa zwei Drittel der sich Bewerbenden , sich gar nicht über den Einsatz von Algorithmen im Bewerbungsprozess bewusst sind. Auch wenn sich dies mittlerweile schätzungsweise zu etwa einem Gleichgewicht verschoben haben dürfte, gibt es dennoch viele, denen dies nicht bewusst ist. Merken Sie sich daher zunächst die Faustformel: Je größer das Unternehmen, desto höher die Chance, dass Algorithmen bei der Bewertung Ihrer Bewerbung involviert sind. Dies gilt vor allem für einfache Algorithmen, die z.B. ein Matching vornehmen oder bestimmte Aspekte sortieren, sowie kategorisieren und katalogisieren. Denn sobald ein Algorithmus im Rahmen des Prozesses auch aktiv eine “Entscheidung trifft”, ist nach DSGVO die Zustimmung der betroffenen Person erforderlich und Sie haben das Recht, Informationen über die zugrundeliegende Entscheidungslogik zu erhalten. Lesen Sie daher im Idealfall vor der Bewerbung aufmerksam die Datenschutzbestimmungen des Unternehmens. Wenn Sie nun aber wissen oder davon ausgehen, dass ein Unternehmen Algorithmen für die Bearbeitung von Bewerbungen einsetzt, dann gibt es eine ganze Menge Tipps und Kniffe, wie Sie dies zu Ihrem Vorteil nutzen können. Algorithmen verarbeiten Informationen vor allem dann besonders zuverlässig, wenn Sie klar strukturiert und innerhalb dieser Struktur logisch angeordnet sind. Versehen Sie daher sämtliche Teilbereiche Ihres Lebenslaufs mit entsprechenden Überschriften, wie “Ausbildung”, “Berufserfahrungen” etc. Achten Sie anschließend darauf, dass Sie diese Struktur stringent einhalten und die Sortierung einheitlich ist. Üblich ist mittlerweile eine antichronologische Auflistung. Verzichten Sie aus diesem Grund auch lieber auf allzu ausgefallene und kreative Designs, schräge Anordnungen, sowie Tabellen, Logos oder Piktogramme, da diese die Dokumentenstruktur unterlaufen. Geben Sie Beschäftigungszeiten niemals nur in Jahren an – offen gesagt hassen das bereits die menschlichen Personalerinnen und Personaler –, sondern immer mit den dazugehörigen Monaten. Haben Sie diese vergessen? Dann finden Sie die Information im jeweiligen Arbeitszeugnis. Sie möchten damit Lücken kaschieren? Das ist sowieso die Vermutung des Personalers oder der Personalerin. In aller Regel “achten” Algorithmen in einer Bewerbung auf bestimmte Stichworte, die Sie in der Regel in der Stellenausschreibung finden. Allerdings liegt der Fokus hierauf vor allem auf fachlichen Anforderungen, weniger auf persönlichen. Kaum ein Algorithmus wird Ihre Bewerbung beispielsweise nach “Kommunikationsfähigkeit” oder “Kundenorientierung” durchleuchten. Wenn in der Ausschreibung aber bestimmte, fachliche Anforderungen genannt werden, wie z.B. bestimmte Technologien und Programmiersprachen bei IT-Positionen, dann müssen diese unbedingt in die Bewerbung mit aufgenommen werden, und zwar im exakten Wortlaut der Stellenanzeige. Weitere Informationen zu fachlich relevanten Themen und Stichworten, auf die auch der Algorithmus möglicherweise reagiert, finden Sie auf der Webseite des Unternehmens. Achten Sie dabei darauf, dass für Ihre angestrebte Position sowohl lokale, als auch globale Begrifflichkeiten gebräuchlich sein könnten und versuchen Sie entsprechend, alle Optionen zu berücksichtigen. Wenn Sie eine Skill-Liste erstellen, ergänzen Sie die einzelnen Fähigkeiten bestenfalls um Ihr Kenntnisniveau. Hierzu sollten Sie Begriffe nutzen, bei denen Sie mit an Sicherheit grenzender Wahrscheinlichkeit davon ausgehen können, dass der Algorithmus diese interpretieren kann – wie z.B. “Expert”, “fortgeschritten” usw. Lesetipp: Fieser Code – Wenn Algorithmen Vorurteile ausspucken Reine Skill-Listen ergeben jedoch ohnehin nur dann Sinn, wenn es um Aufgaben mit einer Vielzahl fachlicher Anforderungen geht, wie z.B. in der Softwareentwicklung. Achten Sie dann darauf, dass Sie die Liste auch für menschliche Augen ansprechend und nachvollziehbar ist. Sollten für Sie hingegen nur einige Kernfähigkeiten relevant sein, dann kann es mehr Sinn machen, die Fähigkeiten anhand praktischer Erfahrungen aufzuführen. Da viele Algorithmen Profile mittlerweile semantisch nach Inhalten durchleuchten, sollte dies der Erfassung Ihrer Fähigkeiten in aller Regel nicht schaden. In den letzten Jahren häufen sich in Bewerbungen sogenannte Management Summaries oder “Kurzprofile”. Diese sind mitunter gar nicht so kurz, wie der Name vermuten lässt. Doch ist hierbei Vorsicht geboten. Denn ausschweifende Formulierungen und irrelevante Informationen sorgen für eine möglicherweise ungenauere oder sogar falsche Klassifizierung durch den Algorithmus. Gleichzeitig sollten Sie darauf achten, die “Sprache des Unternehmens” zu sprechen. Auch hier bietet Ihnen bereits die Stellenanzeige wichtige Anhaltspunkte. Wenn es für einen Sachverhalt Ihrer Arbeit mehrere, unterschiedliche Formulierungen gibt, nutzen Sie immer diejenige, die auch in dem Unternehmen verwendet wird, in dem Sie sich bewerben. Nehmen Sie übrigens lieber Abstand davon, Ihre Teamfähigkeit, Flexibilität, Kreativität, Belastbarkeit usw. in Ihrer Bewerbung zu betonen. Zum einen sucht kein HR-Algorithmus dieser Welt nach diesen Begriffen und zum anderen sind diese Worthülsen ohne konkrete Beispiele aus der Praxis für Ihre Bewerbung auch für den menschlichen Betrachter im Unternehmen nutzlos. Der Tipp, Rechtschreibfehler in der Bewerbung zu vermeiden, ist sicherlich nicht erst seit dem Einsatz von Algorithmen gültig und wichtig. Doch während das menschliche Auge über manchen Rechtschreibfehler genauso flüchtig hinwegliest, wie er auch entstanden ist, oder der menschliche Leser diesen sanftmütig toleriert, wird ein Algorithmus in den meisten Fällen unverzeihlich aussortieren. Der Begriff, den Sie ja eigentlich auch meinen, kommt für den Algorithmus im Dokument schlicht nicht vor. Wenn Sie beispielsweise anstatt “Kreditorenbuchhaltung” laut Ihrem Lebenslauf Erfahrungen in “Kreditprenbuchhaltung” haben, dann wird der Algorithmus Ihnen diese Fähigkeit einfach nicht zuerkennen. Achten Sie unbedingt darauf, dass Ihr finales Dokument maschinenlesbar und das Kopieren von Text möglich ist. Verzichten Sie außerdem auf irrelevante Informationen, wie z.B. Namen, Geburtsdatum oder gar Beruf der Eltern, denn solche Informationen “verwirren” den Algorithmus. Nehmen Sie übrigens auch lieber Abstand von dem Gedanken, Ihre Stichwortliste noch um ein paar interessante, aber nicht zutreffende Begriffe mit weißer Schrift auf weißem Grund zu ergänzen. Manch ein Algorithmus erkennt mittlerweile sehr wohl auch die Textfarbe. Zudem werden Sie ja auch in möglicherweise anschließenden Gesprächen gezielt auf diese Kenntnisse hin befragt. Spätestens dann sollte ein solcher “Täuschungsversuch” auffallen und Sie haben bei diesem Unternehmen keine Chancen mehr. Daher empfiehlt sich gegenüber dem Algorithmus schon im eigenen Interesse Ehrlichkeit bei der Bewerbung. Befolgen Sie diese Kniffe bei der Erstellung Ihrer Vita, sollte Ihre Vita so aufbereitet sein, dass sie die erste Hürde im Recruiting-Prozess gut meistert – egal ob der erste Empfänger ein Mensch oder eine Künstliche Intelligenz ist.",
    "source": "cio",
    "crawled_at": "2025-05-28T09:16:54.010995+00:00"
  },
  {
    "url": "https://www.cio.de/article/3831704/cio-des-jahres-2025-wettbewerb-startet-2.html",
    "title": "Bewerben Sie sich noch bis 30. Mai für den CIO des Jahres 2025",
    "published": "2025-05-26T07:14:25+00:00",
    "author": "",
    "text": "cio.de / Tobias Tschepe Es ist wieder so weit: Der renommierteste IT-Award Deutschlands ist startklar. Bis zum 30. Mai 2025 laden wir CIOs, IT-Vorstände aber auch CISOs und Digital-Verantwortliche aus Unternehmen sowie Öffentlichen Einrichtungen in Bund, Ländern und Kommunen herzlich ein, sich mit spannenden IT-Projekten für den „CIO des Jahres 2025“ zu bewerben. +++ Machen Sie mit beim CIO des Jahres Award 2025 +++ Wie immer küren wir die Gewinnerinnen und Gewinner in den Kategorien Großunternehmen, Mittelstand und Public Sector. Darüber hinaus vergibt die Jury wieder eine Reihe von Special Awards – unter anderem zu den Themen Artificial Intelligence, Customer Experience, Cloud Excellence und Sustainability. Alle Preisträgerinnen und Preisträger sowie die Finalistinnen und Finalisten, die es unter die jeweiligen Top-5 geschafft haben, zeichnen wir im Rahmen unserer feierlichen Award-Gala am 16. Oktober 2025 in München aus. Machen Sie also mit und bewerben Sie sich für den CIO des Jahres 2025 . Wir freuen uns auf Ihre Teilnahme. Alle weiteren Informationen zum Wettbewerb und alle Unterlagen finden Sie ab sofort hier . cio.de / Tobias Tschepe Es ist wieder so weit: Der renommierteste IT-Award Deutschlands ist startklar. Bis zum 30. Mai 2025 laden wir CIOs, IT-Vorstände aber auch CISOs und Digital-Verantwortliche aus Unternehmen sowie Öffentlichen Einrichtungen in Bund, Ländern und Kommunen herzlich ein, sich mit spannenden IT-Projekten für den „CIO des Jahres 2025“ zu bewerben. +++ Machen Sie mit beim CIO des Jahres Award 2025 +++ Wie immer küren wir die Gewinnerinnen und Gewinner in den Kategorien Großunternehmen, Mittelstand und Public Sector. Darüber hinaus vergibt die Jury wieder eine Reihe von Special Awards – unter anderem zu den Themen Artificial Intelligence, Customer Experience, Cloud Excellence und Sustainability. Alle Preisträgerinnen und Preisträger sowie die Finalistinnen und Finalisten, die es unter die jeweiligen Top-5 geschafft haben, zeichnen wir im Rahmen unserer feierlichen Award-Gala am 16. Oktober 2025 in München aus. Machen Sie also mit und bewerben Sie sich für den CIO des Jahres 2025 . Wir freuen uns auf Ihre Teilnahme. Alle weiteren Informationen zum Wettbewerb und alle Unterlagen finden Sie ab sofort hier .",
    "source": "cio",
    "crawled_at": "2025-05-28T09:16:54.051066+00:00"
  },
  {
    "url": "https://www.cio.de/article/3992261/heute-startet-der-cio-charity-runandbike-2025.html",
    "title": "Der CIO Charity Run&Bike 2025 ist live!",
    "published": "2025-05-26T07:22:35+00:00",
    "author": "",
    "text": "Foundry Es geht los! Vom 23. Mai bis 9. Juni 2025 sporteln Deutschlands IT-Verantwortliche im Rahmen den CIO Charity Run&Bike gemeinsam für den guten Zweck. Über 1.000 IT-Verantwortliche haben sich bereits angemeldet. Kurzentschlossene können sich weiterhin registrieren: https://www.cio-charity.de/ Egal ob Laufschuh, Fahrrad oder Rollstuhl: mit jedem gemeinsam erzielten Kilometer unterstützt die Charity-Aktion der CIO-Community gemeinnützige Organisationen für mehr Bildungsgerechtigkeit, Chancengleichheit sowie die digitale Integration von benachteiligten Jugendlichen und jungen Erwachsenen. Verfolgt die Aktion und teilt euren Beitrag in den sozialen Medien unter dem Hashtag #CIOcharity25. „Unterstützen benachteiligter Kinder ist ganz viele Schweißtropfen wert“, bringt Peter Meyerhans, CIO bei der Drees & Sommer SE, den Grund für das rege Interesse deutscher CIOs an der Spendenaktion auf den Punkt. Markus Bentele, VP Information Technology / Group CIO und Mitglied des Aufsichtsrats bei der Mahle GmbH, freut sich auch in diesem Jahr auf die Veranstaltung und appelliert an die Community: „Wir haben auch als CIOs eine soziale Mitverantwortung und deswegen lasst uns sporteln für den guten Zweck. Mit jedem erzielten Kilometer, egal ob Laufschuh, Fahrrad oder Rollstuhl unterstützten wir die Charity-Aktion der CIO-Community und damit gemeinnützige Organisationen für mehr Bildungsgerechtigkeit, Chancengleichheit und die digitale Integration von benachteiligten Jugendlichen und jungen Erwachsenen – Also nicht nachdenken, sondern laufen, radeln oder rollen.“ 2025 unterstützt der CIO Charity Run&Bike die START-Stiftung und Save the Children. START setzt sich seit 2002 für Chancengerechtigkeit ein, indem die Stiftung deutschlandweit Jugendliche mit Migrationshintergrund in Bildung und Engagement fördert. Das Sozialunternehmen bietet ihnen Ressourcen, Netzwerke und Zugangsmöglichkeiten, um ihre Zukunft aktiv zu gestalten und einen gesellschaftlichen Beitrag zu leisten. Mehr zur START-Stiftung und deren Förderinitiativen lest ihr im ausführlichen Artikel: „CIO Charity Run&Bike 2025 – Lernen Sie die START-Stiftung kennen“ Save the Children ist die weltweit größte unabhängige Kinderrechtsorganisation. Sie unterstützt Kinder und ihre Familien in Deutschland und rund 120 Ländern. Die Organisation agiert unparteiisch und unabhängig von politischen, religiösen oder anderen Bindungen, mit dem Ziel, die Rechte und das Wohlergehen aller Kinder zu fördern. Mehr zum Engagement von Save the Children und welchen Impact jeder gespendete Euro hat, erfahrt ihr im Artikel: „CIO Charity Run&Bike 2025 – Lernen Sie Save the Children kennen“ Der Spendentopf ist bereits jetzt mit 75.000 Euro gefüllt. Dafür danken wir unseren Partnern: Acent, Adesso, Faktor D Consulting, Infosys, p.digital, Randstad digital, Servicenow, Skaylink, Tata Consultancy Services (TCS) und Foundry. Außerdem kann der Spendentopf durch Direktspenden weiter befüllt werden! Der Spender mit der höchsten Direktspende erhält in diesem Jahr ein Bild des Performancekünstlers Michael Raivard! Hier geht es zur Direktspende: https://www.betterplace.org/de/fundraising-events/48834-cio-charity-run-bike25 Wer lieber gemeinsam mit anderen für den guten Zweck laufen möchte, ist herzlich zum Local Run am 27. Mai 2025 in Frankfurt am Main eingeladen. Local-Run-Partner ist Tata Consultancy Services (TCS). Die Strecke ist ein Rundweg und einen Kilometer lang. Jeder kann so viele Runde drehen, wie er möchte. Hier findet Ihr alle Informationen dazu: CIO Charity Run&Bike 25 ist eine Aktion von CIO, CIO Stiftung und WHU. Seit 2011 unterstützen die Charity-Initiativen der CIO-Community Kinder und Jugendliche, die einen erschwerten Zugang zu Bildungsmöglichkeiten haben – aus finanziellen oder sozialen Gründen. Jedes Jahr wählt das Kuratorium der CIO-Stiftung zwei Förderinitiativen als Nutznießer der Aktion, die sich der Förderungen der gesellschaftlichen und digitalen Teilhabe verschrieben haben. Foundry Es geht los! Vom 23. Mai bis 9. Juni 2025 sporteln Deutschlands IT-Verantwortliche im Rahmen den CIO Charity Run&Bike gemeinsam für den guten Zweck. Über 1.000 IT-Verantwortliche haben sich bereits angemeldet. Kurzentschlossene können sich weiterhin registrieren: https://www.cio-charity.de/ Egal ob Laufschuh, Fahrrad oder Rollstuhl: mit jedem gemeinsam erzielten Kilometer unterstützt die Charity-Aktion der CIO-Community gemeinnützige Organisationen für mehr Bildungsgerechtigkeit, Chancengleichheit sowie die digitale Integration von benachteiligten Jugendlichen und jungen Erwachsenen. Verfolgt die Aktion und teilt euren Beitrag in den sozialen Medien unter dem Hashtag #CIOcharity25. „Unterstützen benachteiligter Kinder ist ganz viele Schweißtropfen wert“, bringt Peter Meyerhans, CIO bei der Drees & Sommer SE, den Grund für das rege Interesse deutscher CIOs an der Spendenaktion auf den Punkt. Markus Bentele, VP Information Technology / Group CIO und Mitglied des Aufsichtsrats bei der Mahle GmbH, freut sich auch in diesem Jahr auf die Veranstaltung und appelliert an die Community: „Wir haben auch als CIOs eine soziale Mitverantwortung und deswegen lasst uns sporteln für den guten Zweck. Mit jedem erzielten Kilometer, egal ob Laufschuh, Fahrrad oder Rollstuhl unterstützten wir die Charity-Aktion der CIO-Community und damit gemeinnützige Organisationen für mehr Bildungsgerechtigkeit, Chancengleichheit und die digitale Integration von benachteiligten Jugendlichen und jungen Erwachsenen – Also nicht nachdenken, sondern laufen, radeln oder rollen.“ 2025 unterstützt der CIO Charity Run&Bike die START-Stiftung und Save the Children. START setzt sich seit 2002 für Chancengerechtigkeit ein, indem die Stiftung deutschlandweit Jugendliche mit Migrationshintergrund in Bildung und Engagement fördert. Das Sozialunternehmen bietet ihnen Ressourcen, Netzwerke und Zugangsmöglichkeiten, um ihre Zukunft aktiv zu gestalten und einen gesellschaftlichen Beitrag zu leisten. Mehr zur START-Stiftung und deren Förderinitiativen lest ihr im ausführlichen Artikel: „CIO Charity Run&Bike 2025 – Lernen Sie die START-Stiftung kennen“ Save the Children ist die weltweit größte unabhängige Kinderrechtsorganisation. Sie unterstützt Kinder und ihre Familien in Deutschland und rund 120 Ländern. Die Organisation agiert unparteiisch und unabhängig von politischen, religiösen oder anderen Bindungen, mit dem Ziel, die Rechte und das Wohlergehen aller Kinder zu fördern. Mehr zum Engagement von Save the Children und welchen Impact jeder gespendete Euro hat, erfahrt ihr im Artikel: „CIO Charity Run&Bike 2025 – Lernen Sie Save the Children kennen“ Der Spendentopf ist bereits jetzt mit 75.000 Euro gefüllt. Dafür danken wir unseren Partnern: Acent, Adesso, Faktor D Consulting, Infosys, p.digital, Randstad digital, Servicenow, Skaylink, Tata Consultancy Services (TCS) und Foundry. Außerdem kann der Spendentopf durch Direktspenden weiter befüllt werden! Der Spender mit der höchsten Direktspende erhält in diesem Jahr ein Bild des Performancekünstlers Michael Raivard! Hier geht es zur Direktspende: https://www.betterplace.org/de/fundraising-events/48834-cio-charity-run-bike25 Wer lieber gemeinsam mit anderen für den guten Zweck laufen möchte, ist herzlich zum Local Run am 27. Mai 2025 in Frankfurt am Main eingeladen. Local-Run-Partner ist Tata Consultancy Services (TCS). Die Strecke ist ein Rundweg und einen Kilometer lang. Jeder kann so viele Runde drehen, wie er möchte. Hier findet Ihr alle Informationen dazu: CIO Charity Run&Bike 25 ist eine Aktion von CIO, CIO Stiftung und WHU. Seit 2011 unterstützen die Charity-Initiativen der CIO-Community Kinder und Jugendliche, die einen erschwerten Zugang zu Bildungsmöglichkeiten haben – aus finanziellen oder sozialen Gründen. Jedes Jahr wählt das Kuratorium der CIO-Stiftung zwei Förderinitiativen als Nutznießer der Aktion, die sich der Förderungen der gesellschaftlichen und digitalen Teilhabe verschrieben haben.",
    "source": "cio",
    "crawled_at": "2025-05-28T09:16:54.093381+00:00"
  },
  {
    "url": "https://www.cio.de/article/3994922/fruhere-vw-manager-wegen-dieselskandal-zu-haft-verurteilt.html",
    "title": "Frühere VW-Manager wegen Dieselskandal zu Haft verurteilt",
    "published": "2025-05-26T09:27:22+00:00",
    "author": "",
    "text": "Wellnhofer Designs – shutterstock.com Im Strafprozess zur Dieselaffäre sind vier frühere Führungskräfte von Volkswagen wegen Betrugs schuldig gesprochen worden. Die Wirtschaftsstrafkammer des Landgerichts Braunschweig verurteilte zwei Angeklagte zu mehrjährigen Haftstrafen, zwei Ex-Mitarbeiter erhielten Bewährungsstrafen. Ein ehemaliger Leiter der Dieselmotoren-Entwicklung muss für viereinhalb Jahre ins Gefängnis. Zwei Jahre und sieben Monate Haft bekam der frühere Leiter der Antriebselektronik. Der ranghöchste Angeklagte, ein Ex-Entwicklungsvorstand der Marke Volkswagen, erhielt ein Jahr und drei Monate auf Bewährung. Ein ehemaliger Abteilungsleiter wurde zu einem Jahr und zehn Monaten auf Bewährung verurteilt. Mit dem Urteil geht ein riesiges Verfahren nach fast vier Jahren zu Ende. Während die Angeklagten aus Sicht der Ermittler überführt sind, wehren sich die Männer und sehen sich als Bauernopfer. Die Staatsanwaltschaft hatte zwischen zwei und vier Jahren Gefängnis gefordert und hielt nur in einem Fall Bewährung für angebracht. Die Verteidigung dagegen plädierte auf drei Freisprüche und eine Verwarnung. Das Urteil ist nicht rechtskräftig und die juristische Aufarbeitung ist auch nach diesem Schuldspruch nicht beendet. In Braunschweig sind nach dem ersten Prozess und dem Komplex gegen Winterkorn noch vier weitere Strafverfahren gegen insgesamt 31 Angeklagte offen, wie ein Sprecher des Landgerichts sagte. Der Skandal um Manipulationen bei Abgastests von Dieselautos war im September 2015 aufgeflogen. In den USA hatte der Wolfsburger Autobauer kurz zuvor falsche Testergebnisse eingeräumt. Wenige Tage später trat Konzernchef Winterkorn zurück. VW schlitterte in eine der größten Krisen, die den Konzern nach eigenen Angaben bisher etwa 33 Milliarden Euro kostete. Ursprünglich geplant war, dass der frühere Volkswagen-Konzernchef Martin Winterkorn mit auf der Anklagebank sitzt. Sein Verfahrensteil wurde aber schon vor dem Auftakt im September 2021 aus gesundheitlichen Gründen abgetrennt. Mittlerweile äußerte sich Winterkorn sowohl als Zeuge als auch als Angeklagter vor Gericht und wies dabei die Verantwortung für den Dieselskandal entschieden von sich. Ein Unfall mit einem Klinikaufenthalt unterbrach den Prozess gegen den prominentesten Angeklagten aber. Ob und wann das Verfahren gegen den mittlerweile 78-Jährigen fortgesetzt werden kann, ist völlig offen. (dpa/ad) Wellnhofer Designs – shutterstock.com Im Strafprozess zur Dieselaffäre sind vier frühere Führungskräfte von Volkswagen wegen Betrugs schuldig gesprochen worden. Die Wirtschaftsstrafkammer des Landgerichts Braunschweig verurteilte zwei Angeklagte zu mehrjährigen Haftstrafen, zwei Ex-Mitarbeiter erhielten Bewährungsstrafen. Ein ehemaliger Leiter der Dieselmotoren-Entwicklung muss für viereinhalb Jahre ins Gefängnis. Zwei Jahre und sieben Monate Haft bekam der frühere Leiter der Antriebselektronik. Der ranghöchste Angeklagte, ein Ex-Entwicklungsvorstand der Marke Volkswagen, erhielt ein Jahr und drei Monate auf Bewährung. Ein ehemaliger Abteilungsleiter wurde zu einem Jahr und zehn Monaten auf Bewährung verurteilt. Mit dem Urteil geht ein riesiges Verfahren nach fast vier Jahren zu Ende. Während die Angeklagten aus Sicht der Ermittler überführt sind, wehren sich die Männer und sehen sich als Bauernopfer. Die Staatsanwaltschaft hatte zwischen zwei und vier Jahren Gefängnis gefordert und hielt nur in einem Fall Bewährung für angebracht. Die Verteidigung dagegen plädierte auf drei Freisprüche und eine Verwarnung. Das Urteil ist nicht rechtskräftig und die juristische Aufarbeitung ist auch nach diesem Schuldspruch nicht beendet. In Braunschweig sind nach dem ersten Prozess und dem Komplex gegen Winterkorn noch vier weitere Strafverfahren gegen insgesamt 31 Angeklagte offen, wie ein Sprecher des Landgerichts sagte. Der Skandal um Manipulationen bei Abgastests von Dieselautos war im September 2015 aufgeflogen. In den USA hatte der Wolfsburger Autobauer kurz zuvor falsche Testergebnisse eingeräumt. Wenige Tage später trat Konzernchef Winterkorn zurück. VW schlitterte in eine der größten Krisen, die den Konzern nach eigenen Angaben bisher etwa 33 Milliarden Euro kostete. Ursprünglich geplant war, dass der frühere Volkswagen-Konzernchef Martin Winterkorn mit auf der Anklagebank sitzt. Sein Verfahrensteil wurde aber schon vor dem Auftakt im September 2021 aus gesundheitlichen Gründen abgetrennt. Mittlerweile äußerte sich Winterkorn sowohl als Zeuge als auch als Angeklagter vor Gericht und wies dabei die Verantwortung für den Dieselskandal entschieden von sich. Ein Unfall mit einem Klinikaufenthalt unterbrach den Prozess gegen den prominentesten Angeklagten aber. Ob und wann das Verfahren gegen den mittlerweile 78-Jährigen fortgesetzt werden kann, ist völlig offen. (dpa/ad)",
    "source": "cio",
    "crawled_at": "2025-05-28T09:16:54.716603+00:00"
  },
  {
    "url": "https://www.cio.de/article/3994686/arzteprasident-algorithmen-entscheiden-nicht-uber-behandlung.html",
    "title": "Ärztepräsident: Algorithmen entscheiden nicht über Behandlung",
    "published": "2025-05-26T09:30:25+00:00",
    "author": "",
    "text": "fizkes – shutterstock.com Ärztepräsident Klaus Reinhardt sieht große Chancen für Künstliche Intelligenz in der Medizin, mahnt aber einen verantwortungsvollen Einsatz an. «Die Entscheidung über eine Behandlung müssen immer Ärztinnen und Ärzte treffen und nicht digitale Algorithmen», sagte der Chef der Bundesärztekammer der Deutschen Presse-Agentur. «Bei aller Technologie darf die menschliche Nähe nicht verloren gehen. Sie ist das Fundament guter Medizin.» Künstliche Intelligenz (KI) ist ein Hauptthema des Deutschen Ärztetags, der am Dienstag in Leipzig beginnt. Reinhardt sagte, auch in der Medizin eröffne KI völlig neue Perspektiven – mit besserer Diagnostik, personalisierten Therapien oder effizienteren Abläufen in der Versorgung. «So kann wieder mehr Raum für die direkte Zuwendung zu den Patientinnen und Patienten entstehen.» In der Forschung könne KI durch die Analyse riesiger Datenmengen die Entwicklung neuer Medikamente und Therapien beschleunigen. Der Ärztepräsident betonte zugleich: «Ethische Leitplanken und verlässliche rechtliche Rahmenbedingungen sind unerlässlich.» Sensible Gesundheitsdaten müssten geschützt und wirtschaftliche Einflussnahmen Dritter auf medizinische Entscheidungen ausgeschlossen werden. Trotz aller Herausforderungen sollte man sich den Blick auf die Chancen und Möglichkeiten nicht verstellen lassen. (dpa/ad) fizkes – shutterstock.com Ärztepräsident Klaus Reinhardt sieht große Chancen für Künstliche Intelligenz in der Medizin, mahnt aber einen verantwortungsvollen Einsatz an. «Die Entscheidung über eine Behandlung müssen immer Ärztinnen und Ärzte treffen und nicht digitale Algorithmen», sagte der Chef der Bundesärztekammer der Deutschen Presse-Agentur. «Bei aller Technologie darf die menschliche Nähe nicht verloren gehen. Sie ist das Fundament guter Medizin.» Künstliche Intelligenz (KI) ist ein Hauptthema des Deutschen Ärztetags, der am Dienstag in Leipzig beginnt. Reinhardt sagte, auch in der Medizin eröffne KI völlig neue Perspektiven – mit besserer Diagnostik, personalisierten Therapien oder effizienteren Abläufen in der Versorgung. «So kann wieder mehr Raum für die direkte Zuwendung zu den Patientinnen und Patienten entstehen.» In der Forschung könne KI durch die Analyse riesiger Datenmengen die Entwicklung neuer Medikamente und Therapien beschleunigen. Der Ärztepräsident betonte zugleich: «Ethische Leitplanken und verlässliche rechtliche Rahmenbedingungen sind unerlässlich.» Sensible Gesundheitsdaten müssten geschützt und wirtschaftliche Einflussnahmen Dritter auf medizinische Entscheidungen ausgeschlossen werden. Trotz aller Herausforderungen sollte man sich den Blick auf die Chancen und Möglichkeiten nicht verstellen lassen. (dpa/ad)",
    "source": "cio",
    "crawled_at": "2025-05-28T09:16:54.765855+00:00"
  },
  {
    "url": "https://www.cio.de/article/3994967/ifo-umfrage-weniger-unternehmen-wollen-stellen-abbauen.html",
    "title": "Ifo-Umfrage: Weniger Unternehmen wollen Stellen abbauen",
    "published": "2025-05-26T10:27:39+00:00",
    "author": "",
    "text": "Photo Smoothies – shutterstock.com Im Mai habe das vom Ifo-Institut ermittelte Beschäftigungsbarometer auf 95,2 Punkte zugelegt, von 94 Punkten im Vormonat, teilte das Forschungsinstitut am Montag in München mit. Der Wert ist damit den zweiten Monat in Folge gestiegen und hat den höchsten Stand seit Juli 2024 erreicht. “Der Arbeitsmarkt zeigt erste Anzeichen einer Stabilisierung”, kommentierte Ifo-Experte Klaus Wohlrabe das Ergebnis einer Umfrage unter deutschen Firmen. Allerdings zeige der Anstieg des Beschäftigungsbarometers bisher noch keine “echte Trendwende”, sagte er. Dies werde maßgeblich von der weiteren wirtschaftlichen Entwicklung abhängen. In den verschiedenen Bereichen der deutschen Wirtschaft zeigte die Umfrage deutliche Unterschiede. In der Industrie sei das Beschäftigungsbarometer im Mai zwar zum fünften Mal in Folge gestiegen. “Insgesamt bauen die Unternehmen jedoch weiterhin mehrheitlich Stellen ab”, heißt es weiter in der Mitteilung des Ifo-Instituts. Dagegen haben Dienstleister ihren Personalbestand leicht aufgestockt – insbesondere in der Leiharbeitsbranche keimt nach Einschätzung der Ifo-Experten “vorsichtiger Optimismus” auf. Im Handel überwiege hingegen weiter der Abbau von Stellen. Auch das Baugewerbe plane noch überwiegend mit weniger Beschäftigten, wenngleich sich auch hier der Stellenabbau verringert habe. Laut jüngsten Daten der Bundesagentur für Arbeit ist die Zahl der Arbeitslosen in Deutschland dank einer leichten Frühjahresbelebung im April um 36.000 auf 2,932 Millionen Menschen gesunken. Das sind aber 182.000 mehr als ein Jahr zuvor. Die Arbeitslosenquote ging im Vergleich zum Vormonat um 0,1 Punkte auf 6,3 Prozent zurück. (dpa/ad) Photo Smoothies – shutterstock.com Im Mai habe das vom Ifo-Institut ermittelte Beschäftigungsbarometer auf 95,2 Punkte zugelegt, von 94 Punkten im Vormonat, teilte das Forschungsinstitut am Montag in München mit. Der Wert ist damit den zweiten Monat in Folge gestiegen und hat den höchsten Stand seit Juli 2024 erreicht. “Der Arbeitsmarkt zeigt erste Anzeichen einer Stabilisierung”, kommentierte Ifo-Experte Klaus Wohlrabe das Ergebnis einer Umfrage unter deutschen Firmen. Allerdings zeige der Anstieg des Beschäftigungsbarometers bisher noch keine “echte Trendwende”, sagte er. Dies werde maßgeblich von der weiteren wirtschaftlichen Entwicklung abhängen. In den verschiedenen Bereichen der deutschen Wirtschaft zeigte die Umfrage deutliche Unterschiede. In der Industrie sei das Beschäftigungsbarometer im Mai zwar zum fünften Mal in Folge gestiegen. “Insgesamt bauen die Unternehmen jedoch weiterhin mehrheitlich Stellen ab”, heißt es weiter in der Mitteilung des Ifo-Instituts. Dagegen haben Dienstleister ihren Personalbestand leicht aufgestockt – insbesondere in der Leiharbeitsbranche keimt nach Einschätzung der Ifo-Experten “vorsichtiger Optimismus” auf. Im Handel überwiege hingegen weiter der Abbau von Stellen. Auch das Baugewerbe plane noch überwiegend mit weniger Beschäftigten, wenngleich sich auch hier der Stellenabbau verringert habe. Laut jüngsten Daten der Bundesagentur für Arbeit ist die Zahl der Arbeitslosen in Deutschland dank einer leichten Frühjahresbelebung im April um 36.000 auf 2,932 Millionen Menschen gesunken. Das sind aber 182.000 mehr als ein Jahr zuvor. Die Arbeitslosenquote ging im Vergleich zum Vormonat um 0,1 Punkte auf 6,3 Prozent zurück. (dpa/ad)",
    "source": "cio",
    "crawled_at": "2025-05-28T09:16:54.808469+00:00"
  },
  {
    "url": "https://www.cio.de/article/3661045/10-ratschlaege-fuer-erfolgreiche-besprechungen.html",
    "title": "10 Ratschläge für erfolgreiche Meetings",
    "published": "2025-05-27T03:31:02+00:00",
    "author": "",
    "text": "Sie wollen eine Botschaft kommunizieren? Dann versetzen Sie sich in die Lage ihrer Zuhörer. Foto: Gorodenkoff – shutterstock.com Zunächst scheint sich bei einer Besprechung in erster Linie alles um die die Sache zu drehen. Dennoch kann das Gespräch um ein sachliches Thema intensiv von Gefühlen mitbestimmt sein. So gehen Kommunikationsmodelle davon aus, dass das Verhältnis zwischen Sach- und Beziehungskomponenten mit einem Eisberg vergleichbar ist: Rund 20 Prozent erscheinen unmittelbar auf der sachlichen Ebene, wohingegen sich die anderen 80 Prozent verdeckt im Beziehungsbereich abspielen. Dieser Teil bedarf jedoch großer Aufmerksamkeit, damit die Besprechung erfolgreich verlaufen soll. Dazu zehn Tipps: Unabhängig davon, ob eine Routine-Besprechung oder eine einzelne Konferenz ansteht, ist die Versuchung groß, möglichst viele Themen abzuarbeiten und somit in die Komplexitätsfalle zu tappen. Dadurch sinkt die Aufmerksamkeit der am Gespräch Beteilgten sehr schnell. Spätestens wenn die Ergebnisse zusammengefasst werden, geht der Durchblick verloren. Am besten ist es, die Tagesordnungspunkte nach der KISS-Methode (keep ist simple and stupid) zu gliedern: Haben sich die Teilnehmer gegenseitig begrüßt und vorgestellt, kommen Themenblock, Zusammenfassung und das weitere Vorgehen zur Sprache. Allerdings sollte der Themenblock so wenig einzelne Themen wie möglich umfassen. Ist die Thematik sehr komplex und weitergehende Gliederungen notwendig, sollten Unterpunkte vorab besprochen werden. Bei unproblematischen Einzelfragen sind auch Einzelgespräche denkbar. Vor allem bei komplizierten Situationen mit verschiedenen Interessen bietet es sich an, Schritt für Schritt vorzugehen und zuerst mit ausgewählten Stakeholder zu konferieren. Allerdings besteht die Gefahr, dass sich später Beteiligte übergangen fühlen könnten und wahrscheinlich Ergebnisse der nachfolgenden gemeinsamen Besprechung in Frage gestelt werden. Für Vorgespräche ist daher eine gewisse Phase der Vorbereitung sinnvoll. Im Zusammenhang mit der terminlichen Abstimmung, der Anreise-Empfehlung oder der Hilfe bei der Hotelbuchung bieten sich zahlreiche Gelegenheiten zum Gedankenaustausch an – entweder direkt oder über die Sekretariate. Reisen kosten Zeit und Geld, daher können Besprechungen über moderne Medien wie Konferenztelefone, Videokonferenzen oder Online-Meetings organisiert werden. Für Routine-Meetings zwischen bekannten Akteuren eignen sich diese Medien hervorragend. Für Kick-offs, Krisengespräche oder Entscheidungsfindungen mit großer Tragweite ist der persönliche Kontakt ein Muss. Ist im Routine-Meeting mit ausschweifenden Erläuterungen zu rechnen? Lässt die Strategie-Konferenz eine schmerzhafte Entscheidung erwarten? Dann bietet sich ein Zeit-Management an, das die alltäglichen Lebensgewohnheiten nutzt: zur Mittagszeit geht es zum Essen, der Berufsverkehr läutet den Feierabend ein und sorgt damit für Unruhe im Besprechungsraum. Situationsgerecht eingeplant, können diese Leitplanken die Besprechungsdauer sinnvoll begrenzen oder eine passende Zäsur erlauben. Die Besprechungsvorbereitung beginnt mit den Einladungen. Innerhalb des Unternehmens können Online-Kalender vielleicht zur effizienten Terminfindung dienen, ansonsten ist die Einladung die erste Möglichkeit, mit den geplanten Teilnehmern in Kontakt zu treten. Der erste Eindruck zählt, selbst wenn sich die Akteure schon aus anderem Zusammenhang kennen. Dabei zeigen schon kleine Gesten große Wirkung: kann ein Parkplatz angeboten werden, gibt es gerade örtliche Besonderheiten bei der Anreise zu beachten, ist der Sitzungszeitraum für alle Teilnehmer akzeptabel und mit der Anreise “kompatibel”? Die Begrüßung beginnt nicht im Sitzungsraum, sondern bereits auf dem Weg dorthin. Sprechen sie die Teilnehmer bereits am Empfang mit deren Namen an und weisen Sie Ihnen den Weg zum Besprechungsraum. Es ist unwahrscheinlich, dass alle Teilnehmer gleichzeitig und exakt zum Besprechungsbeginn eintreffen. Hieraus ergeben sich gute Gelegenheiten, weitere Wertschätzung zu signalisieren: der kleine Imbiss aus der Teeküche wird besonders die weiter angereisten Teilnehmer erfreuen; die fünf Minuten Karrenzzeit erspart verspäteten Teilnehmern die Peinlichkeit, mit einer Entschuldigung in die Begrüßungsphase zu platzen; eine ausgedruckte Agenda mit Teilnehmerliste sowie Namensschildern und Schreibzeug auf dem Tisch schafft für alle Beteiligten gleiche Augenhöhe. Idealerweise lässt sich damit eine Aufmerksamkeit verbinden, welche mit dem Unternehmenslogo für den Wiedererkennungswert geschmückt, als “kleines Geschenk dir Freundschaft erhält”. Entscheidend ist dafür nicht der materielle Wert, sondern allein die freundliche Geste. Mit der Begrüßung und Vorstellung des geplanten Besprechungsverlaufs kann eine Vorstellungsrunde unmittelbar mit einem so genannten Blitzlicht verknüpft werden: welche Erwartungen haben die Teilnehmer mitgebracht, ist die Reihenfolge des geplanten Verlaufs akzeptabel, gibt es unberücksichtigte Aspekte? Diese Vorgehensweise erfordert zwar den Mut, unvorhergesehenen Situationen Raum zu eröffnen. Sie schafft aber ein offenes Gesprächsklima, das sich noch auszahlen kann. Visualisierungen können Besprechungsablauf sinnvoll unterstützen. Der Folieneinsatz wird jedoch dann Distanz schaffen, falls er den Eindruck erweckt, vorgefertigte Besprechungsergebnisse zu platzieren. Eine gemeinschaftlich entwickelte Skizze – etwa am Flipchart – fördert dagegen das offene Gesprächsklima und kann zu den besseren Ergebnissen führen, weil sich alle Beteiligten aktiv in das Geschehen einbringen und wiederfinden können. Das ist vor allem bei der Diskussion technologisch komplexer Fragen unter verschiedenen Personengruppen, wie Fachabteilung und IT-Abteilung oder IT-Manager im Führungs-Meeting des Unternehmens – entscheidend. Die Flipchart-Skizzen kann man leicht fotografieren und so dokumentieren sowie bei Bedarf auch später in eine professionelle Grafik umwandeln. Erfahrene Gesprächsmoderatoren fassen das Diskussionsergebnis am Ende jedes Besprechungspunktes in eigenen Worten zusammen und sorgen durch aktives Nachfragen dafür, dass spätestens hier letztmals Widerspruch angemeldet werden kann. Ist dies nicht der Fall, wird das Ergebnis im Protokoll festgehalten. Dabei ist das Herbeiführen einer einvernehmlichen Entscheidung natürlich wünschenswert, steht jedoch nicht alleine im Mittelpunkt. Entscheidend ist die Formulierung des kollektiv getragenen Ergebnisses, welches Mindermeinungen angemessen berücksichtigt. Moderne Medien lassen es gerade in schwierigen Besprechungssituationen zu, dass die Ergebnisse direkt formuliert und mittels Beamer für alle Beteiligten sichtbar dargestellt werden. Im Idealfall liegt so am Ende der Besprechung das Protokoll vor. Die besten Gesprächsergebnisse sind wertlos, wenn sie nach der Besprechung nicht unmittelbar weiter verfolgt werden. Grundlage dafür ist die zügige Bereitstellung Dokumentation der Ergebnisse, möglicherweise mit zeitlichem Versatz zur Durchsicht der Teilnehmer gegenüber Dritten – falls eine formale Genehmigung des Protokolls nötig ist. Dann gilt es, die Ergebnisse beziehungsweise Ziele aktiv zu verfolgen, ob im Einzelgespräch oder in der Folgebesprechung. Hier schließt sich der Kreislauf: je positiver die Teilnehmer das Meeting in Erinnerung haben, desto erfolgreicher wird der Folgekontakt verlaufen. Meetings sind wie Eisberge Foto: adike – shutterstock.com Auch wenn es um ein Sachthema (= Spitze des Eisbergs) geht, entscheidet die emotionale Kommunktion über Erfolg und Misserfolg einer Sitzung. Und letztere ist leider nicht sichtbar, ebenso wie der größte Teil des Eisbergs. 1. Lichten Sie Ihre Agenda … Foto: Ruslan Ivantsov – shutterstock.com … sonst sehen Sie den Wald vor lauter Bäumen nicht. Beschränken Sie sich auf das Wesentliche und halten Sie sich an eine Struktur: Begrüßung und Vorstellung; Themenblock; Zusammenfassung; weiteres Vorgehen. 2. Bringen Sie alle an einen Tisch … Foto: Rawpixels.com – shutterstock.com … sonst fühlen sich einige übergangen. Bei schwierigen Themen bieten sich Vorgespräche an. 3. Videokonferenzen … Foto: Cisco … sparen Zeit und Geld. Sie eignen sich für Routine-Meetings. Bei Kick-offs oder Krisengesprächen ist der persönliche Kontakt dagegen ein Muss. 4. Der Zeitpunkt eines Meetings … Foto: Andrey Popov – shutterstock.com … ist schon die halbe Miete. Wer ausschweifende Sitzungen vermeiden will, setzt sie vor der Mittagspause oder dann an, wenn der Berufsverkehr schon einsetzt. 5. Die Einladung … Foto: Zhukov Oleg – shutterstock.com …ist die erste Möglichkeit mit den Teilnehmern in Kontakt zu treten. Dabei zeigen schon kleine Gesten grosse Wirkung: kann ein Parkplatz angeboten werden, gibt es gerade örtliche Besonderheiten bei der Anreise zu beachten. 6. Begrüßen Sie die Teilnehmer … Foto: tsyhun – shutterstock.com … nicht erst im Sitzungsraum, sondern schon am Empfang. 7. Eine kleine Aufmerksamkeit aus der Teeküche … Foto: Silatip – shutterstock.com … erfreut besonders die weiter angereisten Teilnehmer der Besprechung. 8. Flipchart statt Powerpoint Foto: auremar – shutterstock.com Eine gemeinsam entwickelte Skizze am Flipchart fördert das offene Gesprächsklima und bringt oft mehr als eine vorgefertigte Präsentation, weil sich die Teilnehmer aktiv einbringen können. 9. Erfahrene Moderatoren … Foto: Michail Petrov – shutterstock.com … fassen die Ergebnisse am Ende des Besprechungspunktes zusammen und haken noch einmal nach, ob es Einwände gibt. 10. Nach dem Meeting ist vor dem Meeting Foto: benjaminec – shutterstock.com Zu Ergebnissen kommen, ist die eine Sache. Die andere ist aber, die Ergebnisse auch umzusetzen beziehungsweise die Ziele zu verfolgen, und zwar möglichst zeitnah zur Besprechung. Sie wollen eine Botschaft kommunizieren? Dann versetzen Sie sich in die Lage ihrer Zuhörer. Foto: Gorodenkoff – shutterstock.com Zunächst scheint sich bei einer Besprechung in erster Linie alles um die die Sache zu drehen. Dennoch kann das Gespräch um ein sachliches Thema intensiv von Gefühlen mitbestimmt sein. So gehen Kommunikationsmodelle davon aus, dass das Verhältnis zwischen Sach- und Beziehungskomponenten mit einem Eisberg vergleichbar ist: Rund 20 Prozent erscheinen unmittelbar auf der sachlichen Ebene, wohingegen sich die anderen 80 Prozent verdeckt im Beziehungsbereich abspielen. Dieser Teil bedarf jedoch großer Aufmerksamkeit, damit die Besprechung erfolgreich verlaufen soll. Dazu zehn Tipps: Unabhängig davon, ob eine Routine-Besprechung oder eine einzelne Konferenz ansteht, ist die Versuchung groß, möglichst viele Themen abzuarbeiten und somit in die Komplexitätsfalle zu tappen. Dadurch sinkt die Aufmerksamkeit der am Gespräch Beteilgten sehr schnell. Spätestens wenn die Ergebnisse zusammengefasst werden, geht der Durchblick verloren. Am besten ist es, die Tagesordnungspunkte nach der KISS-Methode (keep ist simple and stupid) zu gliedern: Haben sich die Teilnehmer gegenseitig begrüßt und vorgestellt, kommen Themenblock, Zusammenfassung und das weitere Vorgehen zur Sprache. Allerdings sollte der Themenblock so wenig einzelne Themen wie möglich umfassen. Ist die Thematik sehr komplex und weitergehende Gliederungen notwendig, sollten Unterpunkte vorab besprochen werden. Bei unproblematischen Einzelfragen sind auch Einzelgespräche denkbar. Vor allem bei komplizierten Situationen mit verschiedenen Interessen bietet es sich an, Schritt für Schritt vorzugehen und zuerst mit ausgewählten Stakeholder zu konferieren. Allerdings besteht die Gefahr, dass sich später Beteiligte übergangen fühlen könnten und wahrscheinlich Ergebnisse der nachfolgenden gemeinsamen Besprechung in Frage gestelt werden. Für Vorgespräche ist daher eine gewisse Phase der Vorbereitung sinnvoll. Im Zusammenhang mit der terminlichen Abstimmung, der Anreise-Empfehlung oder der Hilfe bei der Hotelbuchung bieten sich zahlreiche Gelegenheiten zum Gedankenaustausch an – entweder direkt oder über die Sekretariate. Reisen kosten Zeit und Geld, daher können Besprechungen über moderne Medien wie Konferenztelefone, Videokonferenzen oder Online-Meetings organisiert werden. Für Routine-Meetings zwischen bekannten Akteuren eignen sich diese Medien hervorragend. Für Kick-offs, Krisengespräche oder Entscheidungsfindungen mit großer Tragweite ist der persönliche Kontakt ein Muss. Ist im Routine-Meeting mit ausschweifenden Erläuterungen zu rechnen? Lässt die Strategie-Konferenz eine schmerzhafte Entscheidung erwarten? Dann bietet sich ein Zeit-Management an, das die alltäglichen Lebensgewohnheiten nutzt: zur Mittagszeit geht es zum Essen, der Berufsverkehr läutet den Feierabend ein und sorgt damit für Unruhe im Besprechungsraum. Situationsgerecht eingeplant, können diese Leitplanken die Besprechungsdauer sinnvoll begrenzen oder eine passende Zäsur erlauben. Die Besprechungsvorbereitung beginnt mit den Einladungen. Innerhalb des Unternehmens können Online-Kalender vielleicht zur effizienten Terminfindung dienen, ansonsten ist die Einladung die erste Möglichkeit, mit den geplanten Teilnehmern in Kontakt zu treten. Der erste Eindruck zählt, selbst wenn sich die Akteure schon aus anderem Zusammenhang kennen. Dabei zeigen schon kleine Gesten große Wirkung: kann ein Parkplatz angeboten werden, gibt es gerade örtliche Besonderheiten bei der Anreise zu beachten, ist der Sitzungszeitraum für alle Teilnehmer akzeptabel und mit der Anreise “kompatibel”? Die Begrüßung beginnt nicht im Sitzungsraum, sondern bereits auf dem Weg dorthin. Sprechen sie die Teilnehmer bereits am Empfang mit deren Namen an und weisen Sie Ihnen den Weg zum Besprechungsraum. Es ist unwahrscheinlich, dass alle Teilnehmer gleichzeitig und exakt zum Besprechungsbeginn eintreffen. Hieraus ergeben sich gute Gelegenheiten, weitere Wertschätzung zu signalisieren: der kleine Imbiss aus der Teeküche wird besonders die weiter angereisten Teilnehmer erfreuen; die fünf Minuten Karrenzzeit erspart verspäteten Teilnehmern die Peinlichkeit, mit einer Entschuldigung in die Begrüßungsphase zu platzen; eine ausgedruckte Agenda mit Teilnehmerliste sowie Namensschildern und Schreibzeug auf dem Tisch schafft für alle Beteiligten gleiche Augenhöhe. Idealerweise lässt sich damit eine Aufmerksamkeit verbinden, welche mit dem Unternehmenslogo für den Wiedererkennungswert geschmückt, als “kleines Geschenk dir Freundschaft erhält”. Entscheidend ist dafür nicht der materielle Wert, sondern allein die freundliche Geste. Mit der Begrüßung und Vorstellung des geplanten Besprechungsverlaufs kann eine Vorstellungsrunde unmittelbar mit einem so genannten Blitzlicht verknüpft werden: welche Erwartungen haben die Teilnehmer mitgebracht, ist die Reihenfolge des geplanten Verlaufs akzeptabel, gibt es unberücksichtigte Aspekte? Diese Vorgehensweise erfordert zwar den Mut, unvorhergesehenen Situationen Raum zu eröffnen. Sie schafft aber ein offenes Gesprächsklima, das sich noch auszahlen kann. Visualisierungen können Besprechungsablauf sinnvoll unterstützen. Der Folieneinsatz wird jedoch dann Distanz schaffen, falls er den Eindruck erweckt, vorgefertigte Besprechungsergebnisse zu platzieren. Eine gemeinschaftlich entwickelte Skizze – etwa am Flipchart – fördert dagegen das offene Gesprächsklima und kann zu den besseren Ergebnissen führen, weil sich alle Beteiligten aktiv in das Geschehen einbringen und wiederfinden können. Das ist vor allem bei der Diskussion technologisch komplexer Fragen unter verschiedenen Personengruppen, wie Fachabteilung und IT-Abteilung oder IT-Manager im Führungs-Meeting des Unternehmens – entscheidend. Die Flipchart-Skizzen kann man leicht fotografieren und so dokumentieren sowie bei Bedarf auch später in eine professionelle Grafik umwandeln. Erfahrene Gesprächsmoderatoren fassen das Diskussionsergebnis am Ende jedes Besprechungspunktes in eigenen Worten zusammen und sorgen durch aktives Nachfragen dafür, dass spätestens hier letztmals Widerspruch angemeldet werden kann. Ist dies nicht der Fall, wird das Ergebnis im Protokoll festgehalten. Dabei ist das Herbeiführen einer einvernehmlichen Entscheidung natürlich wünschenswert, steht jedoch nicht alleine im Mittelpunkt. Entscheidend ist die Formulierung des kollektiv getragenen Ergebnisses, welches Mindermeinungen angemessen berücksichtigt. Moderne Medien lassen es gerade in schwierigen Besprechungssituationen zu, dass die Ergebnisse direkt formuliert und mittels Beamer für alle Beteiligten sichtbar dargestellt werden. Im Idealfall liegt so am Ende der Besprechung das Protokoll vor. Die besten Gesprächsergebnisse sind wertlos, wenn sie nach der Besprechung nicht unmittelbar weiter verfolgt werden. Grundlage dafür ist die zügige Bereitstellung Dokumentation der Ergebnisse, möglicherweise mit zeitlichem Versatz zur Durchsicht der Teilnehmer gegenüber Dritten – falls eine formale Genehmigung des Protokolls nötig ist. Dann gilt es, die Ergebnisse beziehungsweise Ziele aktiv zu verfolgen, ob im Einzelgespräch oder in der Folgebesprechung. Hier schließt sich der Kreislauf: je positiver die Teilnehmer das Meeting in Erinnerung haben, desto erfolgreicher wird der Folgekontakt verlaufen. Meetings sind wie Eisberge Foto: adike – shutterstock.com Auch wenn es um ein Sachthema (= Spitze des Eisbergs) geht, entscheidet die emotionale Kommunktion über Erfolg und Misserfolg einer Sitzung. Und letztere ist leider nicht sichtbar, ebenso wie der größte Teil des Eisbergs. 1. Lichten Sie Ihre Agenda … Foto: Ruslan Ivantsov – shutterstock.com … sonst sehen Sie den Wald vor lauter Bäumen nicht. Beschränken Sie sich auf das Wesentliche und halten Sie sich an eine Struktur: Begrüßung und Vorstellung; Themenblock; Zusammenfassung; weiteres Vorgehen. 2. Bringen Sie alle an einen Tisch … Foto: Rawpixels.com – shutterstock.com … sonst fühlen sich einige übergangen. Bei schwierigen Themen bieten sich Vorgespräche an. 3. Videokonferenzen … Foto: Cisco … sparen Zeit und Geld. Sie eignen sich für Routine-Meetings. Bei Kick-offs oder Krisengesprächen ist der persönliche Kontakt dagegen ein Muss. 4. Der Zeitpunkt eines Meetings … Foto: Andrey Popov – shutterstock.com … ist schon die halbe Miete. Wer ausschweifende Sitzungen vermeiden will, setzt sie vor der Mittagspause oder dann an, wenn der Berufsverkehr schon einsetzt. 5. Die Einladung … Foto: Zhukov Oleg – shutterstock.com …ist die erste Möglichkeit mit den Teilnehmern in Kontakt zu treten. Dabei zeigen schon kleine Gesten grosse Wirkung: kann ein Parkplatz angeboten werden, gibt es gerade örtliche Besonderheiten bei der Anreise zu beachten. 6. Begrüßen Sie die Teilnehmer … Foto: tsyhun – shutterstock.com … nicht erst im Sitzungsraum, sondern schon am Empfang. 7. Eine kleine Aufmerksamkeit aus der Teeküche … Foto: Silatip – shutterstock.com … erfreut besonders die weiter angereisten Teilnehmer der Besprechung. 8. Flipchart statt Powerpoint Foto: auremar – shutterstock.com Eine gemeinsam entwickelte Skizze am Flipchart fördert das offene Gesprächsklima und bringt oft mehr als eine vorgefertigte Präsentation, weil sich die Teilnehmer aktiv einbringen können. 9. Erfahrene Moderatoren … Foto: Michail Petrov – shutterstock.com … fassen die Ergebnisse am Ende des Besprechungspunktes zusammen und haken noch einmal nach, ob es Einwände gibt. 10. Nach dem Meeting ist vor dem Meeting Foto: benjaminec – shutterstock.com Zu Ergebnissen kommen, ist die eine Sache. Die andere ist aber, die Ergebnisse auch umzusetzen beziehungsweise die Ziele zu verfolgen, und zwar möglichst zeitnah zur Besprechung.",
    "source": "cio",
    "crawled_at": "2025-05-28T09:16:54.854364+00:00"
  },
  {
    "url": "https://www.cio.de/article/3994197/wie-tech-konzerne-das-dei-rad-zuruckdrehen.html",
    "title": "Wie Tech-Konzerne das DEI-Rad zurückdrehen",
    "published": "2025-05-27T04:13:00+00:00",
    "author": "",
    "text": "Jacob Lund / Shutterstock Im Zuge der Kampagne der Trump-Administration gegen DEI-Initiativen (Diversity, Equity und Inclusion – Vielfalt, Gerechtigkeit und Inklusion) sind viele Unternehmen der Tech-Branche auf eine neue Linie eingeschwenkt. Im Gegensatz zu ihren Versprechen aus dem Jahr 2020, sich für Vielfalt einzusetzen, machten bekannte Konzerne wie Google, Amazon und Meta Schlagzeilen, weil sie ihre DEI-Programme beendet oder zurückgefahren haben. Einige eilten den Übergriffen der Trump-Administration sogar voraus, indem sie bereits am 10. Januar 2025, mehr als eine Woche vor dem offiziellen Amtsantritt der Trump-Administration, Änderungen an der DEI-Sprache und den Programmen vorgenommen haben. Abonnieren Sie unsere CIO-Newsletter für mehr Einblicke, Hintergründe und Deep Dives aus der IT-Community. Berichten zufolge sehen sich Unternehmen aus allen Branchen den Forderungen von Aktionären ausgesetzt, die DEI-Sprache zu reduzieren und Diversitätsziele aus den öffentlichen Berichten zu streichen. Unternehmen wie Costco und Apple haben sich gegen diese „Vorschläge“ gewehrt. Viele andere haben jedoch nachgegeben und darüber hinaus DEI-Mitarbeiter entlassen sowie interne DEI-Initiativen zusammengestrichen. Im Zuge dessen ist dieser Abbau auch in Europa angekommen. So hieß es Mitte Mai in Berichten , dass SAP den Frauenanteil im Konzern nicht weiter gezielt fördern will – die angepeilte Quote von 40 Prozent in der Belegschaft werde aufgegeben. Zudem verliere das „Diversity & Inclusion Office seine Eigenständigkeit. Auch T-Mobile, Roche, Novartis und die UBS hätte ihre Ziele angepasst, so die „ Personalwirtschaft “ im April. Die „Süddeutsche Zeitung“ titelte einen Monat später: „ Goodbye, Diversity? “ Wir zeigen Ihnen, wo die wichtigsten Akteure der US-Tech-Branche derzeit in Sachen Vielfalt, Gleichberechtigung und Integration stehen. Zu Beginn des Jahres schien es, als wolle IBM an seinen DEI-Initiativen festhalten. Als die konservative Denkfabrik „The Heritage Foundation“ unter anderem IBM aufforderte, finanzielle Anreize und Boni für DEI aufzugeben, wehrte sich der Konzern zunächst gegen diesen Forderung. In den vergangenen Monaten hat die Führung von Big Blue jedoch eine Kehrtwende vollzogen und erhebliche Änderungen an den DEI-Praktiken angekündigt. Dies ist ein überraschender Schritt für ein Unternehmen, das ein Pionier der Inklusion gewesen ist, indem es 1984 die sexuelle Orientierung in seine globale Nichtdiskriminierungs-Policy aufnahm und diese 2002 um die Geschlechtsidentität erweiterte. Am 10. April 2025 gab der rechte Influencer Robby Starbuck eine Erklärung ab, in der er sich auf ein internes Memo bezog. Demnach hatte IBM das Ende der DEI-Abteilung und des Diversity Councils angekündigt, die ursprünglich in den 1990er Jahren ins Leben gerufen worden waren. IBM soll zudem angekündigt haben, dass es nicht mehr am HRC-Arbeitsplatzindex (Human Rights Campaign) teilnehmen wird. In den vergangenen 15 Jahren hatte der Konzern hier eine Quote von 100 Prozent erreichte und damit zu den besten Arbeitsplätzen für LGBTQ+-Gleichstellung gezählt. In einer Erklärung gegenüber Bloomberg gab IBM an, dass diese Änderungen durch die „inhärenten Spannungen bei der Umsetzung der Inklusion“ sowie durch rechtliche Faktoren angesichts der zunehmenden Kontrolle motiviert seien. Während einer Aktionärsversammlung am 30. April 2025 stellte die Heritage Foundation erneut einen Antrag, in dem die IBM-Aktionäre aufgefordert wurden, für die Abschaffung der DEI zu stimmen. Der Antrag wurde zurückgezogen, nachdem IBM Änderungen vorgenommen hatte, um die DEI im Unternehmen zu verringern. Im Januar dieses Jahres kündigte Meta an, mehrere interne DEI-Programme zu beenden , die sich um Diversität im Recruiting drehen. Außerdem wurde Maxine Williams, Chief Diversity Officer, in eine neue Rolle versetzt, um sich auf „Zugänglichkeit und Engagement“ zu konzentrieren. Meta zufolge zielt ein Teil dieses Rückzugs darauf ab, auf „faire und konsistente“ Praktiken zu fokussieren, die Voreingenommenheit („bias“) für alle, unabhängig von ihrem Hintergrund, abmildern, wie aus einem durchgesickerten Memo von Janelle Gale, VP of HR, hervorgeht. Zu diesen Bemühungen gehörten bisher die Abschaffung von Quoten, die Beendigung diversitätsgetriebener Rekrutierung sowie die Aufgabe von Bemühungen um die Vielfalt bei Lieferanten. Darüber hinaus wurden Programme für Gleichberechtigung und Eingliederung gestrichen und das Meta DEI-Team geschrumpft. Das Unternehmen sagte außerdem eine Spende in Höhe von einer Million Dollar für Trumps Amtseinführung zu und holte den UFC-Präsidenten und CEO Dana White, einen erklärten Trump-Unterstützer, in seinen Vorstand. Meta ersetzte auch seinen Präsidenten für globale Angelegenheiten laut dem Nachrichtenportal Axios durch Joel Kaplan, einen prominenten Republikaner. Nach dem Vorbild von Meta hat Google alle Ziele für die Einstellung von Mitarbeitern nach diversen Kriterien gestrichen. Obwohl das Unternehmen seit 2014 regelmäßig Berichte über Diversität publik gemacht hat, will Google die weitere Veröffentlichung solcher Reports prüfen, berichtet das Wall Street Journal . Darüber hinaus plant Google, alle DEI-Initiativen zu überprüfen, um zu sehen, ob sie mit den Anordnungen der Exekutive, die auf die Reduzierung der DEI abzielen, konform sind. Im jährlichen 10-K-Bericht des Unternehmens an die Börsenaufsicht in den USA wurde „Vielfalt“ nicht erwähnt – nach acht Mal im Vorjahr. Google entfernte außerdem Ende 2024 eine Handvoll kultureller Veranstaltungen aus dem Standard-Google-Kalender und änderte für alle Google Maps-Nutzer in den USA den Golf von Mexiko in den Golf von Amerika (inzwischen sehen mexikanische Nutzer den „Golf von Mexiko“, während alle Nutzer außerhalb der USA und Mexikos sowohl den „Golf von Mexiko“ als auch den „Golf von Amerika“ auf der Karte sehen). Google wurde inzwischen von der mexikanischen Regierung wegen der Umbenennung verklagt. Amazon hat in diesem Jahr seinen Jahresbericht und seine Website in Bezug auf Vielfalt gestrichen und einige DEI-Programme eingestellt. Einem internen Memo zufolge war das Unternehmen dabei, „veraltete Programme und Materialien zurückzuschrauben“. Im Jahr 2020 hatte sich Amazon verpflichtet, den Anteil Schwarzer Führungskräfte auf der Ebene der Vizepräsidenten und Direktoren zu verdoppeln, und dies im Jahr 2021 bekräftigt. Auf der Positionsseite des Unternehmens heißt es heute immerhin noch, dass sich das Unternehmen für ein vielfältiges und integratives Unternehmen einsetzt. Amazon hat auch erklärt, dass die von den Mitarbeitern geleiteten Affinitätsgruppen weiterhin tätig sein werden. Auf einer Aktionärsversammlung von Apple wurde der Antrag einer konservativen Gruppe abgelehnt, die eine Abschaffung der DEI-Richtlinien gefordert hatte. Dabei riet Apple seinen Aktionären, gegen den Antrag zu stimmen. Apple hat keine Änderungen an seiner Website oder seiner Diversity-Sprache vorgenommen und scheint sich verpflichtet zu fühlen, eine gerechtere Wirtschaft zu fördern. Auf seiner Website werden die Diversity-Daten beibehalten, Nutzer können seit 2014 globale demografische Daten zu den Mitarbeitenden einsehen. Auf der jüngsten Jahreshauptversammlung wurde ein Vorschlag zur Abschaffung der DEI-Programme vorgelegt und mit einer überwältigenden Mehrheit von 97 Prozent der Stimmen abgelehnt . Im aktuellen Klima hat Apple Schritte unternommen, die zeigen, dass das Unternehmen seine Unterstützung für Inklusivität und Fortschritt beibehalten will. Salesforce ist ein weiteres Unternehmen, das die Erwähnung von Diversitätszielen aus seinem 10-K-Bericht für 2023 gestrichen hat. Jedoch veröffentlichte das Unternehmen ein „ Gleichstellungs-Update “ für 2024, in dem es sein Engagement für Vielfalt und Repräsentation bekräftigt. CEO Marc Benioff erklärte außerdem in einem Gespräch mit Axios, dass das Unternehmen den Mitarbeitenden angesichts der gegen die DEI gerichteten Anordnungen der Trump-Administration zur Seite stehen wird. „Präsidenten ändern sich, Verwaltungen ändern sich. Wir ändern uns nicht“, sagte Benioff in einem Interview mit MarketWatch. Salesforce hat die demografische Zusammensetzung seiner Belegschaft bereits offengelegt, bevor dies üblich war. Zudem drängte der Konzern schon auf ein Engagement für DEI im Jahr 2019, bevor es 2020 nach der Ermordung von George Floyd in Minneapolis eine größere DEI-Initiative gab. (ajf/jd) Jacob Lund / Shutterstock Im Zuge der Kampagne der Trump-Administration gegen DEI-Initiativen (Diversity, Equity und Inclusion – Vielfalt, Gerechtigkeit und Inklusion) sind viele Unternehmen der Tech-Branche auf eine neue Linie eingeschwenkt. Im Gegensatz zu ihren Versprechen aus dem Jahr 2020, sich für Vielfalt einzusetzen, machten bekannte Konzerne wie Google, Amazon und Meta Schlagzeilen, weil sie ihre DEI-Programme beendet oder zurückgefahren haben. Einige eilten den Übergriffen der Trump-Administration sogar voraus, indem sie bereits am 10. Januar 2025, mehr als eine Woche vor dem offiziellen Amtsantritt der Trump-Administration, Änderungen an der DEI-Sprache und den Programmen vorgenommen haben. Abonnieren Sie unsere CIO-Newsletter für mehr Einblicke, Hintergründe und Deep Dives aus der IT-Community. Berichten zufolge sehen sich Unternehmen aus allen Branchen den Forderungen von Aktionären ausgesetzt, die DEI-Sprache zu reduzieren und Diversitätsziele aus den öffentlichen Berichten zu streichen. Unternehmen wie Costco und Apple haben sich gegen diese „Vorschläge“ gewehrt. Viele andere haben jedoch nachgegeben und darüber hinaus DEI-Mitarbeiter entlassen sowie interne DEI-Initiativen zusammengestrichen. Im Zuge dessen ist dieser Abbau auch in Europa angekommen. So hieß es Mitte Mai in Berichten , dass SAP den Frauenanteil im Konzern nicht weiter gezielt fördern will – die angepeilte Quote von 40 Prozent in der Belegschaft werde aufgegeben. Zudem verliere das „Diversity & Inclusion Office seine Eigenständigkeit. Auch T-Mobile, Roche, Novartis und die UBS hätte ihre Ziele angepasst, so die „ Personalwirtschaft “ im April. Die „Süddeutsche Zeitung“ titelte einen Monat später: „ Goodbye, Diversity? “ Wir zeigen Ihnen, wo die wichtigsten Akteure der US-Tech-Branche derzeit in Sachen Vielfalt, Gleichberechtigung und Integration stehen. Zu Beginn des Jahres schien es, als wolle IBM an seinen DEI-Initiativen festhalten. Als die konservative Denkfabrik „The Heritage Foundation“ unter anderem IBM aufforderte, finanzielle Anreize und Boni für DEI aufzugeben, wehrte sich der Konzern zunächst gegen diesen Forderung. In den vergangenen Monaten hat die Führung von Big Blue jedoch eine Kehrtwende vollzogen und erhebliche Änderungen an den DEI-Praktiken angekündigt. Dies ist ein überraschender Schritt für ein Unternehmen, das ein Pionier der Inklusion gewesen ist, indem es 1984 die sexuelle Orientierung in seine globale Nichtdiskriminierungs-Policy aufnahm und diese 2002 um die Geschlechtsidentität erweiterte. Am 10. April 2025 gab der rechte Influencer Robby Starbuck eine Erklärung ab, in der er sich auf ein internes Memo bezog. Demnach hatte IBM das Ende der DEI-Abteilung und des Diversity Councils angekündigt, die ursprünglich in den 1990er Jahren ins Leben gerufen worden waren. IBM soll zudem angekündigt haben, dass es nicht mehr am HRC-Arbeitsplatzindex (Human Rights Campaign) teilnehmen wird. In den vergangenen 15 Jahren hatte der Konzern hier eine Quote von 100 Prozent erreichte und damit zu den besten Arbeitsplätzen für LGBTQ+-Gleichstellung gezählt. In einer Erklärung gegenüber Bloomberg gab IBM an, dass diese Änderungen durch die „inhärenten Spannungen bei der Umsetzung der Inklusion“ sowie durch rechtliche Faktoren angesichts der zunehmenden Kontrolle motiviert seien. Während einer Aktionärsversammlung am 30. April 2025 stellte die Heritage Foundation erneut einen Antrag, in dem die IBM-Aktionäre aufgefordert wurden, für die Abschaffung der DEI zu stimmen. Der Antrag wurde zurückgezogen, nachdem IBM Änderungen vorgenommen hatte, um die DEI im Unternehmen zu verringern. Im Januar dieses Jahres kündigte Meta an, mehrere interne DEI-Programme zu beenden , die sich um Diversität im Recruiting drehen. Außerdem wurde Maxine Williams, Chief Diversity Officer, in eine neue Rolle versetzt, um sich auf „Zugänglichkeit und Engagement“ zu konzentrieren. Meta zufolge zielt ein Teil dieses Rückzugs darauf ab, auf „faire und konsistente“ Praktiken zu fokussieren, die Voreingenommenheit („bias“) für alle, unabhängig von ihrem Hintergrund, abmildern, wie aus einem durchgesickerten Memo von Janelle Gale, VP of HR, hervorgeht. Zu diesen Bemühungen gehörten bisher die Abschaffung von Quoten, die Beendigung diversitätsgetriebener Rekrutierung sowie die Aufgabe von Bemühungen um die Vielfalt bei Lieferanten. Darüber hinaus wurden Programme für Gleichberechtigung und Eingliederung gestrichen und das Meta DEI-Team geschrumpft. Das Unternehmen sagte außerdem eine Spende in Höhe von einer Million Dollar für Trumps Amtseinführung zu und holte den UFC-Präsidenten und CEO Dana White, einen erklärten Trump-Unterstützer, in seinen Vorstand. Meta ersetzte auch seinen Präsidenten für globale Angelegenheiten laut dem Nachrichtenportal Axios durch Joel Kaplan, einen prominenten Republikaner. Nach dem Vorbild von Meta hat Google alle Ziele für die Einstellung von Mitarbeitern nach diversen Kriterien gestrichen. Obwohl das Unternehmen seit 2014 regelmäßig Berichte über Diversität publik gemacht hat, will Google die weitere Veröffentlichung solcher Reports prüfen, berichtet das Wall Street Journal . Darüber hinaus plant Google, alle DEI-Initiativen zu überprüfen, um zu sehen, ob sie mit den Anordnungen der Exekutive, die auf die Reduzierung der DEI abzielen, konform sind. Im jährlichen 10-K-Bericht des Unternehmens an die Börsenaufsicht in den USA wurde „Vielfalt“ nicht erwähnt – nach acht Mal im Vorjahr. Google entfernte außerdem Ende 2024 eine Handvoll kultureller Veranstaltungen aus dem Standard-Google-Kalender und änderte für alle Google Maps-Nutzer in den USA den Golf von Mexiko in den Golf von Amerika (inzwischen sehen mexikanische Nutzer den „Golf von Mexiko“, während alle Nutzer außerhalb der USA und Mexikos sowohl den „Golf von Mexiko“ als auch den „Golf von Amerika“ auf der Karte sehen). Google wurde inzwischen von der mexikanischen Regierung wegen der Umbenennung verklagt. Amazon hat in diesem Jahr seinen Jahresbericht und seine Website in Bezug auf Vielfalt gestrichen und einige DEI-Programme eingestellt. Einem internen Memo zufolge war das Unternehmen dabei, „veraltete Programme und Materialien zurückzuschrauben“. Im Jahr 2020 hatte sich Amazon verpflichtet, den Anteil Schwarzer Führungskräfte auf der Ebene der Vizepräsidenten und Direktoren zu verdoppeln, und dies im Jahr 2021 bekräftigt. Auf der Positionsseite des Unternehmens heißt es heute immerhin noch, dass sich das Unternehmen für ein vielfältiges und integratives Unternehmen einsetzt. Amazon hat auch erklärt, dass die von den Mitarbeitern geleiteten Affinitätsgruppen weiterhin tätig sein werden. Auf einer Aktionärsversammlung von Apple wurde der Antrag einer konservativen Gruppe abgelehnt, die eine Abschaffung der DEI-Richtlinien gefordert hatte. Dabei riet Apple seinen Aktionären, gegen den Antrag zu stimmen. Apple hat keine Änderungen an seiner Website oder seiner Diversity-Sprache vorgenommen und scheint sich verpflichtet zu fühlen, eine gerechtere Wirtschaft zu fördern. Auf seiner Website werden die Diversity-Daten beibehalten, Nutzer können seit 2014 globale demografische Daten zu den Mitarbeitenden einsehen. Auf der jüngsten Jahreshauptversammlung wurde ein Vorschlag zur Abschaffung der DEI-Programme vorgelegt und mit einer überwältigenden Mehrheit von 97 Prozent der Stimmen abgelehnt . Im aktuellen Klima hat Apple Schritte unternommen, die zeigen, dass das Unternehmen seine Unterstützung für Inklusivität und Fortschritt beibehalten will. Salesforce ist ein weiteres Unternehmen, das die Erwähnung von Diversitätszielen aus seinem 10-K-Bericht für 2023 gestrichen hat. Jedoch veröffentlichte das Unternehmen ein „ Gleichstellungs-Update “ für 2024, in dem es sein Engagement für Vielfalt und Repräsentation bekräftigt. CEO Marc Benioff erklärte außerdem in einem Gespräch mit Axios, dass das Unternehmen den Mitarbeitenden angesichts der gegen die DEI gerichteten Anordnungen der Trump-Administration zur Seite stehen wird. „Präsidenten ändern sich, Verwaltungen ändern sich. Wir ändern uns nicht“, sagte Benioff in einem Interview mit MarketWatch. Salesforce hat die demografische Zusammensetzung seiner Belegschaft bereits offengelegt, bevor dies üblich war. Zudem drängte der Konzern schon auf ein Engagement für DEI im Jahr 2019, bevor es 2020 nach der Ermordung von George Floyd in Minneapolis eine größere DEI-Initiative gab. (ajf/jd)",
    "source": "cio",
    "crawled_at": "2025-05-28T09:16:54.897882+00:00"
  },
  {
    "url": "https://www.cio.de/article/3994401/sap-will-ki-allgegenwaertig-machen.html",
    "title": "SAP will KI allgegenwärtig machen",
    "published": "2025-05-27T05:11:00+00:00",
    "author": "",
    "text": "TenPixels – shutterstock.com „Wir machen wir KI für Unternehmen greifbar und treiben die digitale Transformation voran, damit unsere Kunden in einer zunehmend unberechenbaren Welt erfolgreich sein können“, verspricht SAP-Chef Christian Klein zur Eröffnung der diesjährigen Sapphire in Orlando, Florida. Der deutsche Softwarekonzern stellt dazu Erweiterungen von Joule, Partnerschaften mit anderen KI-Pionieren sowie neue Features für die Business Data Cloud und die Business Suite vor. „SAP kombiniert die weltweit leistungsfähigste Suite von Geschäftsanwendungen mit einer einzigartigen Datenvielfalt und den neuesten KI-Innovationen, um Mehrwerte für die Kunden zu schaffen“, so Klein. Christian Klein (SAP) / Supplied Sein Kollege Thomas Saueressig, als SAP-Vorstand verantwortlich für den Bereich Customer Services & Delivery, spricht zur diesjährigen Sapphire von einem regelrechten Feuerwerk an Innovationen. Der Blick des Managers richtet sich dabei vor allem auf SAPs Copiloten Joule und ein wachsendes Netz von KI-Agenten. Joule werde die Art und Weise verändern, wie Menschen arbeiten und Unternehmen funktionieren, stellt Saueressig seinen Kunden in Aussicht. 34.000 Betriebe würden bereits mit SAPs Business AI arbeiten. 230 AI-Szenarien seien heute schon fest im eigenen Softwarekosmos eingebettet – bis Ende 2025 sollen es über 400 sein. Joule soll als Begleiter der Anwenderinnen und Anwender allgegenwärtig werden, so der Plan der SAP-Verantwortlichen. Der KI-Assistent soll die User während ihres gesamten Tages begleiten können, sowohl innerhalb wie auch außerhalb des SAP-Anwendungsuniversums. Der Business-Copilot sei in der Lage, Daten zu finden, daraus Erkenntnisse in Echtzeit zu gewinnen und Arbeitsabläufe zu optimieren. Rund um Joule baut SAP zusätzliche Tools, um Anwendern die Nutzung des KI-Assistenten so komfortabel wie möglich zu machen. Beispielsweise soll es eine Art Aktionsleiste geben, die von SAP WalkMe angetrieben wird und das Nutzerverhalten über alle Anwendungen hinweg untersucht. Damit entwickle sich Joule zu einer proaktiven KI, die die Bedürfnisse der Nutzer vorhersehe, bevor sie entstehen, hieß es in einer Mitteilung des Softwarekonzerns. Zusätzlich will SAP seinen Kunden im Rahmen einer Partnerschaft mit Perplexity eine Business Answer Engine an die Hand geben. Damit könnten User auch außerhalb von SAP Fragen an Joule stellen. Anwender könnten eine Wirtschaftsmeldung auf einer Nachrichtenseite, beispielsweise zu neuen Zöllen, markieren und Joule direkt fragen, was dies für das eigene Business bedeute, beschreibt Saueressig ein mögliches Szenario. Der Copilot könne diese Meldung dann direkt mit Daten aus dem SAP-System verknüpfen und entsprechend Tipps geben, wie das Unternehmen angesichts der Veränderungen reagieren sollte. Neben Joule arbeitet SAP eigenen Angaben zufolge mit Hochdruck am Bau weiterer KI-Agenten. Diese Agenten, die auf Geschäftsdaten aus der eigenen Business Data Cloud (BCD) basieren und von Joule orchestriert werden, sollen system- und bereichsübergreifend arbeiten können, um zu antizipieren, sich anzupassen und eigenständig zu handeln. Unternehmen könnten damit in einer sich schnell verändernden Welt agil bleiben, verspricht SAP. Zusätzlich kündigt SAP eine Art Betriebssystem für die KI-Entwicklung an. Die SAP AI Foundation biete Entwicklern Zugang zu allen Werkzeugen, die sie für den Aufbau, die Erweiterung und den Betrieb benutzerdefinierter KI-Lösungen benötigten. Damit Anwenderunternehmen angesichts immer zahlreicherer KI-Agenten nicht den Überblick verlieren, hat SAP außerdem eine erweiterte Bibliothek von KI-Agenten vorgestellt. Darüber hinaus arbeitet SAP mit anderen KI-Anbietern zusammen, um ein Ökosystem interoperabler Agenten auf die Beine zu stellen, die End-to-End-Prozesse ausführen können. SAP-Manager Saueressig nennt an dieser Stelle Googles A2A-Initiative. Das Agent-to-Agent-Protocol soll plattformübergreifend Spezifikationen anbieten, damit KI-Agenten verschiedener Anbieter interagieren können. Für die Business Data Cloud (BDC) hat SAP außerdem neue intelligente Anwendungen sogenannte Insight Apps angekündigt. Diese Apps sollen Unternehmen helfen, Routinearbeiten durch eine Kombination aus Standardgeschäftskennzahlen, KI-Modellen und integrierten Planungsfunktionen zu optimieren. Der Softwarekonzern nennt als Beispiel die Anwendung People Intelligence. Diese verknüpft Daten zu Mitarbeitern und Fähigkeiten aus der SAP SuccessFactors HCM Suite für tiefere Einblicke in die Belegschaft. Mit Hilfe KI-gesteuerter Empfehlungen sollen Führungskräfte die Teamleistung optimieren, das Mitarbeiterwachstum fördern und die Einhaltung von Vorschriften gewährleisten können, hieß es. In Sachen Datenanalysen will SAP außerdem enger mit dem Analytics-Spezialisten Palantir zusammenarbeiten. Die Nutzung der entsprechenden Werkzeuge im SAP-Kontext sei jedoch optional, relativiert Saueressig und versucht so Bedenken hinsichtlich der Kooperation mit dem umstrittenen Softwareanbieter zu zerstreuen. Vor allem Kunden in den USA nutzten die Tools von Palantir, begründet der SAP-Manager die engere Zusammenarbeit. Den Schlussakkord in SAPs Dreiklang aus Geschäftsdaten, Business AI und Geschäftsanwendungen setzt die Business Suite. Zur Sapphire stellt der Softwarehersteller zusätzliche Pakete für dedizierte Anwendungsbereiche vor – beispielsweise Finance, Supply Chain Management (SCM), Human Capital Management (HCM), das Strategic Procurement und das Kundenmanagement. Unter dem im Februar dieses Jahres vorgestellten Label Business Suite, mit der der Konzern in alten On-Premises-Zeiten große Erfolge gefeiert hatte, versteht SAP ein modulares Set verschiedener miteinander integrierter Lösungen. Konkret nennt der Anbieter Cloud ERP, Business Applikationen, die Business Data Cloud und Business AI sowie als gemeinsame Basis die Business Technology Platform (BTP). Mit integriert ist außerdem SAP Build, um Kunden dabei zu helfen, ihre Anwendungen an individuelle Anforderungen anzupassen – ohne dabei allerdings in ein zu starkes Customizing abzudriften und immer einen „Clean Core“ zu behalten. Auffallend an dieser Stelle: SAP spricht im Zusammenhang mit Business-Anwendungen nur noch von Cloud ERP und der Business Suite. Der Name S/4HANA, der die Strategie der SAP im zurückliegenden Jahrzehnt maßgeblich bestimmt hat , fällt gar nicht mehr. In einem 26-seitigen Innovation-Guide, den SAP zu Sapphire 2025 veröffentlicht hat, wird S/4HANA kein einziges Mal erwähnt. Inwieweit damit ein regelrechter Strategiewechsel einhergeht oder ob es sich lediglich um ein Umlabeln handelt, ist noch nicht klar ersichtlich. Vielleicht möchte SAP an dieser Stelle auch einen Schlussstrich ziehen unter die ständigen Migrationsdiskussionen der vergangenen Jahre. Viele Unternehmen verbinden mit S/4HANA langwierige und kostenintensive Umstiegsprojekte und haben vielfach noch gar damit nicht angefangen, obwohl das Support-Ende für das Vorgänger-Release immer näher rückt. SAP-Vorstand Saueressig verspricht seinen Kunden zur diesjährigen Sapphire jedenfalls, dass künftig vieles einfacher soll – angefangen von der Migration bis hin zu den Preis- und Lizenzmodellen. Die Transition Guidance soll Anwenderunternehmen dabei helfen, schneller in die Cloud zu wechseln. Mit Joule als Einstiegspunkt und auf der Grundlage von Erkenntnissen aus SAP-Lösungen wie SAP Signavio und SAP LeanIX liefere die App personalisierte Anleitungen und umsetzbare Empfehlungen, die auf die Transformationsziele eines Unternehmens zugeschnitten seien, versprechen die Walldorfer. SAP Für die Business Suite in der Cloud soll es in Zukunft ein vereinfachtes Service- und Supportmodell in drei Stufen geben: „Wir wollen näher am Kunden sein und deren Transformation begleiten“, verspricht Saueressig und verweist noch einmal auf den Dreiklang aus Daten, Applikationen und KI. Der Business Kontext mache den Unterschied. SAP sitze mit seinen Lösungen am richtigen Hebel. Der SAP-Mann gibt sich selbstbewusst: „Wir halten nicht nur Schritt mit den Entwicklungen, sondern wir sind Schrittmacher.“ TenPixels – shutterstock.com „Wir machen wir KI für Unternehmen greifbar und treiben die digitale Transformation voran, damit unsere Kunden in einer zunehmend unberechenbaren Welt erfolgreich sein können“, verspricht SAP-Chef Christian Klein zur Eröffnung der diesjährigen Sapphire in Orlando, Florida. Der deutsche Softwarekonzern stellt dazu Erweiterungen von Joule, Partnerschaften mit anderen KI-Pionieren sowie neue Features für die Business Data Cloud und die Business Suite vor. „SAP kombiniert die weltweit leistungsfähigste Suite von Geschäftsanwendungen mit einer einzigartigen Datenvielfalt und den neuesten KI-Innovationen, um Mehrwerte für die Kunden zu schaffen“, so Klein. Christian Klein (SAP) / Supplied Sein Kollege Thomas Saueressig, als SAP-Vorstand verantwortlich für den Bereich Customer Services & Delivery, spricht zur diesjährigen Sapphire von einem regelrechten Feuerwerk an Innovationen. Der Blick des Managers richtet sich dabei vor allem auf SAPs Copiloten Joule und ein wachsendes Netz von KI-Agenten. Joule werde die Art und Weise verändern, wie Menschen arbeiten und Unternehmen funktionieren, stellt Saueressig seinen Kunden in Aussicht. 34.000 Betriebe würden bereits mit SAPs Business AI arbeiten. 230 AI-Szenarien seien heute schon fest im eigenen Softwarekosmos eingebettet – bis Ende 2025 sollen es über 400 sein. Joule soll als Begleiter der Anwenderinnen und Anwender allgegenwärtig werden, so der Plan der SAP-Verantwortlichen. Der KI-Assistent soll die User während ihres gesamten Tages begleiten können, sowohl innerhalb wie auch außerhalb des SAP-Anwendungsuniversums. Der Business-Copilot sei in der Lage, Daten zu finden, daraus Erkenntnisse in Echtzeit zu gewinnen und Arbeitsabläufe zu optimieren. Rund um Joule baut SAP zusätzliche Tools, um Anwendern die Nutzung des KI-Assistenten so komfortabel wie möglich zu machen. Beispielsweise soll es eine Art Aktionsleiste geben, die von SAP WalkMe angetrieben wird und das Nutzerverhalten über alle Anwendungen hinweg untersucht. Damit entwickle sich Joule zu einer proaktiven KI, die die Bedürfnisse der Nutzer vorhersehe, bevor sie entstehen, hieß es in einer Mitteilung des Softwarekonzerns. Zusätzlich will SAP seinen Kunden im Rahmen einer Partnerschaft mit Perplexity eine Business Answer Engine an die Hand geben. Damit könnten User auch außerhalb von SAP Fragen an Joule stellen. Anwender könnten eine Wirtschaftsmeldung auf einer Nachrichtenseite, beispielsweise zu neuen Zöllen, markieren und Joule direkt fragen, was dies für das eigene Business bedeute, beschreibt Saueressig ein mögliches Szenario. Der Copilot könne diese Meldung dann direkt mit Daten aus dem SAP-System verknüpfen und entsprechend Tipps geben, wie das Unternehmen angesichts der Veränderungen reagieren sollte. Neben Joule arbeitet SAP eigenen Angaben zufolge mit Hochdruck am Bau weiterer KI-Agenten. Diese Agenten, die auf Geschäftsdaten aus der eigenen Business Data Cloud (BCD) basieren und von Joule orchestriert werden, sollen system- und bereichsübergreifend arbeiten können, um zu antizipieren, sich anzupassen und eigenständig zu handeln. Unternehmen könnten damit in einer sich schnell verändernden Welt agil bleiben, verspricht SAP. Zusätzlich kündigt SAP eine Art Betriebssystem für die KI-Entwicklung an. Die SAP AI Foundation biete Entwicklern Zugang zu allen Werkzeugen, die sie für den Aufbau, die Erweiterung und den Betrieb benutzerdefinierter KI-Lösungen benötigten. Damit Anwenderunternehmen angesichts immer zahlreicherer KI-Agenten nicht den Überblick verlieren, hat SAP außerdem eine erweiterte Bibliothek von KI-Agenten vorgestellt. Darüber hinaus arbeitet SAP mit anderen KI-Anbietern zusammen, um ein Ökosystem interoperabler Agenten auf die Beine zu stellen, die End-to-End-Prozesse ausführen können. SAP-Manager Saueressig nennt an dieser Stelle Googles A2A-Initiative. Das Agent-to-Agent-Protocol soll plattformübergreifend Spezifikationen anbieten, damit KI-Agenten verschiedener Anbieter interagieren können. Für die Business Data Cloud (BDC) hat SAP außerdem neue intelligente Anwendungen sogenannte Insight Apps angekündigt. Diese Apps sollen Unternehmen helfen, Routinearbeiten durch eine Kombination aus Standardgeschäftskennzahlen, KI-Modellen und integrierten Planungsfunktionen zu optimieren. Der Softwarekonzern nennt als Beispiel die Anwendung People Intelligence. Diese verknüpft Daten zu Mitarbeitern und Fähigkeiten aus der SAP SuccessFactors HCM Suite für tiefere Einblicke in die Belegschaft. Mit Hilfe KI-gesteuerter Empfehlungen sollen Führungskräfte die Teamleistung optimieren, das Mitarbeiterwachstum fördern und die Einhaltung von Vorschriften gewährleisten können, hieß es. In Sachen Datenanalysen will SAP außerdem enger mit dem Analytics-Spezialisten Palantir zusammenarbeiten. Die Nutzung der entsprechenden Werkzeuge im SAP-Kontext sei jedoch optional, relativiert Saueressig und versucht so Bedenken hinsichtlich der Kooperation mit dem umstrittenen Softwareanbieter zu zerstreuen. Vor allem Kunden in den USA nutzten die Tools von Palantir, begründet der SAP-Manager die engere Zusammenarbeit. Den Schlussakkord in SAPs Dreiklang aus Geschäftsdaten, Business AI und Geschäftsanwendungen setzt die Business Suite. Zur Sapphire stellt der Softwarehersteller zusätzliche Pakete für dedizierte Anwendungsbereiche vor – beispielsweise Finance, Supply Chain Management (SCM), Human Capital Management (HCM), das Strategic Procurement und das Kundenmanagement. Unter dem im Februar dieses Jahres vorgestellten Label Business Suite, mit der der Konzern in alten On-Premises-Zeiten große Erfolge gefeiert hatte, versteht SAP ein modulares Set verschiedener miteinander integrierter Lösungen. Konkret nennt der Anbieter Cloud ERP, Business Applikationen, die Business Data Cloud und Business AI sowie als gemeinsame Basis die Business Technology Platform (BTP). Mit integriert ist außerdem SAP Build, um Kunden dabei zu helfen, ihre Anwendungen an individuelle Anforderungen anzupassen – ohne dabei allerdings in ein zu starkes Customizing abzudriften und immer einen „Clean Core“ zu behalten. Auffallend an dieser Stelle: SAP spricht im Zusammenhang mit Business-Anwendungen nur noch von Cloud ERP und der Business Suite. Der Name S/4HANA, der die Strategie der SAP im zurückliegenden Jahrzehnt maßgeblich bestimmt hat , fällt gar nicht mehr. In einem 26-seitigen Innovation-Guide, den SAP zu Sapphire 2025 veröffentlicht hat, wird S/4HANA kein einziges Mal erwähnt. Inwieweit damit ein regelrechter Strategiewechsel einhergeht oder ob es sich lediglich um ein Umlabeln handelt, ist noch nicht klar ersichtlich. Vielleicht möchte SAP an dieser Stelle auch einen Schlussstrich ziehen unter die ständigen Migrationsdiskussionen der vergangenen Jahre. Viele Unternehmen verbinden mit S/4HANA langwierige und kostenintensive Umstiegsprojekte und haben vielfach noch gar damit nicht angefangen, obwohl das Support-Ende für das Vorgänger-Release immer näher rückt. SAP-Vorstand Saueressig verspricht seinen Kunden zur diesjährigen Sapphire jedenfalls, dass künftig vieles einfacher soll – angefangen von der Migration bis hin zu den Preis- und Lizenzmodellen. Die Transition Guidance soll Anwenderunternehmen dabei helfen, schneller in die Cloud zu wechseln. Mit Joule als Einstiegspunkt und auf der Grundlage von Erkenntnissen aus SAP-Lösungen wie SAP Signavio und SAP LeanIX liefere die App personalisierte Anleitungen und umsetzbare Empfehlungen, die auf die Transformationsziele eines Unternehmens zugeschnitten seien, versprechen die Walldorfer. SAP Für die Business Suite in der Cloud soll es in Zukunft ein vereinfachtes Service- und Supportmodell in drei Stufen geben: „Wir wollen näher am Kunden sein und deren Transformation begleiten“, verspricht Saueressig und verweist noch einmal auf den Dreiklang aus Daten, Applikationen und KI. Der Business Kontext mache den Unterschied. SAP sitze mit seinen Lösungen am richtigen Hebel. Der SAP-Mann gibt sich selbstbewusst: „Wir halten nicht nur Schritt mit den Entwicklungen, sondern wir sind Schrittmacher.“",
    "source": "cio",
    "crawled_at": "2025-05-28T09:16:54.940912+00:00"
  },
  {
    "url": "https://www.cio.de/article/3695844/was-ist-ein-kooperativer-fuehrungsstil.html",
    "title": "Was ist ein kooperativer Führungsstil?",
    "published": "2025-05-27T06:10:42+00:00",
    "author": "",
    "text": "Kooperative Führungskräfte teilen Verantwortung mit ihren Mitarbeitern und beziehen sie in Entscheidungen ein. Foto: NDAB Creativity – shutterstock.com Ein Führungsstil beschreibt die Grundhaltung einer Führungskraft sowie ihr Verhalten gegenüber Mitarbeitern. Es gibt verschiedene Theorien und Modelle mit unterschiedlichen Führungsstilen . Eine bekannte Einteilung hat der Sozialpsychologe Kurt Lewin vorgenommen. Lewin emigrierte 1933 aus Deutschland und forschte in den USA. In dieser Zeit entstand die Unterscheidung und Abstufung zwischen den Führungsstilen autoritär, laissez-faire und kooperativ: Beim autoritären Führungsstil gibt die Führungsperson ihren Mitarbeitern Anweisungen, was zu tun ist. Mitarbeiter haben diese Anweisungen zu akzeptieren und auszuführen. Beim Laissez-faire-Führungsstil überträgt die Führungskraft Aufgaben auf die Mitarbeiter. Vorgesetzte machen klare Zielvorgaben, definieren die erwarteten Arbeitsergebnisse und delegieren die Aufgaben an die Mitarbeiter. Dazwischen liegt der kooperative Führungsstil , bei dem Führungskraft und Mitarbeiter Verantwortung teilen beziehungsweise gemeinsam übernehmen. Eines der Forschungsergebnisse Lewins war, dass ein kooperativer Führungsstil mit einer erhöhten Arbeitszufriedenheit der Mitarbeiter verbunden ist. Kooperative Führungskräfte teilen Verantwortung mit ihren Mitarbeitern und beziehen sie in Entscheidungen ein. Für Prof. Dr. Guido Möllering, Direktor des Reinhard-Mohn-Instituts für Unternehmensführung an der Universität Witten/Herdecke, zählt zu den Merkmalen einer kooperativen Führungskraft auch, dass mehr Autonomie gewährt wird bei zugleich gegenseitiger Transparenz und Koordination: “Die formale Führungskraft kommuniziert auf Augenhöhe, das heißt mit Respekt und Anerkennung der Fähigkeiten und Bedürfnisse der Geführten. Es gibt kaum noch Anweisungen, sondern man einigt sich, was zu tun ist”, so Möllering. Man verständige sich häufiger über die gemeinsamen Werte und Ziele. Führungskräfte sähen sich selbst als Vermittelnde. Für den Transformationsexperten und Berater Martin Michaelis ist es nicht nur eine Frage von Branchen, Unternehmenskultur oder Generationen, ob kooperatives Führen sinnvoll ist. “In der heutigen Zeit ständiger und schneller Veränderung haben Unternehmen gar keine andere Wahl, als Ihren Mitarbeitern in einem bestimmten Maße mehr Verantwortung zu übergeben. Das bedeutet für Führungskräfte, dass sie ihre Mitarbeiter mehr in Entscheidungsprozesse einbinden müssen.” Schwierig werde es dann, wenn unter den Mitarbeitern nur eine niedrige Bereitschaft bestehe, Verantwortung zu übernehmen. “Wichtig ist dann, Schritt für Schritt vorzugehen: je nach individueller Kapazität und nicht zu viel auf einmal an Verantwortungen zu delegieren”, rät Michaelis. “Die stärkere Partizipation und das Empowerment, das kooperative Führung ermöglicht, sind sehr motivierend, können aber auch überfordern”, weiß Experte Möllering. Wenn Verantwortung stärker geteilt werde, werfe das Fragen auf: Wer trägt das Risiko von gemeinsamen Entscheidungen? Und: Wer bekommt welchen Anteil am gemeinsamen Erfolg? “Wenn ein gemeinsames Verständnis hergestellt werden kann, wie die kooperative Führung wirklich gemeint ist, dann überwiegen klar die Vorteile”, ist Möllering überzeugt. Wichtig sei auch, dass eine echte Beteiligung an der Führung möglich ist. Also nicht am Ende doch wieder einer alles alleine entscheide. Doch lässt sich ein solcher kooperativer Führungsstil erlernen? “Es gibt eine Menge Kompetenzen, die erlernt werden können”, sagt Martin Michaelis auf die Frage, ob sich kooperatives Führen erlernen lässt. Dabei unterscheidet er zwischen Methoden und Verhalten, sowie Haltung. Neue Methoden und Verhaltensweisen lassen sich erlernen. Dazu zählt beispielsweise, sich selbst als Führungskraft zurückzunehmen, Mitarbeitern mehr Raum zu geben und ihnen mehr Fragen zu stellen. “Eine kooperative Haltung braucht meist etwas mehr Zeit”, so Michaelis. Je nach Person ständen oft alte Einstellungen und Glaubenssätze im Weg. Eine wichtige Erkenntnis lautet: Wer kooperativ führen möchte, muss Schritt für Schritt lernen, Vertrauen zu haben. “Eine ‘Dann mache ich das jetzt lieber selbst’-Haltung ergibt keinen Sinn”, sagt Michaelis. In einer konkreten Situation ist eine Aufgabe damit vielleicht schneller und auch besser erledigt. Aber damit nehme man seinen Mitarbeitern den Raum, zu lernen und sich weiterzuentwickeln. Und damit auch die Möglichkeit, zumindest mittelfristig mehr Verantwortung zu übernehmen. Die Bertelsmann Stiftung und das Reinhard-Mohn-Institut der Universität Witten/Herdecke haben für ihren Führungskräfte-Radar eine repräsentative Befragung unter Führungskräften in Deutschland vorgenommen. Eine Beobachtung: Wenn Home-Office zur Dauereinrichtung wird, befürchten Führungskräfte, dass der Austausch mit den Mitarbeitern mehr und mehr verloren geht und die Unternehmenskultur leidet. Viele Führungskräfte konnten ihre Mitarbeiter in Home-Office-Corona-Zeiten nicht so unterstützen, wie sie es gerne getan hätten (45,7 Prozent). Guido Möllering vom Reinhard-Mohn-Institut sagt: “Die Ausnahmesituation hat uns verschiedene Aspekte deutlicher sehen lassen als sonst”. Er nennt die folgenden drei Punkte: Führung funktioniert nur, wenn die Geführten mitspielen, also kooperativ die Impulse der Führenden aufnehmen oder konstruktiv der Führungskraft Feedback geben. Das Management kann gerade in einer Krise nicht alle Probleme alleine lösen und alle Entscheidungen alleine treffen. Notgedrungen wird mehr delegiert, pragmatisch gehandelt und sich aufeinander verlassen. Man ist im Team beim gemeinsamen, kooperativen Problemlösen mehr auf Augenhöhe. Gerade beim Führen auf Distanz (insbesondere wegen Homeoffice) merkt man deutlich, dass Führen nicht primär Kontrolle, sondern Unterstützung der Geführten bedeutet. Der Team-Gedanke verstärkt sich und die Verantwortung für das gemeinsame Ergebnis wird stärker geteilt. Übergreifend werde deutlich, wie wichtig eine solide Vertrauensbasis sei, so Möllering: “Diese baut man nicht durch hierarchische Anweisungen, sondern durch kollegiale Zusammenarbeit auf.” Im Gegensatz zu dem oft in Krisen vermuteten autoritären Führungsstil hat sich in der Corona-Pandemie nicht die lenkende Führungskraft früherer Zeiten, sondern die vermittelnde Führungskraft bewährt. Tipps zur virtuellen Mitarbeiterführung Foto: fizkes – shutterstock.com Seit der Pandemie gehört virtuelle Mitarbeiterführung zu den Standartaufgaben für jeden Vorgesetzten. Wir haben die wichtigsten Learnings aus dieser Zeit zusammengefasst. Unterschiedliche Arbeits- und Lebensumstände anerkennen Foto: Jelena Zelen – shutterstock.com Zu den größten Herausforderungen zählen die unterschiedlichen Voraussetzungen, womit Teammitglieder bei der Heimarbeit konfrontiert sind. Nicht jeder hat ausreichenden Raum für ein separates Home-Office. Dazu kommen Ablenkungen wie Kinder, Haustiere oder bei Singles ein Gefühl der Isolation. All das hat Einfluss darauf, wie und zu welchen Zeiten Mitarbeiter ihre Aufgaben am besten erledigen können. Vorgesetzte, die offen Verständnis für individuelle Situationen zeigen, schaffen die Grundlage einer vertrauensvollen Zusammenarbeit. Stress-Level steuern Foto: Rawpixel.com – shutterstock.com Permanenter Stress im Home-Office ist keine gute Voraussetzung, um kontinuierlich gute Arbeit zu leisten. Wer als Führungskraft vermittelt, dass es okay ist, nicht immer perfekt zu funktionieren, nimmt Mitarbeitern etwas den Druck in der Gewöhnung an die neue Normalität. Vielen fällt es mit dieser Gewissheit leichter, Deadlines einzuhalten und den Erwartungen zu entsprechen. Regelmäßigen Kontakt pflegen Foto: fizkes – shutterstock.com Ein tägliches Gespräch mit Chefin oder Chef – ist das nicht zu viel der Kommunikation? Nein, denn insbesondere bei der digitalen Mitarbeiterführung ist die Regelmäßigkeit des Austauschs entscheidend. Nur so lässt sich einschätzen, ob alles wie besprochen läuft und sich alle im Team den Anforderungen gewachsen fühlen. Missverständnisse und Fehler passieren – ähnlich wie im Büro – vor allem, wenn zu wenig kommuniziert wird. Neue Technologien nutzen Foto: Tada Images – shutterstock.com Nur mit Personen, zu denen man regelmäßigen Kontakt pflegt, können Beziehungen entstehen. Das funktioniert im Zeitalter des digitalen Austauschs über zahlreiche Kommunikationskanäle. Moderne Videokonferenz-Tools wie Zoom, Teams, Google Meet etc. ermöglichen eine Kommunikation von Angesicht zu Angesicht und machen sichtbar, wie es allen Teammitgliedern geht. Kommunikationsregeln festlegen Foto: patpitchaya – shutterstock.com Dezentral organisierte Teamarbeit funktioniert am effektivsten, wenn sich alle über die Grundregeln der Kommunikation einig sind. Vorgesetzte können für klare Verhältnisse sorgen, indem sie Häufigkeit, Zweck und Timing des Austauschs und die dafür priorisierten Kanäle festlegen. Videokonferenzen sind in der Regel die erste Wahl für die tägliche Gruppenbesprechung. Gerade größere Gesprächsrunden lassen sich durch simple Tricks so strukturieren, dass auch Meetings mit hoher Teilnehmerzahl geordnet und effektiv ablaufen. Wenn es um dringliche Angelegenheiten oder Nachfragen geht, sind andere Kanäle wie Instant Messaging der bessere Weg. Unified-Communications-Plattformen ermöglichen eine Vielzahl von Anwendungen und Kommunikationskanälen. Erwartungen definieren Foto: ogichobanov – shutterstock.com Oft werden beim Übergang von der klassischen Büroarbeit ins Home-Office Aufgaben innerhalb eines Teams neu verteilt oder kommen neue hinzu. Damit Mitarbeiter diese erfüllen können, muss klar sein, was genau von ihnen erwartet wird. Manchen mag es außerhalb der gewohnten Büroatmosphäre anfangs schwerfallen, Aufträge zu priorisieren. Gemeinsam kann geklärt werden, welche Aufgaben Priorität haben und zu schaffen ist. Einfach davon auszugehen, dass jeder weiß, was zu tun ist, ist kontraproduktiv. Besser ist, von Anfang an eine Feedback-Schleife zu vereinbaren, um Erwartungen anzupassen und in den bekannten Applikationen zu dokumentieren. Ein gemeinsames Ziel verfolgen Foto: Rawpixel.com – shutterstock.com Teams funktionieren vor allem dann, wenn alle Mitglieder eine gemeinsame Mission verfolgen. Das dabei entstehende Gemeinschaftsgefühl hilft auch, Unsicherheiten zu überwinden und mit ungewohnten Arbeitssituationen umzugehen. Wenn jeder weiß, was er zum gemeinsamen Erfolg beiträgt, ist das die beste Motivation, Höchstleistungen zu erbringen. Erfolge sollten außerdem gewürdigt werden. Auf die Ergebnisse konzentrieren Foto: everything possible – shutterstock.com Wie lassen sich Engagement und Selbstverantwortung fördern? Indem Führungskräfte sich auf die gewünschten Ergebnisse konzentrieren und Teammitgliedern den Freiraum lassen, selbst einzuteilen, wie sie zum Ziel kommen wollen. Voraussetzung dafür ist ausreichend Zeit und zuvor aufgebautes Vertrauen. Ist das der Fall, lässt sich auf diesem Weg nicht nur die Kreativität der Mitarbeiter fördern, sondern auch kräftezehrendes Mikromanagement vermeiden. Virtuelle Brainstorms lassen sich beispielsweise in Breakout-Räume aufteilen. Kleinere Teams können dadurch in separaten Sitzungen arbeiten und ihre Ideen sammeln, die anschließend in der größeren Runde präsentiert werden. Strikte Kontrollmechanismen vermeiden Foto: ibreakstock – shutterstock.com Regelmäßige Kommunikation und klare Zielvorgaben sind wichtig. Sie dürfen aber nicht dazu führen, dass Mitarbeiter das Gefühl bekommen, im Home-Office überwacht zu werden. Vorgesetzte, die mehrmals täglich penible Rückmeldungen zu erledigten Arbeitsschritten einfordern, signalisieren damit fehlendes Vertrauen. Sie riskieren zudem, dass Teams den Fokus verlieren. Beratung und Betreuung sind besser als strikte Kontrolle. Neue Team-Mitglieder integrieren Foto: iQoncept – shutterstock.com Als neues Mitglied in ein dezentral arbeitendes Team zu kommen, kann zur Herausforderung werden, weil sich die Dynamik einer Gruppe anfangs schwerer erspüren lässt. Umso wichtiger ist es, Neulingen zu Beginn ihrer Tätigkeit das Gefühl zu geben, Teil der Gruppe zu sein. Unternehmen, die bereits über längere Erfahrung in dezentralem Arbeiten verfügen, haben dies zum festen Bestandteil ihres Onboardings gemacht. Das Wir-Gefühl stärken Foto: Girts Ragelis – shutterstock.com Selbst in gut funktionierenden Arbeitsumfeldern kann es gelegentlich zu Unsicherheiten, Unzufriedenheit oder Ängsten der Mitarbeiter kommen. Die Aufgabe von Führungskräften besteht darin, Teams davor zu schützen. Das gelingt am besten, wenn auch die sozialen Aspekte der gemeinsamen Arbeit berücksichtigt werden. Dafür braucht es keine verpflichtenden gemeinsamen Kaffeepausen, aber von Zeit zu Zeit die Gelegenheit für einen lockeren Austausch, der Mitarbeitern das Gefühl gibt, trotz der Distanz wahrgenommen zu werden. Virtuell lässt sich der Teamgeist auch fördern, wenn zur Abwechslung mal eine Happy Hour, ein virtuelles Quizzen oder ein gemeinsames Essen per Videochat organisiert wird. Kooperative Führungskräfte teilen Verantwortung mit ihren Mitarbeitern und beziehen sie in Entscheidungen ein. Foto: NDAB Creativity – shutterstock.com Ein Führungsstil beschreibt die Grundhaltung einer Führungskraft sowie ihr Verhalten gegenüber Mitarbeitern. Es gibt verschiedene Theorien und Modelle mit unterschiedlichen Führungsstilen . Eine bekannte Einteilung hat der Sozialpsychologe Kurt Lewin vorgenommen. Lewin emigrierte 1933 aus Deutschland und forschte in den USA. In dieser Zeit entstand die Unterscheidung und Abstufung zwischen den Führungsstilen autoritär, laissez-faire und kooperativ: Beim autoritären Führungsstil gibt die Führungsperson ihren Mitarbeitern Anweisungen, was zu tun ist. Mitarbeiter haben diese Anweisungen zu akzeptieren und auszuführen. Beim Laissez-faire-Führungsstil überträgt die Führungskraft Aufgaben auf die Mitarbeiter. Vorgesetzte machen klare Zielvorgaben, definieren die erwarteten Arbeitsergebnisse und delegieren die Aufgaben an die Mitarbeiter. Dazwischen liegt der kooperative Führungsstil , bei dem Führungskraft und Mitarbeiter Verantwortung teilen beziehungsweise gemeinsam übernehmen. Eines der Forschungsergebnisse Lewins war, dass ein kooperativer Führungsstil mit einer erhöhten Arbeitszufriedenheit der Mitarbeiter verbunden ist. Kooperative Führungskräfte teilen Verantwortung mit ihren Mitarbeitern und beziehen sie in Entscheidungen ein. Für Prof. Dr. Guido Möllering, Direktor des Reinhard-Mohn-Instituts für Unternehmensführung an der Universität Witten/Herdecke, zählt zu den Merkmalen einer kooperativen Führungskraft auch, dass mehr Autonomie gewährt wird bei zugleich gegenseitiger Transparenz und Koordination: “Die formale Führungskraft kommuniziert auf Augenhöhe, das heißt mit Respekt und Anerkennung der Fähigkeiten und Bedürfnisse der Geführten. Es gibt kaum noch Anweisungen, sondern man einigt sich, was zu tun ist”, so Möllering. Man verständige sich häufiger über die gemeinsamen Werte und Ziele. Führungskräfte sähen sich selbst als Vermittelnde. Für den Transformationsexperten und Berater Martin Michaelis ist es nicht nur eine Frage von Branchen, Unternehmenskultur oder Generationen, ob kooperatives Führen sinnvoll ist. “In der heutigen Zeit ständiger und schneller Veränderung haben Unternehmen gar keine andere Wahl, als Ihren Mitarbeitern in einem bestimmten Maße mehr Verantwortung zu übergeben. Das bedeutet für Führungskräfte, dass sie ihre Mitarbeiter mehr in Entscheidungsprozesse einbinden müssen.” Schwierig werde es dann, wenn unter den Mitarbeitern nur eine niedrige Bereitschaft bestehe, Verantwortung zu übernehmen. “Wichtig ist dann, Schritt für Schritt vorzugehen: je nach individueller Kapazität und nicht zu viel auf einmal an Verantwortungen zu delegieren”, rät Michaelis. “Die stärkere Partizipation und das Empowerment, das kooperative Führung ermöglicht, sind sehr motivierend, können aber auch überfordern”, weiß Experte Möllering. Wenn Verantwortung stärker geteilt werde, werfe das Fragen auf: Wer trägt das Risiko von gemeinsamen Entscheidungen? Und: Wer bekommt welchen Anteil am gemeinsamen Erfolg? “Wenn ein gemeinsames Verständnis hergestellt werden kann, wie die kooperative Führung wirklich gemeint ist, dann überwiegen klar die Vorteile”, ist Möllering überzeugt. Wichtig sei auch, dass eine echte Beteiligung an der Führung möglich ist. Also nicht am Ende doch wieder einer alles alleine entscheide. Doch lässt sich ein solcher kooperativer Führungsstil erlernen? “Es gibt eine Menge Kompetenzen, die erlernt werden können”, sagt Martin Michaelis auf die Frage, ob sich kooperatives Führen erlernen lässt. Dabei unterscheidet er zwischen Methoden und Verhalten, sowie Haltung. Neue Methoden und Verhaltensweisen lassen sich erlernen. Dazu zählt beispielsweise, sich selbst als Führungskraft zurückzunehmen, Mitarbeitern mehr Raum zu geben und ihnen mehr Fragen zu stellen. “Eine kooperative Haltung braucht meist etwas mehr Zeit”, so Michaelis. Je nach Person ständen oft alte Einstellungen und Glaubenssätze im Weg. Eine wichtige Erkenntnis lautet: Wer kooperativ führen möchte, muss Schritt für Schritt lernen, Vertrauen zu haben. “Eine ‘Dann mache ich das jetzt lieber selbst’-Haltung ergibt keinen Sinn”, sagt Michaelis. In einer konkreten Situation ist eine Aufgabe damit vielleicht schneller und auch besser erledigt. Aber damit nehme man seinen Mitarbeitern den Raum, zu lernen und sich weiterzuentwickeln. Und damit auch die Möglichkeit, zumindest mittelfristig mehr Verantwortung zu übernehmen. Die Bertelsmann Stiftung und das Reinhard-Mohn-Institut der Universität Witten/Herdecke haben für ihren Führungskräfte-Radar eine repräsentative Befragung unter Führungskräften in Deutschland vorgenommen. Eine Beobachtung: Wenn Home-Office zur Dauereinrichtung wird, befürchten Führungskräfte, dass der Austausch mit den Mitarbeitern mehr und mehr verloren geht und die Unternehmenskultur leidet. Viele Führungskräfte konnten ihre Mitarbeiter in Home-Office-Corona-Zeiten nicht so unterstützen, wie sie es gerne getan hätten (45,7 Prozent). Guido Möllering vom Reinhard-Mohn-Institut sagt: “Die Ausnahmesituation hat uns verschiedene Aspekte deutlicher sehen lassen als sonst”. Er nennt die folgenden drei Punkte: Führung funktioniert nur, wenn die Geführten mitspielen, also kooperativ die Impulse der Führenden aufnehmen oder konstruktiv der Führungskraft Feedback geben. Das Management kann gerade in einer Krise nicht alle Probleme alleine lösen und alle Entscheidungen alleine treffen. Notgedrungen wird mehr delegiert, pragmatisch gehandelt und sich aufeinander verlassen. Man ist im Team beim gemeinsamen, kooperativen Problemlösen mehr auf Augenhöhe. Gerade beim Führen auf Distanz (insbesondere wegen Homeoffice) merkt man deutlich, dass Führen nicht primär Kontrolle, sondern Unterstützung der Geführten bedeutet. Der Team-Gedanke verstärkt sich und die Verantwortung für das gemeinsame Ergebnis wird stärker geteilt. Übergreifend werde deutlich, wie wichtig eine solide Vertrauensbasis sei, so Möllering: “Diese baut man nicht durch hierarchische Anweisungen, sondern durch kollegiale Zusammenarbeit auf.” Im Gegensatz zu dem oft in Krisen vermuteten autoritären Führungsstil hat sich in der Corona-Pandemie nicht die lenkende Führungskraft früherer Zeiten, sondern die vermittelnde Führungskraft bewährt. Tipps zur virtuellen Mitarbeiterführung Foto: fizkes – shutterstock.com Seit der Pandemie gehört virtuelle Mitarbeiterführung zu den Standartaufgaben für jeden Vorgesetzten. Wir haben die wichtigsten Learnings aus dieser Zeit zusammengefasst. Unterschiedliche Arbeits- und Lebensumstände anerkennen Foto: Jelena Zelen – shutterstock.com Zu den größten Herausforderungen zählen die unterschiedlichen Voraussetzungen, womit Teammitglieder bei der Heimarbeit konfrontiert sind. Nicht jeder hat ausreichenden Raum für ein separates Home-Office. Dazu kommen Ablenkungen wie Kinder, Haustiere oder bei Singles ein Gefühl der Isolation. All das hat Einfluss darauf, wie und zu welchen Zeiten Mitarbeiter ihre Aufgaben am besten erledigen können. Vorgesetzte, die offen Verständnis für individuelle Situationen zeigen, schaffen die Grundlage einer vertrauensvollen Zusammenarbeit. Stress-Level steuern Foto: Rawpixel.com – shutterstock.com Permanenter Stress im Home-Office ist keine gute Voraussetzung, um kontinuierlich gute Arbeit zu leisten. Wer als Führungskraft vermittelt, dass es okay ist, nicht immer perfekt zu funktionieren, nimmt Mitarbeitern etwas den Druck in der Gewöhnung an die neue Normalität. Vielen fällt es mit dieser Gewissheit leichter, Deadlines einzuhalten und den Erwartungen zu entsprechen. Regelmäßigen Kontakt pflegen Foto: fizkes – shutterstock.com Ein tägliches Gespräch mit Chefin oder Chef – ist das nicht zu viel der Kommunikation? Nein, denn insbesondere bei der digitalen Mitarbeiterführung ist die Regelmäßigkeit des Austauschs entscheidend. Nur so lässt sich einschätzen, ob alles wie besprochen läuft und sich alle im Team den Anforderungen gewachsen fühlen. Missverständnisse und Fehler passieren – ähnlich wie im Büro – vor allem, wenn zu wenig kommuniziert wird. Neue Technologien nutzen Foto: Tada Images – shutterstock.com Nur mit Personen, zu denen man regelmäßigen Kontakt pflegt, können Beziehungen entstehen. Das funktioniert im Zeitalter des digitalen Austauschs über zahlreiche Kommunikationskanäle. Moderne Videokonferenz-Tools wie Zoom, Teams, Google Meet etc. ermöglichen eine Kommunikation von Angesicht zu Angesicht und machen sichtbar, wie es allen Teammitgliedern geht. Kommunikationsregeln festlegen Foto: patpitchaya – shutterstock.com Dezentral organisierte Teamarbeit funktioniert am effektivsten, wenn sich alle über die Grundregeln der Kommunikation einig sind. Vorgesetzte können für klare Verhältnisse sorgen, indem sie Häufigkeit, Zweck und Timing des Austauschs und die dafür priorisierten Kanäle festlegen. Videokonferenzen sind in der Regel die erste Wahl für die tägliche Gruppenbesprechung. Gerade größere Gesprächsrunden lassen sich durch simple Tricks so strukturieren, dass auch Meetings mit hoher Teilnehmerzahl geordnet und effektiv ablaufen. Wenn es um dringliche Angelegenheiten oder Nachfragen geht, sind andere Kanäle wie Instant Messaging der bessere Weg. Unified-Communications-Plattformen ermöglichen eine Vielzahl von Anwendungen und Kommunikationskanälen. Erwartungen definieren Foto: ogichobanov – shutterstock.com Oft werden beim Übergang von der klassischen Büroarbeit ins Home-Office Aufgaben innerhalb eines Teams neu verteilt oder kommen neue hinzu. Damit Mitarbeiter diese erfüllen können, muss klar sein, was genau von ihnen erwartet wird. Manchen mag es außerhalb der gewohnten Büroatmosphäre anfangs schwerfallen, Aufträge zu priorisieren. Gemeinsam kann geklärt werden, welche Aufgaben Priorität haben und zu schaffen ist. Einfach davon auszugehen, dass jeder weiß, was zu tun ist, ist kontraproduktiv. Besser ist, von Anfang an eine Feedback-Schleife zu vereinbaren, um Erwartungen anzupassen und in den bekannten Applikationen zu dokumentieren. Ein gemeinsames Ziel verfolgen Foto: Rawpixel.com – shutterstock.com Teams funktionieren vor allem dann, wenn alle Mitglieder eine gemeinsame Mission verfolgen. Das dabei entstehende Gemeinschaftsgefühl hilft auch, Unsicherheiten zu überwinden und mit ungewohnten Arbeitssituationen umzugehen. Wenn jeder weiß, was er zum gemeinsamen Erfolg beiträgt, ist das die beste Motivation, Höchstleistungen zu erbringen. Erfolge sollten außerdem gewürdigt werden. Auf die Ergebnisse konzentrieren Foto: everything possible – shutterstock.com Wie lassen sich Engagement und Selbstverantwortung fördern? Indem Führungskräfte sich auf die gewünschten Ergebnisse konzentrieren und Teammitgliedern den Freiraum lassen, selbst einzuteilen, wie sie zum Ziel kommen wollen. Voraussetzung dafür ist ausreichend Zeit und zuvor aufgebautes Vertrauen. Ist das der Fall, lässt sich auf diesem Weg nicht nur die Kreativität der Mitarbeiter fördern, sondern auch kräftezehrendes Mikromanagement vermeiden. Virtuelle Brainstorms lassen sich beispielsweise in Breakout-Räume aufteilen. Kleinere Teams können dadurch in separaten Sitzungen arbeiten und ihre Ideen sammeln, die anschließend in der größeren Runde präsentiert werden. Strikte Kontrollmechanismen vermeiden Foto: ibreakstock – shutterstock.com Regelmäßige Kommunikation und klare Zielvorgaben sind wichtig. Sie dürfen aber nicht dazu führen, dass Mitarbeiter das Gefühl bekommen, im Home-Office überwacht zu werden. Vorgesetzte, die mehrmals täglich penible Rückmeldungen zu erledigten Arbeitsschritten einfordern, signalisieren damit fehlendes Vertrauen. Sie riskieren zudem, dass Teams den Fokus verlieren. Beratung und Betreuung sind besser als strikte Kontrolle. Neue Team-Mitglieder integrieren Foto: iQoncept – shutterstock.com Als neues Mitglied in ein dezentral arbeitendes Team zu kommen, kann zur Herausforderung werden, weil sich die Dynamik einer Gruppe anfangs schwerer erspüren lässt. Umso wichtiger ist es, Neulingen zu Beginn ihrer Tätigkeit das Gefühl zu geben, Teil der Gruppe zu sein. Unternehmen, die bereits über längere Erfahrung in dezentralem Arbeiten verfügen, haben dies zum festen Bestandteil ihres Onboardings gemacht. Das Wir-Gefühl stärken Foto: Girts Ragelis – shutterstock.com Selbst in gut funktionierenden Arbeitsumfeldern kann es gelegentlich zu Unsicherheiten, Unzufriedenheit oder Ängsten der Mitarbeiter kommen. Die Aufgabe von Führungskräften besteht darin, Teams davor zu schützen. Das gelingt am besten, wenn auch die sozialen Aspekte der gemeinsamen Arbeit berücksichtigt werden. Dafür braucht es keine verpflichtenden gemeinsamen Kaffeepausen, aber von Zeit zu Zeit die Gelegenheit für einen lockeren Austausch, der Mitarbeitern das Gefühl gibt, trotz der Distanz wahrgenommen zu werden. Virtuell lässt sich der Teamgeist auch fördern, wenn zur Abwechslung mal eine Happy Hour, ein virtuelles Quizzen oder ein gemeinsames Essen per Videochat organisiert wird.",
    "source": "cio",
    "crawled_at": "2025-05-28T09:16:54.986999+00:00"
  },
  {
    "url": "https://www.cio.de/article/3995672/putin-will-westliche-it-firmen-in-russland-ausbremsen.html",
    "title": "Putin will westliche IT-Firmen in Russland ausbremsen",
    "published": "2025-05-27T07:49:13+00:00",
    "author": "",
    "text": "Asatur Yesayants – shutterstock.com Kremlchef Wladimir Putin will die Dienstleistungen aus Russland fortgegangener westlicher IT-Konzerne im Land sperren. «Man muss sie drosseln», sagte Putin bei einer Besprechung mit russischen Unternehmern. Er sage dies ohne jede Verlegenheit. Der Westen wolle Russland strangulieren, also müsse man Gleiches mit Gleichem vergelten, forderte der 72-Jährige. Auch anderen Branchen versprach er Protektionsmaßnahmen. Vorausgegangen war die Klage eines russischen IT-Managers über Milliardenverluste für einheimische Technologieunternehmen. Die Branche leide darunter, dass Russen weiter vielfach auf Zoom oder Microsoft setzten. Putin versprach, die Bürger «von ihren schlechten Angewohnheiten zu befreien». Virtuelle ausländische Handelsplattformen kritisierte Putin zudem als «Loch», über die alles Mögliche nach Russland eingeführt werde. Russland hat bereits jetzt, die Netzgeschwindigkeit vieler ausländischer Online-Dienste gedrosselt. So können Russen YouTube ohne virtuelles privates Netzwerk (VPN) praktisch nicht mehr nutzen, da Videos zu lange laden. Russland baut parallel dazu die Videoplattform RUTube auf. Facebook oder Instagram sind seit Kriegsbeginn ebenfalls als extremistisch eingestuft und daher gesperrt. Die Behörden haben auch viele große VPN-Anbieter bereits blockiert, damit die Russen nicht auf Umwegen unkontrolliert im Netz surfen. (dpa/ad) Asatur Yesayants – shutterstock.com Kremlchef Wladimir Putin will die Dienstleistungen aus Russland fortgegangener westlicher IT-Konzerne im Land sperren. «Man muss sie drosseln», sagte Putin bei einer Besprechung mit russischen Unternehmern. Er sage dies ohne jede Verlegenheit. Der Westen wolle Russland strangulieren, also müsse man Gleiches mit Gleichem vergelten, forderte der 72-Jährige. Auch anderen Branchen versprach er Protektionsmaßnahmen. Vorausgegangen war die Klage eines russischen IT-Managers über Milliardenverluste für einheimische Technologieunternehmen. Die Branche leide darunter, dass Russen weiter vielfach auf Zoom oder Microsoft setzten. Putin versprach, die Bürger «von ihren schlechten Angewohnheiten zu befreien». Virtuelle ausländische Handelsplattformen kritisierte Putin zudem als «Loch», über die alles Mögliche nach Russland eingeführt werde. Russland hat bereits jetzt, die Netzgeschwindigkeit vieler ausländischer Online-Dienste gedrosselt. So können Russen YouTube ohne virtuelles privates Netzwerk (VPN) praktisch nicht mehr nutzen, da Videos zu lange laden. Russland baut parallel dazu die Videoplattform RUTube auf. Facebook oder Instagram sind seit Kriegsbeginn ebenfalls als extremistisch eingestuft und daher gesperrt. Die Behörden haben auch viele große VPN-Anbieter bereits blockiert, damit die Russen nicht auf Umwegen unkontrolliert im Netz surfen. (dpa/ad)",
    "source": "cio",
    "crawled_at": "2025-05-28T09:16:55.026663+00:00"
  },
  {
    "url": "https://www.cio.de/article/3995683/meta-startet-ki-training-in-deutschland.html",
    "title": "Meta startet KI-Training in Deutschland",
    "published": "2025-05-27T07:54:32+00:00",
    "author": "",
    "text": "Algi Febri Sugita – shutterstock.com Der Facebook-Konzern Meta kann ab sofort in großem Stil damit beginnen, seine Systeme mit Künstlicher Intelligenz mit Nutzerdaten aus Deutschland zu trainieren. Das US-Unternehmen will dazu alle Beiträge, die Nutzer jemals auf Facebook oder Instagram gepostet haben, auslesen, um damit seine KI-Modelle zu verbessern. Kunden konnten dieser Nutzung aktiv widersprechen. Die Widerspruchsfrist war allerdings in der Nacht zum Dienstag ausgelaufen. WhatsApp gehört ebenfalls zu Meta, die Chat-Inhalte sind aber verschlüsselt – der Konzern kann sie deshalb nicht verwenden. Allerdings gelten Chats mit dem KI-Assistenten «Meta AI» als öffentlich und können ebenfalls für das Training genutzt werden. Zuvor waren Verbraucherschützer aus Deutschland mit ihrem Versuch gescheitert, die Verwendung der Daten für das KI-Training gerichtlich untersagen zu lassen. Das Oberlandesgericht Köln entschied am vergangenen Freitag in einem Eilverfahren, dass Meta Nutzerbeiträge aus Facebook und Instagram für das Training seiner KI-Software Meta AI verwenden darf (Az. 15 UKl 2/25). Geklagt hatte die Verbraucherzentrale Nordrhein-Westfalen. Sie begründete ihren Antrag auf Erlass einer einstweiligen Anordnung unter anderem mit einem Verstoß gegen europäisches Datenschutzrecht. Meta betonte nach der Urteilsverkündung, dass mit dem Verfahren zum KI-Training keine Datenschutz-Bestimmungen verletzt würden. «Wir sind verpflichtet, Deutsch-trainierte KI in die Hände der deutschen Bevölkerung zu bringen und sicherzustellen, dass jeder in Europa gleichberechtigten Zugang zu den vollen Vorteilen der generativen KI hat», sagte ein Meta-Sprecher. Meta kann bislang im KI-Wettbewerb mit den Marktführern nicht mithalten. Bei einer aktuellen Umfrage des deutschen Digital-Branchenverbandes Bitkom zur Nutzung von KI-Anwendungen durch die Menschen in Deutschland lagen die Konkurrenten OpenAI (ChatGPT) mit 43 Prozent, Microsoft (CoPilot) mit 39 Prozent und Google (Gemini) mit 28 Prozent weit vorn. In der Liste der meistgenutzten KI-Anwendungen tauchte das KI-Sprachmodell Llama von Meta überhaupt nicht auf. Meta hatte Llama 2023 als quell-offenes System (Open Source) vorgestellt und in der Fachwelt für große Aufmerksamkeit gesorgt. Inzwischen sind aber etliche Experten der Meinung, dass Meta mit dem Tempo der drei US-Marktführer nicht mehr mithalten kann. Sie sehen selbst bei chinesischen Herausforderern wie DeepSeek eine größere Dynamik. (dpa/ad) Algi Febri Sugita – shutterstock.com Der Facebook-Konzern Meta kann ab sofort in großem Stil damit beginnen, seine Systeme mit Künstlicher Intelligenz mit Nutzerdaten aus Deutschland zu trainieren. Das US-Unternehmen will dazu alle Beiträge, die Nutzer jemals auf Facebook oder Instagram gepostet haben, auslesen, um damit seine KI-Modelle zu verbessern. Kunden konnten dieser Nutzung aktiv widersprechen. Die Widerspruchsfrist war allerdings in der Nacht zum Dienstag ausgelaufen. WhatsApp gehört ebenfalls zu Meta, die Chat-Inhalte sind aber verschlüsselt – der Konzern kann sie deshalb nicht verwenden. Allerdings gelten Chats mit dem KI-Assistenten «Meta AI» als öffentlich und können ebenfalls für das Training genutzt werden. Zuvor waren Verbraucherschützer aus Deutschland mit ihrem Versuch gescheitert, die Verwendung der Daten für das KI-Training gerichtlich untersagen zu lassen. Das Oberlandesgericht Köln entschied am vergangenen Freitag in einem Eilverfahren, dass Meta Nutzerbeiträge aus Facebook und Instagram für das Training seiner KI-Software Meta AI verwenden darf (Az. 15 UKl 2/25). Geklagt hatte die Verbraucherzentrale Nordrhein-Westfalen. Sie begründete ihren Antrag auf Erlass einer einstweiligen Anordnung unter anderem mit einem Verstoß gegen europäisches Datenschutzrecht. Meta betonte nach der Urteilsverkündung, dass mit dem Verfahren zum KI-Training keine Datenschutz-Bestimmungen verletzt würden. «Wir sind verpflichtet, Deutsch-trainierte KI in die Hände der deutschen Bevölkerung zu bringen und sicherzustellen, dass jeder in Europa gleichberechtigten Zugang zu den vollen Vorteilen der generativen KI hat», sagte ein Meta-Sprecher. Meta kann bislang im KI-Wettbewerb mit den Marktführern nicht mithalten. Bei einer aktuellen Umfrage des deutschen Digital-Branchenverbandes Bitkom zur Nutzung von KI-Anwendungen durch die Menschen in Deutschland lagen die Konkurrenten OpenAI (ChatGPT) mit 43 Prozent, Microsoft (CoPilot) mit 39 Prozent und Google (Gemini) mit 28 Prozent weit vorn. In der Liste der meistgenutzten KI-Anwendungen tauchte das KI-Sprachmodell Llama von Meta überhaupt nicht auf. Meta hatte Llama 2023 als quell-offenes System (Open Source) vorgestellt und in der Fachwelt für große Aufmerksamkeit gesorgt. Inzwischen sind aber etliche Experten der Meinung, dass Meta mit dem Tempo der drei US-Marktführer nicht mehr mithalten kann. Sie sehen selbst bei chinesischen Herausforderern wie DeepSeek eine größere Dynamik. (dpa/ad)",
    "source": "cio",
    "crawled_at": "2025-05-28T09:16:55.066667+00:00"
  },
  {
    "url": "https://www.cio.de/article/3995695/uber-steigt-ins-kurier-geschaft-ein.html",
    "title": "Uber steigt ins Kurier-Geschäft ein",
    "published": "2025-05-27T07:59:00+00:00",
    "author": "",
    "text": "Lutsenko_Oleksandr – shutterstock.com Der Fahrtenvermittler und Essenslieferant Uber wird künftig in Deutschland auch den Transport von Gegenständen vermitteln. Der neue Service «Uber Courier» sei von sofort an in Berlin, Köln, München, Frankfurt,‬ Düsseldorf, Hamburg, Hannover, Stuttgart und Mannheim verfügbar, teilte das Unternehmen in Berlin mit.‬ In Großbritannien wurde der Dienst vor einer Woche eingeführt. Uber setzt bei dem neuen Kurier-Dienst auf sein bestehendes Netzwerk aus Lieferpartnern. Die Kuriere sind je nach Größe der Sendung und Entfernung entweder mit dem Fahrrad oder dem Auto unterwegs. Die verschickten Gegenstände dürfen jeweils maximal 20 Kilogramm wiegen, insgesamt allerdings nicht mehr als 60 Kilogramm. Zudem müssen sie in den Kofferraum eines Mittelklassewagens passen. Wie bei vermittelten Fahrten über die Uber-App üblich werden auch bei «Uber Courier» die Kosten vorab in der App angezeigt – diese berechnen sich anhand von Fahrtzeit und Entfernung. Nach Worten Deutschland-Chef Christoph Weigler richtet sich Uber mit der neuen Option auch an lokale‬ Kleinunternehmer, die damit bestellte Artikel schnell an Kundinnen und Kunden innerhalb der Stadt verschicken könnten. Uber sieht sich seit Markteintritt in Deutschland vor elf Jahren mit erheblichem Widerstand von Taxi-Innungen, Gewerkschaften und Teilen der Politik konfrontiert. Kritisiert werden unter anderem die Geschäftsmodelle und die Arbeitsbedingungen bei den Uber-Partnerfirmen. Besonders die Vertreter der traditionellen Taxi-Branche sehen Uber sehr kritisch. Im vergangenen Jahr öffnete Uber seine App für alle Taxiunternehmen in Deutschland, um seine Präsenz deutlich zu erweitern und sich stärker als Partner der Taxi-Branche zu positionieren. In Städten wie Berlin kooperieren nach Angaben von Uber inzwischen rund 20 Prozent aller Taxis mit Uber, deutschlandweit sind es über 4.000 Taxifahrer. (dpa/ad) Lutsenko_Oleksandr – shutterstock.com Der Fahrtenvermittler und Essenslieferant Uber wird künftig in Deutschland auch den Transport von Gegenständen vermitteln. Der neue Service «Uber Courier» sei von sofort an in Berlin, Köln, München, Frankfurt,‬ Düsseldorf, Hamburg, Hannover, Stuttgart und Mannheim verfügbar, teilte das Unternehmen in Berlin mit.‬ In Großbritannien wurde der Dienst vor einer Woche eingeführt. Uber setzt bei dem neuen Kurier-Dienst auf sein bestehendes Netzwerk aus Lieferpartnern. Die Kuriere sind je nach Größe der Sendung und Entfernung entweder mit dem Fahrrad oder dem Auto unterwegs. Die verschickten Gegenstände dürfen jeweils maximal 20 Kilogramm wiegen, insgesamt allerdings nicht mehr als 60 Kilogramm. Zudem müssen sie in den Kofferraum eines Mittelklassewagens passen. Wie bei vermittelten Fahrten über die Uber-App üblich werden auch bei «Uber Courier» die Kosten vorab in der App angezeigt – diese berechnen sich anhand von Fahrtzeit und Entfernung. Nach Worten Deutschland-Chef Christoph Weigler richtet sich Uber mit der neuen Option auch an lokale‬ Kleinunternehmer, die damit bestellte Artikel schnell an Kundinnen und Kunden innerhalb der Stadt verschicken könnten. Uber sieht sich seit Markteintritt in Deutschland vor elf Jahren mit erheblichem Widerstand von Taxi-Innungen, Gewerkschaften und Teilen der Politik konfrontiert. Kritisiert werden unter anderem die Geschäftsmodelle und die Arbeitsbedingungen bei den Uber-Partnerfirmen. Besonders die Vertreter der traditionellen Taxi-Branche sehen Uber sehr kritisch. Im vergangenen Jahr öffnete Uber seine App für alle Taxiunternehmen in Deutschland, um seine Präsenz deutlich zu erweitern und sich stärker als Partner der Taxi-Branche zu positionieren. In Städten wie Berlin kooperieren nach Angaben von Uber inzwischen rund 20 Prozent aller Taxis mit Uber, deutschlandweit sind es über 4.000 Taxifahrer. (dpa/ad)",
    "source": "cio",
    "crawled_at": "2025-05-28T09:16:55.106147+00:00"
  },
  {
    "url": "https://www.cio.de/article/3685723/mit-diesen-powerpoint-tipps-ist-ihre-praesentation-up-to-date.html",
    "title": "Mit diesen Powerpoint-Tipps ist Ihre Präsentation up-to-date",
    "published": "2025-05-28T03:30:33+00:00",
    "author": "",
    "text": "Seit einiger Zeit waren große Bilder in Powerpoint Gang und Gäbe. Doch Trends ändern sich. Jetzt wird verstärkt mit Worten gearbeitet. Text darf und soll alleine stehen, ohne Ablenkung durch Bilder, auffällige Hintergründe, Rahmen oder Linien. Mit der Typografie spielen darf man dagegen schon. Besondere Schriftarten abseits von Times New Roman und Arial, Hervorhebungen durch Farbe oder unterschiedliche Schriftgrößen stellen das Wichtigste in den Mittelpunkt: den Inhalt. Wem gefällt schon die immer gleiche, unrealistische Scheinwelt der Stockfotos? Bisher lächelten händeschüttelnde Chefs, Mitarbeiterinnen in frisch gebügelten Blusen oder Einkaufstüten schwingende Kunden von den Slides. Wenn schon Bilder zum Einsatz kommen, dann individuelle, vielleicht sogar selbst fotografierte Bilder. Es muss nicht alles perfekt aussehen, sondern authentisch und sympathisch wirken. Dies gelingt beispielsweise, wenn Sie “echte” Mitarbeiter in ihrem Arbeitsumfeld fotografieren. So können sich Ihre Zuschauer viel besser mit den Inhalten identifizieren und lernen Ihr Unternehmen auf ganz neue Art und Weise kennen. Was kommt wie bei meinem Publikum an? Denken Sie bei Ihrer Präsentation immer an Ihre Zuhörer. Foto: Zita – shutterstock.com Aufgeräumt, individuell, clean, wenig Inhalt, selbst gemacht – dies gilt nicht nur für Fotos, sondern auch für Icons, Illustrationen und andere eingebundene Medien. Verabschieden Sie sich von unnötigen Linien, Kästen und Logos, sie lenken nur vom Wesentlichen ab. Auch inhaltlich sollte der Verlauf Ihrer Präsentation einen roten Faden haben, den Sie beim Vortrag ohne Umwege verfolgen. Ein bewusstes Mixen von Stilarten ist nicht nur erlaubt, sondern ab sofort ein Muss. Aber Achtung, es sollte trotzdem alles zusammenpassen. Dafür braucht es wie in der Mode ein gewisses Stilgefühl: Man kann beispielsweise selbstgezeichnete bunte Figuren mit einer geometrischen Anordnung von Textkästen und einer schlichten Schrift ohne Serifen mixen, braucht dann aber eine gemeinsame Linie wie beispielsweise die gleiche Grundfarbe. Der neueste Schrei in Powerpoint: Cinemagramme, also leicht bewegte Bilder und Animationen auf statischem Hintergrund. Man kann sie mit den Animationsmöglichkeiten in Powerpoint herstellen und Abläufe verdeutlichen, indem sich komplexere Diagramme, grafische Darstellungen von Vorgängen oder Organigramme Schritt für Schritt aufbauen lassen. Damit lässt sich Aufmerksamkeit erzeugen, ohne dass es übertrieben wirkt oder ablenkt. Augmented Reality wird bei komplexen Produkten eine wichtige Rolle übernehmen. Bauteile, Autos, Medizintechnik oder auch Architektur-Entwürfe kann man sich zur besseren Vorstellung in 3D anschauen. Große Überschrift, drei bis fünf Bullet Points und noch ein nettes Bild daneben. Nun, es geht besser. Foto: stockfour – shutterstock.com Mehr ist mehr? Nein, auch bei Präsentationen bewahrheitet sich immer wieder das Sprichwort “Weniger ist mehr”. Nicht jede Information, die Sie vermitteln wollen, muss auf den Folien stehen. Vergessen Sie nicht, dass Sie als Vortragender im Mittelpunkt stehen, nicht Ihre Präsentation. Diese soll lediglich die wichtigsten Zahlen und Fakten hervorheben. Dazu reicht es auch mal, wenn nur ein einziges Wort auf der Folie steht – der Rest folgt dann über die Tonspur. Sie wollen Zeit sparen und erstellen Präsentationen, die Sie als ausgedruckt gleich als Handout verwenden? Lassen Sie das, im besten Fall haben Sie dann ein toll gestaltetes Handout, aber eine schlechte Vortragspräsentation. Diese sollte im Gegensatz zum Handout schnell und einfach erfassbar sein, die Kernaussagen klar in den Fokus stellen und eine eventuelle Entscheidung gut vorbereiten. Zuviel Content verwirrt und Ihre Zuhörer schweifen ab. Das Handout dagegen sollte Erinnerungen festigen und Detailfragen klären. Verzichten Sie auf einen unkontrollierten Farbenmix, Ihr Corporate Design ist keine Demokratie, sondern eine berechtigte Vorgabe, um Ihr Unternehmen einheitlich nach innen und außen zu präsentieren. Mehr als zwei bis drei verschiedene Farben wirken unruhig und verhindern, dass die Präsentation wie aus einem Guss wirkt. Es flirrt und flattert und jede Animation, die Powerpoint bietet, wird ausprobiert? Ein absolutes No-go, das Sie unbedingt vermeiden sollten. Die Augen Ihrer Zuhörer freuen sich! Seit einiger Zeit waren große Bilder in Powerpoint Gang und Gäbe. Doch Trends ändern sich. Jetzt wird verstärkt mit Worten gearbeitet. Text darf und soll alleine stehen, ohne Ablenkung durch Bilder, auffällige Hintergründe, Rahmen oder Linien. Mit der Typografie spielen darf man dagegen schon. Besondere Schriftarten abseits von Times New Roman und Arial, Hervorhebungen durch Farbe oder unterschiedliche Schriftgrößen stellen das Wichtigste in den Mittelpunkt: den Inhalt. Wem gefällt schon die immer gleiche, unrealistische Scheinwelt der Stockfotos? Bisher lächelten händeschüttelnde Chefs, Mitarbeiterinnen in frisch gebügelten Blusen oder Einkaufstüten schwingende Kunden von den Slides. Wenn schon Bilder zum Einsatz kommen, dann individuelle, vielleicht sogar selbst fotografierte Bilder. Es muss nicht alles perfekt aussehen, sondern authentisch und sympathisch wirken. Dies gelingt beispielsweise, wenn Sie “echte” Mitarbeiter in ihrem Arbeitsumfeld fotografieren. So können sich Ihre Zuschauer viel besser mit den Inhalten identifizieren und lernen Ihr Unternehmen auf ganz neue Art und Weise kennen. Was kommt wie bei meinem Publikum an? Denken Sie bei Ihrer Präsentation immer an Ihre Zuhörer. Foto: Zita – shutterstock.com Aufgeräumt, individuell, clean, wenig Inhalt, selbst gemacht – dies gilt nicht nur für Fotos, sondern auch für Icons, Illustrationen und andere eingebundene Medien. Verabschieden Sie sich von unnötigen Linien, Kästen und Logos, sie lenken nur vom Wesentlichen ab. Auch inhaltlich sollte der Verlauf Ihrer Präsentation einen roten Faden haben, den Sie beim Vortrag ohne Umwege verfolgen. Ein bewusstes Mixen von Stilarten ist nicht nur erlaubt, sondern ab sofort ein Muss. Aber Achtung, es sollte trotzdem alles zusammenpassen. Dafür braucht es wie in der Mode ein gewisses Stilgefühl: Man kann beispielsweise selbstgezeichnete bunte Figuren mit einer geometrischen Anordnung von Textkästen und einer schlichten Schrift ohne Serifen mixen, braucht dann aber eine gemeinsame Linie wie beispielsweise die gleiche Grundfarbe. Der neueste Schrei in Powerpoint: Cinemagramme, also leicht bewegte Bilder und Animationen auf statischem Hintergrund. Man kann sie mit den Animationsmöglichkeiten in Powerpoint herstellen und Abläufe verdeutlichen, indem sich komplexere Diagramme, grafische Darstellungen von Vorgängen oder Organigramme Schritt für Schritt aufbauen lassen. Damit lässt sich Aufmerksamkeit erzeugen, ohne dass es übertrieben wirkt oder ablenkt. Augmented Reality wird bei komplexen Produkten eine wichtige Rolle übernehmen. Bauteile, Autos, Medizintechnik oder auch Architektur-Entwürfe kann man sich zur besseren Vorstellung in 3D anschauen. Große Überschrift, drei bis fünf Bullet Points und noch ein nettes Bild daneben. Nun, es geht besser. Foto: stockfour – shutterstock.com Mehr ist mehr? Nein, auch bei Präsentationen bewahrheitet sich immer wieder das Sprichwort “Weniger ist mehr”. Nicht jede Information, die Sie vermitteln wollen, muss auf den Folien stehen. Vergessen Sie nicht, dass Sie als Vortragender im Mittelpunkt stehen, nicht Ihre Präsentation. Diese soll lediglich die wichtigsten Zahlen und Fakten hervorheben. Dazu reicht es auch mal, wenn nur ein einziges Wort auf der Folie steht – der Rest folgt dann über die Tonspur. Sie wollen Zeit sparen und erstellen Präsentationen, die Sie als ausgedruckt gleich als Handout verwenden? Lassen Sie das, im besten Fall haben Sie dann ein toll gestaltetes Handout, aber eine schlechte Vortragspräsentation. Diese sollte im Gegensatz zum Handout schnell und einfach erfassbar sein, die Kernaussagen klar in den Fokus stellen und eine eventuelle Entscheidung gut vorbereiten. Zuviel Content verwirrt und Ihre Zuhörer schweifen ab. Das Handout dagegen sollte Erinnerungen festigen und Detailfragen klären. Verzichten Sie auf einen unkontrollierten Farbenmix, Ihr Corporate Design ist keine Demokratie, sondern eine berechtigte Vorgabe, um Ihr Unternehmen einheitlich nach innen und außen zu präsentieren. Mehr als zwei bis drei verschiedene Farben wirken unruhig und verhindern, dass die Präsentation wie aus einem Guss wirkt. Es flirrt und flattert und jede Animation, die Powerpoint bietet, wird ausprobiert? Ein absolutes No-go, das Sie unbedingt vermeiden sollten. Die Augen Ihrer Zuhörer freuen sich!",
    "source": "cio",
    "crawled_at": "2025-05-28T09:16:55.224047+00:00"
  },
  {
    "url": "https://www.cio.de/article/3994153/adelholzener-profitiert-von-effizientem-endpoint-management.html",
    "title": "Adelholzener profitiert von effizientem Endpoint-Management",
    "published": "2025-05-28T04:13:00+00:00",
    "author": "",
    "text": "Robert Ruidl – shutterstock.com Die Adelholzener Alpenquellen GmbH mit Sitz in Bad Adelholzen in Oberbayern ist einer der führenden Mineralbrunnen Deutschlands. Das Unternehmen füllt jährlich rund 700 Millionen Flaschen Mineralwasser und Erfrischungsgetränke ab. Abonnieren Sie unsere CIO-Newsletter für mehr spannende Best Practices, Case Studies und Hintergründe aus der CIO-Community. Seit 1907 ist die GmbH im Besitz der Kongregation der Barmherzigen Schwestern vom heiligen Vinzenz von Paul. Gewinne des Unternehmens fließen in soziale und karitative Projekte der Ordensgemeinschaft. Als Lebensmittelhersteller muss das Unternehmen die Vorgaben der KRITIS-Verordnung (Kritische Infrastruktur) erfüllen. Diese sehen beispielsweise erhöhte Anforderungen an die IT-Sicherheit, Verfügbarkeit und Ausfallsicherheit vor. Dasselbe gilt für die Zugangskontrolle und das Identity Management. Für die Umsetzung dieser Anforderungen ist bei Adelholzener ein zwölfköpfiges Team unter dem IT-Leiter Thorsten Caus zuständig. Das Team verwaltet am Hauptsitz des Getränkeproduzenten rund 700 Windows-Clients, 140 Server und 300 Mobilgeräte. Es handelt sich hauptsächlich um Laptops und Desktop-PCs, aber auch Industrie-Tablets. Den Rahmen bildet eine Microsoft-Umgebung mit Windows-Servern, Windows-11-Clients, Microsoft 365 sowie Microsoft Dynamics Business Central als ERP-Lösung. Als IT-Managementsystem setzte Adelholzener bislang DSM von Ivanti ein. Als der Anbieter die Software abkündigte, war eine neue Lösung erforderlich. “Neben der Abkündigung gab es zahlreiche Gründe, den Einsatz von Ivanti DSM zu überdenken”, erläutert Bernhard Buchner, IT-Experte bei Adelholzener. “Wir hatten nicht nur die Software-Verteilung von Ivanti im Einsatz, sondern auch das Ticket-System. Bei beiden Produkten vermissten wir ein Consulting des Partners auf Augenhöhe. Außerdem mussten die Ivanti-Lizenzen für das Patch-Management verlängert werden. Generell passte das Produkt von Ivanti nicht optimal zu uns.” Zunächst erstellen die IT-Fachleute einen detaillierten Anforderungskatalog. Er umfasste die Inventarisierung und das Software-Deployment und zwar sowohl die Installation von Betriebssystemen als auch die Paketierung. Außerdem waren eine Configuration Management Database (CMDB) und ein ITILv4-konformes Ticket-System erforderlich. Bernhard Buchner ist IT-Experte bei Adelholzener. Adelholzener Alpenquellen “Über unsere Münchner Kollegen der Kongregation der Barmherzigen Schwestern, zu denen Adelholzener gehört, wurden wir dann auf Baramundi aufmerksam gemacht. Dort fanden wir für all unsere Anforderungen das passende Produkt”, so Buchner. Zunächst implementierte Adelholzener die Inventarisierungssoftware und das Ticketing-System. Schrittweise fügte das IT-Team weitere Komponenten von Baramundi hinzu. “Nachfolgend bauten wir ein OS-Install- und Patch-Management auf und lösen damit in einer Migrationsphase die Paketierung von DSM ab”, schildert Buchner die Vorgehensweise. “Als KRITIS-Unternehmen reizen wir vor allem das Ticket-System vollumfänglich aus”, ergänzt Buchner. “Wir bilden darin das klassische Incident- und Service-Request-Management ab, haben eine Asset-Datenbank aufgebaut und dokumentieren dort auch Abhängigkeiten. Außerdem stellen wir hier genehmigungspflichtige IT-Services bereit.” Außerdem nutzt der Getränkehersteller die Inventarisierung und setzt Neugeräte mit den OS-Install- und Deployment-Funktionen auf. Die Baramundi Management Suite ermöglicht es Unternehmen, Endpoints zentral zu verwalten, entweder über ein LAN oder das Internet. Updates lassen sich auf Smartphones, Tablets und Notebooks überspielen, auch wenn sich diese außerhalb des Unternehmens befinden. Baramundi Die erste große Bewährungsprobe der neuen IT-Managementumgebung war ein KRITIS-Audit. Dabei wurden die CMDB, das Ticket-System und die Inventarisierung geprüft – “ohne eine einzige abweichende Feststellung hinsichtlich der Arbeitsweise im IT-Team und der Abbildung von Prozessen mit Baramundi”, betont Buchner. Als weitere Vorteile der neuen Lösung führt er die höhere Effizienz an, vor allem die Zeitersparnis sowie die höhere Performance der IT-Abteilung dank der zentralen Verwaltung von Hard- und Software. Nicht nur mir der Technik von Baramundi ist das IT-Team von Adelholzener zufrieden, auch mit der Betreuung durch den Anbieter: “Wir stellen eine Anforderung; das Team von Baramundi findet in der Regel eine Lösung – auch für schwierige Herausforderungen”, sagt Bernhard Buchner. Sein Fazit: “Wir fühlen uns professionell aufgehoben, das Team dahinter überzeugt mit Kompetenz und wir bewegen uns auf Augenhöhe. Die Zusammenarbeit mit Baramundi macht Spaß.” Adelholzener | Endpoint-Management Branche : Nahrungsmittel Use Case : Ticketing-System; Inventarisierung und Verwaltung von Hard- und Software Lösung : Baramundi Management Suite Partner : Baramundi Robert Ruidl – shutterstock.com Die Adelholzener Alpenquellen GmbH mit Sitz in Bad Adelholzen in Oberbayern ist einer der führenden Mineralbrunnen Deutschlands. Das Unternehmen füllt jährlich rund 700 Millionen Flaschen Mineralwasser und Erfrischungsgetränke ab. Abonnieren Sie unsere CIO-Newsletter für mehr spannende Best Practices, Case Studies und Hintergründe aus der CIO-Community. Seit 1907 ist die GmbH im Besitz der Kongregation der Barmherzigen Schwestern vom heiligen Vinzenz von Paul. Gewinne des Unternehmens fließen in soziale und karitative Projekte der Ordensgemeinschaft. Als Lebensmittelhersteller muss das Unternehmen die Vorgaben der KRITIS-Verordnung (Kritische Infrastruktur) erfüllen. Diese sehen beispielsweise erhöhte Anforderungen an die IT-Sicherheit, Verfügbarkeit und Ausfallsicherheit vor. Dasselbe gilt für die Zugangskontrolle und das Identity Management. Für die Umsetzung dieser Anforderungen ist bei Adelholzener ein zwölfköpfiges Team unter dem IT-Leiter Thorsten Caus zuständig. Das Team verwaltet am Hauptsitz des Getränkeproduzenten rund 700 Windows-Clients, 140 Server und 300 Mobilgeräte. Es handelt sich hauptsächlich um Laptops und Desktop-PCs, aber auch Industrie-Tablets. Den Rahmen bildet eine Microsoft-Umgebung mit Windows-Servern, Windows-11-Clients, Microsoft 365 sowie Microsoft Dynamics Business Central als ERP-Lösung. Als IT-Managementsystem setzte Adelholzener bislang DSM von Ivanti ein. Als der Anbieter die Software abkündigte, war eine neue Lösung erforderlich. “Neben der Abkündigung gab es zahlreiche Gründe, den Einsatz von Ivanti DSM zu überdenken”, erläutert Bernhard Buchner, IT-Experte bei Adelholzener. “Wir hatten nicht nur die Software-Verteilung von Ivanti im Einsatz, sondern auch das Ticket-System. Bei beiden Produkten vermissten wir ein Consulting des Partners auf Augenhöhe. Außerdem mussten die Ivanti-Lizenzen für das Patch-Management verlängert werden. Generell passte das Produkt von Ivanti nicht optimal zu uns.” Zunächst erstellen die IT-Fachleute einen detaillierten Anforderungskatalog. Er umfasste die Inventarisierung und das Software-Deployment und zwar sowohl die Installation von Betriebssystemen als auch die Paketierung. Außerdem waren eine Configuration Management Database (CMDB) und ein ITILv4-konformes Ticket-System erforderlich. Bernhard Buchner ist IT-Experte bei Adelholzener. Adelholzener Alpenquellen “Über unsere Münchner Kollegen der Kongregation der Barmherzigen Schwestern, zu denen Adelholzener gehört, wurden wir dann auf Baramundi aufmerksam gemacht. Dort fanden wir für all unsere Anforderungen das passende Produkt”, so Buchner. Zunächst implementierte Adelholzener die Inventarisierungssoftware und das Ticketing-System. Schrittweise fügte das IT-Team weitere Komponenten von Baramundi hinzu. “Nachfolgend bauten wir ein OS-Install- und Patch-Management auf und lösen damit in einer Migrationsphase die Paketierung von DSM ab”, schildert Buchner die Vorgehensweise. “Als KRITIS-Unternehmen reizen wir vor allem das Ticket-System vollumfänglich aus”, ergänzt Buchner. “Wir bilden darin das klassische Incident- und Service-Request-Management ab, haben eine Asset-Datenbank aufgebaut und dokumentieren dort auch Abhängigkeiten. Außerdem stellen wir hier genehmigungspflichtige IT-Services bereit.” Außerdem nutzt der Getränkehersteller die Inventarisierung und setzt Neugeräte mit den OS-Install- und Deployment-Funktionen auf. Die Baramundi Management Suite ermöglicht es Unternehmen, Endpoints zentral zu verwalten, entweder über ein LAN oder das Internet. Updates lassen sich auf Smartphones, Tablets und Notebooks überspielen, auch wenn sich diese außerhalb des Unternehmens befinden. Baramundi Die erste große Bewährungsprobe der neuen IT-Managementumgebung war ein KRITIS-Audit. Dabei wurden die CMDB, das Ticket-System und die Inventarisierung geprüft – “ohne eine einzige abweichende Feststellung hinsichtlich der Arbeitsweise im IT-Team und der Abbildung von Prozessen mit Baramundi”, betont Buchner. Als weitere Vorteile der neuen Lösung führt er die höhere Effizienz an, vor allem die Zeitersparnis sowie die höhere Performance der IT-Abteilung dank der zentralen Verwaltung von Hard- und Software. Nicht nur mir der Technik von Baramundi ist das IT-Team von Adelholzener zufrieden, auch mit der Betreuung durch den Anbieter: “Wir stellen eine Anforderung; das Team von Baramundi findet in der Regel eine Lösung – auch für schwierige Herausforderungen”, sagt Bernhard Buchner. Sein Fazit: “Wir fühlen uns professionell aufgehoben, das Team dahinter überzeugt mit Kompetenz und wir bewegen uns auf Augenhöhe. Die Zusammenarbeit mit Baramundi macht Spaß.” Adelholzener | Endpoint-Management Branche : Nahrungsmittel Use Case : Ticketing-System; Inventarisierung und Verwaltung von Hard- und Software Lösung : Baramundi Management Suite Partner : Baramundi",
    "source": "cio",
    "crawled_at": "2025-05-28T09:16:55.264165+00:00"
  },
  {
    "url": "https://www.cio.de/article/3991900/t-systems-ceo-im-interview-digitale-faehigkeiten-auch-selbst-nutzen.html",
    "title": "T-Systems-CEO im Interview: Digitale Fähigkeiten auch selbst nutzen",
    "published": "2025-05-28T05:11:00+00:00",
    "author": "",
    "text": "Deutsche Telekom Angesichts der veränderten geopolitischen Rahmenbedingungen ist die Digitale Souveränität derzeit ein heißes Thema – gerade in Deutschland. Wie positioniert sich T-Systems in diesem relevanten Feld? Ferri Abolhassan: Unser Konzernchef Tim Höttges betont immer wieder, dass wir mit unserem einzigartigen KI- und Cloud-Know-how ein sehr wichtiger Differenzierer für die Telekom sind. Denn diese Zukunftstechnologien gewinnen mehr und mehr an Bedeutung. Damit steigt auch unsere Bedeutung für den Konzern kontinuierlich. Digitale Souveränität spielt dabei eine große Rolle. Unsere Kunden verlangen inzwischen verstärkt danach. Angesichts der Diskussionen um KI-Rechenzentren sind wir mit unserem Angebot also genau richtig positioniert. Und das heißt konkret? Ferri Abolhassan: Wir waren einer der Pioniere im Bereich Cloud und Rechenzentren und verfügen daher auch über eine langjährige, branchenumfassende Expertise. Jetzt, wo die Anwender großen Wert auf die Hoheit über ihre eigenen Daten legen, sind wir bestens darauf vorbereitet und sehen hier einen wachsenden Markt für uns. Unsere Open Telekom Cloud (OTC) und die darauf entwickelte Open Sovereign Cloud (OSC) sind Beispiele für souveräne Angebote. Mit unserer Future Cloud Infrastructure (FCI) bieten wir darüber hinaus eine sichere Lösung mit Zero Downtime. Wir sind ein Verfechter souveräner Lösungen. Allerdings glaube ich auch an die Vielfalt und die Wahlmöglichkeiten, die man den Kunden bieten sollte. Deshalb bin ich auch Fürsprecher eines Multi-Cloud -Ansatzes, solange dieser souverän, sicher und qualitativ hochwertig ist. Ja, aber neben ihren eigenen souveränen Cloud-Diensten bieten Sie auch die Lösungen der US-Hyperscaler an. Wie passt das zusammen? Ferri Abolhassan: Uns ist es heute zu wenig, nur ein Treuhänder für die Angebote anderer zu sein. Wir wollen den Anwendern ganzheitliche Lösungen anbieten, die ihre Geschäftsprozesse sicher und umfassend unterstützen. Wenn die Kunden dies wünschen, bieten wir auch die Lösungen von Hyperscalern an. Der Weg führt daher mittelfristig über hybride und Multi-Cloud-Modelle. Dann liegen unkritische Workloads bei Hyperscalern, die sensiblen Daten und Workloads hingegen in souveränen europäischen Clouds. Wir als T-Systems glauben aber, dass Datenhoheit und Souveränität zunehmend an Bedeutung gewinnen. Und hier kommen unsere eigenen Plattformen wie OTC (Open Telekom Cloud), OSC (Open Sovereign Cloud) und FCI (Future Cloud Infrastructure) mit all ihren Dimensionen ins Spiel: Vom Rechenzentrum über die Hardware und das Betriebsmodell bis hin zur Software. Zudem helfen wir den Anwendern beim Wechsel zwischen verschiedenen Cloud-Welten. Von Ihnen ist der Satz überliefert, dass Sie bei den Themen, bei denen Sie sich engagieren, die Nummer Eins sein wollen. Wie wollen Sie hierzulande die Dominanz der Hyperscaler in Sachen Rechenzentren brechen? Ferri Abolhassan: Darüber, dass wir mehr Data-Center-Kapazität brauchen, sind wir uns beide vollkommen einig. Das ist überhaupt kein Thema. Die Frage ist nur, wie schnell können wir liefern. Auch wenn aktuell noch ein Großteil der Rechenleistung von US-Hyperscalern bereitgestellt wird, das wird sich verändern. Dazu muss man allerdings anfangen, Kapazitäten aufzubauen, sonst kann man nicht liefern. Wir betreiben das Geschäft seit 20 Jahren und investieren seitdem kontinuierlich in Data Center. Und wir planen weitere hohe Investitionen in Rechenzentren. Bereits jetzt haben wir 400 Megawatt an Rechenleistung im Netz. Die geplanten Ausbauten und Neubauten werden uns in den Gigawattbereich führen. Das ist ein fortlaufender Prozess, bei dem wir nicht bei null anfangen. Deutsche Telekom Welche Rahmenbedingungen oder regulatorischen Maßnahmen wünschen Sie sich, um diesen Ausbau weiter voranzutreiben? Ferri Abolhassan: Ein wichtiger Faktor sind sicherlich die Energiekosten. Unterstützung braucht die Branche zudem bei den Genehmigungsprozessen, auch wenn wir beispielsweise die Genehmigung bekommen haben, unseren RZ-Standort Biere weiterauszubauen. Noch entscheidender ist jedoch, dass sich die politisch Verantwortlichen in Deutschland auch zur Nachfrage nach nationaler, souveräner Rechenleistung bekennen. Es kann nicht sein, dass ich als Staat mit Hinweis auf die digitale Souveränität, Data-Center-Investitionen fordere, mich dieser aber nicht bediene. Stichwort “Verwaltungsdigitalisierung und Staatsmodernisierung”. Hier sehe ich den Staat unter dem Stichwort Ankerkunde gefordert. Wir entwickeln unsere digitalen Fähigkeiten nur, wenn wir diese auch selbst nutzen. Und kommt der Staat diesem Ansinnen nach? Ferri Abolhassan: Wir führen hierzu gute Gespräche. Aber es ist noch nicht die Denke vorhanden, die es bräuchte. Andere Länder, insbesondere die USA tun sich hier leichter, die sagen einfach „America first“. Verstehen Sie mich nicht falsch, ich bin nicht derjenige, der sagt „Germany first“. Aber Europa darf hier zur Stärkung des Binnenmarktes auch an sich denken, wenn es um die öffentliche, also steuerfinanzierte Vergabe von IT-Diensten geht. In Brüssel und auch in der neuen Bundesregierung nehme ich Verständnis hierfür wahr. Cloud und Rechenzentren sind ja nur zwei Aspekte der Digitalen Souveränität. Noch viel größer ist doch unsere Abhängigkeit beim Zukunftsthema KI? Ferri Abolhassan: Nein, denken Sie nur an das Projekt OpenGPT-X als deutschen Beitrag zur Digitalen Souveränität Europas in Sachen GenAI-Modelle. So entstand etwa mit dem Opensource-LLM Teuken-7B eine Alternative zu den US-amerikanischen KI-Sprachmodellen. Wir offerieren dieses Modell im Rahmen unserer AI Foundation Services . Teuken-7B wurde unter anderem mit den 24 Amtssprachen der EU trainiert und richtet sich an Unternehmen und Behörden. Wir sehen uns hier als erster Anbieter für solche europäischen KI-Sprachmodelle mit über sieben Milliarden Parametern. Daher auch der Zusatz 7B für 7 Billions. Sie erwähnen das KI-Angebot von T-Systems. Wie gehen Sie intern mit dem Thema KI um? Ferri Abolhassan: „Use what you sell“ lautet eines unserer Prinzipien. Wir haben eine umfangreiche KI-Expertise aufgebaut und setzen KI intern in verschiedenen Bereichen ein. Dazu gehören intelligente Chatbots, Frontend-Assistenten und Predictive Analytics im Kundenservice. Auch das lernende Netz der Telekom nutzt KI zur Optimierung der Netzkapazität. Zudem haben wir ein Kompetenzcenter im Konzern etabliert, das alle KI-Aktivitäten bündelt. Ein konkretes Produkt ist unser AI Engineer, der zeigt, wie KI bei der Code-Erstellung, -Modernisierung und im Testing unterstützen kann. Unser AI Engineer verkürzt den Entwicklungsprozess von 6 Monaten auf wenige Minuten – Testing und Bereitstellung inklusive. Ein kurzer Prompt in natürlicher Sprache genügt. Auch der AI Engineer ist Bestandteil unserer AI Foundation Services. Ferner fördern wir sowohl dedizierte Schulungen als auch das experimentelle Ausprobieren neuer KI-Tools durch unsere Mitarbeitenden. Unser Ziel ist es, dass alle unsere Beschäftigten KI als ein nützliches Werkzeug verstehen und es aktiv in ihrer Arbeit einsetzen können. Apropos KI und Mitarbeiter. Wie sehen Sie das Verhältnis zwischen Mensch und KI in Zukunft? Wird der Mensch in vielen Bereichen ersetzt werden? Ferri Abolhassan: KI verändert gerade unsere Welt und ist aus keinem Bereich mehr wegzudenken. Das Potenzial von Künstlicher Intelligenz ist riesig. Richtig eingesetzt sorgt sie branchenübergreifend für mehr Kreativität, Produktivität und Effizienz. Darum ist es so wichtig, dass alle schnellstmöglich lernen, mit dieser disruptiven Technologie umzugehen. KI eröffnet uns Menschen neue Möglichkeiten, um besser zu forschen, zu entwickeln, zu dokumentieren und zu administrieren. Ich bin überzeugt: Der Mensch wird weiterhin den Unterschied machen, aber KI kann uns in vielen Bereichen einen erheblichen Mehrwert biete – wenn wir sie sinnvoll und verantwortungsbewusst einsetzen. Wenn ich den aktuellen Stand der KI-Adaption in Deutschland betrachte, dann scheint sich diese Erkenntnis noch nicht weit durchgesetzt zu haben. Wie schätzen Sie die aktuelle Nutzung von KI in deutschen Unternehmen ein und wo sehen Sie die größten Chancen? Ferri Abolhassan: Es ist richtig, ältere Zahlen sprachen von einer eher geringen Nutzung. Allerdings zeigt eine aktuellere Bitkom-Studie, dass bereits 42 Prozent der Unternehmen KI in der Produktion einsetzen. Ein weiteres Drittel hat entsprechende Planungen. Beispiele hierfür sind die Überwachung von Maschinen, die intelligente Steuerung von Robotern und die Optimierung des Energieverbrauchs. Trotz dieser positiven Entwicklung sehen wir weiterhin erhebliches Potenzial und Chancen für den Einsatz von KI in Unternehmen. Unser Ansatz ist es, Unternehmen konkrete Anwendungsfälle aufzuzeigen, wie sie KI gewinnbringend einsetzen können und Ihnen bei Bedarf auch beim Einsatz zu helfen. Deutsche Telekom Könnten Sie uns einige konkrete Beispiele für diese Anwendungsfälle nennen? Ferri Abolhassan: Ja, unser Fokus liegt auf dem konkreten Nutzen für die Anwender. Wir sehen Möglichkeiten in der verbesserten Patientenversorgung im Krankenhaus, in Fortschritten in der Krebsforschung. Ein anderes Feld ist die Optimierung von Logistikprozessen in der Automobilindustrie. Es geht darum, praktische Arbeits- und Problemstellungen von Unternehmen mit Automatisierung und KI zu lösen. Zum Beispiel können wir in einem Krankenhaus die Wundversorgung verbessern, indem die Nachdokumentation und Vorbereitung direkt am Patientenbett mit KI-Unterstützung erfolgt. In der Automobilindustrie können wir beispielsweise helfen, die Logistik ganzer Flotten zu optimieren oder die Qualitätskontrolle in der Produktion durch KI-gestützte Anomalie-Erkennung zu verbessern. Das klingt durchaus vielversprechend, aber sind uns andere Länder wie China nicht weit voraus? Ferri Abolhassan: China ist in der Tat ein ernstzunehmender Wettbewerber. Um hier aufzuholen, ist es wichtig, dass wir unsere Aversion gegenüber neuen Technologien ablegen. Wir haben immer noch eine Menge Ideen “Made in Germany”. Aber wir müssen einen Weg des “Machens” einschlagen. Es bedarf konkreter Angebote und der Unterstützung der Unternehmen bei der Implementierung von KI-Lösungen. Wir müssen weg von der reinen Theorie hin zur praktischen Anwendung. Dazu zählt für mich auch, den Unternehmen einen konkreten Nutzen zu bieten. Ein ganz anderes Thema. Sie sind jetzt seit fast anderthalb Jahren CEO der T-Systems. Wo steht das Unternehmen heute, es war ja lange Zeit ein Sorgenkind der Telekom? Ferri Abolhassan: Ab Ende 2023 haben wir als Team die richtigen Prioritäten gesetzt: Den Kunden in den Mittelpunkt. Fokus auf Qualität und Resilienz. Ein wettbewerbsfähiges Portfolio. Einen integrierten Marktangang. So haben wir unseren Wachstumskurs erfolgreich ausgebaut. Heute sind wir, das kann man schon sagen, in stabilem Fahrwasser. Deutsche Telekom Woran machen Sie das fest, dass Sie sich in stabilen Fahrwassern befinden? Ferri Abolhassan: Wir haben alle wichtigen Kennzahlen weiterentwickelt und wachsen inzwischen profitabel. Unseren Auftragseingang haben wir zuletzt um elf Prozent gesteigert. Das ist ein wichtiger Indikator für zukünftiges Geschäft. Unser Umsatz ist um 2,8 Prozent gestiegen. Und in dieser Größenordnung wollen wir weiterwachsen. Das EBITDA, sprich, unser Ergebnis vor Zinsen, Steuern und Abschreibungen, haben wir sogar überproportional um 14,8 Prozent verbessert. Aber damit stehen wir erst am Anfang unserer Reise. Wir ruhen uns aus diesen Erfolgen nicht aus. Wir wollen unsere Zahlen Monat für Monat hinstellen und auch in unserem Jubiläumsjahr – wir feiern 25 Jahre T-Systems – weiter profitabel wachsen. Und wie ist es um das Standing einer T-Systems im Markt bestellt? Ferri Abolhassan: Wir haben eine ganze Menge an Vertriebserfolgen erzielt. Im Moment sind wir im B2B-Markt in Europa die Nummer Zwei, in der DACH-Region die Nummer Eins. Kunden wie AOK, KMD oder Daimler Truck schenken uns ihr Vertrauen, um nur einige zu nennen. Letztlich kommen unsere Kunden aus allen Branchen, aus Automotive, Public, Health, Finance, Transport & Logistics und Manufacturing. Als wir beide vor einem Jahr miteinander sprachen, sagte ich Ihnen, dass wir ganz klar auf das Thema Qualität setzen werden. Dazu sind wir noch mal den Dreiklang von People, Process, Platform angegangen – der Grundlage von Zero Outage. Wir haben unsere Mitarbeitenden weiter geschult und sensibilisiert, bessere, stabilere Prozesse eingeführt, und unsere Plattformen noch ausfallsicherer gemacht. Damit sind wir jetzt in Sachen Stabilität und Ausfallsicherheit gut unterwegs und konnten das auch gegenüber unseren Kunden beweisen. Deutsche Telekom Angesichts der veränderten geopolitischen Rahmenbedingungen ist die Digitale Souveränität derzeit ein heißes Thema – gerade in Deutschland. Wie positioniert sich T-Systems in diesem relevanten Feld? Ferri Abolhassan: Unser Konzernchef Tim Höttges betont immer wieder, dass wir mit unserem einzigartigen KI- und Cloud-Know-how ein sehr wichtiger Differenzierer für die Telekom sind. Denn diese Zukunftstechnologien gewinnen mehr und mehr an Bedeutung. Damit steigt auch unsere Bedeutung für den Konzern kontinuierlich. Digitale Souveränität spielt dabei eine große Rolle. Unsere Kunden verlangen inzwischen verstärkt danach. Angesichts der Diskussionen um KI-Rechenzentren sind wir mit unserem Angebot also genau richtig positioniert. Und das heißt konkret? Ferri Abolhassan: Wir waren einer der Pioniere im Bereich Cloud und Rechenzentren und verfügen daher auch über eine langjährige, branchenumfassende Expertise. Jetzt, wo die Anwender großen Wert auf die Hoheit über ihre eigenen Daten legen, sind wir bestens darauf vorbereitet und sehen hier einen wachsenden Markt für uns. Unsere Open Telekom Cloud (OTC) und die darauf entwickelte Open Sovereign Cloud (OSC) sind Beispiele für souveräne Angebote. Mit unserer Future Cloud Infrastructure (FCI) bieten wir darüber hinaus eine sichere Lösung mit Zero Downtime. Wir sind ein Verfechter souveräner Lösungen. Allerdings glaube ich auch an die Vielfalt und die Wahlmöglichkeiten, die man den Kunden bieten sollte. Deshalb bin ich auch Fürsprecher eines Multi-Cloud -Ansatzes, solange dieser souverän, sicher und qualitativ hochwertig ist. Ja, aber neben ihren eigenen souveränen Cloud-Diensten bieten Sie auch die Lösungen der US-Hyperscaler an. Wie passt das zusammen? Ferri Abolhassan: Uns ist es heute zu wenig, nur ein Treuhänder für die Angebote anderer zu sein. Wir wollen den Anwendern ganzheitliche Lösungen anbieten, die ihre Geschäftsprozesse sicher und umfassend unterstützen. Wenn die Kunden dies wünschen, bieten wir auch die Lösungen von Hyperscalern an. Der Weg führt daher mittelfristig über hybride und Multi-Cloud-Modelle. Dann liegen unkritische Workloads bei Hyperscalern, die sensiblen Daten und Workloads hingegen in souveränen europäischen Clouds. Wir als T-Systems glauben aber, dass Datenhoheit und Souveränität zunehmend an Bedeutung gewinnen. Und hier kommen unsere eigenen Plattformen wie OTC (Open Telekom Cloud), OSC (Open Sovereign Cloud) und FCI (Future Cloud Infrastructure) mit all ihren Dimensionen ins Spiel: Vom Rechenzentrum über die Hardware und das Betriebsmodell bis hin zur Software. Zudem helfen wir den Anwendern beim Wechsel zwischen verschiedenen Cloud-Welten. Von Ihnen ist der Satz überliefert, dass Sie bei den Themen, bei denen Sie sich engagieren, die Nummer Eins sein wollen. Wie wollen Sie hierzulande die Dominanz der Hyperscaler in Sachen Rechenzentren brechen? Ferri Abolhassan: Darüber, dass wir mehr Data-Center-Kapazität brauchen, sind wir uns beide vollkommen einig. Das ist überhaupt kein Thema. Die Frage ist nur, wie schnell können wir liefern. Auch wenn aktuell noch ein Großteil der Rechenleistung von US-Hyperscalern bereitgestellt wird, das wird sich verändern. Dazu muss man allerdings anfangen, Kapazitäten aufzubauen, sonst kann man nicht liefern. Wir betreiben das Geschäft seit 20 Jahren und investieren seitdem kontinuierlich in Data Center. Und wir planen weitere hohe Investitionen in Rechenzentren. Bereits jetzt haben wir 400 Megawatt an Rechenleistung im Netz. Die geplanten Ausbauten und Neubauten werden uns in den Gigawattbereich führen. Das ist ein fortlaufender Prozess, bei dem wir nicht bei null anfangen. Deutsche Telekom Welche Rahmenbedingungen oder regulatorischen Maßnahmen wünschen Sie sich, um diesen Ausbau weiter voranzutreiben? Ferri Abolhassan: Ein wichtiger Faktor sind sicherlich die Energiekosten. Unterstützung braucht die Branche zudem bei den Genehmigungsprozessen, auch wenn wir beispielsweise die Genehmigung bekommen haben, unseren RZ-Standort Biere weiterauszubauen. Noch entscheidender ist jedoch, dass sich die politisch Verantwortlichen in Deutschland auch zur Nachfrage nach nationaler, souveräner Rechenleistung bekennen. Es kann nicht sein, dass ich als Staat mit Hinweis auf die digitale Souveränität, Data-Center-Investitionen fordere, mich dieser aber nicht bediene. Stichwort “Verwaltungsdigitalisierung und Staatsmodernisierung”. Hier sehe ich den Staat unter dem Stichwort Ankerkunde gefordert. Wir entwickeln unsere digitalen Fähigkeiten nur, wenn wir diese auch selbst nutzen. Und kommt der Staat diesem Ansinnen nach? Ferri Abolhassan: Wir führen hierzu gute Gespräche. Aber es ist noch nicht die Denke vorhanden, die es bräuchte. Andere Länder, insbesondere die USA tun sich hier leichter, die sagen einfach „America first“. Verstehen Sie mich nicht falsch, ich bin nicht derjenige, der sagt „Germany first“. Aber Europa darf hier zur Stärkung des Binnenmarktes auch an sich denken, wenn es um die öffentliche, also steuerfinanzierte Vergabe von IT-Diensten geht. In Brüssel und auch in der neuen Bundesregierung nehme ich Verständnis hierfür wahr. Cloud und Rechenzentren sind ja nur zwei Aspekte der Digitalen Souveränität. Noch viel größer ist doch unsere Abhängigkeit beim Zukunftsthema KI? Ferri Abolhassan: Nein, denken Sie nur an das Projekt OpenGPT-X als deutschen Beitrag zur Digitalen Souveränität Europas in Sachen GenAI-Modelle. So entstand etwa mit dem Opensource-LLM Teuken-7B eine Alternative zu den US-amerikanischen KI-Sprachmodellen. Wir offerieren dieses Modell im Rahmen unserer AI Foundation Services . Teuken-7B wurde unter anderem mit den 24 Amtssprachen der EU trainiert und richtet sich an Unternehmen und Behörden. Wir sehen uns hier als erster Anbieter für solche europäischen KI-Sprachmodelle mit über sieben Milliarden Parametern. Daher auch der Zusatz 7B für 7 Billions. Sie erwähnen das KI-Angebot von T-Systems. Wie gehen Sie intern mit dem Thema KI um? Ferri Abolhassan: „Use what you sell“ lautet eines unserer Prinzipien. Wir haben eine umfangreiche KI-Expertise aufgebaut und setzen KI intern in verschiedenen Bereichen ein. Dazu gehören intelligente Chatbots, Frontend-Assistenten und Predictive Analytics im Kundenservice. Auch das lernende Netz der Telekom nutzt KI zur Optimierung der Netzkapazität. Zudem haben wir ein Kompetenzcenter im Konzern etabliert, das alle KI-Aktivitäten bündelt. Ein konkretes Produkt ist unser AI Engineer, der zeigt, wie KI bei der Code-Erstellung, -Modernisierung und im Testing unterstützen kann. Unser AI Engineer verkürzt den Entwicklungsprozess von 6 Monaten auf wenige Minuten – Testing und Bereitstellung inklusive. Ein kurzer Prompt in natürlicher Sprache genügt. Auch der AI Engineer ist Bestandteil unserer AI Foundation Services. Ferner fördern wir sowohl dedizierte Schulungen als auch das experimentelle Ausprobieren neuer KI-Tools durch unsere Mitarbeitenden. Unser Ziel ist es, dass alle unsere Beschäftigten KI als ein nützliches Werkzeug verstehen und es aktiv in ihrer Arbeit einsetzen können. Apropos KI und Mitarbeiter. Wie sehen Sie das Verhältnis zwischen Mensch und KI in Zukunft? Wird der Mensch in vielen Bereichen ersetzt werden? Ferri Abolhassan: KI verändert gerade unsere Welt und ist aus keinem Bereich mehr wegzudenken. Das Potenzial von Künstlicher Intelligenz ist riesig. Richtig eingesetzt sorgt sie branchenübergreifend für mehr Kreativität, Produktivität und Effizienz. Darum ist es so wichtig, dass alle schnellstmöglich lernen, mit dieser disruptiven Technologie umzugehen. KI eröffnet uns Menschen neue Möglichkeiten, um besser zu forschen, zu entwickeln, zu dokumentieren und zu administrieren. Ich bin überzeugt: Der Mensch wird weiterhin den Unterschied machen, aber KI kann uns in vielen Bereichen einen erheblichen Mehrwert biete – wenn wir sie sinnvoll und verantwortungsbewusst einsetzen. Wenn ich den aktuellen Stand der KI-Adaption in Deutschland betrachte, dann scheint sich diese Erkenntnis noch nicht weit durchgesetzt zu haben. Wie schätzen Sie die aktuelle Nutzung von KI in deutschen Unternehmen ein und wo sehen Sie die größten Chancen? Ferri Abolhassan: Es ist richtig, ältere Zahlen sprachen von einer eher geringen Nutzung. Allerdings zeigt eine aktuellere Bitkom-Studie, dass bereits 42 Prozent der Unternehmen KI in der Produktion einsetzen. Ein weiteres Drittel hat entsprechende Planungen. Beispiele hierfür sind die Überwachung von Maschinen, die intelligente Steuerung von Robotern und die Optimierung des Energieverbrauchs. Trotz dieser positiven Entwicklung sehen wir weiterhin erhebliches Potenzial und Chancen für den Einsatz von KI in Unternehmen. Unser Ansatz ist es, Unternehmen konkrete Anwendungsfälle aufzuzeigen, wie sie KI gewinnbringend einsetzen können und Ihnen bei Bedarf auch beim Einsatz zu helfen. Deutsche Telekom Könnten Sie uns einige konkrete Beispiele für diese Anwendungsfälle nennen? Ferri Abolhassan: Ja, unser Fokus liegt auf dem konkreten Nutzen für die Anwender. Wir sehen Möglichkeiten in der verbesserten Patientenversorgung im Krankenhaus, in Fortschritten in der Krebsforschung. Ein anderes Feld ist die Optimierung von Logistikprozessen in der Automobilindustrie. Es geht darum, praktische Arbeits- und Problemstellungen von Unternehmen mit Automatisierung und KI zu lösen. Zum Beispiel können wir in einem Krankenhaus die Wundversorgung verbessern, indem die Nachdokumentation und Vorbereitung direkt am Patientenbett mit KI-Unterstützung erfolgt. In der Automobilindustrie können wir beispielsweise helfen, die Logistik ganzer Flotten zu optimieren oder die Qualitätskontrolle in der Produktion durch KI-gestützte Anomalie-Erkennung zu verbessern. Das klingt durchaus vielversprechend, aber sind uns andere Länder wie China nicht weit voraus? Ferri Abolhassan: China ist in der Tat ein ernstzunehmender Wettbewerber. Um hier aufzuholen, ist es wichtig, dass wir unsere Aversion gegenüber neuen Technologien ablegen. Wir haben immer noch eine Menge Ideen “Made in Germany”. Aber wir müssen einen Weg des “Machens” einschlagen. Es bedarf konkreter Angebote und der Unterstützung der Unternehmen bei der Implementierung von KI-Lösungen. Wir müssen weg von der reinen Theorie hin zur praktischen Anwendung. Dazu zählt für mich auch, den Unternehmen einen konkreten Nutzen zu bieten. Ein ganz anderes Thema. Sie sind jetzt seit fast anderthalb Jahren CEO der T-Systems. Wo steht das Unternehmen heute, es war ja lange Zeit ein Sorgenkind der Telekom? Ferri Abolhassan: Ab Ende 2023 haben wir als Team die richtigen Prioritäten gesetzt: Den Kunden in den Mittelpunkt. Fokus auf Qualität und Resilienz. Ein wettbewerbsfähiges Portfolio. Einen integrierten Marktangang. So haben wir unseren Wachstumskurs erfolgreich ausgebaut. Heute sind wir, das kann man schon sagen, in stabilem Fahrwasser. Deutsche Telekom Woran machen Sie das fest, dass Sie sich in stabilen Fahrwassern befinden? Ferri Abolhassan: Wir haben alle wichtigen Kennzahlen weiterentwickelt und wachsen inzwischen profitabel. Unseren Auftragseingang haben wir zuletzt um elf Prozent gesteigert. Das ist ein wichtiger Indikator für zukünftiges Geschäft. Unser Umsatz ist um 2,8 Prozent gestiegen. Und in dieser Größenordnung wollen wir weiterwachsen. Das EBITDA, sprich, unser Ergebnis vor Zinsen, Steuern und Abschreibungen, haben wir sogar überproportional um 14,8 Prozent verbessert. Aber damit stehen wir erst am Anfang unserer Reise. Wir ruhen uns aus diesen Erfolgen nicht aus. Wir wollen unsere Zahlen Monat für Monat hinstellen und auch in unserem Jubiläumsjahr – wir feiern 25 Jahre T-Systems – weiter profitabel wachsen. Und wie ist es um das Standing einer T-Systems im Markt bestellt? Ferri Abolhassan: Wir haben eine ganze Menge an Vertriebserfolgen erzielt. Im Moment sind wir im B2B-Markt in Europa die Nummer Zwei, in der DACH-Region die Nummer Eins. Kunden wie AOK, KMD oder Daimler Truck schenken uns ihr Vertrauen, um nur einige zu nennen. Letztlich kommen unsere Kunden aus allen Branchen, aus Automotive, Public, Health, Finance, Transport & Logistics und Manufacturing. Als wir beide vor einem Jahr miteinander sprachen, sagte ich Ihnen, dass wir ganz klar auf das Thema Qualität setzen werden. Dazu sind wir noch mal den Dreiklang von People, Process, Platform angegangen – der Grundlage von Zero Outage. Wir haben unsere Mitarbeitenden weiter geschult und sensibilisiert, bessere, stabilere Prozesse eingeführt, und unsere Plattformen noch ausfallsicherer gemacht. Damit sind wir jetzt in Sachen Stabilität und Ausfallsicherheit gut unterwegs und konnten das auch gegenüber unseren Kunden beweisen.",
    "source": "cio",
    "crawled_at": "2025-05-28T09:16:55.309389+00:00"
  },
  {
    "url": "https://www.cio.de/article/3996445/chiphersteller-tsmc-eroffnet-designzentrum-in-munchen.html",
    "title": "Chiphersteller TSMC eröffnet Designzentrum in München",
    "published": "2025-05-28T05:11:58+00:00",
    "author": "",
    "text": "Vidpen | shutterstock.com Der taiwanische Chiphersteller TSMC will ein Designzentrum für Halbleiter in München eröffnen. Eröffnet werden soll der neue Standort im dritten Quartal, dort sollen in Kooperation mit den Kunden des Konzerns Chips für Automobilindustrie und andere Branchen entwickelt werden. Das teilte Bayerns Wirtschaftsminister Hubert Aiwanger (Freie Wähler) mit. Der taiwanische Konzern zählt zu den technologisch führenden Unternehmen der Branche, bekannt unter anderem für außerordentlich dünne und damit sowohl effiziente als auch energiesparende Chips. TSMC baut derzeit auch mit mehreren Partnerunternehmen eine Fabrik bei Dresden. Aiwanger wertete die Ansiedlung des Designzentrums in München als Stärkung Bayerns in der Mikroelektronik. Die Landeshauptstadt ist unter anderem Sitz des Chipherstellers Infineon. 2021 hatte bereits der US-Konzern Apple München als Sitz seines europäischen Chip-Designzentrums gewählt. Wie viel Geld TSMC in München investiert und wie viele Menschen in dem neuen Entwicklungszentrum arbeiten sollen, teilten weder das Ministerium noch TSMC mit. (dpa/ad) Vidpen | shutterstock.com Der taiwanische Chiphersteller TSMC will ein Designzentrum für Halbleiter in München eröffnen. Eröffnet werden soll der neue Standort im dritten Quartal, dort sollen in Kooperation mit den Kunden des Konzerns Chips für Automobilindustrie und andere Branchen entwickelt werden. Das teilte Bayerns Wirtschaftsminister Hubert Aiwanger (Freie Wähler) mit. Der taiwanische Konzern zählt zu den technologisch führenden Unternehmen der Branche, bekannt unter anderem für außerordentlich dünne und damit sowohl effiziente als auch energiesparende Chips. TSMC baut derzeit auch mit mehreren Partnerunternehmen eine Fabrik bei Dresden. Aiwanger wertete die Ansiedlung des Designzentrums in München als Stärkung Bayerns in der Mikroelektronik. Die Landeshauptstadt ist unter anderem Sitz des Chipherstellers Infineon. 2021 hatte bereits der US-Konzern Apple München als Sitz seines europäischen Chip-Designzentrums gewählt. Wie viel Geld TSMC in München investiert und wie viele Menschen in dem neuen Entwicklungszentrum arbeiten sollen, teilten weder das Ministerium noch TSMC mit. (dpa/ad)",
    "source": "cio",
    "crawled_at": "2025-05-28T09:16:55.348232+00:00"
  },
  {
    "url": "https://www.cio.de/article/3685696/gehaltserhoehung-was-sie-wissen-muessen-2.html",
    "title": "Gehaltserhöhung – was Sie wissen müssen",
    "published": "2025-05-28T06:10:50+00:00",
    "author": "",
    "text": "Pavel105 – shutterstock.com Nicht nur zu Beginn einer Tätigkeit, nämlich im Vorstellungsgespräch, sondern auch nach einiger Zeit Mitarbeit steht sie an: die Gehaltsverhandlung. Für den Arbeitnehmer ist es die Chance auf eine Gehaltserhöhung, birgt aber auch die Gefahr, vom jeweiligen Vorgesetzten eine Rüge zu kassieren. Mit der richtigen Vorbereitung und Taktik jedoch lassen sich Gehaltsverhandlungen entspannt angehen. Einfach “ins Blaue hinein” an den Chef herantreten und mehr Geld fordern ist kein guter Plan. Auch darauf zu warten, bis der Vorgesetzte Ihnen mehr Geld anbietet, wird meist nicht der Schlüssel zum Erfolg sein. Daher sollten Sie sich vor einer anstehenden Gehaltsverhandlung vorbereiten. Unabdingbar für eine gute Vorbereitung ist es, sich selbst drei Fragen zu beantworten: Was will ich? Was will ich nicht? Was muss ich mindestens erreichen? Informieren Sie sich beispielsweise über übliche Gehälter in Ihrer Branche. Zudem sollten Sie Ihrem Vorgesetzten Ihre eigene Arbeitsleistung präzise darlegen können, um daraus eine realistische finanzielle Forderung ableiten zu können. Ebenfalls zur Vorbereitung gehört das richtige Timing. In Zeiten wirtschaftlicher Umbrüche oder großer Veränderungen im Unternehmen könnte die Bitte um eine Gehaltserhöhung von Ihrem Chef als aufdringlich und eigennützig eingestuft werden. Aber auch in ruhigeren Zeiten sollten Sie den Terminplan des Vorgesetzten im Auge behalten, um den passenden Moment für ein Gespräch abpassen zu können. Wenn es um eine Gehaltserhöhung geht, sollten Sie nicht mit der Tür ins Haus fallen. Sie werden am ehesten Erfolg haben, wenn Sie Ihr Anliegen mit einigen guten Argumenten untermauern können. Hierbei steht selbstverständlich Ihre aktuelle und zukünftige Arbeitsleistung im Vordergrund. Machen Sie sich Gedanken darüber, wie hoch Ihre Verantwortung im momentanen Arbeitsbereich ist. Möglicherweise haben Sie gerade ein Projekt erfolgreich abgeschlossen oder es steht eine Projektleitung an. Um Ihre Leistung darlegen zu können, schreiben Sie zum Beispiel zwei Wochen lang vor dem geplanten Gespräch auf, was Sie tagtäglich tun. Damit kann nachvollzogen werden, wie viel Sie tatsächlich leisten. Ein starkes Argument für eine Gehaltserhöhung ist Personalverantwortung. Hat sich beispielsweise Ihr Team in der letzten Zeit vergrößert oder arbeiten Sie mit neuen Mitarbeitern, sollten Sie dies anbringen. Reflektieren Sie Ihre Arbeitsleistung genau und achten Sie darauf, ob Sie oder möglicherweise eine Ihrer Ideen zu einer Umsatzsteigerung geführt hat. Wenn ja, ist dies ein gutes Argument für ein höheres Gehalt . Zudem sollten Sie den Blick nicht nur auf vergangene, sondern auch auf zukünftige Leistung richten: Steht eine große Herausforderung an die Sie meistern müssen? Wichtig bei den angebrachten Argumenten ist insbesondere Ihre innere Überzeugung. Wenn Sie authentisch auftreten und Souveränität ausstrahlen, wirkt auch ein eher schwaches Argument manchmal überzeugend. Eine Anstellung beginnt im Normalfall mit einem Einstellungsgespräch, in dem bereits das erste Mal über Gehalt verhandelt wird. Hierbei sind insbesondere Ihre Qualifikation und die Branchenüblichen Gehälter ausschlaggebend. Wer Mut hat, kann sich bereits bei den ersten Gehaltsverhandlungen die Option auf eine Gehaltserhöhung nach bestandener Probezeit im Arbeitsvertrag festschreiben lassen. Aber auch wenn dies nicht gemacht wurde, ist der Zeitpunkt nach erfolgreicher Probezeit richtig, um über eine erste Gehaltsverhandlung zu sprechen. Da meist ohnehin ein Feedbackgespräch ansteht, ist dies der optimale Zeitpunkt, um über mehr Geld zu verhandeln. Als Arbeitnehmer haben Sie innerhalb der Probezeit Ihre Kompetenz unter Beweis stellen können, und auch Ihr Arbeitgeber hatte Gelegenheit, Bilanz zu ziehen. Ist das Unternehmen mit Ihrer Leistung zufrieden, ist eine Erhöhung um bis zu 10 Prozent des Einstiegsgehalts realistisch. Heutzutage wollen Unternehmen häufig schon im Bewerbungsschreiben eine Gehaltsvorstellung lesen. Dies kann bei Bewerbern, ob Berufseinsteiger oder nicht, zu Komplikationen führen, da man sich einerseits nicht “zu billig” verkaufen will, andererseits aber die Forderungen nicht übertreiben will. Zunächst sollten Sie sich im Klaren darüber sein, was Sie beziehungsweise Ihre Leistung wert ist. Eine konkrete Zahl anzugeben, die sich beispielsweise aus dem bisherigen Gehalt plus 10 Prozent zusammensetzt, kann zwar realistisch sein, schreckt aber viele Entscheider ab. Daher empfiehlt es sich immer, eine Gehaltsspanne anzugeben, ob im Bewerbungsschreiben oder im Vorstellungsgespräch selbst. Zudem sollten Sie gute Gründe für Ihre finanzielle Forderung anführen können. Damit setzen Sie eine Untergrenze und zeigen trotzdem Verhandlungsbereitschaft und Offenheit. Wie hoch Ihre Gehaltserhöhung ausfällt, hängt stark von ihrer Leistung, der Branche in der Sie tätig sind und von Ihrem Arbeitgeber ab. Durchschnittlich können Sie drei bis fünf Prozent mehr Gehalt aushandeln. Um nach unten verhandeln zu können, sollten Sie zunächst etwa zwei Prozent mehr veranschlagen. In besonderen Fällen und bei besonderen Leistungen Ihrerseits ist aber auch deutlich mehr drin, wie beispielsweise nach der Probezeit, bei einem Jobwechsel oder wenn Sie zu einer Umsatzsteigerung des Unternehmens beigetragen haben. Und: Wenn Sie nicht den Gehaltssprung realisieren können, den Sie sich erhofft haben, machen Sie sich Gedanken über eventuelle Zusatzleistungen, die einer Gehaltserhöhung gleichkommen, wie beispielsweise mehr Zeit im Home-Office oder mehr Urlaubstage. Unabdingbar für ein erfolgreiches Gehaltsgespräch ist es, dass Sie selbstbewusst, aber nicht überheblich auftreten. Souveränität und Authentizität können überzeugender sein als auswendig gelernte Standardargumente. Zudem sollten Sie signalisieren, dass Sie Ihr fachliches Know-How und besondere Leistungen auch in der Zukunft zum Wohle des Unternehmens einbringen wollen. Worauf Sie jedoch verzichten sollten, sind Vergleiche. Etwa mit dem Gehalt des Kollegen zu argumentieren oder ein Konkurrenzangebot vorzulegen, sind keine guten Ideen. Pavel105 – shutterstock.com Nicht nur zu Beginn einer Tätigkeit, nämlich im Vorstellungsgespräch, sondern auch nach einiger Zeit Mitarbeit steht sie an: die Gehaltsverhandlung. Für den Arbeitnehmer ist es die Chance auf eine Gehaltserhöhung, birgt aber auch die Gefahr, vom jeweiligen Vorgesetzten eine Rüge zu kassieren. Mit der richtigen Vorbereitung und Taktik jedoch lassen sich Gehaltsverhandlungen entspannt angehen. Einfach “ins Blaue hinein” an den Chef herantreten und mehr Geld fordern ist kein guter Plan. Auch darauf zu warten, bis der Vorgesetzte Ihnen mehr Geld anbietet, wird meist nicht der Schlüssel zum Erfolg sein. Daher sollten Sie sich vor einer anstehenden Gehaltsverhandlung vorbereiten. Unabdingbar für eine gute Vorbereitung ist es, sich selbst drei Fragen zu beantworten: Was will ich? Was will ich nicht? Was muss ich mindestens erreichen? Informieren Sie sich beispielsweise über übliche Gehälter in Ihrer Branche. Zudem sollten Sie Ihrem Vorgesetzten Ihre eigene Arbeitsleistung präzise darlegen können, um daraus eine realistische finanzielle Forderung ableiten zu können. Ebenfalls zur Vorbereitung gehört das richtige Timing. In Zeiten wirtschaftlicher Umbrüche oder großer Veränderungen im Unternehmen könnte die Bitte um eine Gehaltserhöhung von Ihrem Chef als aufdringlich und eigennützig eingestuft werden. Aber auch in ruhigeren Zeiten sollten Sie den Terminplan des Vorgesetzten im Auge behalten, um den passenden Moment für ein Gespräch abpassen zu können. Wenn es um eine Gehaltserhöhung geht, sollten Sie nicht mit der Tür ins Haus fallen. Sie werden am ehesten Erfolg haben, wenn Sie Ihr Anliegen mit einigen guten Argumenten untermauern können. Hierbei steht selbstverständlich Ihre aktuelle und zukünftige Arbeitsleistung im Vordergrund. Machen Sie sich Gedanken darüber, wie hoch Ihre Verantwortung im momentanen Arbeitsbereich ist. Möglicherweise haben Sie gerade ein Projekt erfolgreich abgeschlossen oder es steht eine Projektleitung an. Um Ihre Leistung darlegen zu können, schreiben Sie zum Beispiel zwei Wochen lang vor dem geplanten Gespräch auf, was Sie tagtäglich tun. Damit kann nachvollzogen werden, wie viel Sie tatsächlich leisten. Ein starkes Argument für eine Gehaltserhöhung ist Personalverantwortung. Hat sich beispielsweise Ihr Team in der letzten Zeit vergrößert oder arbeiten Sie mit neuen Mitarbeitern, sollten Sie dies anbringen. Reflektieren Sie Ihre Arbeitsleistung genau und achten Sie darauf, ob Sie oder möglicherweise eine Ihrer Ideen zu einer Umsatzsteigerung geführt hat. Wenn ja, ist dies ein gutes Argument für ein höheres Gehalt . Zudem sollten Sie den Blick nicht nur auf vergangene, sondern auch auf zukünftige Leistung richten: Steht eine große Herausforderung an die Sie meistern müssen? Wichtig bei den angebrachten Argumenten ist insbesondere Ihre innere Überzeugung. Wenn Sie authentisch auftreten und Souveränität ausstrahlen, wirkt auch ein eher schwaches Argument manchmal überzeugend. Eine Anstellung beginnt im Normalfall mit einem Einstellungsgespräch, in dem bereits das erste Mal über Gehalt verhandelt wird. Hierbei sind insbesondere Ihre Qualifikation und die Branchenüblichen Gehälter ausschlaggebend. Wer Mut hat, kann sich bereits bei den ersten Gehaltsverhandlungen die Option auf eine Gehaltserhöhung nach bestandener Probezeit im Arbeitsvertrag festschreiben lassen. Aber auch wenn dies nicht gemacht wurde, ist der Zeitpunkt nach erfolgreicher Probezeit richtig, um über eine erste Gehaltsverhandlung zu sprechen. Da meist ohnehin ein Feedbackgespräch ansteht, ist dies der optimale Zeitpunkt, um über mehr Geld zu verhandeln. Als Arbeitnehmer haben Sie innerhalb der Probezeit Ihre Kompetenz unter Beweis stellen können, und auch Ihr Arbeitgeber hatte Gelegenheit, Bilanz zu ziehen. Ist das Unternehmen mit Ihrer Leistung zufrieden, ist eine Erhöhung um bis zu 10 Prozent des Einstiegsgehalts realistisch. Heutzutage wollen Unternehmen häufig schon im Bewerbungsschreiben eine Gehaltsvorstellung lesen. Dies kann bei Bewerbern, ob Berufseinsteiger oder nicht, zu Komplikationen führen, da man sich einerseits nicht “zu billig” verkaufen will, andererseits aber die Forderungen nicht übertreiben will. Zunächst sollten Sie sich im Klaren darüber sein, was Sie beziehungsweise Ihre Leistung wert ist. Eine konkrete Zahl anzugeben, die sich beispielsweise aus dem bisherigen Gehalt plus 10 Prozent zusammensetzt, kann zwar realistisch sein, schreckt aber viele Entscheider ab. Daher empfiehlt es sich immer, eine Gehaltsspanne anzugeben, ob im Bewerbungsschreiben oder im Vorstellungsgespräch selbst. Zudem sollten Sie gute Gründe für Ihre finanzielle Forderung anführen können. Damit setzen Sie eine Untergrenze und zeigen trotzdem Verhandlungsbereitschaft und Offenheit. Wie hoch Ihre Gehaltserhöhung ausfällt, hängt stark von ihrer Leistung, der Branche in der Sie tätig sind und von Ihrem Arbeitgeber ab. Durchschnittlich können Sie drei bis fünf Prozent mehr Gehalt aushandeln. Um nach unten verhandeln zu können, sollten Sie zunächst etwa zwei Prozent mehr veranschlagen. In besonderen Fällen und bei besonderen Leistungen Ihrerseits ist aber auch deutlich mehr drin, wie beispielsweise nach der Probezeit, bei einem Jobwechsel oder wenn Sie zu einer Umsatzsteigerung des Unternehmens beigetragen haben. Und: Wenn Sie nicht den Gehaltssprung realisieren können, den Sie sich erhofft haben, machen Sie sich Gedanken über eventuelle Zusatzleistungen, die einer Gehaltserhöhung gleichkommen, wie beispielsweise mehr Zeit im Home-Office oder mehr Urlaubstage. Unabdingbar für ein erfolgreiches Gehaltsgespräch ist es, dass Sie selbstbewusst, aber nicht überheblich auftreten. Souveränität und Authentizität können überzeugender sein als auswendig gelernte Standardargumente. Zudem sollten Sie signalisieren, dass Sie Ihr fachliches Know-How und besondere Leistungen auch in der Zukunft zum Wohle des Unternehmens einbringen wollen. Worauf Sie jedoch verzichten sollten, sind Vergleiche. Etwa mit dem Gehalt des Kollegen zu argumentieren oder ein Konkurrenzangebot vorzulegen, sind keine guten Ideen.",
    "source": "cio",
    "crawled_at": "2025-05-28T09:16:55.389994+00:00"
  },
  {
    "url": "https://www.cio.de/article/3996710/kalte-und-wenig-wind-sorgen-fur-hoheren-energieverbrauch.html",
    "title": "Kälte und wenig Wind sorgen für höheren Energieverbrauch",
    "published": "2025-05-28T07:32:44+00:00",
    "author": "",
    "text": "Dmitry-Arhangel 29 – shutterstock.com Der Energieverbrauch in Deutschland ist in den ersten drei Monaten im Vergleich zum Vorjahreszeitraum deutlich gestiegen. Ein wichtiger Grund war das Wetter: Es war kälter und es wehte weniger Wind. Das teilte die Arbeitsgemeinschaft Energiebilanzen (AGEB) in Berlin mit. Die kühlen Temperaturen – vor allem im Februar – sorgten dafür, dass mehr geheizt werden musste. Und wegen des windarmen und trockenen Wetters wurde weniger Strom aus Wind- und Wasserkraft erzeugt. Dafür sprangen verstärkt Kraftwerke ein, die mit Kohle, Gas oder Öl betrieben werden – diese arbeiten aber weniger effizient und brauchen daher mehr Rohstoffe. Die weiterhin schwache wirtschaftliche Lage und der fehlende Schalttag in diesem Jahr dämpften aber den Verbrauch. Insgesamt stieg der Primärenergieverbrauch – also der Verbrauch aller Energien in ihrer Ursprungsform – im ersten Quartal nach vorläufigen Berechnungen der AGEB um 5,5 Prozent auf 3.151 Petajoule. Das entspricht etwa 875 Terawattstunden. Zur Einordnung: 2024 wurden in Deutschland laut Statistischem Bundesamt insgesamt 432 Terawattstunden Strom produziert und ins Netz eingespeist. Auch die unterschiedliche Preisentwicklung bei den einzelnen Energieträgern wirkte sich laut AGEB auf den Verbrauch aus. So sorgten gesunkene Einfuhrpreise für Rohöl für höhere Verbräuche im Verkehrssektor. Viele Verbraucherinnen und Verbraucher stockten zudem ihre Heizölvorräte auf. Bei der Steinkohle sorgten gesunkene Importpreise für einen verstärkten Einsatz in der Stromerzeugung. Weil mehr fossile Brennstoffe wie Kohle und Gas für die Stromerzeugung verwendet wurden, stiegen auch die energiebedingten CO2-Emissionen im Jahresvergleich um rund elf Millionen Tonnen – das entspricht einem Zuwachs von etwa sieben Prozent. (dpa/ad) Dmitry-Arhangel 29 – shutterstock.com Der Energieverbrauch in Deutschland ist in den ersten drei Monaten im Vergleich zum Vorjahreszeitraum deutlich gestiegen. Ein wichtiger Grund war das Wetter: Es war kälter und es wehte weniger Wind. Das teilte die Arbeitsgemeinschaft Energiebilanzen (AGEB) in Berlin mit. Die kühlen Temperaturen – vor allem im Februar – sorgten dafür, dass mehr geheizt werden musste. Und wegen des windarmen und trockenen Wetters wurde weniger Strom aus Wind- und Wasserkraft erzeugt. Dafür sprangen verstärkt Kraftwerke ein, die mit Kohle, Gas oder Öl betrieben werden – diese arbeiten aber weniger effizient und brauchen daher mehr Rohstoffe. Die weiterhin schwache wirtschaftliche Lage und der fehlende Schalttag in diesem Jahr dämpften aber den Verbrauch. Insgesamt stieg der Primärenergieverbrauch – also der Verbrauch aller Energien in ihrer Ursprungsform – im ersten Quartal nach vorläufigen Berechnungen der AGEB um 5,5 Prozent auf 3.151 Petajoule. Das entspricht etwa 875 Terawattstunden. Zur Einordnung: 2024 wurden in Deutschland laut Statistischem Bundesamt insgesamt 432 Terawattstunden Strom produziert und ins Netz eingespeist. Auch die unterschiedliche Preisentwicklung bei den einzelnen Energieträgern wirkte sich laut AGEB auf den Verbrauch aus. So sorgten gesunkene Einfuhrpreise für Rohöl für höhere Verbräuche im Verkehrssektor. Viele Verbraucherinnen und Verbraucher stockten zudem ihre Heizölvorräte auf. Bei der Steinkohle sorgten gesunkene Importpreise für einen verstärkten Einsatz in der Stromerzeugung. Weil mehr fossile Brennstoffe wie Kohle und Gas für die Stromerzeugung verwendet wurden, stiegen auch die energiebedingten CO2-Emissionen im Jahresvergleich um rund elf Millionen Tonnen – das entspricht einem Zuwachs von etwa sieben Prozent. (dpa/ad)",
    "source": "cio",
    "crawled_at": "2025-05-28T09:16:55.429720+00:00"
  }
]